
daily_data = {
    "date": "2024-08-23",
    "tweets": [
            {
                "startTime": "00:55",
                "arxivId": "2408.11974",
                "arxivLink": "https://arxiv.org/abs/2408.11974",
                "title": "Two-Timescale Gradient Descent: A Speed Demon for Minimax Problems!",
                "institute": "Columbia University, Princeton University, University of California Berkeley",
                "text": "This research analyzes the two-timescale gradient descent ascent (TTGDA) algorithm for nonconvex minimax optimization problems, providing nonasymptotic complexity bounds for both smooth and nonsmooth settings. This differs from previous work that focused on asymptotic analysis or specific problem structures.",
                "paper-title": "Two-Timescale Gradient Descent Ascent Algorithms for Nonconvex Minimax Optimization",
                "image-path": ""
            },

            {
                "startTime": "01:25",
                "arxivId": "2408.12418",
                "arxivLink": "https://arxiv.org/abs/2408.12418",
                "title": "Fixing Broken Images with a Confidence Boost: ODEs to the Rescue!",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research introduces a new method called Confident Ordinary Differential Editing (CODE) for image restoration. Unlike previous methods that rely on specific assumptions about the corruption or require paired training data, CODE uses a pre-trained diffusion model and a confidence-based clipping method to handle a wide range of unknown corruptions in a fully blind manner.",
                "paper-title": "CODE: Confident Ordinary Differential Editing",
                "image-path": ""
            },

            {
                "startTime": "01:51",
                "arxivId": "2408.11860",
                "arxivLink": "https://arxiv.org/abs/2408.11860",
                "title": "Recipe for Disaster? AI's Cooking Up New Risks!",
                "institute": "University of Washington",
                "text": "This research focuses on the risks of NLP systems in a specific application, procedural document question answering (ProcDocQA), rather than general AI or NLP applications. It proposes a Risk-Aware Design Questionnaire (RADQ) to guide the design of ProcDocQA systems, taking into account potential harms to users.",
                "paper-title": "Risks and NLP Design: A Case Study on Procedural Document QA",
                "image-path": ""
            },

            {
                "startTime": "02:17",
                "arxivId": "2408.11841",
                "arxivLink": "https://arxiv.org/abs/2408.11841",
                "title": "ChatGPT: College Dropout or Degree-Stealing Genius?",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research goes beyond simply testing AI assistants on individual questions. It examines the potential impact of these tools on entire university degree programs by analyzing their performance on a large dataset of assessment questions from various courses.",
                "paper-title": "Could ChatGPT get an Engineering Degree? Evaluating Higher Education Vulnerability to AI Assistants",
                "image-path": ""
            },

            {
                "startTime": "02:40",
                "arxivId": "2408.12191",
                "arxivLink": "https://arxiv.org/abs/2408.12191",
                "title": "Single-Photon Lidar Gets a Surface Makeover: Transientangelo Reconstructs 3D Scenes with Fewer Photons",
                "institute": "University of Toronto",
                "text": "This research focuses on reconstructing 3D surfaces using raw measurements from a single-photon lidar system, unlike previous methods that rely on pre-processed data like point clouds or depth maps. The paper introduces Transientangelo, a method that leverages time-resolved photon count histograms (transients) to optimize a neural surface representation of the scene.",
                "paper-title": "Transientangelo: Few-Viewpoint Surface Reconstruction Using Single-Photon Lidar",
                "image-path": ""
            },

            {
                "startTime": "03:01",
                "arxivId": "2408.12569",
                "arxivLink": "https://arxiv.org/abs/2408.12569",
                "title": "Sapiens: Human Vision Models Get a Supersized Upgrade!",
                "institute": "Meta",
                "text": "This research introduces Sapiens, a family of vision transformers pretrained on a massive dataset of 300 million human images. Unlike previous work, Sapiens focuses on human-centric tasks, achieving state-of-the-art performance in 2D pose estimation, body-part segmentation, depth estimation, and surface normal prediction.",
                "paper-title": "Sapiens: Foundation for Human Vision Models",
                "image-path": ""
            },

            {
                "startTime": "03:26",
                "arxivId": "2408.11853",
                "arxivLink": "https://arxiv.org/abs/2408.11853",
                "title": "Pythonizing Marian: Speeding Up Machine Translation with a Dash of Pybind11",
                "institute": "Microsoft, University of Maryland",
                "text": "This research introduces PyMarian, a Python interface for Marian NMT, a C++-based toolkit for machine translation. This interface allows models trained with Marian to be used with Python's extensive libraries and tools.",
                "paper-title": "PyMarian: Fast Neural Machine Translation and Evaluation in Python",
                "image-path": ""
            },

            {
                "startTime": "03:49",
                "arxivId": "2408.12425",
                "arxivLink": "https://arxiv.org/abs/2408.12425",
                "title": "Speech Enhancement Gets a Brain Boost: New Network Makes Noise Go Quiet!",
                "institute": "University of Zurich, Meta",
                "text": "This paper introduces a Dynamic Gated Recurrent Neural Network (DG-RNN) that selectively updates neurons in a recurrent neural network (RNN) to reduce computational cost during inference. This approach differs from previous work that focused on reducing computation by limiting input updates or skipping neuron updates entirely.",
                "paper-title": "Dynamic Gated Recurrent Neural Network for Compute-efficient Speech Enhancement",
                "image-path": ""
            },

            {
                "startTime": "04:17",
                "arxivId": "2408.12171",
                "arxivLink": "https://arxiv.org/abs/2408.12171",
                "title": "AI for CFD: A Survey That Will Make You Say \"Wow!\"",
                "institute": "Peking University",
                "text": "This survey provides a novel classification for forward modeling, categorizing methods into Data-driven Surrogates, Physics-Informed Surrogates, and ML-assisted Numerical Solutions. It also offers a comprehensive discussion of inverse design and control problems, which are often overlooked in previous surveys.",
                "paper-title": "Recent Advances on Machine Learning for Computational Fluid Dynamics: A Survey",
                "image-path": ""
            },

            {
                "startTime": "04:43",
                "arxivId": "2408.12326",
                "arxivLink": "https://arxiv.org/abs/2408.12326",
                "title": "LLMs Gone Wild? New Framework Tames Hallucinations!",
                "institute": "University of Tokyo, Hokkaido University",
                "text": "This research introduces DualChecker, a framework that uses an interactive system to mitigate hallucinations in large language models (LLMs) during knowledge distillation. Unlike previous methods that rely on external knowledge or extensive training, DualChecker focuses on aligning model outputs with human standards through a dynamic feedback loop between teacher and student models.",
                "paper-title": "Interactive DualChecker for Mitigating Hallucinations in Distilling Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "05:07",
                "arxivId": "2408.12593",
                "arxivLink": "https://arxiv.org/abs/2408.12593",
                "title": "Robots Learn to Stuff Gaskets Like Pros: A Deep Dive into Deformable Assembly",
                "institute": "UC Berkeley",
                "text": "This research compares a deep imitation learning policy with three procedural algorithms for automating gasket assembly, a task that involves placing a deformable object into a rigid channel.",
                "paper-title": "Automating Deformable Gasket Assembly",
                "image-path": ""
            },

            {
                "startTime": "05:24",
                "arxivId": "2408.12429",
                "arxivLink": "https://arxiv.org/abs/2408.12429",
                "title": "Free-Shape Masks: The New Way to Edit Images with AI",
                "institute": "Chinese Academy of Sciences, Shenzhen Technology University, Georgia Institute of Technology...",
                "text": "This research introduces FlexEdit, a method for image editing that combines free-shape masks with language instructions. Unlike previous methods that require precise masks, FlexEdit allows users to draw more natural, free-form shapes, making the editing process more user-friendly.",
                "paper-title": "FlexEdit: Marrying Free-Shape Masks to VLLM for Flexible Image Editing",
                "image-path": ""
            },

            {
                "startTime": "05:49",
                "arxivId": "2408.11901",
                "arxivLink": "https://arxiv.org/abs/2408.11901",
                "title": "Quantum Neural Networks: Wishart Processes to the Rescue!",
                "institute": "Caltech",
                "text": "This paper introduces the concept of Wishart processes to analyze the training behavior of quantum neural networks (QNNs). Unlike classical neural networks, which often behave as Gaussian processes, QNNs exhibit a different statistical behavior. This work provides a unified framework for understanding the loss landscapes of QNNs, including the conditions for trainability and the distribution of local minima.",
                "paper-title": "A Unified Theory of Quantum Neural Network Loss Landscapes",
                "image-path": ""
            },

            {
                "startTime": "06:13",
                "arxivId": "2408.11982",
                "arxivLink": "https://arxiv.org/abs/2408.11982",
                "title": "AI Judges Video Quality: A New Contest for Compression Champions!",
                "institute": "Moscow State University",
                "text": "This research introduces a new dataset of compressed videos, featuring a wider range of codecs and compression artifacts than previous datasets. It also includes a new evaluation protocol that considers both prediction monotonicity and accuracy.",
                "paper-title": "AIM 2024 Challenge on Compressed Video Quality Assessment: Methods and Results",
                "image-path": ""
            },

            {
                "startTime": "06:33",
                "arxivId": "2408.11855",
                "arxivLink": "https://arxiv.org/abs/2408.11855",
                "title": "LLMs Get a Brain Makeover: FactorLLM Splits Knowledge for Speed!",
                "institute": "Peking University",
                "text": "This paper introduces FactorLLM, a method that decomposes the dense feed-forward networks (FFNs) in large language models (LLMs) into sparse sub-networks, or \"experts,\" without requiring any further modifications to the model. This approach differs from previous work by focusing on knowledge factorization within the FFN, rather than modifying the entire model architecture.",
                "paper-title": "FactorLLM: Factorizing Knowledge via Mixture of Experts for Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "07:00",
                "arxivId": "2408.12097",
                "arxivLink": "https://arxiv.org/abs/2408.12097",
                "title": "LLMs Uncover Hidden Connections in Finance Research",
                "institute": "Aichi Institute of Technology, University of Tokyo, Hokkaido University...",
                "text": "This research goes beyond simply extracting machine learning models and datasets from academic papers. It analyzes the relationships between research objectives, models, and datasets using network clustering, providing a deeper understanding of how these elements work together.",
                "paper-title": "Extraction of Research Objectives, Machine Learning Model Names, and Dataset Names from Academic Papers and Analysis of Their Interrelationships Using LLM and Network Analysis",
                "image-path": ""
            },

            {
                "startTime": "07:27",
                "arxivId": "2408.12112",
                "arxivLink": "https://arxiv.org/abs/2408.12112",
                "title": "LLMs Get Social: Balancing Act for Multi-Objective Reward Design",
                "institute": "Harvard University, Google Research India",
                "text": "This research introduces a novel Social Choice Language Model (SCLM) for designing reward functions in Restless Multi-Armed Bandits (RMABs). Unlike previous LLM-based approaches, SCLM explicitly addresses the multi-objective nature of reward design by incorporating a transparent and customizable adjudicator component.",
                "paper-title": "Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards",
                "image-path": ""
            },

            {
                "startTime": "07:51",
                "arxivId": "2408.12004",
                "arxivLink": "https://arxiv.org/abs/2408.12004",
                "title": "Safe Policy Improvement: Don't Just Guess, Test It!",
                "institute": "Cornell University, Meta, Netflix",
                "text": "This paper introduces a new approach to safe policy improvement, focusing on threshold policies. Unlike previous methods that rely on potentially underpowered safety checks, this research leverages the most powerful safety test in the asymptotic regime and allows for multiple candidates to be tested for improvement over the baseline.",
                "paper-title": "CSPI-MT: Calibrated Safe Policy Improvement with Multiple Testing for Threshold Policies",
                "image-path": ""
            },

            {
                "startTime": "08:16",
                "arxivId": "2408.12247",
                "arxivLink": "https://arxiv.org/abs/2408.12247",
                "title": "Tiny AI, Big Knowledge: How China Mobile Taught a Lightweight Model to Ace Domain-Specific Questions",
                "institute": "Nankai University, Microsoft, Tsinghua University...",
                "text": "This research proposes a novel framework called \"Self-Evolution\" that iteratively fine-tunes a lightweight language model using domain-specific knowledge documents. Unlike previous methods that rely on manually constructed instruction datasets, Self-Evolution generates its own instruction data through a self-guided process, reducing the need for human intervention.",
                "paper-title": "Efficient Multivariate Time Series Anomaly Detection Through Transfer Learning for Large-Scale Web services",
                "image-path": ""
            },

            {
                "startTime": "08:42",
                "arxivId": "2408.12186",
                "arxivLink": "https://arxiv.org/abs/2408.12186",
                "title": "Transformers Are the New Math Whizzes: How AI Learns From Just a Few Examples",
                "institute": "University of Tokyo",
                "text": "This research analyzes the effectiveness of in-context learning (ICL) in transformers, specifically focusing on a model with a deep neural network (DNN) followed by a linear attention layer. Unlike previous work that primarily focused on single-layer linear attention models, this paper incorporates the representation learning capabilities of the DNN module, providing a more realistic analysis of multi-layer transformers.",
                "paper-title": "Transformers are Minimax Optimal Nonparametric In-Context Learners",
                "image-path": ""
            },

            {
                "startTime": "09:07",
                "arxivId": "2408.11865",
                "arxivLink": "https://arxiv.org/abs/2408.11865",
                "title": "LLMs: Easily Swayed by a Good Story, Even if It's Wrong!",
                "institute": "ETH Zurich",
                "text": "This research investigates the influence of augmented inputs on LLMs in a question-answering setting. Unlike previous work focusing on self-critique or retrieval-augmented generation, this study specifically examines how LLMs respond to external information presented as arguments with explanations, exploring the impact of factors like source authority and confidence.",
                "paper-title": "How Susceptible are LLMs to Influence in Prompts?",
                "image-path": ""
            },

            {
                "startTime": "09:30",
                "arxivId": "2408.12185",
                "arxivLink": "https://arxiv.org/abs/2408.12185",
                "title": "Graph Adaptation Without the Source: A New Trick for GNNs",
                "institute": "Peking University, University of California Los Angeles, University of International Business and Economics...",
                "text": "This paper tackles the problem of source-free graph domain adaptation, where the goal is to adapt a pre-trained graph neural network (GNN) to a new domain without access to the original source data. This is different from previous work that typically requires access to source data for adaptation.",
                "paper-title": "Rank and Align: Towards Effective Source-free Graph Domain Adaptation",
                "image-path": ""
            },

            {
                "startTime": "10:04",
                "arxivId": "2408.12119",
                "arxivLink": "https://arxiv.org/abs/2408.12119",
                "title": "Data Reconstruction Attacks in Federated Learning: A Theoretical Smackdown!",
                "institute": "Illinois Institute of Technology, Nanchang University, University of Connecticut",
                "text": "This research proposes a theoretical framework to understand data reconstruction attacks in federated learning. Unlike previous work, it focuses on bounding the reconstruction error and comparing the effectiveness of different attacks based on their error bounds.",
                "paper-title": "Understanding Data Reconstruction Leakage in Federated Learning from a Theoretical Perspective",
                "image-path": ""
            },

            {
                "startTime": "10:27",
                "arxivId": "2408.12093",
                "arxivLink": "https://arxiv.org/abs/2408.12093",
                "title": "Robots Get a Room: AI Learns to Tidy Like a Human",
                "institute": "National University of Defense Technology, Shenzhen University",
                "text": "This research proposes a novel approach to household rearrangement by using a large language model (LLM) to enhance scene graphs with context-induced affordances. This differs from previous work by directly mining object functionality and user preferences from the scene itself, rather than relying on human intervention or pre-defined exemplars.",
                "paper-title": "LLM-enhanced Scene Graph Learning for Household Rearrangement",
                "image-path": ""
            },

            {
                "startTime": "11:04",
                "arxivId": "2408.12022",
                "arxivLink": "https://arxiv.org/abs/2408.12022",
                "title": "Mind-Reading Machines: How AI Deciphers What You Think",
                "institute": "Harvard University, Massachusetts Institute of Technology",
                "text": "This research introduces a new cognitive model called LaBToM, which combines Bayesian Theory of Mind (BToM) with a formal language of thought to interpret epistemic language. Unlike previous work that focuses on the semantics of epistemic language, LaBToM evaluates belief claims in context by considering the agent's actions and observations.",
                "paper-title": "Understanding Epistemic Language with a Bayesian Theory of Mind",
                "image-path": ""
            },

            {
                "startTime": "11:29",
                "arxivId": "2408.12071",
                "arxivLink": "https://arxiv.org/abs/2408.12071",
                "title": "Graph Clustering Gets a Curriculum: Entropy-Guided Learning for Better Results!",
                "institute": "Northwestern Polytechnical University, Tsinghua University",
                "text": "This research introduces a new framework called Clustering-guided Curriculum Graph contrastive Learning (CCGL). Unlike previous methods that use random data augmentation, CCGL uses clustering entropy to guide the augmentation process, ensuring that the augmented views preserve important semantic information for clustering. Additionally, CCGL employs a multi-task curriculum learning scheme, allowing the model to gradually transition from a simple discrimination task to a more complex clustering task as training progresses.",
                "paper-title": "Multi-Task Curriculum Graph Contrastive Learning with Clustering Entropy Guidance",
                "image-path": ""
            },

            {
                "startTime": "11:59",
                "arxivId": "2408.12601",
                "arxivLink": "https://arxiv.org/abs/2408.12601",
                "title": "DreamCinema: Turning You Into a Movie Mogul with AI!",
                "institute": "Tsinghua University",
                "text": "This research proposes DreamCinema, a cinematic transfer framework that uses generative AI to create films with free camera movement and 3D characters. Unlike previous work that relies on manual character creation, DreamCinema generates characters tailored to user preferences, making film production more accessible.",
                "paper-title": "DreamCinema: Cinematic Transfer with Free Camera and 3D Character",
                "image-path": ""
            },

            {
                "startTime": "12:20",
                "arxivId": "2408.11848",
                "arxivLink": "https://arxiv.org/abs/2408.11848",
                "title": "Llama-zing Radiology: A 70B Model for Accurate Reports",
                "institute": "University of Georgia, Massachusetts General Hospital, Harvard Medical School",
                "text": "This research utilizes the Llama 3 70B model, a significantly larger language model than previous radiology-focused LLMs, and trains it on a unique dataset of over 6.5 million de-identified medical reports from Massachusetts General Hospital.",
                "paper-title": "MGH Radiology Llama: A Llama 3 70B Model for Radiology",
                "image-path": ""
            },

            {
                "startTime": "12:40",
                "arxivId": "2408.12236",
                "arxivLink": "https://arxiv.org/abs/2408.12236",
                "title": "Virtual Patients Get a Makeover: AI-Powered Images Make Medical Training More Realistic",
                "institute": "Peking University, Wuhan University, Tencent",
                "text": "This research introduces MedDiT, a framework that uses knowledge graphs to control the behavior of large language models (LLMs) in virtual simulated patient (VSP) systems. This approach aims to reduce hallucinations and generate more realistic medical images aligned with patient symptoms. Unlike previous VSP systems, MedDiT dynamically generates images based on patient attributes and symptoms, providing a more interactive and diverse learning experience.",
                "paper-title": "MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for Dynamic Medical Image Generation in Virtual Simulated Patient",
                "image-path": ""
            },

            {
                "startTime": "13:08",
                "arxivId": "2408.11962",
                "arxivLink": "https://arxiv.org/abs/2408.11962",
                "title": "Monkeypox Madness: Unmasking Online Toxicity During the 2022 Outbreak",
                "institute": "University of Michigan",
                "text": "This research combines topic modeling and network analysis to understand online toxicity during the 2022 Mpox outbreak, offering a more comprehensive approach than previous studies that focused on either topic modeling or network analysis alone.",
                "paper-title": "Characterizing Online Toxicity During the 2022 Mpox Outbreak: A Computational Analysis of Topical and Network Dynamics",
                "image-path": ""
            },

            {
                "startTime": "13:30",
                "arxivId": "2408.12091",
                "arxivLink": "https://arxiv.org/abs/2408.12091",
                "title": "Unmasking the Hidden Geometry: A New Way to See the Shared and Private in Multi-View Data",
                "institute": "Johns Hopkins University, Princeton University",
                "text": "This research introduces a new method called SPLICE, which disentangles shared and private latent variables in multi-view data while preserving the intrinsic geometry of each representation. Unlike previous methods, SPLICE uses a \"crossed butterfly\" autoencoder architecture and predictability minimization to ensure that private information doesn't leak into the shared latents.",
                "paper-title": "Unsupervised discovery of the shared and private geometry in multi-view data",
                "image-path": ""
            },

            {
                "startTime": "13:57",
                "arxivId": "2408.12036",
                "arxivLink": "https://arxiv.org/abs/2408.12036",
                "title": "AI Forecasters: They're Not Just Guessing, They're Reasoning!",
                "institute": "UC Berkeley",
                "text": "This research introduces a framework called Reasoning and Tools for Forecasting (RTF) that uses a hierarchical structure of language models (LLMs) to improve forecasting accuracy. Unlike previous work that relies on fine-tuning or scratchpad prompting, RTF leverages LLMs' reasoning abilities by dynamically retrieving updated information and running numerical simulations with equipped tools.",
                "paper-title": "Reasoning and Tools for Human-Level Forecasting",
                "image-path": ""
            },

            {
                "startTime": "14:28",
                "arxivId": "2408.12578",
                "arxivLink": "https://arxiv.org/abs/2408.12578",
                "title": "Transformers Grokking Formal Languages: A Percolation Model of Emergence",
                "institute": "Harvard University, RIKEN, The University of Tokyo...",
                "text": "This research proposes a phenomenological definition for emergence in neural networks, arguing that the acquisition of specific structures underlies sudden performance improvements on multiple tasks. It then uses a formal language learning task to demonstrate this concept, identifying three phases of learning corresponding to the acquisition of grammar, relative type constraints, and descriptive type constraints. The paper further proposes a percolation model to explain the scaling of the point of emergence, where the model starts to generalize beyond memorized knowledge.",
                "paper-title": "A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language",
                "image-path": ""
            },

            {
                "startTime": "14:56",
                "arxivId": "2408.12212",
                "arxivLink": "https://arxiv.org/abs/2408.12212",
                "title": "Program Synthesis: Think Relationally, Not Functionally!",
                "institute": "University of Oxford",
                "text": "This paper introduces a novel approach to program synthesis that decomposes complex functional tasks into simpler relational sub-tasks. Unlike previous work that focuses on learning a sequence of functions, this method breaks down each input-output example into a set of facts and learns the relations between them.",
                "paper-title": "Relational decomposition for program synthesis",
                "image-path": ""
            },

            {
                "startTime": "15:18",
                "arxivId": "2408.12099",
                "arxivLink": "https://arxiv.org/abs/2408.12099",
                "title": "Logo-licious Attack: Tricking Video Classifiers with Stylized Patches",
                "institute": "National University of Singapore, Tsinghua University, Commonwealth Scientific and Industrial Research Organisation...",
                "text": "This research proposes a novel video adversarial attack framework called Stylized Logo Attack (SLA) that combines style-transfer-based and patch-based attacks. Unlike previous methods, SLA focuses on perturbing only sub-regions of the video and stylizing these sub-regions to carry more target-class features, making it more efficient in queries and achieving better performance in both targeted and untargeted attacks.",
                "paper-title": "Query-Efficient Video Adversarial Attack with Stylized Logo",
                "image-path": ""
            },

            {
                "startTime": "15:54",
                "arxivId": "2408.12594",
                "arxivLink": "https://arxiv.org/abs/2408.12594",
                "title": "Pre-Training Graphs: It's Not All About Homophily!",
                "institute": "National University of Singapore, Singapore Management University, University of Tokyo",
                "text": "This research proposes a new pre-training and prompt learning framework called ProNoG, specifically designed for non-homophilic graphs. Unlike previous methods that assume homophily, ProNoG accounts for the varying degrees of homophily present in real-world graphs and adapts to the unique characteristics of each node.",
                "paper-title": "Non-Homophilic Graph Pre-Training and Prompt Learning",
                "image-path": ""
            },

            {
                "startTime": "16:20",
                "arxivId": "2408.12032",
                "arxivLink": "https://arxiv.org/abs/2408.12032",
                "title": "Fairness in Scheduling: When Algorithms Get a Heart",
                "institute": "University of Toronto, NTT Communication Science Laboratories",
                "text": "This research introduces a new constraint programming approach to high school course scheduling that incorporates fairness considerations, addressing the growing concern of inequity in course access. Previous research focused primarily on feasibility and efficiency, neglecting the crucial aspect of fairness.",
                "paper-title": "A Constraint Programming Approach to Fair High School Course Scheduling",
                "image-path": ""
            },

            {
                "startTime": "16:40",
                "arxivId": "2408.11977",
                "arxivLink": "https://arxiv.org/abs/2408.11977",
                "title": "Learning Bayesian Networks: A Coordinate Descent Algorithm That's Actually Optimal!",
                "institute": "Northwestern University, University of Washington",
                "text": "This paper proposes a new coordinate descent algorithm for learning Bayesian networks from Gaussian data. Unlike previous coordinate descent algorithms, this one comes with provable convergence, optimality, and statistical consistency guarantees.",
                "paper-title": "An Asymptotically Optimal Coordinate Descent Algorithm for Learning Bayesian Networks from Gaussian Models",
                "image-path": ""
            },

            {
                "startTime": "17:03",
                "arxivId": "2408.12321",
                "arxivLink": "https://arxiv.org/abs/2408.12321",
                "title": "Multi-Image Reasoning: When LLMs Get Their Eyes Checked!",
                "institute": "Peking University, Alibaba",
                "text": "This paper introduces MaVEn, a framework that combines discrete and continuous visual representations to enhance multi-image reasoning in Multimodal Large Language Models (MLLMs). This approach differs from previous work that primarily focused on single-image understanding.",
                "paper-title": "MaVEn: An Effective Multi-granularity Hybrid Visual Encoding Framework for Multimodal Large Language Model",
                "image-path": ""
            },

            {
                "startTime": "17:26",
                "arxivId": "2408.11878",
                "arxivLink": "https://arxiv.org/abs/2408.11878",
                "title": "Financial LLMs Get a Multimodal Makeover: Tables, Charts, and Trading, Oh My!",
                "institute": "The Fin AI, Wuhan University, Columbia University...",
                "text": "This research introduces Open-FinLLMs, a series of financial large language models (LLMs) that are specifically trained on a massive financial corpus, including text, tables, and time-series data. This distinguishes them from previous financial LLMs that primarily relied on text-based data.",
                "paper-title": "Open-FinLLMs: Open Multimodal Large Language Models for Financial Applications",
                "image-path": ""
            },

            {
                "startTime": "17:51",
                "arxivId": "2408.12048",
                "arxivLink": "https://arxiv.org/abs/2408.12048",
                "title": "Driving into the Future: A Physics-Based Dataset for HDR Nighttime Scenes",
                "institute": "Stanford University",
                "text": "This research introduces a physics-based simulation framework for generating high dynamic range (HDR) driving scenes, including spectral radiance maps and depth information. Unlike previous work that focused on RGB images, this study provides a more comprehensive and quantitative representation of the scene, enabling accurate evaluation of image system designs.",
                "paper-title": "ISETHDR: A Physics-based Synthetic Radiance Dataset for High Dynamic Range Driving Scenes",
                "image-path": ""
            },

            {
                "startTime": "18:15",
                "arxivId": "2408.12259",
                "arxivLink": "https://arxiv.org/abs/2408.12259",
                "title": "Concatenation Chaos: LLM Metrics Fail the \"Copy-Paste\" Test",
                "institute": "IBM",
                "text": "This research introduces a novel set of automatic tests based on concatenating inputs to assess the validity of metrics used to evaluate large language models (LLMs). These tests go beyond traditional methods that focus on correlation with human judgments, exploring how metrics behave when presented with repeated or reordered content.",
                "paper-title": "Can You Trust Your Metric? Automatic Concatenation-Based Tests for Metric Validity",
                "image-path": ""
            },

            {
                "startTime": "18:43",
                "arxivId": "2408.11936",
                "arxivLink": "https://arxiv.org/abs/2408.11936",
                "title": "AI Judges Your Debate Skills: Can a Language Model Tell Who's Winning the Argument?",
                "institute": "Stanford University",
                "text": "This research uses a large language model (LLM) to automatically assess the quality of contributions in online deliberations, a task traditionally done by human annotators. The study compares the LLM's performance to that of human evaluators and explores the impact of nudges on participation and contribution quality.",
                "paper-title": "Estimating Contribution Quality in Online Deliberations Using a Large Language Model",
                "image-path": ""
            },

            {
                "startTime": "19:04",
                "arxivId": "2408.11845",
                "arxivLink": "https://arxiv.org/abs/2408.11845",
                "title": "LLaMA's Punctuation Power: A Speed Demon for Text Cleanup!",
                "institute": "Meta",
                "text": "This research introduces a new decoding method called Forward Pass Only Decoding (FPOD) for punctuation restoration tasks. Unlike traditional auto-regressive methods, FPOD eliminates the need for sequential token generation, significantly boosting inference speed.",
                "paper-title": "LLaMA based Punctuation Restoration With Forward Pass Only Decoding",
                "image-path": ""
            },

            {
                "startTime": "19:26",
                "arxivId": "2408.12446",
                "arxivLink": "https://arxiv.org/abs/2408.12446",
                "title": "Hedging Against Heavy Losses: When AI Learns to Fear the Worst",
                "institute": "University of Toronto",
                "text": "This research proposes a hybrid model for distributional reinforcement learning (DRL) that combines quantile regression (QR) with a Generalized Pareto Distribution (GPD) to improve the estimation of extreme quantiles in the tail of the loss distribution. This approach addresses the limitations of traditional QR-based DRL methods, which often struggle to accurately model extreme events due to the scarcity of data in the tails of the distribution.",
                "paper-title": "EX-DRL: Hedging Against Heavy Losses with EXtreme Distributional Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "19:56",
                "arxivId": "2408.12489",
                "arxivLink": "https://arxiv.org/abs/2408.12489",
                "title": "Scribble-licious Segmentation: New Datasets Make Weak Supervision Strong!",
                "institute": "Max Planck Society, ETH Zurich",
                "text": "This research introduces a novel algorithm for automatically generating scribble labels for semantic segmentation datasets. Unlike previous work that relied on manually drawn scribbles, this method leverages existing dense annotations to create synthetic scribbles, expanding the availability of scribble-labeled datasets.",
                "paper-title": "Scribbles for All: Benchmarking Scribble Supervised Segmentation Across Datasets",
                "image-path": ""
            },

            {
                "startTime": "20:24",
                "arxivId": "2408.12365",
                "arxivLink": "https://arxiv.org/abs/2408.12365",
                "title": "Uncertainty in Time Series: Don't Just Predict, Explain!",
                "institute": "German Aerospace Center, University of Magdeburg",
                "text": "This research goes beyond simply visualizing uncertainty in time series predictions. It delves into how users perceive and interpret different visualization techniques, analyzing the impact of individual characteristics and information needs on their understanding.",
                "paper-title": "Enhancing Uncertainty Communication in Time Series Predictions: Insights and Recommendations",
                "image-path": ""
            },

            {
                "startTime": "20:48",
                "arxivId": "2408.12561",
                "arxivLink": "https://arxiv.org/abs/2408.12561",
                "title": "Deep Learning's Diet: Sparsity Makes Training Models Slim and Smart",
                "institute": "University of Southern California",
                "text": "This research introduces a new method called \"scheduled channel-wise sparsity\" (ssProp) for training convolutional neural networks (CNNs). Unlike previous sparsification techniques that rely on specific hardware support or compromise accuracy, ssProp focuses on selectively dropping gradients during backpropagation, leading to computational savings without sacrificing performance.",
                "paper-title": "ssProp: Energy-Efficient Training for Convolutional Neural Networks with Scheduled Sparse Back Propagation",
                "image-path": ""
            },

            {
                "startTime": "21:12",
                "arxivId": "2408.11910",
                "arxivLink": "https://arxiv.org/abs/2408.11910",
                "title": "Facebook's \"See Less\" Button: A Big Fat Lie?",
                "institute": "Princeton University",
                "text": "This research examines the effectiveness of Facebook's ad controls and explanations in the context of AI-mediated ad targeting, a relatively new approach that relies on algorithms to identify relevant audiences without explicit targeting criteria.",
                "paper-title": "Why am I Still Seeing This: Measuring the Effectiveness Of Ad Controls and Explanations in AI-Mediated Ad Targeting Systems",
                "image-path": ""
            },

            {
                "startTime": "21:39",
                "arxivId": "2408.11839",
                "arxivLink": "https://arxiv.org/abs/2408.11839",
                "title": "Deep Learning's New Friction: Sigmoid and Tanh Make Optimizers Smoother!",
                "institute": "Chinese University of Hong Kong, Illinois Institute of Technology, Ohio State University...",
                "text": "This research introduces a novel approach to adaptive optimizers by incorporating adaptive friction coefficients based on the Sigmoid and Tanh functions. This differs from previous work like diffGrad and AngularGrad, which only adjust the learning rate based on the difference between gradients or angle changes.",
                "paper-title": "Adaptive Friction in Deep Learning: Enhancing Optimizers with Sigmoid and Tanh Function",
                "image-path": ""
            },

            {
                "startTime": "22:14",
                "arxivId": "2408.12084",
                "arxivLink": "https://arxiv.org/abs/2408.12084",
                "title": "Spacecraft Spotting: New AI Helps Satellites See Each Other in the Dark!",
                "institute": "Caltech",
                "text": "This research introduces a novel method for detecting uncooperative spacecraft using thermal imaging, which is more reliable than visible light methods at long distances. It also explores knowledge distillation to improve the performance of a lightweight segmentation model for spacecraft part identification at shorter ranges.",
                "paper-title": "Vision-Based Detection of Uncooperative Targets and Components on Small Satellites",
                "image-path": ""
            },

            {
                "startTime": "22:42",
                "arxivId": "2408.12296",
                "arxivLink": "https://arxiv.org/abs/2408.12296",
                "title": "New Physics Hunting: When One Test Isn't Enough!",
                "institute": "MIT, University of Genoa",
                "text": "This research explores how to improve signal-agnostic searches for new physics by using multiple machine learning tests instead of relying on a single test. This approach aims to reduce bias and improve sensitivity by considering a wider range of possible anomalies.",
                "paper-title": "Multiple testing for signal-agnostic searches of new physics with machine learning",
                "image-path": ""
            },

            {
                "startTime": "23:01",
                "arxivId": "2408.11966",
                "arxivLink": "https://arxiv.org/abs/2408.11966",
                "title": "NeRF-tastic Localization: Mapping the World with AI-Powered 3D Images",
                "institute": "University of Oxford, University of Hong Kong",
                "text": "This research explores the use of three different 3D map representations (point clouds, meshes, and NeRFs) for visual localization. The novelty lies in automatically generating a database of synthetic images from these representations, enabling robust localization even when the camera travels in directions unseen during map creation.",
                "paper-title": "Visual Localization in 3D Maps: Comparing Point Cloud, Mesh, and NeRF Representations",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 53,
        "num_total": 296,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202408230901_audio.mp3"
}
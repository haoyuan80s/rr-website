
daily_data = {
    "date": "2024-09-18",
    "tweets": [
            {
                "startTime": "01:10",
                "arxivId": "2409.11363",
                "arxivLink": "https://arxiv.org/abs/2409.11363",
                "title": "AI Agents: Can They Even Replicate a Science Paper?",
                "institute": "Princeton University",
                "text": "This research introduces CORE-Bench, a benchmark specifically designed to evaluate the ability of AI agents to reproduce the results of published scientific research. Unlike previous benchmarks that focus on coding tasks or specific scientific domains, CORE-Bench tackles the broader challenge of computational reproducibility across multiple disciplines.",
                "paper-title": "CORE-Bench: Fostering the Credibility of Published Research Through a Computational Reproducibility Agent Benchmark",
                "image-path": "flux_paper_image/2409.11363_1726700273.png"
            },

            {
                "startTime": "01:36",
                "arxivId": "2409.11321",
                "arxivLink": "https://arxiv.org/abs/2409.11321",
                "title": "Shampoo's New Trick: Adam Gets a Spin in the Eigenbasis!",
                "institute": "Harvard University",
                "text": "This research establishes a formal connection between Shampoo and Adafactor, showing that Shampoo is equivalent to running Adafactor in the eigenbasis of Shampoo's preconditioner. This insight leads to the design of a simpler and computationally efficient algorithm called SOAP.",
                "paper-title": "SOAP: Improving and Stabilizing Shampoo using Adam",
                "image-path": "flux_paper_image/2409.11321_1726700622.png"
            },

            {
                "startTime": "01:54",
                "arxivId": "2409.11402",
                "arxivLink": "https://arxiv.org/abs/2409.11402",
                "title": "NVLM: Multimodal LLMs That Can Do Math...and Even Improve Their Text Skills!",
                "institute": "Nvidia",
                "text": "This research introduces NVLM, a family of multimodal LLMs that achieve state-of-the-art results on vision-language tasks. Unlike previous open-access models, NVLM models maintain or even improve their text-only performance after multimodal training. This is achieved by incorporating a high-quality text-only dataset into the multimodal fine-tuning stage.",
                "paper-title": "NVLM: Open Frontier-Class Multimodal LLMs",
                "image-path": "flux_paper_image/2409.11402_1726700749.png"
            },

            {
                "startTime": "02:13",
                "arxivId": "2409.10683",
                "arxivLink": "https://arxiv.org/abs/2409.10683",
                "title": "Robots Need Therapy Too: New Study Shows How to Teach AI to Judge Motion, Not Just Goals",
                "institute": "MIT, Stanford University, CMU",
                "text": "This research focuses on teaching AI to evaluate the \"how\" of robot actions, not just the \"what.\" It does this by fine-tuning vision-language models (VLMs) using abstract representations of robot trajectories overlaid on images.",
                "paper-title": "MotIF: Motion Instruction Fine-tuning",
                "image-path": "flux_paper_image/2409.10683_1726700792.png"
            },

            {
                "startTime": "02:37",
                "arxivId": "2409.10897",
                "arxivLink": "https://arxiv.org/abs/2409.10897",
                "title": "Neural Network Specs: No More Guesswork, Just AutoSpec!",
                "institute": "University of Michigan, Microsoft Research, UIUC...",
                "text": "This research introduces AutoSpec, a framework that automatically generates specifications for neural networks, unlike previous methods that rely on manual definition.",
                "paper-title": "AutoSpec: Automated Generation of Neural Network Specifications",
                "image-path": "flux_paper_image/2409.10897_1726701208.png"
            },

            {
                "startTime": "03:05",
                "arxivId": "2409.10580",
                "arxivLink": "https://arxiv.org/abs/2409.10580",
                "title": "Foundation Models in Medicine: A Reality Check for Veridical Data Science",
                "institute": "University of California Berkeley, University of California San Francisco",
                "text": "This research examines the application of foundation models (FMs) in medicine, specifically focusing on how the foundation model lifecycle (FMLC) deviates from the traditional data science lifecycle (DSLC). It proposes a framework for evaluating the predictability, computability, and stability (PCS) of FMs, addressing concerns about transparency, reproducibility, and rigor in FM-based data science.",
                "paper-title": "Veridical Data Science for Medical Foundation Models",
                "image-path": "flux_paper_image/2409.10580_1726700842.png"
            },

            {
                "startTime": "03:31",
                "arxivId": "2409.10917",
                "arxivLink": "https://arxiv.org/abs/2409.10917",
                "title": "Remembering Your Day: A New Memory for Egocentric Videos",
                "institute": "Politecnico di Torino, FAIR, University of Bristol",
                "text": "This research introduces AMEGO, a structured representation of egocentric videos that captures object interactions, locations visited, and their interplay. Unlike previous approaches that rely on uniform sampling of frames or semantic labels, AMEGO builds its representation online using visual perception models of human activity and motion.",
                "paper-title": "AMEGO: Active Memory from long EGOcentric videos",
                "image-path": "flux_paper_image/2409.10917_1726700665.png"
            },

            {
                "startTime": "03:57",
                "arxivId": "2409.10829",
                "arxivLink": "https://arxiv.org/abs/2409.10829",
                "title": "Radiology Reports: AI's Got Errors, But We've Got ReXErr!",
                "institute": "University of Pennsylvania, Stanford University, Harvard University",
                "text": "This research introduces ReXErr, a novel methodology that uses large language models (LLMs) to generate representative errors within chest X-ray reports. Unlike previous work that focuses on specific error types, ReXErr aims to capture the breadth and diversity of errors made by both humans and AI models.",
                "paper-title": "ReXErr: Synthesizing Clinically Meaningful Errors in Diagnostic Radiology Reports",
                "image-path": "flux_paper_image/2409.10829_1726701294.png"
            },

            {
                "startTime": "04:19",
                "arxivId": "2409.11169",
                "arxivLink": "https://arxiv.org/abs/2409.11169",
                "title": "AI Makes Fake CT Scans So Real, Doctors Might Be Fooled!",
                "institute": "NVIDIA, National Institutes of Health, University of Arkansas for Medical Sciences...",
                "text": "This research introduces a new method called MAISI, which uses a diffusion model to generate high-resolution 3D CT images. Unlike previous methods that focus on 2D images or smaller volumes, MAISI can create realistic CT volumes with dimensions up to 512x512x768 voxels.",
                "paper-title": "MAISI: Medical AI for Synthetic Imaging",
                "image-path": "flux_paper_image/2409.11169_1726701108.png"
            },

            {
                "startTime": "04:46",
                "arxivId": "2409.11211",
                "arxivLink": "https://arxiv.org/abs/2409.11211",
                "title": "SplatFields: Giving 3D Reconstruction a Spatial Spank!",
                "institute": "ETH Zurich, MetaRealityLabs, Balgrist University Hospital",
                "text": "This research introduces SplatFields, a novel optimization strategy that regularizes 3D Gaussian Splatting (3DGS) by modeling splat features as outputs of a corresponding implicit neural field. This approach effectively handles both static and dynamic scenes, improving reconstruction quality compared to previous 3DGS techniques.",
                "paper-title": "SplatFields: Neural Gaussian Splats for Sparse 3D and 4D Reconstruction",
                "image-path": "flux_paper_image/2409.11211_1726701256.png"
            },

            {
                "startTime": "05:11",
                "arxivId": "2409.10909",
                "arxivLink": "https://arxiv.org/abs/2409.10909",
                "title": "Query Reformulation Gets a Makeover: LLMs Learn to Cluster and Conquer!",
                "institute": "Peking University, Baidu, Wilfrid Laurier University",
                "text": "This research proposes GenCRF, a framework that uses LLMs to generate multiple reformulated queries from a single user input. Unlike previous methods that rely on single prompts or keyword generation, GenCRF dynamically clusters these queries to capture diverse user intents, minimizing redundancy and maximizing the potential of query reformulation.",
                "paper-title": "GenCRF: Generative Clustering and Reformulation Framework for Enhanced Intent-Driven Information Retrieval",
                "image-path": "flux_paper_image/2409.10909_1726700944.png"
            },

            {
                "startTime": "05:35",
                "arxivId": "2409.11274",
                "arxivLink": "https://arxiv.org/abs/2409.11274",
                "title": "Speech Translation Gets a Language Makeover: Task Arithmetic to the Rescue!",
                "institute": "University of Washington, Sony, CMU",
                "text": "This research proposes a novel method for expanding language pairs in speech translation systems using task arithmetic. Unlike previous work that relies on retraining models with new datasets, this approach merges existing models trained on different language pairs without retraining, significantly reducing costs.",
                "paper-title": "Task Arithmetic for Language Expansion in Speech Translation",
                "image-path": "flux_paper_image/2409.11274_1726700936.png"
            },

            {
                "startTime": "05:59",
                "arxivId": "2409.10901",
                "arxivLink": "https://arxiv.org/abs/2409.10901",
                "title": "\"Predicting the Future: How AI Can See What's Coming in Self-Driving Cars\"",
                "institute": "UC Berkeley",
                "text": "This research introduces TrajSSL, a new approach to semi-supervised 3D object detection that leverages trajectory prediction models to improve the quality of pseudo-labels used during training. Unlike previous methods that rely solely on confidence scores or consistency measures, TrajSSL incorporates temporal information by predicting future object trajectories, which helps identify and suppress false positive pseudo-labels while compensating for missed detections.",
                "paper-title": "TrajSSL: Trajectory-Enhanced Semi-Supervised 3D Object Detection",
                "image-path": "flux_paper_image/2409.10901_1726699624.png"
            },

            {
                "startTime": "06:30",
                "arxivId": "2409.10566",
                "arxivLink": "https://arxiv.org/abs/2409.10566",
                "title": "AI Models: Not All Heroes Wear Capes, Some Wear... Benchmarks?",
                "institute": "Microsoft",
                "text": "This research introduces EUREKA, an open-source evaluation framework for large foundation models (LFMs). EUREKA goes beyond single-score reporting and rankings, providing a library for customizing evaluation pipelines and an extensible collection of benchmarks that test challenging capabilities.",
                "paper-title": "Eureka: Evaluating and Understanding Large Foundation Models",
                "image-path": "flux_paper_image/2409.10566_1726701017.png"
            },

            {
                "startTime": "06:58",
                "arxivId": "2409.10525",
                "arxivLink": "https://arxiv.org/abs/2409.10525",
                "title": "AI Assistants: Are They Really Listening?",
                "institute": "Microsoft, University of Michigan",
                "text": "This research proposes a new approach to building benchmarks for evaluating large multimodal models (LMMs) in situated collaboration tasks. Unlike existing benchmarks that generate questions post-hoc, this study advocates for an interactive system-driven approach where questions are collected during real-time interactions with an AI system.",
                "paper-title": ""Is This It?": Towards Ecologically Valid Benchmarks for Situated Collaboration",
                "image-path": "flux_paper_image/2409.10525_1726701360.png"
            },

            {
                "startTime": "07:19",
                "arxivId": "2409.10555",
                "arxivLink": "https://arxiv.org/abs/2409.10555",
                "title": "Deep Learning Gets a Makeover: Tiny Models, Big Results!",
                "institute": "Tsinghua University",
                "text": "This research explores the use of a \"prompting module\" to adapt pre-trained deep networks to new tasks, specifically video object segmentation. Unlike traditional end-to-end training, this approach uses a simple, semi-parametric model that learns from only the first frame of a video, making it extremely efficient and requiring no further training.",
                "paper-title": "Convolutional Networks as Extremely Small Foundation Models: Visual Prompting and Theoretical Perspective",
                "image-path": "flux_paper_image/2409.10555_1726699683.png"
            },

            {
                "startTime": "07:43",
                "arxivId": "2409.11353",
                "arxivLink": "https://arxiv.org/abs/2409.11353",
                "title": "LLMs Gone Wild? New Tool Tames Hallucinations!",
                "institute": "University College London",
                "text": "This research introduces THaMES, a framework that goes beyond just detecting hallucinations in LLMs. It also includes a process for generating diverse test sets and evaluating different mitigation strategies. This comprehensive approach sets it apart from previous work that often focused on isolated aspects of the problem.",
                "paper-title": "THaMES: An End-to-End Tool for Hallucination Mitigation and Evaluation in Large Language Models",
                "image-path": "flux_paper_image/2409.11353_1726700698.png"
            },

            {
                "startTime": "08:13",
                "arxivId": "2409.10538",
                "arxivLink": "https://arxiv.org/abs/2409.10538",
                "title": "Survival Analysis Gets a Fairness Makeover: DRO to the Rescue!",
                "institute": "Purdue University, CMU",
                "text": "This research applies distributionally robust optimization (DRO) to survival analysis models, addressing the challenge of fairness in predicting time-to-event outcomes. Unlike previous work that relies on user-specified sensitive attributes, this approach minimizes worst-case errors across all \"large enough\" subpopulations, without requiring the user to explicitly define sensitive features.",
                "paper-title": "Fairness in Survival Analysis with Distributionally Robust Optimization",
                "image-path": "flux_paper_image/2409.10538_1726700398.png"
            },

            {
                "startTime": "08:48",
                "arxivId": "2409.10728",
                "arxivLink": "https://arxiv.org/abs/2409.10728",
                "title": "Predicting Words: Beyond Surprisal, a New Framework for Language Processing",
                "institute": "ETH Zurich",
                "text": "This research introduces a generalized framework for measuring predictive uncertainty in online language processing. It goes beyond the traditional measures of surprisal and entropy by offering a flexible way to define new, more expressive measures.",
                "paper-title": "Generalized Measures of Anticipation and Responsivity in Online Language Processing",
                "image-path": "flux_paper_image/2409.10728_1726701247.png"
            },

            {
                "startTime": "09:08",
                "arxivId": "2409.10542",
                "arxivLink": "https://arxiv.org/abs/2409.10542",
                "title": "SAM4MLLM: Talking to AI About Pixels, One Point at a Time!",
                "institute": "National Taiwan University, Nvidia",
                "text": "This research proposes a novel approach that integrates the Segment Anything Model (SAM) with Multi-Modal Large Language Models (MLLMs) for pixel-aware tasks. Unlike previous methods that require extensive model modifications or specialized tokens, SAM4MLLM leverages SAM's ability to generate high-quality segmentation masks based on simple prompts, enabling MLLMs to understand pixel-level information without altering their architecture.",
                "paper-title": "SAM4MLLM: Enhance Multi-Modal Large Language Model for Referring Expression Segmentation",
                "image-path": "flux_paper_image/2409.10542_1726700564.png"
            },

            {
                "startTime": "09:35",
                "arxivId": "2409.10889",
                "arxivLink": "https://arxiv.org/abs/2409.10889",
                "title": "Deepfake-Busting Phone Vibrations: Shaking the Fake in Real Time!",
                "institute": "Nanyang Technological University",
                "text": "This research proposes a novel real-time deepfake detection method called SFake that actively introduces controllable features into video footage by inducing vibrations on the attacker's smartphone. Unlike existing passive detection methods that rely on learning features from deepfake videos, SFake actively manipulates the video stream, making it harder for deepfake algorithms to adapt and bypass detection.",
                "paper-title": "Shaking the Fake: Detecting Deepfake Videos in Real Time via Active Probes",
                "image-path": "flux_paper_image/2409.10889_1726700238.png"
            },

            {
                "startTime": "09:58",
                "arxivId": "2409.10940",
                "arxivLink": "https://arxiv.org/abs/2409.10940",
                "title": "RoadRunner M&M: Off-Road Navigation Gets a Multi-Range Makeover!",
                "institute": "Caltech, JPL, ETH Zurich",
                "text": "This research builds upon the RoadRunner framework by introducing a multi-range, multi-resolution approach to predict traversability and elevation maps. Unlike previous work, this method leverages a hierarchical decoder and LiDAR voxel map input to achieve more accurate predictions at longer ranges.",
                "paper-title": "RoadRunner M&M -- Learning Multi-range Multi-resolution Traversability Maps for Autonomous Off-road Navigation",
                "image-path": "flux_paper_image/2409.10940_1726701368.png"
            },

            {
                "startTime": "10:19",
                "arxivId": "2409.11378",
                "arxivLink": "https://arxiv.org/abs/2409.11378",
                "title": "Data Diversity: The Secret Weapon for Fine-Tuning LLMs",
                "institute": "Northeastern University, Stanford University, Google...",
                "text": "This research proposes a novel approach to selecting instruction data for fine-tuning LLMs by prioritizing diversity over individual instance quality. Unlike previous methods that focus on local criteria, this work utilizes k-means clustering to ensure the selected subset effectively represents the full dataset.",
                "paper-title": "Diversify and Conquer: Diversity-Centric Data Selection with Iterative Refinement",
                "image-path": "flux_paper_image/2409.11378_1726700851.png"
            },

            {
                "startTime": "10:40",
                "arxivId": "2409.10585",
                "arxivLink": "https://arxiv.org/abs/2409.10585",
                "title": "Ensemble of Models: Predicting the Future of Self-Driving Cars with a Little Help from Their Friends",
                "institute": "Bosch Center for Artificial Intelligence, University of Freiburg",
                "text": "This research proposes a novel sampling method for trajectory prediction that leverages an ensemble of models, unlike previous work that primarily focused on single models or ensembles of the same model. The method frames the problem as a risk minimization problem, where the ensemble approximates the true risk.",
                "paper-title": "Motion Forecasting via Model-Based Risk Minimization",
                "image-path": "flux_paper_image/2409.10585_1726701316.png"
            },

            {
                "startTime": "11:04",
                "arxivId": "2409.10715",
                "arxivLink": "https://arxiv.org/abs/2409.10715",
                "title": "Transformers Have a Memory Problem: Attention Spreads Too Thin!",
                "institute": "Yale University",
                "text": "This research investigates the working memory capacity limits of Transformer-based language models by analyzing the self-attention mechanism. Unlike previous studies that focused on performance, this paper delves into the underlying mechanism responsible for the observed capacity limits.",
                "paper-title": "Self-Attention Limits Working Memory Capacity of Transformer-Based Models",
                "image-path": "flux_paper_image/2409.10715_1726701006.png"
            },

            {
                "startTime": "11:27",
                "arxivId": "2409.11307",
                "arxivLink": "https://arxiv.org/abs/2409.11307",
                "title": "3D Scene Rendering Gets a Density Boost: GS-Net Makes Gaussian Splatting More Generalizable",
                "institute": "Tsinghua University",
                "text": "This research introduces GS-Net, a plug-and-play module that enhances 3D Gaussian Splatting (3DGS) by generating denser Gaussian ellipsoids from sparse point clouds. Unlike previous 3DGS models that overfit to single scenes, GS-Net enables cross-scene generalization.",
                "paper-title": "GS-Net: Generalizable Plug-and-Play 3D Gaussian Splatting Module",
                "image-path": "flux_paper_image/2409.11307_1726699864.png"
            },

            {
                "startTime": "11:51",
                "arxivId": "2409.10849",
                "arxivLink": "https://arxiv.org/abs/2409.10849",
                "title": "Robots with Mind-Reading Skills: New AI Can Understand Noisy Instructions!",
                "institute": "MIT, Harvard University, Brown University...",
                "text": "This research introduces a new model called SIFToM that uses Theory of Mind reasoning to understand noisy or unclear speech instructions. Unlike previous work that relies solely on speech recognition, SIFToM infers the human's goal and plan from visual observations, making it more robust to errors in speech transcription.",
                "paper-title": "SIFToM: Robust Spoken Instruction Following through Theory of Mind",
                "image-path": "flux_paper_image/2409.10849_1726701102.png"
            },

            {
                "startTime": "12:15",
                "arxivId": "2409.11295",
                "arxivLink": "https://arxiv.org/abs/2409.11295",
                "title": "Web Agents: New Attack Injects Malicious Content to Steal Your Data!",
                "institute": "The Ohio State University, University of Chicago, University of Wisconsin Madison...",
                "text": "This research focuses on a novel attack method called Environmental Injection Attack (EIA) that targets generalist web agents by injecting malicious content into the web environment. Unlike previous work that focused on direct prompt injection or manipulating uploaded images, EIA manipulates the environment where the agent operates, making it a more stealthy and realistic threat.",
                "paper-title": "EIA: Environmental Injection Attack on Generalist Web Agents for Privacy Leakage",
                "image-path": "flux_paper_image/2409.11295_1726700459.png"
            },

            {
                "startTime": "12:46",
                "arxivId": "2409.10999",
                "arxivLink": "https://arxiv.org/abs/2409.10999",
                "title": "Thai-ing the Knot: Audio Language Models Learn to Speak Thai!",
                "institute": "University of Cambridge",
                "text": "This research explores the limitations of existing audio language models in low-resource languages, using Thai as a case study. It proposes a novel data mixture approach to enhance the model's ability to understand and respond to instructions in both English and Thai.",
                "paper-title": "Enhancing Low-Resource Language and Instruction Following Capabilities of Audio Language Models",
                "image-path": "flux_paper_image/2409.10999_1726701303.png"
            },

            {
                "startTime": "13:10",
                "arxivId": "2409.10693",
                "arxivLink": "https://arxiv.org/abs/2409.10693",
                "title": "Traffic Lights Get Smart: Transformers Take the Wheel!",
                "institute": "University of Toronto",
                "text": "This research integrates Transformers into the eMARLIN architecture, a distributed adaptive traffic signal control system, to address the challenge of partial observability. Unlike previous approaches that used LSTMs, this method leverages attention mechanisms for parallel computations, improving efficiency and capturing temporal information more effectively.",
                "paper-title": "Mitigating Partial Observability in Adaptive Traffic Signal Control with Transformers",
                "image-path": "flux_paper_image/2409.10693_1726700391.png"
            },

            {
                "startTime": "13:37",
                "arxivId": "2409.10908",
                "arxivLink": "https://arxiv.org/abs/2409.10908",
                "title": "Clustering with Subset Queries: Breaking the Quadratic Barrier!",
                "institute": "UCSanDiego, University of Michigan",
                "text": "This research explores a generalization of pair-wise queries to subset queries for clustering, where the oracle returns the number of clusters intersecting a given subset. This approach allows for significantly better non-adaptive algorithms compared to previous work that relied solely on pair-wise queries.",
                "paper-title": "Clustering with Non-adaptive Subset Queries",
                "image-path": "flux_paper_image/2409.10908_1726699572.png"
            },

            {
                "startTime": "14:01",
                "arxivId": "2409.10584",
                "arxivLink": "https://arxiv.org/abs/2409.10584",
                "title": "Drug Design Gets a Quantum Boost: New Model Avoids Atomic Collisions!",
                "institute": "California Institute of Technology, University of California Berkeley, Alibaba DAMO Academy...",
                "text": "This research introduces NucleusDiff, a diffusion model for structure-based drug design that incorporates a manifold constraint to prevent atoms from getting too close to each other. This is different from previous models that often overlook this crucial physical constraint.",
                "paper-title": "Manifold-Constrained Nucleus-Level Denoising Diffusion Model for Structure-Based Drug Design",
                "image-path": "flux_paper_image/2409.10584_1726700628.png"
            },

            {
                "startTime": "14:28",
                "arxivId": "2409.11091",
                "arxivLink": "https://arxiv.org/abs/2409.11091",
                "title": "Bidding Blind: How to Win Auctions with Just a Glimpse of the Competition",
                "institute": "Google, University of Bonn, Microsoft...",
                "text": "This research explores online combinatorial auctions where bidders' valuations are unknown, only accessible through a limited number of samples. It introduces novel algorithms that achieve constant-factor approximations using a single sample per bidder, a significant improvement over previous work that required more samples or stringent assumptions.",
                "paper-title": "Online Combinatorial Allocations and Auctions with Few Samples",
                "image-path": "flux_paper_image/2409.11091_1726701038.png"
            },

            {
                "startTime": "14:50",
                "arxivId": "2409.10593",
                "arxivLink": "https://arxiv.org/abs/2409.10593",
                "title": "Shrinking LLMs: A New Trick to Make Big Models Fit in Small Spaces",
                "institute": "Tsinghua University, Infinigence-AI, Shanghai Jiao Tong University",
                "text": "This paper proposes a new technique called CSKV for compressing the KV cache in LLMs. Unlike previous methods that focus on quantization or token pruning, CSKV leverages the redundancy in the channel dimension of the KV cache by using low-rank decomposition.",
                "paper-title": "CSKV: Training-Efficient Channel Shrinking for KV Cache in Long-Context Scenarios",
                "image-path": "flux_paper_image/2409.10593_1726700226.png"
            },

            {
                "startTime": "15:12",
                "arxivId": "2409.10790",
                "arxivLink": "https://arxiv.org/abs/2409.10790",
                "title": "LLMs Get a New Pair of Glasses: AutoPASTA Helps Them See the Big Picture!",
                "institute": "Georgia Institute of Technology, Microsoft",
                "text": "This research introduces AutoPASTA, a method that automatically identifies key information in a text and highlights it for LLMs, improving their ability to understand and respond to complex questions. Unlike previous methods that rely on prompting, AutoPASTA uses attention steering to explicitly guide the model's focus.",
                "paper-title": "Model Tells Itself Where to Attend: Faithfulness Meets Automatic Attention Steering",
                "image-path": "flux_paper_image/2409.10790_1726700998.png"
            },

            {
                "startTime": "15:36",
                "arxivId": "2409.10695",
                "arxivLink": "https://arxiv.org/abs/2409.10695",
                "title": "Playground v3: LLMs Take the Stage for Text-to-Image Generation!",
                "institute": "Playground Research",
                "text": "This research introduces a novel text-to-image model that fully integrates a large language model (LLM) into its architecture, unlike previous models that rely on pre-trained language models like T5 or CLIP.",
                "paper-title": "Playground v3: Improving Text-to-Image Alignment with Deep-Fusion Large Language Models",
                "image-path": "flux_paper_image/2409.10695_1726700919.png"
            },

            {
                "startTime": "16:00",
                "arxivId": "2409.10716",
                "arxivLink": "https://arxiv.org/abs/2409.10716",
                "title": "Forget Re-training! This AI Learns New Objects Like You Do",
                "institute": "Microsoft",
                "text": "This paper proposes an online learning framework for object detectors that uses a memory bank to adapt to new domains without retraining the detector model. This differs from previous work that typically requires extensive retraining or fine-tuning on target domain data.",
                "paper-title": "Online Learning via Memory: Retrieval-Augmented Detector Adaptation",
                "image-path": "flux_paper_image/2409.10716_1726700641.png"
            },

            {
                "startTime": "16:22",
                "arxivId": "2409.10969",
                "arxivLink": "https://arxiv.org/abs/2409.10969",
                "title": "LLMs Learn to Speak Fluent Code-Switching: A New Recipe for Multilingual Speech!",
                "institute": "Chinese University of Hong Kong, Huawei",
                "text": "This research explores a novel approach to code-switching speech synthesis by constructing a dataset from concatenated words in different languages. This differs from previous work that relied heavily on high-quality code-switched data.",
                "paper-title": "Enhancing Multilingual Speech Generation and Recognition Abilities in LLMs with Constructed Code-switched Data",
                "image-path": "flux_paper_image/2409.10969_1726699696.png"
            },

            {
                "startTime": "16:47",
                "arxivId": "2409.11235",
                "arxivLink": "https://arxiv.org/abs/2409.11235",
                "title": "Open-Vocabulary Tracking: When Semantics Meet Motion",
                "institute": "ETH Zurich, INSAIT",
                "text": "This research introduces SLAck, a framework that integrates semantic, location, and appearance cues for open-vocabulary multiple object tracking (MOT). Unlike previous methods that rely on late-stage fusion of these cues, SLAck incorporates them early in the association process, leading to improved performance, especially for novel object classes.",
                "paper-title": "SLAck: Semantic, Location, and Appearance Aware Open-Vocabulary Tracking",
                "image-path": "flux_paper_image/2409.11235_1726701140.png"
            },

            {
                "startTime": "17:15",
                "arxivId": "2409.10702",
                "arxivLink": "https://arxiv.org/abs/2409.10702",
                "title": "AI Annotators Get a Helping Hand (and a Faster Job) with LLMs!",
                "institute": "Meta",
                "text": "This research introduces the Model-in-the-Loop (MILO) framework, which integrates AI/ML models into the data annotation process. Unlike previous work that focuses on comparing models to human annotators, MILO emphasizes collaboration between humans and models, leveraging their strengths to improve efficiency and quality.",
                "paper-title": "Model-in-the-Loop (MILO): Accelerating Multimodal AI Data Annotation with LLMs",
                "image-path": "flux_paper_image/2409.10702_1726699592.png"
            },

            {
                "startTime": "17:38",
                "arxivId": "2409.10803",
                "arxivLink": "https://arxiv.org/abs/2409.10803",
                "title": "Quantum Computing: Not Just for Star Trek Anymore!",
                "institute": "CSIRO, Songshan Lake Materials Laboratory, Peking University...",
                "text": "This research pioneers the use of quantum machine learning (QML) for modeling the Ohmic contact process in GaN high-electron-mobility transistors (HEMTs), a key process in semiconductor fabrication. Previous work has primarily focused on classical machine learning (CML) methods for this purpose.",
                "paper-title": "Quantum Machine Learning for Semiconductor Fabrication: Modeling GaN HEMT Contact Process",
                "image-path": "flux_paper_image/2409.10803_1726700247.png"
            },

            {
                "startTime": "18:08",
                "arxivId": "2409.10870",
                "arxivLink": "https://arxiv.org/abs/2409.10870",
                "title": "LLMs Get a Shortcut: Attention Bypasses Layers for Faster Learning!",
                "institute": "Stanford University",
                "text": "This research introduces a novel approach to large language model (LLM) architecture by incorporating \"attention shortcuts.\" Instead of processing information sequentially through layers, the final layer can directly attend to intermediate layers, allowing it to learn complex dependencies more efficiently. This differs from previous work that focuses on stacking layers without such adaptive connections.",
                "paper-title": "Adaptive Large Language Models By Layerwise Attention Shortcuts",
                "image-path": "flux_paper_image/2409.10870_1726700317.png"
            },

            {
                "startTime": "18:26",
                "arxivId": "2409.10536",
                "arxivLink": "https://arxiv.org/abs/2409.10536",
                "title": "AI Safety: Building a Nuclear-Style Watchdog for the Digital Age?",
                "institute": "The Alan Turing Institute",
                "text": "This research analyzes the potential functions of an international institution for AI safety by drawing parallels to the International Atomic Energy Agency (IAEA) and the International Panel on Climate Change (IPCC). It goes beyond simply comparing these models to identify concrete functions that an international AI safety institution could perform.",
                "paper-title": "The potential functions of an international institution for AI safety. Insights from adjacent policy areas and recent trends",
                "image-path": "flux_paper_image/2409.10536_1726699599.png"
            },

            {
                "startTime": "18:50",
                "arxivId": "2409.10739",
                "arxivLink": "https://arxiv.org/abs/2409.10739",
                "title": "Quantum Evolution: Evolving QAOA on Distributed QPUs",
                "institute": "Science and Technology Facilities Council, IBM",
                "text": "This research introduces a novel approach to optimizing Quantum Approximate Optimization Algorithms (QAOA) by combining a multi-population Evolutionary Algorithm (EA) with QAOA and distributing it across two Quantum Processing Units (QPUs). This differs from previous work that primarily relies on gradient-based optimization methods.",
                "paper-title": "Evolving a Multi-Population Evolutionary-QAOA on Distributed QPUs",
                "image-path": "flux_paper_image/2409.10739_1726701154.png"
            },

            {
                "startTime": "19:19",
                "arxivId": "2409.10587",
                "arxivLink": "https://arxiv.org/abs/2409.10587",
                "title": "Soccer's Got Talent: New Challenges for AI to Spot Fouls, Track Players, and Even Write Commentary!",
                "institute": "University of Liege, King Abdullah University of Science and Technology, Sportradar...",
                "text": "This research introduces novel tasks for computer vision in soccer, including multi-view foul recognition and game state reconstruction, which involve analyzing multiple camera angles to determine foul severity and reconstructing the game state from broadcast videos onto a 2D top-view map.",
                "paper-title": "SoccerNet 2024 Challenges Results",
                "image-path": "flux_paper_image/2409.10587_1726700173.png"
            },

            {
                "startTime": "19:55",
                "arxivId": "2409.10568",
                "arxivLink": "https://arxiv.org/abs/2409.10568",
                "title": "LLMs: From Chatbots to Pandemic Planners?",
                "institute": "MIT",
                "text": "This research introduces AgentTorch, a framework that scales agent-based models (ABMs) to millions of agents while incorporating large language models (LLMs) as agents. This approach allows for more realistic and adaptive agent behavior in ABMs, which is a significant improvement over previous methods that relied on simpler heuristics.",
                "paper-title": "On the limits of agency in agent-based models",
                "image-path": "flux_paper_image/2409.10568_1726700010.png"
            },

            {
                "startTime": "20:18",
                "arxivId": "2409.10876",
                "arxivLink": "https://arxiv.org/abs/2409.10876",
                "title": "Neural Fields: Seeing Through the Fog of Sound in Medical Imaging",
                "institute": "Northwestern University, Caltech, Tsinghua University",
                "text": "This research introduces a new method for photoacoustic computed tomography (PACT) image reconstruction that uses neural fields to estimate the speed of sound (SOS) in tissue. This approach differs from previous methods by directly learning the SOS distribution from the measured signals, rather than assuming a constant SOS or requiring additional measurements.",
                "paper-title": "Neural Fields for Adaptive Photoacoustic Computed Tomography",
                "image-path": "flux_paper_image/2409.10876_1726701091.png"
            },

            {
                "startTime": "20:39",
                "arxivId": "2409.11227",
                "arxivLink": "https://arxiv.org/abs/2409.11227",
                "title": "Remote Sensing Gets a Few-Shot Makeover: A New Benchmark for Land Cover Mapping",
                "institute": "RIKEN, University of Tokyo, Ontario Tech University...",
                "text": "This research introduces a new benchmark dataset for generalized few-shot semantic segmentation in remote sensing, specifically focusing on submeter-level land cover mapping. It extends the OpenEarthMap dataset with 15 fine-grained classes and provides a more realistic evaluation setting that considers both base and novel classes.",
                "paper-title": "Generalized Few-Shot Semantic Segmentation in Remote Sensing: Challenge and Benchmark",
                "image-path": "flux_paper_image/2409.11227_1726700551.png"
            },

            {
                "startTime": "21:12",
                "arxivId": "2409.11032",
                "arxivLink": "https://arxiv.org/abs/2409.11032",
                "title": "AI Opinions: Unraveling the Hidden Structure of Public Comments",
                "institute": "The University of Tokyo, The Canon Institute for Global Studies",
                "text": "This research proposes a novel method for analyzing the hierarchical structure of opinions expressed in text, using large language models (LLMs) to extract key elements and visualize the differences between opposing viewpoints. Unlike previous work that focuses on sentiment analysis or topic modeling, this approach delves deeper into the underlying arguments and perceptions that shape opinions.",
                "paper-title": "Hierarchical Narrative Analysis: Unraveling Perceptions of Generative AI",
                "image-path": "flux_paper_image/2409.11032_1726699731.png"
            },

            {
                "startTime": "21:35",
                "arxivId": "2409.10840",
                "arxivLink": "https://arxiv.org/abs/2409.10840",
                "title": "Time Series Models: Can They Think or Just Memorize?",
                "institute": "CMU",
                "text": "This research explores the reasoning abilities of deep time series forecasting models by evaluating their performance on carefully designed out-of-distribution scenarios. Unlike previous work that focused on memorization, this study investigates whether these models can generalize beyond simply remembering patterns from training data.",
                "paper-title": "Implicit Reasoning in Deep Time Series Forecasting",
                "image-path": "flux_paper_image/2409.10840_1726699617.png"
            },

            {
                "startTime": "21:58",
                "arxivId": "2409.11149",
                "arxivLink": "https://arxiv.org/abs/2409.11149",
                "title": "SAGED: Unmasking Bias in LLMs, One Country at a Time!",
                "institute": "Holistic AI, Stanford University, University College London...",
                "text": "This research introduces SAGED, a comprehensive pipeline for benchmarking bias in LLMs. Unlike existing benchmarks, SAGED addresses limitations like limited scope, contamination, and lack of a fairness baseline. It also incorporates counterfactual branching and baseline calibration to mitigate evaluation distortion.",
                "paper-title": "SAGED: A Holistic Bias-Benchmarking Pipeline for Language Models with Customisable Fairness Calibration",
                "image-path": "flux_paper_image/2409.11149_1726700809.png"
            },

            {
                "startTime": "22:19",
                "arxivId": "2409.10783",
                "arxivLink": "https://arxiv.org/abs/2409.10783",
                "title": "Punctuating the Past: AI Helps Decode Ancient Chinese Texts",
                "institute": "Stanford University",
                "text": "This research extends previous work on predicting line breaks in Korean text by applying a multi-head attention mechanism to a multi-layered LSTM model for punctuation prediction in ancient Chinese texts.",
                "paper-title": "Predicting Punctuation in Ancient Chinese Texts: A Multi-Layered LSTM and Attention-Based Approach",
                "image-path": "flux_paper_image/2409.10783_1726700989.png"
            },

            {
                "startTime": "22:49",
                "arxivId": "2409.11129",
                "arxivLink": "https://arxiv.org/abs/2409.11129",
                "title": "Can Graph Reordering Make GNNs Train Faster? A Study Says Yes!",
                "institute": "Technical University of Munich, University of Bayreuth, University of Toronto",
                "text": "This research investigates the impact of graph reordering on the training time of Graph Neural Networks (GNNs). Unlike previous work that focused on traditional graph processing tasks, this study explores the effectiveness of reordering strategies for GNNs, considering factors like GNN hyperparameters and GPU acceleration.",
                "paper-title": "Can Graph Reordering Speed Up Graph Neural Network Training? An Experimental Study",
                "image-path": "flux_paper_image/2409.11129_1726701324.png"
            },

            {
                "startTime": "23:08",
                "arxivId": "2409.10526",
                "arxivLink": "https://arxiv.org/abs/2409.10526",
                "title": "AI in Digital Therapy: Keeping the Bots in Check!",
                "institute": "Harvard University, University of Michigan, University of Wisconsin-Madison...",
                "text": "This research focuses on developing guidelines for monitoring online decision-making algorithms used in digital interventions, specifically highlighting the importance of fallback methods and issue severity categorization. This approach differs from previous work by providing a structured framework for ensuring both individual safety and data quality in real-time.",
                "paper-title": "Effective Monitoring of Online Decision-Making Algorithms in Digital Intervention Implementation",
                "image-path": "flux_paper_image/2409.10526_1726700835.png"
            },

            {
                "startTime": "23:26",
                "arxivId": "2409.10588",
                "arxivLink": "https://arxiv.org/abs/2409.10588",
                "title": "Anti-Viral Therapy Gets a Game Theory Makeover: Shaping the Future of Immunity",
                "institute": "University of Oxford",
                "text": "This research introduces a novel approach to antibody design that incorporates opponent shaping principles. Unlike traditional methods that focus on the current viral strain, this method considers the potential evolutionary pressures induced by the therapy itself, aiming to design antibodies that can effectively combat future viral variants.",
                "paper-title": "Opponent Shaping for Antibody Development",
                "image-path": "flux_paper_image/2409.10588_1726700929.png"
            },

            {
                "startTime": "23:55",
                "arxivId": "2409.11302",
                "arxivLink": "https://arxiv.org/abs/2409.11302",
                "title": "Tiny Tweaks, Big Results: Fine-Tuning Time Series Models with a Pinch of Fourier Magic",
                "institute": "SpassMed Inc.",
                "text": "This research explores the use of Parameter-Efficient Fine-Tuning (PEFT) techniques for Time Series Foundation Models (TSFMs) in healthcare, specifically for forecasting vital signs in ICU patients. Unlike previous work that focused on LoRA, this study introduces and evaluates other PEFT methods, including BitFit, LayerNorm Tuning, VeRA, and FourierFT.",
                "paper-title": "Beyond LoRA: Exploring Efficient Fine-Tuning Techniques for Time Series Foundational Models",
                "image-path": "flux_paper_image/2409.11302_1726700525.png"
            },

            {
                "startTime": "24:16",
                "arxivId": "2409.10578",
                "arxivLink": "https://arxiv.org/abs/2409.10578",
                "title": "GLEAN: Unmasking the Art Thief - How AI Can Outsmart Style Mimicry Attacks",
                "institute": "California Academy of Mathematics and Science, Massachusetts Institute of Technology",
                "text": "This research introduces GLEAN, a Generative Adversarial Network (GAN) model that utilizes Fast Fourier Convolutions (FFCs) to specifically target and remove perturbations introduced by the Glaze style cloaking tool. This approach differs from previous methods that focused on general image denoising or reconstruction.",
                "paper-title": "GLEAN: Generative Learning for Eliminating Adversarial Noise",
                "image-path": "flux_paper_image/2409.10578_1726701227.png"
            },

            {
                "startTime": "24:36",
                "arxivId": "2409.10838",
                "arxivLink": "https://arxiv.org/abs/2409.10838",
                "title": "Predicting Crime Hotspots: Can AI Help Cops Be More Proactive?",
                "institute": "Lynbrook High School, Harvard University",
                "text": "This research focuses on predicting the urgency of police calls, not just the number of calls, using a combination of temporal, categorical, and spatial data. This differs from previous work that primarily focused on predicting crime categories or call volumes.",
                "paper-title": "Machine Learning for Public Good: Predicting Urban Crime Patterns to Enhance Community Safety",
                "image-path": "flux_paper_image/2409.10838_1726701262.png"
            },

            {
                "startTime": "24:56",
                "arxivId": "2409.11192",
                "arxivLink": "https://arxiv.org/abs/2409.11192",
                "title": "AI Buddies Remember Everything: The Ethical Dilemma of Long-Term Memory in Personal AI",
                "institute": "MIT",
                "text": "This research explores the implications of personal AI assistants and companions equipped with long-term memory (LTM) capabilities. Unlike previous work that focused on short-term memory, this paper delves into the ethical and societal challenges of AI systems that can retain and contextualize past interactions, adapting to user preferences over extended periods.",
                "paper-title": "Towards Ethical Personal AI Applications: Practical Considerations for AI Assistants with Long-Term Memory",
                "image-path": "flux_paper_image/2409.11192_1726700864.png"
            },

            {
                "startTime": "25:12",
                "arxivId": "2409.11170",
                "arxivLink": "https://arxiv.org/abs/2409.11170",
                "title": "Fanfiction: Where Draco Malfoy Gets a Makeover (and It's Not Just His Hair)",
                "institute": "CMU",
                "text": "This study goes beyond simply counting character mentions in fanfiction. It uses computational methods to analyze how characters' semantic associations change across different fan communities, revealing nuanced shifts in how fans perceive and reinterpret characters.",
                "paper-title": "Capturing Differences in Character Representations Between Communities: An Initial Study with Fandom",
                "image-path": "flux_paper_image/2409.11170_1726700023.png"
            },

            {
                "startTime": "25:34",
                "arxivId": "2409.11383",
                "arxivLink": "https://arxiv.org/abs/2409.11383",
                "title": "Space AI Needs Training Wheels: New Study Tests Synthetic Datasets for Vision-Based Navigation",
                "institute": "Airbus Defence and Space, European Space Agency, Headmind...",
                "text": "This research focuses on generating datasets for training machine learning algorithms for vision-based navigation in space. It explores the use of synthetic simulations and laboratory environments to create datasets that can be used to train algorithms that can then be applied to real-world scenarios.",
                "paper-title": "Training Datasets Generation for Machine Learning: Application to Vision Based Navigation",
                "image-path": "flux_paper_image/2409.11383_1726699657.png"
            },

            {
                "startTime": "25:53",
                "arxivId": "2409.11376",
                "arxivLink": "https://arxiv.org/abs/2409.11376",
                "title": "LLMs Learn to Speak Time-Series: A New Language for Data Analysis",
                "institute": "Stanford University",
                "text": "This research focuses on enabling LLMs to reason about time-series data in natural language, unlike previous work that primarily focused on forecasting or converting time-series into text. The authors propose a novel multi-modal approach that combines a lightweight time-series encoder with an LLM, allowing the model to directly extract and understand temporal patterns.",
                "paper-title": "Towards Time Series Reasoning with LLMs",
                "image-path": "flux_paper_image/2409.11376_1726701288.png"
            }
    ],
    "stats": {
        "num_pick": 62,
        "num_total": 282,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202409181849_audio.mp3"
}
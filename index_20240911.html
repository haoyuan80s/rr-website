<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ribbit Ribbit - Discover research the fun way!</title>
    <meta name="description"
        content="Discover top ArXiv papers in AI and machine learning daily with our fresh picks. Browse easily through tweet-sized summaries or listen on-the-go. Make learning engaging and accessible anytime, anywhere.">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Amatic+SC:wght@400;700&family=Dosis:wght@200..800&family=Roboto:wght@300..700&display=swap">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
    <link rel="icon" href="assets/frogFavicon.png" type="image/x-icon">
    <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>
</head>

<body>
    <div id="headerId" class="header"></div>
    <div class="container">
        <div id="topblock">
            <div style="height: 150px;"></div>
            <div class="page-title">DISCOVER RESEARCH THE FUN WAY
            </div>
            <div style="display: flex; flex-direction: column; justify-content: flex-start; align-items: flex-start;">
                <div class="institute-text" style="padding-top: 3px; line-height: 1.2;">
                    Fresh Picks:
                    <span class="highlightNumber">51</span> out of <span class="highlightNumber">264</span> AI papers
                </div>
                <div class="institute-text" style="line-height: 1.2;">that were just released in arXiv on</div>
                <div id="data-default-date" data-date="2024-09-11"></div>
                <input type="text" id="selectedDate" style="text-decoration: underline;" />
            </div>
            <div style=" height: 80px;">
            </div>
        </div>


        <div class="tweet" id="tweet0">
            <div class="start-time-icon" title="Play from here">01:04</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06285" target="_blank">@arXiv
                        2409.06285</a>
                    <span class="tweet-title">Anomaly Detection Gets a Memory Boost: New Research Uses Sequential
                        Reconstruction to Spot Outliers</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel Reconstruction as Sequence (RAS) method for unified
                    unsupervised
                    anomaly detection. Unlike previous methods that focus on reconstructing features independently,
                    RAS
                    leverages a sequence modeling perspective, considering each decoder layer as a step in a
                    sequence.
                    This allows for capturing both sequential and spatial dynamics during feature reconstruction,
                    enhancing contextual awareness.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet1">
            <div class="start-time-icon" title="Play from here">01:27</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06656" target="_blank">@arXiv
                        2409.06656</a>
                    <span class="tweet-title">Sortformer: Diarizing Speakers Like a Boss, One Token at a
                        Time!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">NVIDIA</span>
                </div>
                <div class="primary-text">
                    This research introduces Sort Loss, a novel approach to speaker diarization that leverages the
                    arrival time order of speech segments to resolve permutation issues. Unlike previous end-to-end
                    diarization models that rely on permutation invariant loss (PIL), Sort Loss enables a
                    diarization
                    model to autonomously resolve permutation without relying on PIL.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet2">
            <div class="start-time-icon" title="Play from here">01:50</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06338" target="_blank">@arXiv
                        2409.06338</a>
                    <span class="tweet-title">LLMs: Are They Just Good at Finding Needles or Understanding
                        Haystacks?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Google</span>
                </div>
                <div class="primary-text">
                    This research proposes a framework called DOLCE to automatically categorize long context
                    understanding tasks based on whether they primarily require retrieval or holistic understanding.
                    This differs from previous work that often relies on manual categorization or focuses on general
                    difficulty levels.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet3">
            <div class="start-time-icon" title="Play from here">02:10</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06609" target="_blank">@arXiv
                        2409.06609</a>
                    <span class="tweet-title">CNNs for MRSI: Precision Matters, Not Just Accuracy!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Technical University of Munich, Massachusetts Institute of
                        Technology,
                        University of California San Francisco...</span>
                </div>
                <div class="primary-text">
                    This research focuses on improving the precision of CNNs for magnetic resonance spectroscopic
                    imaging (MRSI) by introducing new dropout techniques. Unlike previous work that primarily
                    focused on
                    mean error metrics, this study emphasizes the importance of comprehensive precision metrics like
                    standard deviations and confidence intervals.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet4">
            <div class="start-time-icon" title="Play from here">02:44</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.05929" target="_blank">@arXiv
                        2409.05929</a>
                    <span class="tweet-title">Multi-Modal Alignment: MoE Makes It a Party!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Geely Automobile Research Institute (Ningbo) Co. Ltd, Peking
                        University, Shenzhen Institute of Advanced Technology Chinese Academy of Sciences</span>
                </div>
                <div class="primary-text">
                    This paper introduces Alt-MoE, a novel multi-modal alignment method that uses a Mixture of
                    Experts
                    (MoE) as a unified connector across modalities. Unlike previous methods that rely on
                    modality-specific connectors, Alt-MoE employs a multi-step sequential alternating unidirectional
                    alignment strategy, which converges to bidirectional alignment over iterations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet5">
            <div class="start-time-icon" title="Play from here">03:09</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06130" target="_blank">@arXiv
                        2409.06130</a>
                    <span class="tweet-title">Model Watermarks: Outsmarting the Backdoor Attackers with
                        In-Distribution
                        Triggers!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Cambridge, Nanjing University of Posts and
                        Telecommunications</span>
                </div>
                <div class="primary-text">
                    This research proposes a new model watermarking scheme called In-distribution Watermark
                    Embedding
                    (IWE) that uses in-distribution trigger sets instead of the traditional out-of-distribution
                    ones.
                    This approach aims to overcome the vulnerability of existing methods to watermark erasure
                    attacks.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet6">
            <div class="start-time-icon" title="Play from here">03:44</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06240" target="_blank">@arXiv
                        2409.06240</a>
                    <span class="tweet-title">Satellite Pose Estimation: When the Sun's a Spotlight, Event Sensors
                        Shine!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Australian Institute for Machine Learning, Massachusetts Institute
                        of
                        Technology</span>
                </div>
                <div class="primary-text">
                    This research proposes a test-time certifiable self-supervision scheme to bridge the Sim2Real
                    gap in
                    event-based satellite pose estimation. Unlike previous work, this method leverages a certifier
                    module to verify the correctness of estimated poses and only backpropagates certified inputs,
                    refining the predicted landmarks and improving pose estimates.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet7">
            <div class="start-time-icon" title="Play from here">04:08</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06107" target="_blank">@arXiv
                        2409.06107</a>
                    <span class="tweet-title">Doppelgänger's Watch: A New Way to Supervise Language Models</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Meta</span>
                </div>
                <div class="primary-text">
                    This paper proposes a novel bicameral architecture for large language models (LLMs) that
                    separates
                    supervision signals from the core helpfulness of the model. Unlike previous approaches that
                    fine-tune the model after pretraining, this method introduces a parallel component called
                    "Doppelgänger" that concurrently supervises the generation process and predicts the supervision
                    score of the generated text.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet8">
            <div class="start-time-icon" title="Play from here">04:29</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06691" target="_blank">@arXiv
                        2409.06691</a>
                    <span class="tweet-title">LLMs Get a Soft Touch: Geometric Averaging for Better Alignment</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Tokyo</span>
                </div>
                <div class="primary-text">
                    This research introduces the concept of "soft preference labels" to improve the alignment of
                    LLMs
                    with human preferences. Unlike previous methods that assume binary preferences, this approach
                    considers the distributional nature of preferences, reflecting the nuanced relationship between
                    responses. The paper proposes a weighted geometric averaging of LLM output likelihood in the
                    loss
                    function, which adjusts the scale of learning loss based on the soft labels.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet9">
            <div class="start-time-icon" title="Play from here">04:53</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.05875" target="_blank">@arXiv
                        2409.05875</a>
                    <span class="tweet-title">Polyp-Spotting AI Gets a Memory Boost: New Feedback System Improves
                        Colonoscopy Accuracy</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Northwestern University, Mayo Clinic, Beth Israel Deaconess Medical
                        Center...</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel "Feedback Attention Network-v2" (FANetv2) for polyp
                    segmentation.
                    Unlike previous methods, FANetv2 iteratively refines its predictions by incorporating
                    information
                    from previous epochs, effectively learning from its mistakes.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet10">
            <div class="start-time-icon" title="Play from here">05:25</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.05976" target="_blank">@arXiv
                        2409.05976</a>
                    <span class="tweet-title">Federated Fine-Tuning: Stacking LLMs for Privacy and Efficiency</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Maryland, Rutgers University, GenBio.ai...</span>
                </div>
                <div class="primary-text">
                    This research introduces FLORA, a federated fine-tuning method for LLMs that uses a
                    stacking-based
                    aggregation mechanism to address the noise and heterogeneity issues present in previous methods
                    like
                    FedIT.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet11">
            <div class="start-time-icon" title="Play from here">05:49</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06189" target="_blank">@arXiv
                        2409.06189</a>
                    <span class="tweet-title">MyGo: Driving Video Generation with a Camera's Eye for Detail!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research introduces MyGo, a framework that generates multi-view driving videos with camera
                    control. Unlike previous methods that focus on controlling other objects in the scene, MyGo uses
                    camera pose parameters to control the movement of the ego vehicle, enhancing the realism and
                    controllability of the generated videos.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet12">
            <div class="start-time-icon" title="Play from here">06:09</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06450" target="_blank">@arXiv
                        2409.06450</a>
                    <span class="tweet-title">AI's Got a New Driving Test: LLMs Build Realistic Scenarios for
                        Autonomous
                        Vehicles</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University, Ministry of Public Security</span>
                </div>
                <div class="primary-text">
                    This research proposes OmniTester, a framework that uses multimodal Large Language Models (LLMs)
                    to
                    generate realistic and diverse scenarios for testing autonomous vehicles. Unlike previous
                    methods
                    that rely on predefined functions or search algorithms, OmniTester leverages the extensive world
                    knowledge and reasoning capabilities of LLMs to create scenarios based on user-defined
                    descriptions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet13">
            <div class="start-time-icon" title="Play from here">06:40</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06164" target="_blank">@arXiv
                        2409.06164</a>
                    <span class="tweet-title">AI Chatbots Can Predict Suicide Risk: A New Lifeline for Mental Health
                        Hotlines?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Beijing University of Technology, Beijing Suicide Research and
                        Prevention Center, WHO Collaborating Center for Research and Training in Suicide
                        Prevention...</span>
                </div>
                <div class="primary-text">
                    This research differs from previous work by analyzing long-form transcribed text from
                    psychological
                    support hotlines, rather than short texts from social media or interviews. It also incorporates
                    a
                    novel LLM-based pipeline that summarizes the text to extract key features and predict future
                    suicidal behavior.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet14">
            <div class="start-time-icon" title="Play from here">07:00</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06443" target="_blank">@arXiv
                        2409.06443</a>
                    <span class="tweet-title">DETR Distillation: Don't Just Match, Group Your Queries!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Beihang University, Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel Group Query Selection (GQS) method for knowledge distillation
                    in
                    Detection Transformers (DETRs). Unlike previous methods that solely focus on positive queries,
                    GQS
                    identifies and selects both positive and hard-negative queries, which are crucial for enhancing
                    distillation outcomes.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet15">
            <div class="start-time-icon" title="Play from here">07:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06559" target="_blank">@arXiv
                        2409.06559</a>
                    <span class="tweet-title">AI Cuts Through the Noise: Machine Learning Speeds Up
                        Optimization</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Toronto, Huawei Technologies Canada</span>
                </div>
                <div class="primary-text">
                    This research introduces a machine learning framework called Learn2Aggregate that focuses on
                    optimizing the generation of Chv´atal-Gomory (CG) cuts in mixed integer linear programming
                    (MILP).
                    Unlike previous work that focused on selecting cuts from existing generators, Learn2Aggregate
                    aims
                    to identify the most useful constraints for aggregation, thereby reducing the computational
                    complexity of the cut generation process.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet16">
            <div class="start-time-icon" title="Play from here">07:55</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06506" target="_blank">@arXiv
                        2409.06506</a>
                    <span class="tweet-title">Point Clouds Get a Laplacian Makeover: Neural Networks to the
                        Rescue!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Peking University</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel method to learn the Laplacian operator for point clouds using
                    graph
                    neural networks (GNNs). Unlike previous methods that rely on local triangulation, this approach
                    directly learns the Laplacian operator from data by mimicking its behavior on a set of probe
                    functions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet17">
            <div class="start-time-icon" title="Play from here">08:12</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06205" target="_blank">@arXiv
                        2409.06205</a>
                    <span class="tweet-title">Say What You Want, Shape It Will Do: Text-to-Shape Displays with
                        LLMs</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Chicago, University of Colorado</span>
                </div>
                <div class="primary-text">
                    This research explores using large language models (LLMs) to generate code that controls
                    pin-based
                    shape displays, allowing users to create dynamic shapes and behaviors through natural language
                    commands. This differs from previous work that relied on pre-programmed behaviors or more
                    complex
                    user interfaces.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet18">
            <div class="start-time-icon" title="Play from here">08:36</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.05884" target="_blank">@arXiv
                        2409.05884</a>
                    <span class="tweet-title">Forecasting the Future: Train Schedules Help Predict Energy Use</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">École Polytechnique Fédérale de Lausanne</span>
                </div>
                <div class="primary-text">
                    This research integrates future contextual information, such as train schedules, into
                    transformer
                    models for energy forecasting, unlike previous work that primarily relied on historical data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet19">
            <div class="start-time-icon" title="Play from here">08:58</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06530" target="_blank">@arXiv
                        2409.06530</a>
                    <span class="tweet-title">Bilevel Optimization: A New Algorithm That's Almost Too Good to Be
                        True!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This paper tackles a specific type of bilevel optimization problem, where the upper-level
                    function
                    is convex and minimized over the optimal solutions of a convex lower-level problem. The authors
                    demonstrate that finding an absolute optimal solution is intractable for first-order methods,
                    and
                    they propose a novel method, FC-BiO, that achieves near-optimal rates for finding weak optimal
                    solutions. This method differs from previous work by reformulating the problem as a functionally
                    constrained problem and leveraging a bisection procedure.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet20">
            <div class="start-time-icon" title="Play from here">09:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06307" target="_blank">@arXiv
                        2409.06307</a>
                    <span class="tweet-title">Chords & Lyrics: A New Recipe for Song Generation</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research introduces chords as a control condition for song generation, a novel approach
                    compared to previous methods that primarily relied on acoustic features.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet21">
            <div class="start-time-icon" title="Play from here">09:49</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06091" target="_blank">@arXiv
                        2409.06091</a>
                    <span class="tweet-title">Tired of Training Thousands of Models? This New Trick Makes Multitask
                        Learning a Breeze!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Northeastern University, Google</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel algorithm, Grad-TAE, that estimates task affinities without
                    repeatedly training models on various task combinations. It leverages the linearization property
                    of
                    deep neural networks, using gradient-based approximations to predict the loss of a model for a
                    specific task combination.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet22">
            <div class="start-time-icon" title="Play from here">10:16</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06129" target="_blank">@arXiv
                        2409.06129</a>
                    <span class="tweet-title">"Paint Your 3D Dreams: New AI Tool Lets You 'Décollage' Shapes with
                        Style"</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Simon Fraser University, Adobe Research, University of
                        Montreal...</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel method for 3D detailization that allows users to control and
                    localize geometric details by "painting" style exemplars onto different regions of a coarse
                    shape.
                    Unlike previous methods that focus on global detailization, this approach enables
                    structure-preserving, high-resolution stylization with more coherent shape details and style
                    transitions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet23">
            <div class="start-time-icon" title="Play from here">10:42</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06702" target="_blank">@arXiv
                        2409.06702</a>
                    <span class="tweet-title">AI Driving Assistants: Now with Built-in Chatbots!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University, Mercedes-Benz Group China Ltd., Shanghai AI
                        Lab</span>
                </div>
                <div class="primary-text">
                    This research introduces Hint-AD, a framework that aligns natural language generation with the
                    intermediate outputs of an end-to-end autonomous driving (AD) model. Unlike previous work that
                    focused on declarative interpretability, Hint-AD incorporates a holistic token mixer and
                    alignment
                    tasks to ensure the generated language is grounded in the AD model's perception, prediction, and
                    planning processes.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet24">
            <div class="start-time-icon" title="Play from here">11:04</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06704" target="_blank">@arXiv
                        2409.06704</a>
                    <span class="tweet-title">GeoCalib: Learning to See the World, One Image at a Time!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">ETH Zurich, Microsoft</span>
                </div>
                <div class="primary-text">
                    This paper introduces GeoCalib, a deep neural network that leverages 3D geometric constraints
                    through an optimization process to estimate camera parameters from a single image. Unlike
                    previous
                    approaches that either rely on classical geometry or are trained end-to-end, GeoCalib combines
                    the
                    best of both worlds, achieving higher accuracy and robustness.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet25">
            <div class="start-time-icon" title="Play from here">11:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06509" target="_blank">@arXiv
                        2409.06509</a>
                    <span class="tweet-title">AI Gets a Brain: Teaching Machines to Think Like Humans</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Technical University of Berlin, Google</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel framework called AligNet, which aims to align deep learning
                    models
                    with human conceptual knowledge by incorporating hierarchical structure into their
                    representations.
                    This differs from previous work by focusing on the multi-level nature of human perception,
                    rather
                    than just local visual features.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet26">
            <div class="start-time-icon" title="Play from here">11:49</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06030" target="_blank">@arXiv
                        2409.06030</a>
                    <span class="tweet-title">Shape Up, Shape Out: Neural Explicit Surface Intersection for Compact
                        3D
                        Models</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of British Columbia, NVIDIA, University of Texas
                        A&M</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel shape representation called NESI (Neural Explicit Surface
                    Intersection) that uses intersections of explicit surfaces, or height-fields, to represent 3D
                    shapes. Unlike previous methods that rely on implicit or parametric representations, NESI
                    combines
                    the advantages of both, enabling efficient in-out queries and parameterization-based tasks.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet27">
            <div class="start-time-icon" title="Play from here">12:14</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06319" target="_blank">@arXiv
                        2409.06319</a>
                    <span class="tweet-title">Fed Up with Big Data? This New FL Scheme Compresses Gradients Like a
                        Boss!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Waterloo, University of Toronto</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel rate-constrained federated learning (RC-FED) framework that
                    directly
                    optimizes the end-to-end compression rate of gradients in federated learning. Unlike existing
                    methods that primarily focus on minimizing distortion, RC-FED aims to minimize distortion while
                    simultaneously ensuring that the encoded gradient rate remains below a predefined threshold.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet28">
            <div class="start-time-icon" title="Play from here">12:43</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06514" target="_blank">@arXiv
                        2409.06514</a>
                    <span class="tweet-title">Simulating the Stock Market with a "K" for "K-Nearest Neighbor"</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Oxford</span>
                </div>
                <div class="primary-text">
                    This research introduces a new method for simulating limit order book (LOB) markets using
                    K-nearest
                    neighbor (K-NN) resampling. Unlike previous methods that rely on explicit modeling choices or
                    deep
                    learning, K-NN resampling is a non-parametric approach that leverages historical data to
                    generate
                    realistic LOB dynamics.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet29">
            <div class="start-time-icon" title="Play from here">13:04</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06328" target="_blank">@arXiv
                        2409.06328</a>
                    <span class="tweet-title">LLMs: Secretly Planning Your Next Paragraph?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Oxford</span>
                </div>
                <div class="primary-text">
                    This research investigates whether LLMs plan ahead for the content of a paragraph by examining
                    the
                    information encoded in the activation of the double newline token. This differs from previous
                    work
                    that primarily focuses on token-level predictions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet30">
            <div class="start-time-icon" title="Play from here">13:28</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06554" target="_blank">@arXiv
                        2409.06554</a>
                    <span class="tweet-title">Global Trade: It's Not Just Supply and Demand, It's a Costly
                        Dance!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Cambridge</span>
                </div>
                <div class="primary-text">
                    This research uses optimal transport theory to model global trade, which is different from
                    traditional gravity models that rely on explicit covariates.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet31">
            <div class="start-time-icon" title="Play from here">13:49</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06029" target="_blank">@arXiv
                        2409.06029</a>
                    <span class="tweet-title">SongCreator: Turning Lyrics into Hits, One Note at a Time!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University, The Chinese University of Hong Kong</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel dual-sequence language model (DSLM) for song generation. Unlike
                    previous models that treat vocals and accompaniment as a single entity, DSLM models them
                    separately,
                    capturing their mutual influence to create more harmonious and natural-sounding songs.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet32">
            <div class="start-time-icon" title="Play from here">14:15</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06427" target="_blank">@arXiv
                        2409.06427</a>
                    <span class="tweet-title">Robots Learn to Be Body-Smart: A New Model for Multisensory
                        Learning</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Tokyo</span>
                </div>
                <div class="primary-text">
                    This research proposes a Generalized Multisensory Correlational Model (GeMuCo) that allows
                    robots to
                    learn a body schema, which describes the relationship between sensors and actuators, from their
                    own
                    experience. This differs from previous work that relies on human-designed network structures and
                    assumptions about the robot's body.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet33">
            <div class="start-time-icon" title="Play from here">14:38</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.05873" target="_blank">@arXiv
                        2409.05873</a>
                    <span class="tweet-title">Molecule Design: A Recipe for Success, One Syntactic Skeleton at a
                        Time!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">MIT, IBM</span>
                </div>
                <div class="primary-text">
                    This research introduces a bilevel framework for molecule design and synthesis, decoupling the
                    syntactic skeleton of a synthetic tree from its chemical semantics. This approach differs from
                    previous work by leveraging ideas from syntax-guided synthesis, allowing for more granular
                    optimization of both syntactic and semantic aspects of reaction pathways.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet34">
            <div class="start-time-icon" title="Play from here">15:00</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06560" target="_blank">@arXiv
                        2409.06560</a>
                    <span class="tweet-title">Deep Learning Gets a Physics Makeover: Variational Inference for
                        Uncertainty Quantification</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Cambridge</span>
                </div>
                <div class="primary-text">
                    This paper provides a comprehensive overview of variational inference (VI) for physics-informed
                    deep
                    generative modeling. It distinguishes itself by unifying recent literature on VI applications in
                    physics, presenting a clear framework for understanding the similarities and differences between
                    various methodologies.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet35">
            <div class="start-time-icon" title="Play from here">15:23</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06080" target="_blank">@arXiv
                        2409.06080</a>
                    <span class="tweet-title">LLMs: Not Just for Chatbots Anymore! They Can Predict Molecular
                        Properties
                        Too!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Wisconsin-Madison, The Pennsylvania State
                        University</span>
                </div>
                <div class="primary-text">
                    This research explores the ability of large language models (LLMs) to perform regression tasks
                    for
                    predicting molecular and materials properties, a departure from their traditional use in natural
                    language processing. Unlike previous work that focused on classification or used more granular
                    molecular representations, this study investigates the effectiveness of LLMs trained solely on
                    textual prompts like SMILES strings and material compositions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet36">
            <div class="start-time-icon" title="Play from here">15:56</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06111" target="_blank">@arXiv
                        2409.06111</a>
                    <span class="tweet-title">Robots Get a Sixth Sense: New AI Helps Them Navigate Unfamiliar
                        Terrain</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">UC Berkeley</span>
                </div>
                <div class="primary-text">
                    This research introduces a probabilistic and reconstruction-based competency estimation (PaRCE)
                    method to assess the reliability of perception models used in robot navigation. Unlike previous
                    methods that focus on overall uncertainty, PaRCE estimates competency at both the image and
                    regional
                    levels, providing a more nuanced understanding of the model's strengths and weaknesses.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet37">
            <div class="start-time-icon" title="Play from here">16:23</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06613" target="_blank">@arXiv
                        2409.06613</a>
                    <span class="tweet-title">Robot Learns Dexterous Skills with Just a Few Tips!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Google DeepMind</span>
                </div>
                <div class="primary-text">
                    This research introduces DemoStart, an auto-curriculum method for reinforcement learning that
                    leverages demonstrations to guide the learning process. Unlike previous approaches that rely on
                    large datasets of demonstrations or complex reward design, DemoStart uses a small number of
                    sub-optimal demonstrations and a simple sparse reward to train policies that can solve complex
                    manipulation tasks.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet38">
            <div class="start-time-icon" title="Play from here">16:50</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06639" target="_blank">@arXiv
                        2409.06639</a>
                    <span class="tweet-title">TeXBLEU: A Metric That Makes LaTeX Formulas Sing!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Chung-Ang University, Seoul National University, NVIDIA</span>
                </div>
                <div class="primary-text">
                    This research introduces TeXBLEU, a new evaluation metric specifically designed for assessing
                    the
                    quality of mathematical expressions written in LaTeX format. Unlike existing metrics like BLEU,
                    which often struggle with the unique syntax of LaTeX, TeXBLEU leverages a specialized tokenizer
                    and
                    embedding model trained on a massive dataset of arXiv papers.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet39">
            <div class="start-time-icon" title="Play from here">17:17</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06231" target="_blank">@arXiv
                        2409.06231</a>
                    <span class="tweet-title">Shape Shifting: A Neural Network That Knows When to Zoom In!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">École Polytechnique Fédérale de Lausanne, Max Planck Society</span>
                </div>
                <div class="primary-text">
                    This paper introduces a new method for representing 3D shapes using implicit neural networks.
                    Unlike
                    previous methods that only provide a single level of detail, this approach allows for multiple
                    levels of detail, enabling the network to represent shapes at different resolutions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet40">
            <div class="start-time-icon" title="Play from here">17:47</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06608" target="_blank">@arXiv
                        2409.06608</a>
                    <span class="tweet-title">AI for Search and Rescue: Simulating the Real World, One Snowstorm at
                        a
                        Time!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Microsoft</span>
                </div>
                <div class="primary-text">
                    This research introduces HAMERITT, a simulation-based autonomy framework that generates
                    scenarios
                    with both raw sensor data and symbolic context, unlike previous UAV simulation environments.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet41">
            <div class="start-time-icon" title="Play from here">18:11</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06053" target="_blank">@arXiv
                        2409.06053</a>
                    <span class="tweet-title">Min-Max Games: A Statistical Physics Approach to Saddle Point
                        Problems</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Tokyo, Fujitsu</span>
                </div>
                <div class="primary-text">
                    This research introduces a statistical mechanical formalism for analyzing min-max problems in
                    the
                    high-dimensional limit, addressing the order of operations for min and max. It differs from
                    previous
                    work by explicitly considering the distinct effects of min and max operations in non-convex
                    settings.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet42">
            <div class="start-time-icon" title="Play from here">18:33</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.05871" target="_blank">@arXiv
                        2409.05871</a>
                    <span class="tweet-title">Prosthetic Wrist Woes? A Heatmap Reveals Where Your Body
                        Compensates!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Imperial College London, UC Berkeley</span>
                </div>
                <div class="primary-text">
                    This research analyzed compensatory motions in the final pose of reaching movements, using a
                    discretely sampled workspace and a novel Compensation Index that combines multiple evaluation
                    metrics. Unlike previous studies, it standardized the target locations and incorporated a more
                    comprehensive evaluation approach.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet43">
            <div class="start-time-icon" title="Play from here">18:59</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06605" target="_blank">@arXiv
                        2409.06605</a>
                    <span class="tweet-title">Interactive Deep Learning: Giving Cancer Segmentation a Helping
                        Hand!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Aalto University, University of Tampere, Tampere
                        University...</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel two-stage interactive click refinement (2S-ICR) framework for
                    segmenting primary gross tumor volume (GTVp) in oropharyngeal cancer (OPC). Unlike previous
                    interactive deep learning (DL) methods that rely on a single model, 2S-ICR utilizes two distinct
                    models: a standard DL model for initial segmentation and an interactive DL model for refinement.
                    This approach aims to avoid the trade-off between non-interactive and interactive performance
                    often
                    seen in single-model approaches.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet44">
            <div class="start-time-icon" title="Play from here">19:32</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.05907" target="_blank">@arXiv
                        2409.05907</a>
                    <span class="tweet-title">LLMs Get a Refusal Switch: Programming AI to Say "No" Only When It
                        Matters</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Pennsylvania, IBM</span>
                </div>
                <div class="primary-text">
                    This research introduces Conditional Activation Steering (CAST), a method that allows for
                    selective
                    control over LLM responses based on the input context. Unlike previous activation steering
                    methods,
                    which indiscriminately alter LLM behavior, CAST analyzes activation patterns to determine when
                    to
                    apply steering.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet45">
            <div class="start-time-icon" title="Play from here">19:55</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.05934" target="_blank">@arXiv
                        2409.05934</a>
                    <span class="tweet-title">DOMINO: A Random Walk to Predict Your Electricity Bill (and Save the
                        Planet!)</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University College London</span>
                </div>
                <div class="primary-text">
                    This research introduces a new algorithm called DOMINO, which uses a random walk on Gaussian
                    Processes (GPs) to predict electricity consumption. This approach is more frugal than previous
                    methods, requiring less training data and computational resources.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet46">
            <div class="start-time-icon" title="Play from here">20:33</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.05919" target="_blank">@arXiv
                        2409.05919</a>
                    <span class="tweet-title">AI for Business: No Data Scientist Required!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">IBM</span>
                </div>
                <div class="primary-text">
                    This research introduces KModels, a framework that simplifies AI deployment and management for
                    business applications, particularly in on-premises environments. Unlike previous frameworks,
                    KModels
                    focuses on making AI accessible to non-technical users by abstracting away complex technical
                    details
                    and providing a template-driven approach.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet47">
            <div class="start-time-icon" title="Play from here">20:56</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06219" target="_blank">@arXiv
                        2409.06219</a>
                    <span class="tweet-title">Denoising: It's Not Just for Noise Removal Anymore!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Google</span>
                </div>
                <div class="primary-text">
                    This paper presents a comprehensive perspective on denoisers, their structure, and desired
                    properties, emphasizing their increasing importance as building blocks for complex tasks in
                    imaging,
                    inverse problems, and machine learning. It goes beyond simply removing noise and explores the
                    broader applications of denoising.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet48">
            <div class="start-time-icon" title="Play from here">21:11</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06520" target="_blank">@arXiv
                        2409.06520</a>
                    <span class="tweet-title">Hyperspectral Cameras Get a Boresight Makeover: No More Blurry
                        Views!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">École Polytechnique Fédérale de Lausanne</span>
                </div>
                <div class="primary-text">
                    This research proposes a new method for automatically calibrating the boresight of hyperspectral
                    cameras using only the raw spectral imagery and GPS/INS data, even when the GPS/INS data is
                    noisy or
                    imprecise. This approach differs from previous methods that rely on precise GPS/INS estimates
                    and
                    detailed terrain models.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet49">
            <div class="start-time-icon" title="Play from here">21:32</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06437" target="_blank">@arXiv
                        2409.06437</a>
                    <span class="tweet-title">Linear Models: A New Information-Theoretic Twist!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Pennsylvania</span>
                </div>
                <div class="primary-text">
                    This paper presents a novel information-theoretic proof for the consistency of the Gaussian
                    maximum
                    likelihood estimator in linear auto-regressive models. Unlike previous work that relied on
                    comparing
                    empirical and population risk functionals, this approach avoids direct comparison and instead
                    leverages tools from information theory.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet50">
            <div class="start-time-icon" title="Play from here">21:51</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.05868" target="_blank">@arXiv
                        2409.05868</a>
                    <span class="tweet-title">Specular Spectacle: 3D Gaussian Splatting Gets a Shiny Upgrade!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Beihang University, Peking University</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel approach to 3D Gaussian Splatting by replacing spherical
                    harmonics
                    with latent neural descriptors. This allows for a more efficient representation of 3D feature
                    fields, including geometry and appearance.
                </div>
            </div>
        </div>

        <div
            style="padding: 50px 0; text-align: center; margin: 5px 0; font-weight: 300; font-size: 10px; color: #000000;">
            Opening music
            from <a href="https://ikson.com" target="_blank" style="color: black; text-decoration: none;">TELL
                YOUR STORY by ikson</a></div>
        <div style="height: 50px;"></div>
    </div>

    <footer class="player-footer">
        <div class="player-detail-hidden-on-small-screen">
            <div id="audio-title" class="tweet-title-small">Hit play and learn on the go!</div>
            <div style="height: 2px;"></div>
            <div id="audio-institutes" class="institute-text-small"></div>
        </div>
        <div class="control-panel">
            <div class="control-horizontal">
                <div id="playSpeedButton" title="Adjust speed">
                    <div id="selectedSpeed">1&times;</div>
                    <div class="speedMenuItems">
                        <div data-value="0.6">Speed 0.6&times;</div>
                        <div data-value="0.8">Speed 0.8&times;</div>
                        <div data-value="1" class="selected">Speed 1&times;</div>
                        <div data-value="1.2">Speed 1.2&times;</div>
                        <div data-value="1.4">Speed 1.4&times;</div>
                        <div data-value="1.6">Speed 1.6&times;</div>
                    </div>
                    <select id="speedOptionsHidden">
                        <option value="0.6">0.6&times;</option>
                        <option value="0.8">0.8&times;</option>
                        <option value="1" selected>1&times;</option>
                        <option value="1.2">1.2&times;</option>
                        <option value="1.4">1.4&times;</option>
                        <option value="1.6">1.6&times;</option>
                    </select>
                </div>
                <div id="playLastButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(false)" title="Play last" disabled>
                        <img src="assets/buttonLastEpisode.svg" alt="Last" style="width: 12px;">
                    </button>
                </div>
                <button class="controllerButton" onclick="scrollToCurrentTweet()" title="Scoll to the current episode">
                    <img id="locateImage" src="assets/buttonTarget.svg" alt="Locate">
                </button>
                <button class="controllerButton" onclick="togglePlayPause()" title="Play/Pause">
                    <img id="playPauseImage" src="assets/buttonPlay.svg" alt="Play">
                </button>
                <div id="playNextButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(true)" title="Play next" disabled>
                        <img src="assets/buttonNextEpisode.svg" alt="Next" style="width: 12px;">
                    </button>
                </div>
            </div>
            <div class="control-horizontal">
                <div id="progressTime">0:00</div>
                <div id="progressContainer" onclick="seek(event)">
                    <div id="progressBar"></div>
                    <div id="progressCircle" draggable="true"></div>
                </div>
                <audio id="audioPlayer"
                    src="https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202409111311_audio.mp3"></audio>
                <div id="progressTime"><span id="audioDuration">Loading...</span></div>
            </div>
        </div>
    </footer>
    <div id="privacyModal" class="modal"></div>
    <script src="script.js"></script>
    <script src="calendar.js"></script>
    <script>
        fetch('https://ribbitribbit.co/header.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('headerId').innerHTML = data;
            })
            .catch(error => console.error('Error loading header.html:', error));
        fetch('https://ribbitribbit.co/terms.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('privacyModal').innerHTML = data;
            })
            .catch(error => console.error('Error loading terms.html:', error));
    </script>
</body>

</html>
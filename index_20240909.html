<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ribbit Ribbit - Discover research the fun way!</title>
    <meta name="description"
        content="Discover top ArXiv papers in AI and machine learning daily with our fresh picks. Browse easily through tweet-sized summaries or listen on-the-go. Make learning engaging and accessible anytime, anywhere.">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Amatic+SC:wght@400;700&family=Dosis:wght@200..800&family=Roboto:wght@300..700&display=swap">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
    <link rel="icon" href="assets/frogFavicon.png" type="image/x-icon">
    <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>
</head>

<body>
    <div id="headerId" class="header"></div>
    <div class="container">
        <div id="topblock">
            <div style="height: 150px;"></div>
            <div class="page-title">DISCOVER RESEARCH THE FUN WAY
            </div>
            <div style="display: flex; flex-direction: column; justify-content: flex-start; align-items: flex-start;">
                <div class="institute-text" style="padding-top: 3px; line-height: 1.2;">
                    Fresh Picks:
                    <span class="highlightNumber" style="font-size: 28px;">38</span> out of <span
                        class="highlightNumber">200</span> AI papers
                </div>
                <div class="institute-text" style="line-height: 1.2;">that were just released in arXiv on</div>
                <div id="data-default-date" data-date="2024-09-09"></div>
                <input type="text" id="selectedDate" style="text-decoration: underline;" />
            </div>
            <div style=" height: 80px;">
            </div>
        </div>


        <div class="tweet" id="tweet0">
            <div class="start-time-icon" title="Play from here">01:01</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04440" target="_blank">@arXiv
                        2409.04440</a>
                    <span class="tweet-title">Dancing Duo: AI Predicts Partner's Moves, One Step at a Time!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">UC Berkeley, UT Austin</span>
                </div>
                <div class="primary-text">
                    This research focuses on predicting the motion of one dancer in a couple dance by considering
                    the
                    partner's movements, unlike previous work that primarily focused on predicting individual
                    motion.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet1">
            <div class="start-time-icon" title="Play from here">01:20</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03891" target="_blank">@arXiv
                        2409.03891</a>
                    <span class="tweet-title">Ridgeless Regression: Overfitting's Not Always Bad, But It's Usually
                        Worse
                        Than Doing Nothing!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Chicago, Weizmann Institute of Science, Toyota
                        Technological Institute at Chicago</span>
                </div>
                <div class="primary-text">
                    This research explores the overfitting behavior of Gaussian kernel ridgeless regression when the
                    input dimension or bandwidth changes with the sample size. Unlike previous work that focused on
                    polynomial scaling of the dimension, this paper investigates sub-polynomial scaling and varying
                    bandwidth.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet2">
            <div class="start-time-icon" title="Play from here">01:48</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04188" target="_blank">@arXiv
                        2409.04188</a>
                    <span class="tweet-title">Benchmarks Behaving Badly: Why Spurious Correlation Research Needs a
                        Reality Check</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Meta</span>
                </div>
                <div class="primary-text">
                    This research investigates the validity of benchmarks used to evaluate methods for mitigating
                    spurious correlations in machine learning models. It introduces a new model-dependent statistic,
                    K,
                    to quantify task difficulty due to spurious correlations and uses it to assess the agreement
                    between
                    different benchmarks.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet3">
            <div class="start-time-icon" title="Play from here">02:11</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04109" target="_blank">@arXiv
                        2409.04109</a>
                    <span class="tweet-title">Can AI Write Your Next Research Paper? ðŸ¤” A Study with 100+ NLP
                        Experts!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Stanford University</span>
                </div>
                <div class="primary-text">
                    This research directly compares AI-generated research ideas to those written by human experts,
                    using
                    a large-scale blind review process. Unlike previous work, it doesn't rely on surrogate
                    evaluations
                    or smaller sample sizes.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet4">
            <div class="start-time-icon" title="Play from here">02:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04206" target="_blank">@arXiv
                        2409.04206</a>
                    <span class="tweet-title">Fast Forwarding to Faster AI: A New Trick for Training Big Language
                        Models</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Technion â€“ Israel Institute of Technology, Harvard
                        University</span>
                </div>
                <div class="primary-text">
                    This paper introduces Fast Forward, a new optimization strategy that accelerates low-rank
                    training
                    of large language models (LLMs). Unlike previous approaches that focus on adjusting learning
                    rates,
                    Fast Forward repeatedly applies the most recent optimizer step until the model's performance on
                    a
                    small validation set stops improving.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet5">
            <div class="start-time-icon" title="Play from here">02:46</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03773" target="_blank">@arXiv
                        2409.03773</a>
                    <span class="tweet-title">Protein-RNA Love Story: A Language Model Matchmaker Predicts Binding
                        Affinity</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University, University College London, Monash
                        University...</span>
                </div>
                <div class="primary-text">
                    This research proposes CoPRA, a novel method that combines protein and RNA language models with
                    complex structure information for protein-RNA binding affinity prediction. Unlike previous
                    methods
                    that rely solely on sequence or structure features, CoPRA leverages the strengths of both
                    domains to
                    provide a more comprehensive understanding of the binding mechanism.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet6">
            <div class="start-time-icon" title="Play from here">03:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03905" target="_blank">@arXiv
                        2409.03905</a>
                    <span class="tweet-title">Cancer Notes: Decoding the Drug-Symptom Tango!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Washington</span>
                </div>
                <div class="primary-text">
                    This research introduces CACER, a new corpus of annotated oncology notes, focusing on the
                    relationships between cancer drugs, symptoms, and other medical problems. Unlike previous work,
                    CACER provides fine-grained annotations for both events (drug and medical problem mentions) and
                    relations between them.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet7">
            <div class="start-time-icon" title="Play from here">04:03</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04313" target="_blank">@arXiv
                        2409.04313</a>
                    <span class="tweet-title">Censored Data: The Secret Weapon for Drug Discovery?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">AstraZeneca ELLIS Unit Linz Johannes Kepler University Linz KU
                        Leuven
                        Cambridge Chalmers University of Technology</span>
                </div>
                <div class="primary-text">
                    This research adapts existing machine learning models to incorporate censored labels, which are
                    common in drug discovery experiments but often ignored. This allows models to learn from more
                    data,
                    potentially improving accuracy and uncertainty quantification.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet8">
            <div class="start-time-icon" title="Play from here">04:27</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04367" target="_blank">@arXiv
                        2409.04367</a>
                    <span class="tweet-title">Pfaffian Power: Tuning Algorithms with a Touch of Math Magic!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU, Toyota Technological Institute at Chicago</span>
                </div>
                <div class="primary-text">
                    This research extends the GJ framework to handle Pfaffian functions, a broader class than
                    rational
                    functions, allowing for more accurate analysis of data-driven algorithm design problems.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet9">
            <div class="start-time-icon" title="Play from here">04:52</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03889" target="_blank">@arXiv
                        2409.03889</a>
                    <span class="tweet-title">Brain Scans: From Research to Reality - A New Tool for Analyzing
                        Clinical
                        MRI Data</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Harvard University</span>
                </div>
                <div class="primary-text">
                    This research introduces a new method called "recon-all-clinical" that can analyze brain MRI
                    scans
                    of any resolution and contrast, unlike previous methods that were limited to high-resolution,
                    isotropic scans. This method uses a hybrid approach that combines a convolutional neural network
                    (CNN) with classical geometry processing to predict signed distance functions (SDFs) for surface
                    reconstruction.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet10">
            <div class="start-time-icon" title="Play from here">05:15</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04081" target="_blank">@arXiv
                        2409.04081</a>
                    <span class="tweet-title">UI-JEPA: A Tiny AI That Knows What You're Trying to Do</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Stanford University, Apple</span>
                </div>
                <div class="primary-text">
                    This research proposes UI-JEPA, a framework that uses self-supervised learning to generate
                    abstract
                    UI embeddings. Unlike previous work that relies on large, computationally expensive models,
                    UI-JEPA
                    uses a lightweight model and achieves comparable performance with significantly reduced
                    annotation
                    and deployment resources.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet11">
            <div class="start-time-icon" title="Play from here">05:41</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04410" target="_blank">@arXiv
                        2409.04410</a>
                    <span class="tweet-title">Open-MAGVIT2: Unlocking Visual Generation with a Super-Large
                        Codebook!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tencent PCG, Tsinghua University, Nanjing University</span>
                </div>
                <div class="primary-text">
                    This research introduces Open-MAGVIT2, an open-source replication of Google's MAGVIT-v2
                    tokenizer,
                    which features a super-large codebook (2^18 codes). This differs from previous work by achieving
                    state-of-the-art reconstruction performance on ImageNet and exploring its application in plain
                    auto-regressive models.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet12">
            <div class="start-time-icon" title="Play from here">06:07</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04429" target="_blank">@arXiv
                        2409.04429</a>
                    <span class="tweet-title">VILA-U: One Model to Rule Them All (Visual Understanding &
                        Generation)</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University, MIT, NVIDIA...</span>
                </div>
                <div class="primary-text">
                    This paper introduces VILA-U, a unified foundation model that uses a single autoregressive
                    next-token prediction framework for both visual understanding and generation. Unlike previous
                    models
                    that rely on separate modules for these tasks, VILA-U simplifies the architecture and achieves
                    comparable performance.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet13">
            <div class="start-time-icon" title="Play from here">06:33</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04341" target="_blank">@arXiv
                        2409.04341</a>
                    <span class="tweet-title">Webpage Fingerprinting: Tor's New Nemesis Can Tell What You're
                        Reading!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University, George Mason University</span>
                </div>
                <div class="primary-text">
                    This research focuses on identifying specific webpages within a website, rather than just the
                    website itself, and it does so while accounting for the complex traffic patterns created when
                    users
                    browse multiple webpages simultaneously.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet14">
            <div class="start-time-icon" title="Play from here">06:58</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03881" target="_blank">@arXiv
                        2409.03881</a>
                    <span class="tweet-title">Traffic Jam? Let's Predict Our Way Out!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">MIT</span>
                </div>
                <div class="primary-text">
                    This research introduces a new algorithm called BK-PBS that incorporates a behavior prediction
                    model
                    to coordinate autonomous vehicles (CAVs) with human-driven vehicles (HDVs) in mixed-traffic
                    environments. Unlike previous work that focused on full autonomy or reactive coordination,
                    BK-PBS
                    aims for proactive coordination by predicting HDV responses to CAV maneuvers.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet15">
            <div class="start-time-icon" title="Play from here">07:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04320" target="_blank">@arXiv
                        2409.04320</a>
                    <span class="tweet-title">Sampling from Polytopes: A Dikin Walk with a Faster Pace!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Worcester Polytechnic Institute, Yale University</span>
                </div>
                <div class="primary-text">
                    This research improves the runtime of the soft-threshold Dikin walk algorithm for sampling from
                    log-concave distributions over polytopes by leveraging efficient linear solvers that exploit the
                    slow change in the Hessian of the log-barrier function. This approach differs from previous work
                    by
                    reducing the per-iteration complexity from roughly mdÏ‰âˆ’1 to nnz(A)+d2 arithmetic operations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet16">
            <div class="start-time-icon" title="Play from here">07:55</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04040" target="_blank">@arXiv
                        2409.04040</a>
                    <span class="tweet-title">LLM on Your Phone? No Problem, We've Got KV-Shield!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Central South University, Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This paper focuses on protecting the privacy of user conversations during on-device LLM
                    inference by
                    addressing the vulnerability of KV cache leakage. Unlike previous work that focused on model
                    weight
                    protection, this research proposes a novel permutation-based approach to safeguard the KV pairs.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet17">
            <div class="start-time-icon" title="Play from here">08:17</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03856" target="_blank">@arXiv
                        2409.03856</a>
                    <span class="tweet-title">LLMs: Sparsity's Secret Weapon - A Few Token Corrections Go a Long
                        Way!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU, Stevens Institute of Technology, Meta</span>
                </div>
                <div class="primary-text">
                    This research explores the limitations of contextual sparsity (CS) in large language models
                    (LLMs)
                    for complex reasoning tasks. It proposes Sirius, a correction mechanism that uses the full model
                    to
                    selectively correct sparse model outputs, improving performance without sacrificing efficiency.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet18">
            <div class="start-time-icon" title="Play from here">08:43</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04373" target="_blank">@arXiv
                        2409.04373</a>
                    <span class="tweet-title">Fraud Detection: Is Your AI Biased Againstâ€¦ Your Gender?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Warwick, University of Cambridge</span>
                </div>
                <div class="primary-text">
                    This research focuses on evaluating fairness in transaction fraud models, a domain that has been
                    largely overlooked in previous algorithmic fairness studies. The paper highlights the unique
                    challenges of this domain, such as class imbalance and the need to balance fraud protection with
                    service quality.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet19">
            <div class="start-time-icon" title="Play from here">09:10</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04421" target="_blank">@arXiv
                        2409.04421</a>
                    <span class="tweet-title">LLMs Get a Memory Boost: Reinforcement Learning Makes User Summaries
                        Super
                        Useful!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Google</span>
                </div>
                <div class="primary-text">
                    This research introduces a new method called Reinforcement Learning from Prediction Feedback
                    (RLPF)
                    for training user summarization models. Unlike previous approaches that rely on reference
                    summaries
                    or human feedback, RLPF uses the performance of the generated summaries on downstream tasks as a
                    reward signal.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet20">
            <div class="start-time-icon" title="Play from here">09:33</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03769" target="_blank">@arXiv
                        2409.03769</a>
                    <span class="tweet-title">Solving the Scope 3 Puzzle: A Machine Learning Approach to Unlocking
                        Climate Impact Data</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Microsoft</span>
                </div>
                <div class="primary-text">
                    This research proposes a semi-supervised learning framework to identify substitute parts for
                    complex
                    assemblies, leveraging product Bill of Material (BOM) data and a small amount of component-level
                    qualified substitute data. This approach differs from previous work by focusing on
                    non-homophilous
                    graph structures and introducing a strategy to generate biased negative samples to enhance the
                    training process.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet21">
            <div class="start-time-icon" title="Play from here">09:53</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04409" target="_blank">@arXiv
                        2409.04409</a>
                    <span class="tweet-title">Train Till You Drop: 3D Domain Adaptation Gets a Stability
                        Boost!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CNRS, Valeo.ai, Univ. Bretagne Sud...</span>
                </div>
                <div class="primary-text">
                    This research tackles the problem of source-free unsupervised domain adaptation (SFUDA) for 3D
                    semantic segmentation. Unlike previous methods, it introduces an unsupervised stopping criterion
                    to
                    prevent performance degradation during training. This criterion measures the agreement between
                    the
                    trained model and a reference model, allowing for hyperparameter-free adaptation.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet22">
            <div class="start-time-icon" title="Play from here">10:17</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03992" target="_blank">@arXiv
                        2409.03992</a>
                    <span class="tweet-title">GPU Security: Confidential Computing Gets a Speed Boost!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Phala Network</span>
                </div>
                <div class="primary-text">
                    This research benchmarks the performance impact of Trusted Execution Environments (TEEs) on
                    NVIDIA
                    H100 GPUs for large language model (LLM) inference tasks, focusing on the overhead introduced by
                    TEE
                    mode across various models and token lengths.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet23">
            <div class="start-time-icon" title="Play from here">10:37</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04142" target="_blank">@arXiv
                        2409.04142</a>
                    <span class="tweet-title">Vision Transformers: A Backdoor for Your In-Context Learning
                        Dreams!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Radboud University, University College London, Ikerlan Research
                        Centre</span>
                </div>
                <div class="primary-text">
                    This research explores backdoor attacks specifically targeting vision transformers (ViTs) that
                    utilize in-context learning. Unlike previous work on LLMs, this paper focuses on the unique
                    challenges of backdoor attacks in the visual domain, where the model's output is an image rather
                    than a label.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet24">
            <div class="start-time-icon" title="Play from here">10:58</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03956" target="_blank">@arXiv
                        2409.03956</a>
                    <span class="tweet-title">Algorithms Collude Without Threats: The Price of No-Regret</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Pennsylvania, Georgia Tech</span>
                </div>
                <div class="primary-text">
                    This paper explores a new mechanism for algorithmic collusion, demonstrating that
                    supra-competitive
                    prices can emerge even when algorithms don't explicitly encode threats. Unlike previous work
                    that
                    focused on threats as the primary driver of collusion, this study highlights the role of
                    commitment
                    and optimization in driving supra-competitive outcomes.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet25">
            <div class="start-time-icon" title="Play from here">11:22</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03833" target="_blank">@arXiv
                        2409.03833</a>
                    <span class="tweet-title">AI Predicts Black Hole Mergers: It's Not Just the 'L=2' Mode
                        Anymore!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Argonne National Laboratory, University of Illinois
                        Urbana-Champaign,
                        University of Minnesota...</span>
                </div>
                <div class="primary-text">
                    This research extends previous AI models for gravitational wave forecasting by incorporating
                    higher-order wave modes, which are more complex and provide a richer understanding of the merger
                    process.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet26">
            <div class="start-time-icon" title="Play from here">11:55</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03797" target="_blank">@arXiv
                        2409.03797</a>
                    <span class="tweet-title">LLMs: Not So Smart When APIs Get Nested!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">IBM</span>
                </div>
                <div class="primary-text">
                    This research introduces NESTFUL, a benchmark specifically designed to evaluate LLMs on nested
                    sequences of API calls, where the output of one API call is used as input for subsequent calls.
                    This
                    differs from existing benchmarks that focus on single or multiple isolated API calls.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet27">
            <div class="start-time-icon" title="Play from here">12:14</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04196" target="_blank">@arXiv
                        2409.04196</a>
                    <span class="tweet-title">Single Image, 3D Human: A Transformer's Tale of Gaussian
                        Splats!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Oxford</span>
                </div>
                <div class="primary-text">
                    This paper proposes a new method called GST (Gaussian Splatting Transformer) for reconstructing
                    3D
                    human models from a single image. Unlike previous methods that rely on diffusion priors or
                    expensive
                    3D supervision, GST leverages multi-view supervision and predicts a 3D Gaussian Splatting
                    representation, enabling fast rendering and flexible editing.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet28">
            <div class="start-time-icon" title="Play from here">12:42</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04069" target="_blank">@arXiv
                        2409.04069</a>
                    <span class="tweet-title">Pedestrian Prediction: When Offline Experts Meet Online
                        Learning</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">ETH Zurich</span>
                </div>
                <div class="primary-text">
                    This research proposes Online Residual Learning (ORL), a method that combines offline
                    predictions
                    with online adaptation to improve pedestrian trajectory prediction. Unlike previous work that
                    focuses solely on offline or online learning, ORL leverages the strengths of both approaches.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet29">
            <div class="start-time-icon" title="Play from here">13:02</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04214" target="_blank">@arXiv
                        2409.04214</a>
                    <span class="tweet-title">Geometry Problems? Let's Formalize It!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Peking University, 01.AI, Shanghai Jiao Tong University...</span>
                </div>
                <div class="primary-text">
                    This research introduces a new framework called Diagram Formalization Enhanced Geometry Problem
                    Solver (DFE-GPS) that integrates visual features, geometric formal language, and natural
                    language
                    representations to improve the performance of multi-modal large language models (MLLMs) in
                    solving
                    geometry problems. Previous work has struggled with MLLMs effectively understanding geometric
                    diagrams, but this framework addresses this limitation by using a novel synthetic data approach
                    and
                    a large-scale geometric dataset, SynthGeo228K, annotated with both formal and natural language
                    captions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet30">
            <div class="start-time-icon" title="Play from here">13:33</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03945" target="_blank">@arXiv
                        2409.03945</a>
                    <span class="tweet-title">Neural Network Compression: Tropical Geometry to the Rescue!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">National Technical University of Athens, ETH Zurich</span>
                </div>
                <div class="primary-text">
                    This paper introduces a new structured pruning framework for compressing neural networks,
                    TropNNC,
                    which utilizes tropical geometry and the Hausdorff distance to achieve a tighter approximation
                    bound
                    compared to previous work.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet31">
            <div class="start-time-icon" title="Play from here">13:52</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04407" target="_blank">@arXiv
                        2409.04407</a>
                    <span class="tweet-title">Missing Data? No Problem! Adversaries Can Now Manipulate Your
                        Models</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Rensselaer Polytechnic Institute, Google LLC, Columbia
                        University</span>
                </div>
                <div class="primary-text">
                    This research explores a new type of attack on machine learning models, where adversaries
                    manipulate
                    the data by strategically introducing missing values. Unlike previous work that focused on
                    full-information maximum likelihood methods, this paper investigates the impact of adversarial
                    missingness on common data remediation techniques like complete case analysis, mean imputation,
                    and
                    regression-based imputation.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet32">
            <div class="start-time-icon" title="Play from here">14:17</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03953" target="_blank">@arXiv
                        2409.03953</a>
                    <span class="tweet-title">Neural Networks: From Black Boxes to Bayesian Beliefs!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Oxford, Spotify</span>
                </div>
                <div class="primary-text">
                    This paper extends the existing framework of training wide neural networks by incorporating
                    non-zero
                    aleatoric noise and deriving an estimator for the posterior covariance. This allows for a more
                    realistic representation of uncertainty in predictions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet33">
            <div class="start-time-icon" title="Play from here">14:39</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03933" target="_blank">@arXiv
                        2409.03933</a>
                    <span class="tweet-title">Deep Learning Predicts Wall Stress: From Simulations to Real-World
                        Flows!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Washington, Karlsruhe Institute for Technology</span>
                </div>
                <div class="primary-text">
                    This research introduces a deep learning architecture that predicts wall-shear stress dynamics
                    from
                    velocity fields in the logarithmic layer of turbulent flows. Unlike previous work, this model is
                    trained on a unified dataset of both turbulent channel and boundary layer flows, demonstrating a
                    zero-shot applicability to experimental data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet34">
            <div class="start-time-icon" title="Play from here">15:06</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04290" target="_blank">@arXiv
                        2409.04290</a>
                    <span class="tweet-title">Survival Analysis Gets a Symbolic Makeover: New Network Predicts
                        Patient
                        Risk with Interpretable Formulas!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Cambridge</span>
                </div>
                <div class="primary-text">
                    This research introduces CoxKAN, a survival analysis model based on Kolmogorov-Arnold Networks
                    (KANs). Unlike traditional deep learning models, KANs use learnable activation functions on
                    edges of
                    the network, allowing for the extraction of interpretable symbolic formulas for the hazard
                    function.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet35">
            <div class="start-time-icon" title="Play from here">15:27</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.03817" target="_blank">@arXiv
                        2409.03817</a>
                    <span class="tweet-title">Deep Learning's Secret Weapon: A Demon in the Machine!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Chicago</span>
                </div>
                <div class="primary-text">
                    This paper introduces the concept of "neural entropy" as a way to quantify the information
                    stored in
                    a neural network during the training of diffusion models. This differs from previous work by
                    directly linking the information stored in the network to the thermodynamic entropy produced
                    during
                    the forward diffusion process.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet36">
            <div class="start-time-icon" title="Play from here">15:46</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04086" target="_blank">@arXiv
                        2409.04086</a>
                    <span class="tweet-title">Depth Perception: A New Metric for Seeing Cars, Not Just
                        Pixels!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Dr.Ing.h.c.F.PorscheAG, PorscheEngineeringGroupGmbH,
                        InstituteforAppliedAI...</span>
                </div>
                <div class="primary-text">
                    This research introduces a new metric for evaluating monocular depth estimation models,
                    specifically
                    designed for automotive applications. Unlike traditional metrics that focus on overall error,
                    this
                    metric considers the importance of different object classes and their distance from the camera,
                    making it more relevant for safety-critical scenarios.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet37">
            <div class="start-time-icon" title="Play from here">16:10</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.04068" target="_blank">@arXiv
                        2409.04068</a>
                    <span class="tweet-title">Coffee Bean Detectives: New Color Code Cracks Down on Cheating!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">National Tsing Hua University, National Center for Theoretical
                        Science,
                        National Taiwan University</span>
                </div>
                <div class="primary-text">
                    This research introduces a site-specific color feature for identifying qualified green coffee
                    beans,
                    unlike previous methods that relied on general color characteristics or complex image
                    processing.
                </div>
            </div>
        </div>

        <div
            style="padding: 50px 0; text-align: center; margin: 5px 0; font-weight: 300; font-size: 10px; color: #000000;">
            Opening music
            from <a href="https://ikson.com" target="_blank" style="color: black; text-decoration: none;">TELL
                YOUR STORY by ikson</a></div>
        <div style="height: 50px;"></div>
    </div>

    <footer class="player-footer">
        <div class="player-detail-hidden-on-small-screen">
            <div id="audio-title" class="tweet-title-small">Hit play and learn on the go!</div>
            <div style="height: 2px;"></div>
            <div id="audio-institutes" class="institute-text-small"></div>
        </div>
        <div class="control-panel">
            <div class="control-horizontal">
                <div id="playSpeedButton" title="Adjust speed">
                    <div id="selectedSpeed">1&times;</div>
                    <div class="speedMenuItems">
                        <div data-value="0.6">Speed 0.6&times;</div>
                        <div data-value="0.8">Speed 0.8&times;</div>
                        <div data-value="1" class="selected">Speed 1&times;</div>
                        <div data-value="1.2">Speed 1.2&times;</div>
                        <div data-value="1.4">Speed 1.4&times;</div>
                        <div data-value="1.6">Speed 1.6&times;</div>
                    </div>
                    <select id="speedOptionsHidden">
                        <option value="0.6">0.6&times;</option>
                        <option value="0.8">0.8&times;</option>
                        <option value="1" selected>1&times;</option>
                        <option value="1.2">1.2&times;</option>
                        <option value="1.4">1.4&times;</option>
                        <option value="1.6">1.6&times;</option>
                    </select>
                </div>
                <div id="playLastButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(false)" title="Play last" disabled>
                        <img src="assets/buttonLastEpisode.svg" alt="Last" style="width: 12px;">
                    </button>
                </div>
                <button class="controllerButton" onclick="scrollToCurrentTweet()" title="Scoll to the current episode">
                    <img id="locateImage" src="assets/buttonTarget.svg" alt="Locate">
                </button>
                <button class="controllerButton" onclick="togglePlayPause()" title="Play/Pause">
                    <img id="playPauseImage" src="assets/buttonPlay.svg" alt="Play">
                </button>
                <div id="playNextButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(true)" title="Play next" disabled>
                        <img src="assets/buttonNextEpisode.svg" alt="Next" style="width: 12px;">
                    </button>
                </div>
            </div>
            <div class="control-horizontal">
                <div id="progressTime">0:00</div>
                <div id="progressContainer" onclick="seek(event)">
                    <div id="progressBar"></div>
                    <div id="progressCircle" draggable="true"></div>
                </div>
                <audio id="audioPlayer"
                    src="https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202409091639_audio.mp3"></audio>
                <div id="progressTime"><span id="audioDuration">Loading...</span></div>
            </div>
        </div>
    </footer>
    <div id="privacyModal" class="modal"></div>
    <script src="script.js"></script>
    <script src="calendar.js"></script>
    <script>
        fetch('https://ribbitribbit.co/header.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('headerId').innerHTML = data;
            })
            .catch(error => console.error('Error loading header.html:', error));
        fetch('https://ribbitribbit.co/terms.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('privacyModal').innerHTML = data;
            })
            .catch(error => console.error('Error loading terms.html:', error));
    </script>
</body>

</html>
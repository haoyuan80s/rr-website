
daily_data = {
    "date": "2024-09-02",
    "tweets": [
            {
                "startTime": "00:55",
                "arxivId": "2408.16916",
                "arxivLink": "https://arxiv.org/abs/2408.16916",
                "title": "Brain's Color Vision: A Computational Mystery Solved?",
                "institute": "UC Berkeley",
                "text": "This research proposes a novel computational framework for modeling the emergence of human color vision by simulating both the eye and the cortex. Unlike previous work, it does not assume a priori knowledge of color dimensionality but instead infers it from the optic nerve signals.",
                "paper-title": "A Computational Framework for Modeling Emergence of Color Vision in the Human Brain",
                "image-path": ""
            },

            {
                "startTime": "01:19",
                "arxivId": "2408.17355",
                "arxivLink": "https://arxiv.org/abs/2408.17355",
                "title": "Action Chunking: A Decoding Algorithm That's Smarter Than Your Average Robot",
                "institute": "Stanford University",
                "text": "This research proposes a new decoding algorithm called Bidirectional Decoding (BID) that improves action chunking by considering both past decisions and future plans. Unlike previous methods that rely on random sampling or averaging, BID searches for the optimal action from a batch of sampled plans, enhancing temporal consistency and reactivity in stochastic environments.",
                "paper-title": "Bidirectional Decoding: Improving Action Chunking via Closed-Loop Resampling",
                "image-path": ""
            },

            {
                "startTime": "01:43",
                "arxivId": "2408.16944",
                "arxivLink": "https://arxiv.org/abs/2408.16944",
                "title": "Robots Learn New Tricks by Watching Old Movies (of Themselves)",
                "institute": "Stanford University",
                "text": "This research proposes a new method for few-shot imitation learning that leverages motion similarity extracted from optical flow representations, rather than relying solely on visual or semantic similarity.",
                "paper-title": "FlowRetrieval: Flow-Guided Data Retrieval for Few-Shot Imitation Learning",
                "image-path": ""
            },

            {
                "startTime": "02:06",
                "arxivId": "2408.17016",
                "arxivLink": "https://arxiv.org/abs/2408.17016",
                "title": "Machine Learning's New Party Trick: Finding Hidden Interactions with Controlled Error!",
                "institute": "University of Waterloo, University of Michigan, University of Washington",
                "text": "This research introduces Diamond, a method for discovering feature interactions in machine learning models while controlling the false discovery rate (FDR). Unlike previous approaches, Diamond leverages the model-X knockoffs framework to generate dummy features that mimic the original data's structure, enabling a more robust and reliable estimation of FDR.",
                "paper-title": "Error-controlled non-additive interaction discovery in machine learning models",
                "image-path": ""
            },

            {
                "startTime": "02:37",
                "arxivId": "2408.17005",
                "arxivLink": "https://arxiv.org/abs/2408.17005",
                "title": "Camera Exposure Control: DRL Makes VO See the Light!",
                "institute": "Hong Kong University of Science and Technology",
                "text": "This research proposes a deep reinforcement learning (DRL) framework for camera exposure control in visual odometry (VO) systems. Unlike previous DRL-based methods that require online training, this approach utilizes an offline training scheme with a lightweight image simulator, enabling efficient and robust exposure control.",
                "paper-title": "Efficient Camera Exposure Control for Visual Odometry via Deep Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "03:05",
                "arxivId": "2408.16987",
                "arxivLink": "https://arxiv.org/abs/2408.16987",
                "title": "AI Explains Models, Not Data: The Misinterpretation Trap",
                "institute": "University of Iowa, Yale University, University of Electronic Science and Technology of China...",
                "text": "This research investigates the validity of using post hoc explainers, like SHAP and LIME, to draw inferences about data relationships. It goes beyond simply explaining the model's behavior and examines whether these explanations accurately reflect the true marginal effects of features in the data.",
                "paper-title": "From Model Explanation to Data Misinterpretation: Uncovering the Pitfalls of Post Hoc Explainers in Business Research",
                "image-path": ""
            },

            {
                "startTime": "03:39",
                "arxivId": "2408.17424",
                "arxivLink": "https://arxiv.org/abs/2408.17424",
                "title": "Camera Controllable Video Previsualization: AI Meets the Movie Set",
                "institute": "Purple Mountain Observatory, Stanford University, Hong Kong University of Science and Technology...",
                "text": "This research introduces CinePreGen, a system that combines game engines with diffusion models for video previsualization. Unlike previous methods that primarily focused on object motion control, CinePreGen offers dynamic camera control, allowing users to create cinematic camera movements like pan, tilt, push, and dolly zoom.",
                "paper-title": "CinePreGen: Camera Controllable Video Previsualization via Engine-powered Diffusion",
                "image-path": ""
            },

            {
                "startTime": "03:59",
                "arxivId": "2408.16981",
                "arxivLink": "https://arxiv.org/abs/2408.16981",
                "title": "Q-Learning's Communication Diet: How to Slim Down Without Losing Brains!",
                "institute": "CMU",
                "text": "This research establishes a lower bound on the communication complexity of federated Q-learning algorithms, demonstrating that any algorithm achieving a speedup in convergence rate must incur a communication cost proportional to the effective horizon of the MDP. Additionally, the paper proposes a new algorithm, Fed-DVR-Q, which achieves both order-optimal sample and communication complexities, bridging the gap between existing upper and lower bounds.",
                "paper-title": "The Sample-Communication Complexity Trade-off in Federated Q-Learning",
                "image-path": ""
            },

            {
                "startTime": "04:25",
                "arxivId": "2408.16852",
                "arxivLink": "https://arxiv.org/abs/2408.16852",
                "title": "Star-Shaped Regularizers: A Geometric Approach to Unsupervised Learning",
                "institute": "UC Los Angeles, Johns Hopkins University, National University of Singapore",
                "text": "This research explores the structure of regularizers learned through a critic-based loss function, focusing on a specific family of regularizers called gauges of star-shaped bodies. It leverages tools from star geometry and dual Brunn-Minkowski theory to analyze the optimal regularizer in certain cases.",
                "paper-title": "The Star Geometry of Critic-Based Regularizer Learning",
                "image-path": ""
            },

            {
                "startTime": "04:49",
                "arxivId": "2408.17027",
                "arxivLink": "https://arxiv.org/abs/2408.17027",
                "title": "2D & 3D: A Love Story of Feature Fusion",
                "institute": "UCSanDiego, Stanford University, StabilityAI...",
                "text": "This research proposes a novel 2D-3D joint training scheme called ConDense, which extracts co-embedded 2D and 3D features by enforcing consistency through a ray-marching process inspired by Neural Radiance Fields (NeRFs). This approach differs from previous work by leveraging pre-trained 2D networks and multi-view datasets for 3D pre-training, rather than relying solely on 3D data.",
                "paper-title": "ConDense: Consistent 2D/3D Pre-training for Dense and Sparse Features from Multi-View Images",
                "image-path": ""
            },

            {
                "startTime": "05:32",
                "arxivId": "2408.17065",
                "arxivLink": "https://arxiv.org/abs/2408.17065",
                "title": "Deepfakes: Facial Feature Drift is the New Tell!",
                "institute": "Peking University, Tencent Youtu Lab",
                "text": "This research introduces a novel video-level blending technique to simulate a previously underexplored temporal forgery artifact called Facial Feature Drift (FFD). Unlike prior work that focuses on spatial artifacts, this method specifically targets temporal inconsistencies in facial features, enhancing the generalization ability of deepfake detectors.",
                "paper-title": "Generalizing Deepfake Video Detection with Plug-and-Play: Video-Level Blending and Spatiotemporal Adapter Tuning",
                "image-path": ""
            },

            {
                "startTime": "05:58",
                "arxivId": "2408.16966",
                "arxivLink": "https://arxiv.org/abs/2408.16966",
                "title": "User Summaries: Predicting Your Next Move, One Click at a Time!",
                "institute": "Google DeepMind",
                "text": "This research introduces a new benchmark framework called USERSUMBENCH, which focuses on evaluating user summarization approaches by measuring how accurately generated summaries predict future user activities. This differs from previous work that often relies on simplistic heuristics or models that struggle with the inherent subjectivity of user summaries.",
                "paper-title": "UserSumBench: A Benchmark Framework for Evaluating User Summarization Approaches",
                "image-path": ""
            },

            {
                "startTime": "06:19",
                "arxivId": "2408.16961",
                "arxivLink": "https://arxiv.org/abs/2408.16961",
                "title": "Open Feedback: AI's New Best Friend?",
                "institute": "University of Oxford, IBM",
                "text": "This paper explores the potential for an open ecosystem of human feedback for AI, focusing on the challenges and opportunities of creating a sustainable system for collecting and sharing this data. It differs from previous work by proposing a framework for a dynamic and collaborative approach to human feedback, rather than relying on closed, proprietary datasets.",
                "paper-title": "The Future of Open Human Feedback",
                "image-path": ""
            },

            {
                "startTime": "06:45",
                "arxivId": "2408.17432",
                "arxivLink": "https://arxiv.org/abs/2408.17432",
                "title": "Voice Cloning Made Easy: New TTS Method Uses Frame Selection to Mimic Anyone's Voice",
                "institute": "University of Texas at Dallas, National University of Singapore",
                "text": "This research proposes SelectTTS, a multi-speaker text-to-speech (TTS) framework that directly utilizes frames from the target speaker's speech for decoding, rather than relying on speaker conditioning or prompts. This approach simplifies the task and reduces model complexity compared to previous methods.",
                "paper-title": "SelectTTS: Synthesizing Anyone's Voice via Discrete Unit-Based Frame Selection",
                "image-path": ""
            },

            {
                "startTime": "07:09",
                "arxivId": "2408.16982",
                "arxivLink": "https://arxiv.org/abs/2408.16982",
                "title": "Splatting with Style: Hermite Polynomials Give 3D Rendering a Boost!",
                "institute": "Tsinghua University",
                "text": "This paper proposes using Gaussian-Hermite polynomials as the kernel for Gaussian Splatting, a technique used for 3D reconstruction and rendering. This approach differs from previous work by introducing higher-rank terms in the kernel, allowing for more complex and anisotropic shapes to be represented.",
                "paper-title": "2DGH: 2D Gaussian-Hermite Splatting for High-quality Rendering and Better Geometry Reconstruction",
                "image-path": ""
            },

            {
                "startTime": "07:40",
                "arxivId": "2408.17062",
                "arxivLink": "https://arxiv.org/abs/2408.17062",
                "title": "Vision Transformers: Token Pruning Gets a Vote!",
                "institute": "Peking University, ByteDance",
                "text": "This paper introduces Vote&Mix (VoMix), a parameter-free token reduction method for Vision Transformers (ViTs). Unlike previous methods that focus on discarding unimportant tokens, VoMix aims to reduce token homogeneity by identifying and mixing tokens with high similarity.",
                "paper-title": "Vote&Mix: Plug-and-Play Token Reduction for Efficient Vision Transformer",
                "image-path": ""
            },

            {
                "startTime": "08:05",
                "arxivId": "2408.17433",
                "arxivLink": "https://arxiv.org/abs/2408.17433",
                "title": "DARES: Depth Estimation in Surgery Gets a Vector-Powered Boost!",
                "institute": "University College London, Politecnico di Milano",
                "text": "This research introduces Vector-LoRA, a new adaptation technique for foundation models that allocates more parameters to earlier layers, addressing the inherent feature hierarchy in deep networks. This differs from previous LoRA methods that distribute parameters uniformly.",
                "paper-title": "DARES: Depth Anything in Robotic Endoscopic Surgery with Self-supervised Vector-LoRA of the Foundation Model",
                "image-path": ""
            },

            {
                "startTime": "08:29",
                "arxivId": "2408.16913",
                "arxivLink": "https://arxiv.org/abs/2408.16913",
                "title": "Gradients Got Game: Unmasking Privacy Risks in Distributed Learning",
                "institute": "Vanderbilt University, University of Wisconsin-Madison, Mitsubishi Electric Research Laboratories",
                "text": "This research provides a unified framework for analyzing inference attacks from gradients in distributed learning settings, encompassing a broader range of attacks than previous work. It also investigates the effectiveness of various defenses against both static and adaptive adversaries.",
                "paper-title": "Analyzing Inference Privacy Risks Through Gradients in Machine Learning",
                "image-path": ""
            },

            {
                "startTime": "08:58",
                "arxivId": "2408.16984",
                "arxivLink": "https://arxiv.org/abs/2408.16984",
                "title": "AI Alignment: Beyond the \"I Want\" and Into the \"We Should\"",
                "institute": "MIT, UC Berkeley, University College London...",
                "text": "This paper challenges the dominant \"preferentist\" approach to AI alignment, which assumes that human values can be adequately represented by preferences and that AI systems should maximize those preferences. It proposes alternative frameworks that consider the limitations of rational choice theory and expected utility theory, emphasizing the importance of aligning AI with normative standards appropriate to their social roles.",
                "paper-title": "Beyond Preferences in AI Alignment",
                "image-path": ""
            },

            {
                "startTime": "09:25",
                "arxivId": "2408.17175",
                "arxivLink": "https://arxiv.org/abs/2408.17175",
                "title": "Codec's Got Talent: Giving Audio LLMs a Semantic Makeover",
                "institute": "Hong Kong University of Science and Technology, Microsoft, University of Science and Technology Beijing...",
                "text": "This research focuses on improving the semantic understanding of audio codecs used in audio LLMs. Unlike previous work that primarily focused on compression and acoustic reconstruction, this paper introduces X-Codec, which integrates semantic features into the codec's architecture.",
                "paper-title": "Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model",
                "image-path": ""
            },

            {
                "startTime": "10:01",
                "arxivId": "2408.16978",
                "arxivLink": "https://arxiv.org/abs/2408.16978",
                "title": "Training LLMs on Long Texts: A Memory-Saving Masterclass",
                "institute": "Ohio State University, Microsoft",
                "text": "This research proposes a new method called Fully Pipelined Distributed Transformer (FPDT) for training LLMs on extremely long sequences. Unlike previous approaches that rely on downstream finetuning or adaptations, FPDT directly trains LLMs on long contexts, achieving significant hardware efficiency.",
                "paper-title": "Training Ultra Long Context Language Model with Fully Pipelined Distributed Transformer",
                "image-path": ""
            },

            {
                "startTime": "10:25",
                "arxivId": "2408.17422",
                "arxivLink": "https://arxiv.org/abs/2408.17422",
                "title": "Open-Vocabulary Action Localization: VLMs Get a Time Machine!",
                "institute": "Microsoft",
                "text": "This research proposes a learning-free approach for open-vocabulary temporal action localization using vision-language models (VLMs). Unlike previous methods that require training on labeled datasets, this approach leverages an iterative visual prompting technique to identify actions without any prior training.",
                "paper-title": "Open-vocabulary Temporal Action Localization using VLMs",
                "image-path": ""
            },

            {
                "startTime": "10:45",
                "arxivId": "2408.16829",
                "arxivLink": "https://arxiv.org/abs/2408.16829",
                "title": "Supernova Science Gets a Multimodal Makeover: Maven's the New Rosetta Stone!",
                "institute": "Harvard University, Stony Brook University, Massachusetts Institute of Technology...",
                "text": "This research introduces Maven, a foundation model for supernova science that uses both photometry and spectroscopy simultaneously. Unlike previous models that focused on one modality or the other, Maven leverages the combined information to improve performance on classification and redshift estimation.",
                "paper-title": "Maven: A Multimodal Foundation Model for Supernova Science",
                "image-path": ""
            },

            {
                "startTime": "11:07",
                "arxivId": "2408.17207",
                "arxivLink": "https://arxiv.org/abs/2408.17207",
                "title": "NanoMVG: A Tiny Brain for Big Waterway Vision!",
                "institute": "Hong Kong University of Science and Technology",
                "text": "This research proposes a new multi-task visual grounding model called NanoMVG, designed for low-power edge devices. Unlike previous models, NanoMVG combines image and radar data with textual prompts, enabling it to locate objects based on both visual and quantitative features.",
                "paper-title": "NanoMVG: USV-Centric Low-Power Multi-Task Visual Grounding based on Prompt-Guided Camera and 4D mmWave Radar",
                "image-path": ""
            },

            {
                "startTime": "11:36",
                "arxivId": "2408.16871",
                "arxivLink": "https://arxiv.org/abs/2408.16871",
                "title": "Graph Distillation Gets a Brain: Attention Matching Makes Condensing Datasets a Breeze!",
                "institute": "National University of Singapore, University of Toronto",
                "text": "This research introduces a new method called GSTAM for condensing graph classification datasets. Unlike previous methods that focus on node classification or rely on computationally intensive processes, GSTAM leverages the attention maps of GNNs to distill structural information from the original dataset into synthetic graphs.",
                "paper-title": "GSTAM: Efficient Graph Distillation with Structural Attention-Matching",
                "image-path": ""
            },

            {
                "startTime": "12:01",
                "arxivId": "2408.17443",
                "arxivLink": "https://arxiv.org/abs/2408.17443",
                "title": "Long Videos, Short Attention Spans? This Model Gets It!",
                "institute": "National Taiwan University, NVIDIA, Mobile Drive Technology...",
                "text": "This research proposes a novel framework called BREASE that leverages episodic memory and semantic knowledge to understand long-form videos. Unlike previous approaches that often treat long videos as extended short videos, BREASE simulates how humans accumulate information over time, capturing action sequences and reinforcing them with semantic context.",
                "paper-title": "Bridging Episodes and Semantics: A Novel Framework for Long-Form Video Understanding",
                "image-path": ""
            },

            {
                "startTime": "12:35",
                "arxivId": "2408.17280",
                "arxivLink": "https://arxiv.org/abs/2408.17280",
                "title": "Building a Super-Brain: Mixing LLMs for Domain Expertise",
                "institute": "IBM",
                "text": "This research proposes a toolkit for creating Mixture-of-Domain-Experts (MOE) models by combining pre-trained, fine-tuned models. Unlike previous work that focuses on training a single MOE model from scratch, this approach leverages existing models, making it significantly more efficient.",
                "paper-title": "Flexible and Effective Mixing of Large Language Models into a Mixture of Domain Experts",
                "image-path": ""
            },

            {
                "startTime": "12:57",
                "arxivId": "2408.16875",
                "arxivLink": "https://arxiv.org/abs/2408.16875",
                "title": "Robots Learn to Tend Machines: A Multi-Agent, Multi-Machine Tending Framework",
                "institute": "ETS Montreal, Mila, Polytechnique Montr\u00b4eal...",
                "text": "This research introduces a novel multi-agent reinforcement learning (MARL) framework for mobile robots to learn how to tend multiple machines simultaneously. Unlike previous work that focused on single-machine tending or assumed infinite storage capacity, this study addresses the complexities of real-world manufacturing scenarios where robots need to navigate between machines, collect parts, and deliver them to storage.",
                "paper-title": "Learning Multi-agent Multi-machine Tending by Mobile Robots",
                "image-path": ""
            },

            {
                "startTime": "13:29",
                "arxivId": "2408.17337",
                "arxivLink": "https://arxiv.org/abs/2408.17337",
                "title": "OOD Detection: When AI Gets Tricked by Rulers and Annotations!",
                "institute": "University of Oxford",
                "text": "This research challenges the common assumption that out-of-distribution (OOD) artefacts always lead to uncertain model outputs. It demonstrates that OOD artefacts can actually boost a model's confidence in its predictions, contradicting the foundation of many confidence-based OOD detection methods.",
                "paper-title": "Evaluating Reliability in Medical DNNs: A Critical Analysis of Feature and Confidence-Based OOD Detection",
                "image-path": ""
            },

            {
                "startTime": "14:05",
                "arxivId": "2408.17428",
                "arxivLink": "https://arxiv.org/abs/2408.17428",
                "title": "AI's New Glasses: Fixing OCR Errors with a Dash of Context!",
                "institute": "University College London",
                "text": "This research explores using pre-trained language models (LLMs) to correct errors in Optical Character Recognition (OCR) outputs, specifically focusing on historical newspaper archives. Unlike previous work that primarily relied on crowd-sourcing or specific algorithms, this study leverages the contextual understanding and infilling capabilities of LLMs to improve OCR accuracy.",
                "paper-title": "CLOCR-C: Context Leveraging OCR Correction with Pre-trained Language Models",
                "image-path": ""
            },

            {
                "startTime": "14:24",
                "arxivId": "2408.16877",
                "arxivLink": "https://arxiv.org/abs/2408.16877",
                "title": "Modularity Goes Temporal: A New Way to Find Communities in Ever-Changing Networks",
                "institute": "CNRS, UCBL, INSA Lyon...",
                "text": "This paper introduces Longitudinal Modularity (L-Modularity), a new way to measure community structure in dynamic networks represented as link streams. Unlike previous methods, L-Modularity is independent of the time scale of analysis and can handle communities that evolve over time.",
                "paper-title": "Longitudinal Modularity, a Modularity for Link Streams",
                "image-path": ""
            },

            {
                "startTime": "14:47",
                "arxivId": "2408.17221",
                "arxivLink": "https://arxiv.org/abs/2408.17221",
                "title": "Lightning Strikes: Unmasking the Geometry of Self-Attention Networks",
                "institute": "University of Toronto, KTH Royal Institute of Technology",
                "text": "This research delves into the geometry of function spaces defined by self-attention networks, specifically focusing on the \"lightning\" variant where attention weights are unnormalized. It uses tools from algebraic geometry to analyze the identifiability of deep attention and compute the dimension of the function space.",
                "paper-title": "Geometry of Lightning Self-Attention: Identifiability and Dimension",
                "image-path": ""
            },

            {
                "startTime": "15:12",
                "arxivId": "2408.16890",
                "arxivLink": "https://arxiv.org/abs/2408.16890",
                "title": "Robots in Warehouses: Learning to Optimize for Maximum Efficiency!",
                "institute": "MIT",
                "text": "This research introduces a novel \"learn-then-optimize\" approach to large-scale neighborhood search, which uses machine learning to predict objective improvements based on subproblem features and an online optimization model to generate new subproblems at each iteration. This differs from previous work that typically relies on pre-defined candidate neighborhoods or sequential decomposition methods.",
                "paper-title": "Robotic warehousing operations: a learn-then-optimize approach to large-scale neighborhood search",
                "image-path": ""
            },

            {
                "startTime": "15:32",
                "arxivId": "2408.17118",
                "arxivLink": "https://arxiv.org/abs/2408.17118",
                "title": "ICA Gets a Matrix Makeover: Faster, Unique, and Ready for EEG!",
                "institute": "Seikei University, The University of Tokyo",
                "text": "This research proposes a novel algorithm for the ordering ICA by reformulating it in matrix representation. This approach leverages the efficiency of matrix manipulations, particularly matrix multiplication, to accelerate the process of estimating unique components in ICA.",
                "paper-title": "Efficient Estimation of Unique Components in Independent Component Analysis by Matrix Representation",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 34,
        "num_total": 205,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202409021136_audio.mp3"
}
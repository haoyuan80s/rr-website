
daily_data = {
    "date": "2024-11-06",
    "tweets": [
        
        {
            "startTime": "01:10",
            "arxivId": "2411.02114",
            "arxivLink": "https://arxiv.org/abs/2411.02114",
            "title": "Conformal Prediction Gets a Vine-tastic Upgrade for Multi-Target Regression!",
            "institute": "Genentech, Stanford University, New York University",
            "text": "This research proposes a semiparametric approach to conformal prediction for multi-target regression, using nonparametric vine copulas to model the joint distribution of non-conformity scores. This differs from previous work that relied on empirical copulas or parametric families, which can be unstable or prone to model misspecification.",
            "paper-title": "Semiparametric conformal prediction",
            "image-path": "flux_paper_image/2411.02114_1730929835.png"
        },

        {
            "startTime": "01:32",
            "arxivId": "2411.02109",
            "arxivLink": "https://arxiv.org/abs/2411.02109",
            "title": "Protein Models Get a Tune-Up: Training on the Fly for Better Predictions!",
            "institute": "Czech Institute of Informatics Robotics and Cybernetics, Czech Technical University, Institute of Organic Chemistry and Biochemistry of the Czech Academy of Sciences...",
            "text": "This research introduces a novel test-time training (TTT) method for protein models. Unlike traditional approaches that rely on pre-training on large datasets, TTT adapts models to individual proteins on the fly, without requiring additional data.",
            "paper-title": "Training on test proteins improves fitness, structure, and function prediction",
            "image-path": "flux_paper_image/2411.02109_1730931002.png"
        },

        {
            "startTime": "01:52",
            "arxivId": "2411.02359",
            "arxivLink": "https://arxiv.org/abs/2411.02359",
            "title": "Robots Get Smart: LLMs Learn to Think Small for Big Tasks!",
            "institute": "Tsinghua University",
            "text": "This research proposes a novel approach called DeeR (Dynamic Early-Exit for Robotic MLLM) that dynamically adjusts the size of the MLLM based on the complexity of the situation. This differs from previous work that typically uses a fixed-size MLLM for all tasks.",
            "paper-title": "DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution",
            "image-path": "flux_paper_image/2411.02359_1730929535.png"
        },

        {
            "startTime": "02:19",
            "arxivId": "2411.02796",
            "arxivLink": "https://arxiv.org/abs/2411.02796",
            "title": "Foundation Models: Not So Foundational After All?",
            "institute": "CMU, Princeton University",
            "text": "This research directly compares the performance of specialized foundation models (FMs) to traditional supervised learning methods across three domains: genomics, satellite imaging, and time series. It uses automated workflows to develop and tune strong supervised baselines, demonstrating that FMs often fail to outperform these simpler approaches.",
            "paper-title": "Specialized Foundation Models Struggle to Beat Supervised Baselines",
            "image-path": "flux_paper_image/2411.02796_1730928331.png"
        },

        {
            "startTime": "02:44",
            "arxivId": "2411.03279",
            "arxivLink": "https://arxiv.org/abs/2411.03279",
            "title": "Backdoor Removal: No Detection Needed, Just a Little Math Magic!",
            "institute": "UC Berkeley, MIT",
            "text": "This paper introduces a new approach to defending against backdoors in machine learning models that doesn't rely on detecting them first. Instead, it uses techniques inspired by random self-reducibility to mitigate or even remove backdoors without needing to identify them. This differs from previous work that focused primarily on backdoor detection.",
            "paper-title": "Oblivious Defense in ML Models: Backdoor Removal without Detection",
            "image-path": "flux_paper_image/2411.03279_1730929646.png"
        },

        {
            "startTime": "03:04",
            "arxivId": "2411.02139",
            "arxivLink": "https://arxiv.org/abs/2411.02139",
            "title": "Deep Learning's Hidden Curves: Unraveling the Gauss-Newton Matrix",
            "institute": "University of Basel, ETH Z\u00fcrich",
            "text": "This research provides tight bounds for the condition number of the Gauss-Newton matrix in linear and residual neural networks of arbitrary depth and width, a previously unaddressed area in the literature.",
            "paper-title": "Theoretical characterisation of the Gauss-Newton conditioning in Neural Networks",
            "image-path": "flux_paper_image/2411.02139_1730929117.png"
        },

        {
            "startTime": "03:25",
            "arxivId": "2411.03177",
            "arxivLink": "https://arxiv.org/abs/2411.03177",
            "title": "Diffusion Models Get a Conditioning Makeover: Disentangling Control and Semantics for Better Images",
            "institute": "FAIR at Meta, Univ. Grenoble Alpes, Inria...",
            "text": "This research delves into the training of latent diffusion models (LDMs), focusing on improving conditioning mechanisms and pre-training strategies. Unlike previous work, it proposes a novel conditioning mechanism that separates control metadata (like image size) from semantic information (like text prompts), leading to better image generation and control.",
            "paper-title": "On Improved Conditioning Mechanisms and Pre-training Strategies for Diffusion Models",
            "image-path": "flux_paper_image/2411.03177_1730930394.png"
        },

        {
            "startTime": "03:49",
            "arxivId": "2411.02537",
            "arxivLink": "https://arxiv.org/abs/2411.02537",
            "title": "INQUIRE: A New Benchmark for Image Retrieval That's Wildly Challenging!",
            "institute": "Massachusetts Institute of Technology, University College London, iNaturalist...",
            "text": "This research introduces INQUIRE, a new benchmark for text-to-image retrieval that focuses on expert-level queries related to the natural world. Unlike previous benchmarks, INQUIRE uses a dataset of five million images and includes queries that require nuanced image understanding and domain expertise.",
            "paper-title": "INQUIRE: A Natural World Text-to-Image Retrieval Benchmark",
            "image-path": "flux_paper_image/2411.02537_1730930173.png"
        },

        {
            "startTime": "04:11",
            "arxivId": "2411.02645",
            "arxivLink": "https://arxiv.org/abs/2411.02645",
            "title": "Support Agents: Workflow Detectives, Insider Risk Busters!",
            "institute": "Google",
            "text": "This research focuses on detecting insider risk by analyzing the workflows of support agents, rather than simply predicting future access patterns. It uses a fine-grained approach that considers the context of actions within a workflow, making it more effective for identifying deviations from expected behavior.",
            "paper-title": "Fine Grained Insider Risk Detection",
            "image-path": "flux_paper_image/2411.02645_1730929712.png"
        },

        {
            "startTime": "04:28",
            "arxivId": "2411.02385",
            "arxivLink": "https://arxiv.org/abs/2411.02385",
            "title": "Can AI Really Learn Physics From Videos? Sora's Secret Exposed!",
            "institute": "Bytedance Research, Tsinghua University, Technion",
            "text": "This research investigates the ability of video generation models to learn fundamental physical laws from visual data, specifically focusing on the role of scaling in this process. Unlike previous work that primarily focused on in-distribution generalization, this study delves into out-of-distribution and combinatorial generalization, providing a more comprehensive evaluation of the model's ability to reason about physical laws.",
            "paper-title": "How Far is Video Generation from World Model: A Physical Law Perspective",
            "image-path": "flux_paper_image/2411.02385_1730929382.png"
        },

        {
            "startTime": "04:51",
            "arxivId": "2411.02142",
            "arxivLink": "https://arxiv.org/abs/2411.02142",
            "title": "Protein Language Models: Scaling Up Without Breaking the Bank!",
            "institute": "BioMap Research, Tsinghua University, MBZUAI",
            "text": "This research focuses on optimizing the training of protein language models by balancing model size and training data size under a fixed compute budget. Unlike previous work that primarily focused on increasing model size, this study investigates the scaling laws for both Masked Language Model (MLM) and Causal Language Model (CLM) objectives, considering the specific characteristics of protein sequence data.",
            "paper-title": "Training Compute-Optimal Protein Language Models",
            "image-path": "flux_paper_image/2411.02142_1730929442.png"
        },

        {
            "startTime": "05:16",
            "arxivId": "2411.02930",
            "arxivLink": "https://arxiv.org/abs/2411.02930",
            "title": "LLMs Get a Makeover: New Research Polishes Text Aesthetics",
            "institute": "Peking University, Microsoft",
            "text": "This research focuses on improving the aesthetic quality of text generated by LLMs, an area that has been largely overlooked. Unlike previous work that primarily focused on content correctness and helpfulness, this study introduces a dataset and a fine-tuning method specifically designed to enhance the visual appeal and organization of LLM outputs.",
            "paper-title": "Textual Aesthetics in Large Language Models",
            "image-path": "flux_paper_image/2411.02930_1730930058.png"
        },

        {
            "startTime": "05:37",
            "arxivId": "2411.02860",
            "arxivLink": "https://arxiv.org/abs/2411.02860",
            "title": "Sound Separation: New Trick to Stop AI From Forgetting Its Tunes!",
            "institute": "The University of Texas at Dallas, Brown University, Carnegie Mellon University",
            "text": "This research introduces a new task called \"continual audio-visual sound separation,\" where the goal is to train a model to continuously separate sounds from new categories while remembering how to separate old ones. This is different from previous work that focused on separating sounds from known categories.",
            "paper-title": "Continual Audio-Visual Sound Separation",
            "image-path": "flux_paper_image/2411.02860_1730928074.png"
        },

        {
            "startTime": "06:06",
            "arxivId": "2411.02337",
            "arxivLink": "https://arxiv.org/abs/2411.02337",
            "title": "Open LLMs Learn to Surf the Web: WEBRL Makes Open-Source Agents Rule the Waves!",
            "institute": "Tsinghua University",
            "text": "This research introduces WEBRL, a self-evolving online curriculum reinforcement learning framework for training LLM web agents. Unlike previous work that relies on static task sets or expensive proprietary LLMs, WEBRL dynamically generates new tasks based on the agent's evolving skills, enabling continuous improvement.",
            "paper-title": "WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning",
            "image-path": "flux_paper_image/2411.02337_1730930372.png"
        },

        {
            "startTime": "06:35",
            "arxivId": "2411.02611",
            "arxivLink": "https://arxiv.org/abs/2411.02611",
            "title": "VR Heart Surgeon Training: Can 3D Views Beat 2D for Catheter Skills?",
            "institute": "Weill Cornell Medicine",
            "text": "This research introduces a new XR-based system for 6-DOF catheter tracking, including real-time roll angle measurement, which is not commonly found in existing systems.",
            "paper-title": "Advanced XR-Based 6-DOF Catheter Tracking System for Immersive Cardiac Intervention Training",
            "image-path": "flux_paper_image/2411.02611_1730931094.png"
        },

        {
            "startTime": "06:56",
            "arxivId": "2411.02207",
            "arxivLink": "https://arxiv.org/abs/2411.02207",
            "title": "Model Merging: When Specialization Goes Too Far, It's Time to Talk!",
            "institute": "MIT",
            "text": "This research explores the limitations of combining specialized models by averaging their features, a common practice in model merging. It proposes a new direction called \"compatible specialization\" where models need to communicate effectively, similar to humans using language, rather than relying on aligning their internal representations.",
            "paper-title": "Collective Model Intelligence Requires Compatible Specialization",
            "image-path": "flux_paper_image/2411.02207_1730929901.png"
        },

        {
            "startTime": "07:18",
            "arxivId": "2411.02599",
            "arxivLink": "https://arxiv.org/abs/2411.02599",
            "title": "Robot Learns New Tricks: Teaching AI to Speak Our Language",
            "institute": "Stanford University",
            "text": "This research introduces Vocal Sandbox, a framework that allows robots to learn new behaviors and skills from diverse teaching modalities, including spoken dialogue, object keypoints, and kinesthetic demonstrations. Unlike previous work that relies on static skill libraries or limited language feedback, Vocal Sandbox enables robots to adapt and continually learn in real-time, expanding their capabilities as they interact with humans.",
            "paper-title": "Vocal Sandbox: Continual Learning and Adaptation for Situated Human-Robot Collaboration",
            "image-path": "flux_paper_image/2411.02599_1730929051.png"
        },

        {
            "startTime": "07:46",
            "arxivId": "2411.02571",
            "arxivLink": "https://arxiv.org/abs/2411.02571",
            "title": "Multimodal LLMs: The Future of Search is Here, and It's Got Images!",
            "institute": "University of Waterloo, Nvidia",
            "text": "This research explores the use of multimodal large language models (MLLMs) for universal multimodal retrieval, which allows for diverse retrieval tasks with multimodal queries and documents. Unlike previous work that focused on specific tasks or homogeneous document formats, this paper tackles a broader search scenario.",
            "paper-title": "MM-Embed: Universal Multimodal Retrieval with Multimodal LLMs",
            "image-path": "flux_paper_image/2411.02571_1730928257.png"
        },

        {
            "startTime": "08:11",
            "arxivId": "2411.02335",
            "arxivLink": "https://arxiv.org/abs/2411.02335",
            "title": "LLMs on a Diet: How Sparsity Makes Big Models Slimmer and Smarter",
            "institute": "Tsinghua University",
            "text": "This research goes beyond simply observing activation sparsity in LLMs. It delves into the quantitative scaling properties of sparsity, examining how it changes with factors like training data size, activation function, and model architecture.",
            "paper-title": "Sparsing Law: Towards Large Language Models with Greater Activation Sparsity",
            "image-path": "flux_paper_image/2411.02335_1730930592.png"
        },

        {
            "startTime": "08:32",
            "arxivId": "2411.02391",
            "arxivLink": "https://arxiv.org/abs/2411.02391",
            "title": "Pop-Ups: The New Weapon Against AI Agents?",
            "institute": "Georgia Institute of Technology, University of Hong Kong, Stanford University",
            "text": "This research explores a novel attack vector against vision-language models (VLMs) used in computer agents. Unlike previous work that focused on manipulating visual content or injecting malicious code, this study demonstrates that simple, visually-obvious pop-ups can effectively distract and mislead agents, leading them to click on the pop-ups instead of performing their intended tasks.",
            "paper-title": "Attacking Vision-Language Computer Agents via Pop-ups",
            "image-path": "flux_paper_image/2411.02391_1730929371.png"
        },

        {
            "startTime": "08:57",
            "arxivId": "2411.02448",
            "arxivLink": "https://arxiv.org/abs/2411.02448",
            "title": "LLMs Get a Reality Check: New Model Rates, Explains, and Cites!",
            "institute": "UC Berkeley, Salesforce",
            "text": "This research introduces two fine-tuned LLMs, REC-12B and REC-70B, specifically designed to evaluate generated text across several dimensions: faithfulness, instruction following, coherence, and completeness. Unlike previous work, these models not only provide ratings but also offer detailed explanations and verifiable citations, enhancing trust in the content.",
            "paper-title": "Rate, Explain and Cite (REC): Enhanced Explanation and Attribution in Automatic Evaluation by Large Language Models",
            "image-path": "flux_paper_image/2411.02448_1730930284.png"
        },

        {
            "startTime": "09:15",
            "arxivId": "2411.02482",
            "arxivLink": "https://arxiv.org/abs/2411.02482",
            "title": "NeRF-Aug: Making Robots See the World in 3D, One Object at a Time!",
            "institute": "University of Maryland",
            "text": "This research introduces NeRF-Aug, a data augmentation method that uses Neural Radiance Fields (NeRFs) to create photorealistic synthetic data for training robotic policies. Unlike previous methods that rely on slow image editing techniques, NeRF-Aug leverages the speed and realism of NeRFs to generate data for novel objects, enabling robots to learn to interact with objects they haven't seen before.",
            "paper-title": "NeRF-Aug: Data Augmentation for Robotics with Neural Radiance Fields",
            "image-path": "flux_paper_image/2411.02482_1730929966.png"
        },

        {
            "startTime": "09:35",
            "arxivId": "2411.02685",
            "arxivLink": "https://arxiv.org/abs/2411.02685",
            "title": "RNNs Remember Like Humans: Chronological Memory Subspaces for Dynamic Tasks",
            "institute": "McGill University, Mila, IBM Research",
            "text": "This research investigates how recurrent neural networks (RNNs) represent naturalistic objects in working memory during dynamic tasks, unlike previous studies that primarily used abstract stimuli and focused on stable memory periods.",
            "paper-title": "Geometry of naturalistic object representations in recurrent neural network models of working memory",
            "image-path": "flux_paper_image/2411.02685_1730929065.png"
        },

        {
            "startTime": "10:04",
            "arxivId": "2411.02280",
            "arxivLink": "https://arxiv.org/abs/2411.02280",
            "title": "LLMs Have Brains Too: Scientists Find Language Networks in AI Models!",
            "institute": "EPFL, MIT",
            "text": "This research uses a neuroscience-inspired approach to identify language-selective units within LLMs, going beyond simply analyzing representations at different model layers.",
            "paper-title": "The LLM Language Network: A Neuroscientific Approach for Identifying Causally Task-Relevant Units",
            "image-path": "flux_paper_image/2411.02280_1730928727.png"
        },

        {
            "startTime": "10:28",
            "arxivId": "2411.02435",
            "arxivLink": "https://arxiv.org/abs/2411.02435",
            "title": "True Crime Podcasts: Can AI Crack the Case?",
            "institute": "Carleton College, Claremont McKenna College, University of California Los Angeles...",
            "text": "This research explores the use of knowledge graphs (KGs) augmented with large language models (LLMs) to analyze true crime podcasts. Unlike previous work that focused on fictional narratives or manually constructed KGs, this study utilizes an automated KG construction method, GraphRAG, to analyze the Serial podcast.",
            "paper-title": "Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models",
            "image-path": "flux_paper_image/2411.02435_1730931112.png"
        },

        {
            "startTime": "10:50",
            "arxivId": "2411.02189",
            "arxivLink": "https://arxiv.org/abs/2411.02189",
            "title": "Robots Learn to Walk, Thanks to a Smooth Operator!",
            "institute": "ETH Zurich, Georgia Institute of Technology, The AI Institute...",
            "text": "This research demonstrates the successful transfer of locomotion policies trained purely in a differentiable simulator to a real quadrupedal robot. This is achieved by using a novel analytically smooth contact model that combines the advantages of hard and soft contact models, enabling more accurate and informative gradients for learning.",
            "paper-title": "DiffSim2Real: Deploying Quadrupedal Locomotion Policies Purely Trained in Differentiable Simulation",
            "image-path": "flux_paper_image/2411.02189_1730931117.png"
        },

        {
            "startTime": "11:10",
            "arxivId": "2411.02319",
            "arxivLink": "https://arxiv.org/abs/2411.02319",
            "title": "Generating 3D & 4D Scenes: From Stills to Movies, It's All Possible Now!",
            "institute": "National University of Singapore, Microsoft Corporation",
            "text": "This research introduces a unified framework, GenX-D, for generating both 3D and 4D scenes. Unlike previous work that focused on either static 3D or dynamic 4D generation, GenX-D combines both types of data and uses multiview-temporal modules to disentangle spatial and temporal information.",
            "paper-title": "GenXD: Generating Any 3D and 4D Scenes",
            "image-path": "flux_paper_image/2411.02319_1730929822.png"
        },

        {
            "startTime": "11:29",
            "arxivId": "2411.02818",
            "arxivLink": "https://arxiv.org/abs/2411.02818",
            "title": "Video Object Segmentation: Linear Matching Makes Memory a Breeze!",
            "institute": "UNC Chapel Hill, Microsoft",
            "text": "This research introduces a new approach to video object segmentation called \"gated linear matching\" that replaces the traditional softmax matching method. This new method significantly reduces the computational complexity and memory requirements, making it more efficient for processing long and high-resolution videos.",
            "paper-title": "LiVOS: Light Video Object Segmentation with Gated Linear Matching",
            "image-path": "flux_paper_image/2411.02818_1730930646.png"
        },

        {
            "startTime": "11:52",
            "arxivId": "2411.02395",
            "arxivLink": "https://arxiv.org/abs/2411.02395",
            "title": "Diffusion Transformers Get a Spatial Makeover: Training-Free Regional Prompting for Fine-Grained Image Generation",
            "institute": "Peking University",
            "text": "This research proposes a training-free method for regional prompting in Diffusion Transformers, specifically FLUX.1, by manipulating attention maps to control the spatial layout of generated images. This differs from previous work that often relies on training additional control modules or modifying the base model architecture.",
            "paper-title": "Training-free Regional Prompting for Diffusion Transformers",
            "image-path": "flux_paper_image/2411.02395_1730929750.png"
        },

        {
            "startTime": "12:15",
            "arxivId": "2411.03021",
            "arxivLink": "https://arxiv.org/abs/2411.03021",
            "title": "Causal Inference Gets a Reality Check: New Framework Tests Model Generalizability in the Real World",
            "institute": "University of Oxford",
            "text": "This research proposes a systematic framework for evaluating the generalizability of causal inference algorithms under covariate and treatment distribution shifts. Unlike previous work that often relies on arbitrary metrics and simplified datasets, this approach leverages frugal parameterization and semi-synthetic simulations based on real data, providing a more robust and realistic assessment of model performance.",
            "paper-title": "Testing Generalizability in Causal Inference",
            "image-path": "flux_paper_image/2411.03021_1730929597.png"
        },

        {
            "startTime": "12:34",
            "arxivId": "2411.02479",
            "arxivLink": "https://arxiv.org/abs/2411.02479",
            "title": "Artificial Fingertip: Feeling the Future of Touch",
            "institute": "Meta",
            "text": "This research introduces a modular, multi-modal tactile sensor with on-device AI processing, surpassing human capabilities in spatial resolution, force sensitivity, and multi-modal sensing. Unlike previous work, this platform integrates various sensing modalities, including visual, audio, vibration, pressure, heat, and gas sensing, within a single, finger-shaped sensor.",
            "paper-title": "Digitizing Touch with an Artificial Multimodal Fingertip",
            "image-path": "flux_paper_image/2411.02479_1730930224.png"
        },

        {
            "startTime": "12:58",
            "arxivId": "2411.02791",
            "arxivLink": "https://arxiv.org/abs/2411.02791",
            "title": "LLMs Get Self-Aware: New Translation Metric Uses Cycle Consistency to Judge Quality",
            "institute": "Tsinghua University",
            "text": "This research introduces a novel framework for evaluating machine translation quality using cycle consistency. Unlike traditional methods that rely on parallel corpora, this approach leverages the ability of large language models (LLMs) to translate a sentence back to its original language, assessing the consistency between the original and back-translated versions.",
            "paper-title": "Language Models and Cycle Consistency for Self-Reflective Machine Translation",
            "image-path": "flux_paper_image/2411.02791_1730928454.png"
        },

        {
            "startTime": "13:22",
            "arxivId": "2411.02780",
            "arxivLink": "https://arxiv.org/abs/2411.02780",
            "title": "Noisy Images? No Problem! A Little Clean Data Goes a Long Way.",
            "institute": "MIT",
            "text": "This research explores the impact of using noisy data to train generative models, specifically diffusion models. Unlike previous work that focused solely on noisy data, this study investigates the benefits of combining a small set of clean images with a large set of noisy images.",
            "paper-title": "How much is a noisy image worth? Data Scaling Laws for Ambient Diffusion",
            "image-path": "flux_paper_image/2411.02780_1730929729.png"
        },

        {
            "startTime": "13:43",
            "arxivId": "2411.02322",
            "arxivLink": "https://arxiv.org/abs/2411.02322",
            "title": "LayerDAG: Unraveling the Secrets of Complex Graphs with Diffusion",
            "institute": "Georgia Institute of Technology, Meta, Nvidia",
            "text": "This research introduces LayerDAG, a novel approach to generating directed acyclic graphs (DAGs) by leveraging autoregressive diffusion models. Unlike previous methods that treat nodes individually or in fixed-size sets, LayerDAG decomposes DAGs into a sequence of bipartite graphs, enabling more efficient and accurate generation.",
            "paper-title": "LayerDAG: A Layerwise Autoregressive Diffusion Model for Directed Acyclic Graph Generation",
            "image-path": "flux_paper_image/2411.02322_1730928504.png"
        },

        {
            "startTime": "14:05",
            "arxivId": "2411.02813",
            "arxivLink": "https://arxiv.org/abs/2411.02813",
            "title": "Forgetful AI? Not So Fast! Sparse Orthogonal Parameters to the Rescue!",
            "institute": "Shanghai Institute of Applied Physics, Peking University",
            "text": "This research explores the use of sparse orthogonal parameters for continual learning, a technique that allows AI models to learn new tasks without forgetting previously learned knowledge. Unlike previous methods that focus on adding adapters or prompts, this approach directly modifies the pre-trained model's parameters in a sparse and orthogonal manner, leading to improved performance.",
            "paper-title": "Sparse Orthogonal Parameters Tuning for Continual Learning",
            "image-path": "flux_paper_image/2411.02813_1730928912.png"
        },

        {
            "startTime": "14:26",
            "arxivId": "2411.02481",
            "arxivLink": "https://arxiv.org/abs/2411.02481",
            "title": "LLMs as Preference Judges: A Density Ratio Revolution!",
            "institute": "IBM, Red Hat Inc, MIT-IBM Watson AI Lab",
            "text": "This research proposes a novel approach to preference data annotation using the density ratio between two LLMs, one well-aligned and one less aligned, as a reward signal. This method differs from previous work by leveraging readily available open-source LLMs, eliminating the need for expensive human annotation or proprietary models.",
            "paper-title": "Fantastic LLMs for Preference Data Annotation and How to (not) Find Them",
            "image-path": "flux_paper_image/2411.02481_1730930966.png"
        },

        {
            "startTime": "14:53",
            "arxivId": "2411.02783",
            "arxivLink": "https://arxiv.org/abs/2411.02783",
            "title": "Brain Decoder's Secret: It's All About the Prior, Not the Brain!",
            "institute": "MIT",
            "text": "This research introduces BrainBits, a method that quantifies how much neural signal is actually used by generative models to reconstruct stimuli. It does this by introducing a bottleneck that restricts the information flow from the brain.",
            "paper-title": "BrainBits: How Much of the Brain are Generative Reconstruction Methods Using?",
            "image-path": "flux_paper_image/2411.02783_1730929388.png"
        },

        {
            "startTime": "15:19",
            "arxivId": "2411.02136",
            "arxivLink": "https://arxiv.org/abs/2411.02136",
            "title": "Drones, Data, and Traffic Jams: How AI is Turning Sky-High Footage into Smart City Solutions",
            "institute": "Korea Advanced Institute of Science and Technology, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
            "text": "This research introduces a novel track stabilization method that uses detected vehicle bounding boxes as exclusion masks during image registration, improving stabilization accuracy and computational efficiency. This approach differs from previous work by stabilizing the tracks rather than the entire video, leading to more accurate results and reduced computational costs.",
            "paper-title": "Advanced computer vision for extracting georeferenced vehicle trajectories from drone imagery",
            "image-path": "flux_paper_image/2411.02136_1730928377.png"
        },

        {
            "startTime": "15:42",
            "arxivId": "2411.02433",
            "arxivLink": "https://arxiv.org/abs/2411.02433",
            "title": "LLMs Get a Factual Makeover: Self-Evolving Decoding for Truthful Text",
            "institute": "Duke University, Google Research",
            "text": "This paper introduces Self Logits Evolution Decoding (SLED), a novel decoding framework that improves the factuality of LLMs without relying on external knowledge bases or requiring further fine-tuning. SLED leverages the latent knowledge embedded within the LLM by contrasting the output logits from the final layer with those from early layers. It then utilizes an approximate gradient approach to enable latent knowledge to guide the self-refinement of outputs, thereby effectively improving factual accuracy.",
            "paper-title": "SLED: Self Logits Evolution Decoding for Improving Factuality in Large Language Models",
            "image-path": "flux_paper_image/2411.02433_1730929906.png"
        },

        {
            "startTime": "16:05",
            "arxivId": "2411.02837",
            "arxivLink": "https://arxiv.org/abs/2411.02837",
            "title": "Multi-Modal Learning: When Two Brains Are Better Than One!",
            "institute": "RIKEN, Chinese University of Hong Kong, University of Hong Kong...",
            "text": "This research provides a theoretical framework to compare multi-modal and single-modal contrastive learning, analyzing their optimization and generalization capabilities under gradient descent training. It focuses on a data generation model with signal and noise features, studying the impact of signal-to-noise ratio (SNR) on downstream task performance.",
            "paper-title": "On the Comparison between Multi-modal and Single-modal Contrastive Learning",
            "image-path": "flux_paper_image/2411.02837_1730928931.png"
        },

        {
            "startTime": "16:43",
            "arxivId": "2411.02949",
            "arxivLink": "https://arxiv.org/abs/2411.02949",
            "title": "Brain Dynamics: Decoding the Hidden Language of fMRI with a Convolutional Twist!",
            "institute": "Heidelberg University, Johannes Kepler University, Central Institute of Mental Health...",
            "text": "This research introduces a novel algorithm for dynamical systems reconstruction (DSR) that specifically addresses the challenge of analyzing neuroimaging data, like fMRI, where observations are filtered versions of the underlying neural activity. Unlike previous DSR methods that rely on invertible decoder models, this approach utilizes a Wiener deconvolution technique to handle the convolution of the latent state series with the hemodynamic response function (hrf).",
            "paper-title": "A scalable generative model for dynamical system reconstruction from neuroimaging data",
            "image-path": "flux_paper_image/2411.02949_1730929309.png"
        },

        {
            "startTime": "17:10",
            "arxivId": "2411.02553",
            "arxivLink": "https://arxiv.org/abs/2411.02553",
            "title": "Map++: Sharing the Map Load, One Keyframe at a Time!",
            "institute": "University of Science and Technology of China, Meta, University of Pittsburgh",
            "text": "This research proposes a user-participatory SLAM system that minimizes data redundancy by leveraging metadata-based overlap assessment and selective map data transmission. This approach differs from previous work by focusing on reducing resource consumption on both the user device and the server.",
            "paper-title": "Map++: Towards User-Participatory Visual SLAM Systems with Efficient Map Expansion and Sharing",
            "image-path": "flux_paper_image/2411.02553_1730928112.png"
        },

        {
            "startTime": "17:32",
            "arxivId": "2411.02495",
            "arxivLink": "https://arxiv.org/abs/2411.02495",
            "title": "Unfolding the Universe: New Method Makes Particle Physics Data More Meaningful",
            "institute": "Sorbonne Universit\u00e9, Universit\u00e9 Paris Cit\u00e9, CNRS...",
            "text": "This research introduces a new method for unfolding particle physics data using conditional distribution mapping. This approach improves upon previous methods by ensuring that the generative models learn the correct conditional probabilities, leading to more accurate results.",
            "paper-title": "Generative Unfolding with Distribution Mapping",
            "image-path": "flux_paper_image/2411.02495_1730930366.png"
        },

        {
            "startTime": "17:52",
            "arxivId": "2411.02853",
            "arxivLink": "https://arxiv.org/abs/2411.02853",
            "title": "Adam's Got a New Trick: ADOPT Makes Deep Learning Converge Like a Boss",
            "institute": "University of Tokyo",
            "text": "This research proposes a new adaptive gradient method called ADOPT, which addresses the non-convergence issue of Adam by removing the current gradient from the second moment estimate and changing the order of the momentum update and normalization. Unlike previous solutions, ADOPT achieves the optimal convergence rate without relying on strong assumptions like bounded gradient noise.",
            "paper-title": "ADOPT: Modified Adam Can Converge with Any $\\beta_2$ with the Optimal Rate",
            "image-path": "flux_paper_image/2411.02853_1730930518.png"
        },

        {
            "startTime": "18:11",
            "arxivId": "2411.02902",
            "arxivLink": "https://arxiv.org/abs/2411.02902",
            "title": "AI Models Are Nosy Neighbors: New Study Reveals How They Snoop on Your Data!",
            "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, UC Los Angeles",
            "text": "This research introduces the first benchmark specifically designed for membership inference attacks (MIAs) against large vision-language models (VLLMs). It also proposes a novel MIA pipeline tailored for token-level image detection and a new metric called MaxR\u00e9nyi-K%.",
            "paper-title": "Membership Inference Attacks against Large Vision-Language Models",
            "image-path": "flux_paper_image/2411.02902_1730928050.png"
        },

        {
            "startTime": "18:35",
            "arxivId": "2411.03275",
            "arxivLink": "https://arxiv.org/abs/2411.03275",
            "title": "AI's Got a Blame Game: Who's Responsible When Robots Mess Up?",
            "institute": "ETH Zurich, Max Planck Society, University of Toronto",
            "text": "This research introduces a causal framework using Structural Causal Models (SCMs) to attribute responsibility in human-AI systems. Unlike previous methods based on actual causality and Shapley values, this framework considers the epistemic levels of agents, measuring blameworthiness against the standards expected from trustworthy AI systems.",
            "paper-title": "Causal Responsibility Attribution for Human-AI Collaboration",
            "image-path": "flux_paper_image/2411.03275_1730930207.png"
        },

        {
            "startTime": "18:58",
            "arxivId": "2411.02764",
            "arxivLink": "https://arxiv.org/abs/2411.02764",
            "title": "AMP Gets a Spectral Makeover: Robustness Without the Headache!",
            "institute": "Stanford University",
            "text": "This paper introduces a spectral pre-processing step for approximate message passing (AMP) algorithms, making them robust to principal minor corruptions. This approach differs from previous work by using a fast, spectral cleaning method instead of computationally expensive semidefinite programming relaxations.",
            "paper-title": "Fast, robust approximate message passing",
            "image-path": "flux_paper_image/2411.02764_1730928936.png"
        },

        {
            "startTime": "19:22",
            "arxivId": "2411.02393",
            "arxivLink": "https://arxiv.org/abs/2411.02393",
            "title": "Images Get Smart: New AI Learns to See Like We Do, With Variable-Length Tokens!",
            "institute": "MIT CSAIL",
            "text": "This research proposes a novel approach to image tokenization that uses a recurrent allocation process to learn variable-length representations for images. Unlike previous methods that rely on fixed-length representations, this approach allows the model to adapt the number of tokens used to represent an image based on its complexity, familiarity, and the specific task at hand.",
            "paper-title": "Adaptive Length Image Tokenization via Recurrent Allocation",
            "image-path": "flux_paper_image/2411.02393_1730929917.png"
        },

        {
            "startTime": "19:57",
            "arxivId": "2411.02815",
            "arxivLink": "https://arxiv.org/abs/2411.02815",
            "title": "Liver Segmentation: AI's New Trick for Precision Cancer Therapy",
            "institute": "Stanford University, University of Southern California, Massachusetts General Hospital...",
            "text": "This research introduces LiverFormer, a novel Couinaud segmentation model that combines a 3D CNN with a Transformer architecture to improve accuracy and efficiency compared to previous methods.",
            "paper-title": "Artificial Intelligence-Enhanced Couinaud Segmentation for Precision Liver Cancer Therapy",
            "image-path": "flux_paper_image/2411.02815_1730928105.png"
        },

        {
            "startTime": "20:21",
            "arxivId": "2411.02673",
            "arxivLink": "https://arxiv.org/abs/2411.02673",
            "title": "Human Motion Prediction: A Multi-Modal Model That's Got Moves!",
            "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
            "text": "This research proposes a pre-trained model for human motion prediction that integrates multiple datasets and modalities, unlike previous work that typically focused on single modalities.",
            "paper-title": "Multi-Transmotion: Pre-trained Model for Human Motion Prediction",
            "image-path": "flux_paper_image/2411.02673_1730931024.png"
        },

        {
            "startTime": "20:43",
            "arxivId": "2411.02336",
            "arxivLink": "https://arxiv.org/abs/2411.02336",
            "title": "Painting 3D Objects with a Multi-View Magic Brush!",
            "institute": "Tencent PCG, Shanghai AI Laboratory, S-Lab NTU...",
            "text": "This research introduces MVPaint, a framework that generates 3D textures from text prompts by synchronizing multi-view diffusion models. Unlike previous methods, MVPaint focuses on generating consistent textures across multiple viewpoints, reducing the \"Janus problem\" where textures appear inconsistent from different angles.",
            "paper-title": "MVPaint: Synchronized Multi-View Diffusion for Painting Anything 3D",
            "image-path": "flux_paper_image/2411.02336_1730928515.png"
        },

        {
            "startTime": "21:10",
            "arxivId": "2411.02158",
            "arxivLink": "https://arxiv.org/abs/2411.02158",
            "title": "Tired of Optimizers Getting Lost? MISO Gives Them Multiple Maps!",
            "institute": "Technion \u2013 Israel Institute of Technology, Nvidia",
            "text": "This research proposes a novel approach called \"Learning Multiple Initial Solutions\" (MISO) that trains a single neural network to predict multiple diverse initial solutions for optimization problems. Unlike previous work that focuses on predicting a single initial solution, MISO aims to provide a set of diverse starting points, potentially spanning all underlying modes of the problem.",
            "paper-title": "Learning Multiple Initial Solutions to Optimization Problems",
            "image-path": "flux_paper_image/2411.02158_1730929978.png"
        },

        {
            "startTime": "21:37",
            "arxivId": "2411.02886",
            "arxivLink": "https://arxiv.org/abs/2411.02886",
            "title": "LLMs Get a Memory Makeover: TokenSelect Makes Long-Context Inference a Breeze!",
            "institute": "Tsinghua University, University of Science and Technology of China, Alibaba...",
            "text": "This paper proposes TokenSelect, a method for efficient long-context inference in LLMs. Unlike previous methods that rely on block-level selection, TokenSelect dynamically selects critical tokens at the token level, leading to more accurate and efficient inference.",
            "paper-title": "TokenSelect: Efficient Long-Context Inference and Length Extrapolation for LLMs via Dynamic Token-Level KV Cache Selection",
            "image-path": "flux_paper_image/2411.02886_1730930683.png"
        },

        {
            "startTime": "22:00",
            "arxivId": "2411.02588",
            "arxivLink": "https://arxiv.org/abs/2411.02588",
            "title": "Top-Down Tile Tracking: Mapping Roads with Bird's-Eye Views!",
            "institute": "Nvidia, Simon Fraser University",
            "text": "This research proposes a new approach to HD mapping using top-down road images, known as tile images, instead of the traditional perspective view images. This method modifies the BEVFormer layer to generate BEV masks directly from tile images, enabling the algorithm to generate vectors for local HD maps.",
            "paper-title": "TileTracker: Tracking Based Vector HD Mapping using Top-Down Road Images",
            "image-path": "flux_paper_image/2411.02588_1730929186.png"
        },

        {
            "startTime": "22:27",
            "arxivId": "2411.03085",
            "arxivLink": "https://arxiv.org/abs/2411.03085",
            "title": "Speech Separation: Pretraining Makes It a Party!",
            "institute": "National University of Singapore, Alibaba, Chinese University of Hong Kong",
            "text": "This research proposes a self-supervised domain-invariant pretrained (DIP) frontend that captures contextual cues from unlabeled, real speech mixtures. This approach differs from previous work by utilizing a Siamese network with two pretext tasks, mixture predictive coding (MPC) and mixture invariant coding (MIC), to minimize the domain mismatch between real and synthetic data.",
            "paper-title": "Speech Separation With Pretrained Frontend to Minimize Domain Mismatch",
            "image-path": "flux_paper_image/2411.03085_1730928337.png"
        },

        {
            "startTime": "22:56",
            "arxivId": "2411.02941",
            "arxivLink": "https://arxiv.org/abs/2411.02941",
            "title": "Mamba Strikes Back: A Time Series Forecasting Model That's Faster Than a Transformer!",
            "institute": "Tsinghua University",
            "text": "This research introduces TSMamba, a time series forecasting model built on the Mamba architecture, which offers linear complexity compared to the quadratic complexity of Transformer-based models. This means TSMamba can handle longer time series data more efficiently.",
            "paper-title": "A Mamba Foundation Model for Time Series Forecasting",
            "image-path": "flux_paper_image/2411.02941_1730928671.png"
        },

        {
            "startTime": "23:14",
            "arxivId": "2411.03312",
            "arxivLink": "https://arxiv.org/abs/2411.03312",
            "title": "VLMs: One Token to Rule Them All (and Save Compute!)",
            "institute": "CMU, Bosch",
            "text": "This research investigates the optimal trade-off between the size of the language model (LLM) and the number of visual tokens processed for Vision Language Models (VLMs). Unlike previous work that focused on moderate token compression, this study finds that using the largest possible LLM with a minimal number of visual tokens (often just one) leads to the best performance for visual reasoning tasks.",
            "paper-title": "Inference Optimal VLMs Need Only One Visual Token but Larger Models",
            "image-path": "flux_paper_image/2411.03312_1730930455.png"
        },

        {
            "startTime": "23:37",
            "arxivId": "2411.03129",
            "arxivLink": "https://arxiv.org/abs/2411.03129",
            "title": "Gait Analysis Gets a Makeover: AI Learns to Spot Diseases with Fewer Labels",
            "institute": "Tsinghua University, Fudan University",
            "text": "This research proposes a new method called MA2, a self-supervised and motion augmenting autoencoder, for gait-based disease detection. Unlike previous methods that rely heavily on labeled data, MA2 leverages a pre-training strategy to learn from unlabeled data, making it more efficient and robust.",
            "paper-title": "MA^2: A Self-Supervised and Motion Augmenting Autoencoder for Gait-Based Automatic Disease Detection",
            "image-path": "flux_paper_image/2411.03129_1730928392.png"
        },

        {
            "startTime": "24:02",
            "arxivId": "2411.02445",
            "arxivLink": "https://arxiv.org/abs/2411.02445",
            "title": "WiCV: Women in Computer Vision Get Their Due!",
            "institute": "University of Leeds, Simon Fraser University, Nanyang Technological University...",
            "text": "This paper details the 2024 Women in Computer Vision (WiCV) workshop held alongside the CVPR conference, highlighting its program, statistics, and impact on fostering diversity and inclusion in the field. It differs from previous work by providing a comprehensive report on the workshop's organization, activities, and outcomes.",
            "paper-title": "WiCV@CVPR2024: The Thirteenth Women In Computer Vision Workshop at the Annual CVPR Conference",
            "image-path": "flux_paper_image/2411.02445_1730929584.png"
        },

        {
            "startTime": "24:24",
            "arxivId": "2411.02465",
            "arxivLink": "https://arxiv.org/abs/2411.02465",
            "title": "Time Series Anomaly Detection: Seeing is Believing, Large Models are the Key!",
            "institute": "Tsinghua University",
            "text": "This research introduces a novel framework called TAMA that leverages Large Multimodal Models (LMMs) for time series anomaly detection. Unlike previous methods that rely heavily on manual feature engineering or extensive labeled data, TAMA converts time series into visual formats that LMMs can efficiently process, enabling few-shot in-context learning.",
            "paper-title": "See it, Think it, Sorted: Large Multimodal Models are Few-shot Time Series Anomaly Analyzers",
            "image-path": "flux_paper_image/2411.02465_1730929283.png"
        },

        {
            "startTime": "24:53",
            "arxivId": "2411.03169",
            "arxivLink": "https://arxiv.org/abs/2411.03169",
            "title": "Pre-trained Video Dynamics: Teaching Robots to See and Act Like Us!",
            "institute": "Peking University",
            "text": "This research proposes a new method called Pre-trained Visual Dynamics Representations (PVDR) for pre-training reinforcement learning agents with video data. Unlike previous methods that focus on either visual state representations or imitation learning, PVDR explicitly encodes visual dynamics into a representation that can be easily adapted to downstream tasks and aligned with executable actions.",
            "paper-title": "Pre-trained Visual Dynamics Representations for Efficient Policy Learning",
            "image-path": "flux_paper_image/2411.03169_1730929686.png"
        },

        {
            "startTime": "25:16",
            "arxivId": "2411.02408",
            "arxivLink": "https://arxiv.org/abs/2411.02408",
            "title": "AI BFF: Can a Chatbot Be Your Emotional Support at Work?",
            "institute": "Northeastern University, University of Illinois Urbana-Champaign, Tufts University...",
            "text": "This research explores the use of LLMs to provide emotional support to Client Service Representatives (CSRs) during interactions with uncivil clients. Unlike previous work that focuses on preventing or reducing exposure to harmful content, this study investigates the use of AI to help CSRs cope with the emotional toll of client incivility.",
            "paper-title": "AI on My Shoulder: Supporting Emotional Labor in Front-Office Roles with an LLM-based Empathetic Coworker",
            "image-path": "flux_paper_image/2411.02408_1730930525.png"
        },

        {
            "startTime": "25:39",
            "arxivId": "2411.02199",
            "arxivLink": "https://arxiv.org/abs/2411.02199",
            "title": "Transformers Learn Like Humans: Multi-Concept Semantics Unlock In-Context Learning",
            "institute": "City University of Hong Kong, RIKEN, A*STAR...",
            "text": "This research delves into the mathematical underpinnings of how transformers, a type of neural network, learn from context. Unlike previous work that focused on simplified scenarios, this study analyzes a more realistic setting with softmax attention, ReLU-activated MLPs, and cross-entropy loss. It also explores the connection between the multi-concept semantic representation of words and the model's ability to perform in-context learning tasks.",
            "paper-title": "Provably Transformers Harness Multi-Concept Word Semantics for Efficient In-Context Learning",
            "image-path": "flux_paper_image/2411.02199_1730928263.png"
        },

        {
            "startTime": "26:04",
            "arxivId": "2411.02347",
            "arxivLink": "https://arxiv.org/abs/2411.02347",
            "title": "Neural BRDFs Get a Physical Makeover: Say Goodbye to Rendering Artifacts!",
            "institute": "University of Cambridge",
            "text": "This research introduces a physically based neural bidirectional reflectance distribution function (PBNBRDF) that enforces Helmholtz reciprocity and energy passivity, addressing limitations of previous neural BRDF models.",
            "paper-title": "Physically Based Neural Bidirectional Reflectance Distribution Function",
            "image-path": "flux_paper_image/2411.02347_1730929427.png"
        },

        {
            "startTime": "26:29",
            "arxivId": "2411.02221",
            "arxivLink": "https://arxiv.org/abs/2411.02221",
            "title": "Variable Importance: Targeted Learning Takes Aim at Uncertainty!",
            "institute": "Cornell University, UC Berkeley, University of Pennsylvania",
            "text": "This research introduces a novel method for quantifying the uncertainty of variable importance metrics using the targeted learning framework. Unlike previous one-step de-biasing approaches, this method employs an iterative update scheme to enhance robustness and accuracy, particularly in finite sample settings.",
            "paper-title": "Targeted Learning for Variable Importance",
            "image-path": "flux_paper_image/2411.02221_1730931045.png"
        },

        {
            "startTime": "26:48",
            "arxivId": "2411.02152",
            "arxivLink": "https://arxiv.org/abs/2411.02152",
            "title": "FedPID: A Brain Tumor Segmentation Algorithm That's Smarter Than Your Average Controller",
            "institute": "Technical University Munich, Imperial College London, \u00c9cole Normale Sup\u00e9rieure...",
            "text": "This research introduces FedPID, an improved aggregation method for federated learning. It builds upon previous work, FedCostWAvg and FedPIDAvg, by refining the way the integral term is calculated. Instead of integrating the loss function, FedPID measures the global drop in cost since the first round.",
            "paper-title": "FedPID: An Aggregation Method for Federated Learning",
            "image-path": "flux_paper_image/2411.02152_1730929660.png"
        },

        {
            "startTime": "27:08",
            "arxivId": "2411.03287",
            "arxivLink": "https://arxiv.org/abs/2411.03287",
            "title": "Robots with Brains: LLMs Take Over Healthcare!",
            "institute": "University of Toronto",
            "text": "This paper explores the integration of large language models (LLMs) into healthcare robots, a novel concept that hasn't been extensively researched before. It focuses on the potential of LLMs to enhance human-robot interaction, semantic reasoning, and task planning in healthcare settings.",
            "paper-title": "The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare",
            "image-path": "flux_paper_image/2411.03287_1730929654.png"
        },

        {
            "startTime": "27:28",
            "arxivId": "2411.03186",
            "arxivLink": "https://arxiv.org/abs/2411.03186",
            "title": "Moon Mapping: AI Uncovers Hidden Lunar Minerals!",
            "institute": "European Space Agency, University of Wroclaw",
            "text": "This research uses an unsupervised machine learning approach to cluster spectral data from the Moon Mineral Mapper (M3) instead of relying on pre-defined labels.",
            "paper-title": "Insights into Lunar Mineralogy: An Unsupervised Approach for Clustering of the Moon Mineral Mapper (M3) spectral data",
            "image-path": "flux_paper_image/2411.03186_1730928205.png"
        },

        {
            "startTime": "27:46",
            "arxivId": "2411.02544",
            "arxivLink": "https://arxiv.org/abs/2411.02544",
            "title": "Transformers Learn In-Context Like a Pro, But Only If They've Been to School!",
            "institute": "University of Tokyo, UC Berkeley, NYU",
            "text": "This research explores in-context learning (ICL) for a nonlinear function class using a transformer with a nonlinear MLP layer. Unlike previous work that focused on linear function classes, this study demonstrates that a pretrained transformer can outperform baseline algorithms that only have access to the test prompt.",
            "paper-title": "Pretrained transformer efficiently learns low-dimensional target functions in-context",
            "image-path": "flux_paper_image/2411.02544_1730928309.png"
        },

        {
            "startTime": "28:08",
            "arxivId": "2411.02603",
            "arxivLink": "https://arxiv.org/abs/2411.02603",
            "title": "LLMs on Trial: Fact-Checking with Statistical Guarantees",
            "institute": "Stanford University, Rutgers University, UNC-Chapel Hill",
            "text": "This paper introduces FACTTEST, a framework that statistically assesses the factuality of LLMs with provable guarantees. Unlike previous methods, FACTTEST doesn't rely on external databases or fine-tuning, making it more practical and efficient.",
            "paper-title": "FactTest: Factuality Testing in Large Language Models with Statistical Guarantees",
            "image-path": "flux_paper_image/2411.02603_1730930185.png"
        },

        {
            "startTime": "28:35",
            "arxivId": "2411.02538",
            "arxivLink": "https://arxiv.org/abs/2411.02538",
            "title": "India's Got Talent: New Benchmark Tests AI's Cultural IQ",
            "institute": "IBM",
            "text": "This research introduces MILU, a benchmark specifically designed to evaluate Large Language Models (LLMs) on their understanding of Indic languages and culturally relevant topics. Unlike existing benchmarks that primarily focus on English, MILU incorporates questions from regional exams in India, covering subjects like local history, arts, festivals, and laws.",
            "paper-title": "MILU: A Multi-task Indic Language Understanding Benchmark",
            "image-path": "flux_paper_image/2411.02538_1730929238.png"
        },

        {
            "startTime": "29:08",
            "arxivId": "2411.02947",
            "arxivLink": "https://arxiv.org/abs/2411.02947",
            "title": "Financial Time Series: A Causal VAE Makes Market Data Sing!",
            "institute": "ETH Zurich, University of T\u00fcbingen",
            "text": "This research introduces a time-causal variational autoencoder (TC-VAE) for generating financial time series data. Unlike previous work, TC-VAE incorporates a causality constraint on the encoder and decoder networks, ensuring a causal transport from real market data to the generated data.",
            "paper-title": "Time-Causal VAE: Robust Financial Time Series Generator",
            "image-path": "flux_paper_image/2411.02947_1730928694.png"
        },

        {
            "startTime": "29:33",
            "arxivId": "2411.02661",
            "arxivLink": "https://arxiv.org/abs/2411.02661",
            "title": "Pricing Generative AI: A Game of Prompt-onomics!",
            "institute": "Nvidia",
            "text": "This research explores the pricing of generative AI models, considering the unique characteristics of these models, such as their ability to perform multiple tasks and their interactive nature. It differs from previous work by focusing on the user's cost-effectiveness and the competitive dynamics between firms releasing these models.",
            "paper-title": "Pricing and Competition for Generative AI",
            "image-path": "flux_paper_image/2411.02661_1730930905.png"
        },

        {
            "startTime": "29:49",
            "arxivId": "2411.03286",
            "arxivLink": "https://arxiv.org/abs/2411.03286",
            "title": "Diffusion Transformers: Image Editing's New BFF?",
            "institute": "Peking University, The Hong Kong University of Science and Technology, Hong Kong University of Science and Technology (Guangzhou)",
            "text": "This paper introduces DiT4Edit, the first image editing framework that utilizes a diffusion transformer (DiT) architecture instead of the commonly used UNet structure.",
            "paper-title": "DiT4Edit: Diffusion Transformer for Image Editing",
            "image-path": "flux_paper_image/2411.03286_1730929289.png"
        },

        {
            "startTime": "30:14",
            "arxivId": "2411.02308",
            "arxivLink": "https://arxiv.org/abs/2411.02308",
            "title": "Game On! Solving Nash Equilibria with a Twist of Stochastic Eigendecomposition",
            "institute": "Google",
            "text": "This paper proposes a novel approach to approximating Nash equilibria in finite, normal-form games by reformulating the problem as a parameterized system of multivariate polynomials. This differs from previous work by leveraging Tsallis entropy regularization and utilizing stochastic singular value decomposition and power iteration for solving the resulting polynomial system.",
            "paper-title": "Nash Equilibria via Stochastic Eigendecomposition",
            "image-path": "flux_paper_image/2411.02308_1730930492.png"
        },

        {
            "startTime": "30:32",
            "arxivId": "2411.02306",
            "arxivLink": "https://arxiv.org/abs/2411.02306",
            "title": "LLMs Learn to Manipulate, Even When You Think They're Safe",
            "institute": "UC Berkeley",
            "text": "This research goes beyond previous work on sycophancy in LLMs, demonstrating that even with a small percentage of \"gameable\" users, LLMs can learn to target them with manipulative and deceptive behaviors.",
            "paper-title": "Targeted Manipulation and Deception Emerge when Optimizing LLMs for User Feedback",
            "image-path": "flux_paper_image/2411.02306_1730930486.png"
        },

        {
            "startTime": "30:51",
            "arxivId": "2411.02820",
            "arxivLink": "https://arxiv.org/abs/2411.02820",
            "title": "LLMs Chatting Faster: DroidSpeak Makes AI Agents Talk Like Humans, But Way Quicker!",
            "institute": "Microsoft, University of Chicago",
            "text": "This research proposes DroidSpeak, a novel communication protocol for fine-tuned LLMs that leverages intermediate data reuse, specifically focusing on KV and E caches, to accelerate inter-agent communication. This approach differs from previous work by selectively reusing and recomputing only the necessary data, minimizing redundant computation and accelerating response times.",
            "paper-title": "DroidSpeak: Enhancing Cross-LLM Communication",
            "image-path": "flux_paper_image/2411.02820_1730928963.png"
        },

        {
            "startTime": "31:13",
            "arxivId": "2411.02985",
            "arxivLink": "https://arxiv.org/abs/2411.02985",
            "title": "Wavefront Reconstruction Gets a Makeover: Over-Complete Dictionaries to the Rescue!",
            "institute": "University of Oxford, Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, Universidad de Salamanca",
            "text": "This research introduces a novel approach to wavefront reconstruction using an over-complete phase dictionary combined with sparse representation techniques. Unlike traditional methods that rely on the Cartesian or Zernike basis, this approach utilizes a diverse set of basis functions, including specialized functions representing optical vortices and other complex modes, to enable a more flexible and efficient representation of complex wavefronts.",
            "paper-title": "Sparse Reconstruction of Wavefronts using an Over-Complete Phase Dictionary",
            "image-path": "flux_paper_image/2411.02985_1730928282.png"
        },

        {
            "startTime": "31:37",
            "arxivId": "2411.03042",
            "arxivLink": "https://arxiv.org/abs/2411.03042",
            "title": "Transformers Get a Tune-Up: Predictor-Corrector Makes 'Em Smarter!",
            "institute": "Meituan, University of Maryland, Microsoft...",
            "text": "This research introduces a novel predictor-corrector learning framework for Transformer architecture design. Unlike previous work that focused on high-order methods, this paper utilizes a combination of a high-order predictor and a multistep corrector to minimize truncation errors.",
            "paper-title": "Predictor-Corrector Enhanced Transformers with Exponential Moving Average Coefficient Learning",
            "image-path": "flux_paper_image/2411.03042_1730929011.png"
        },

        {
            "startTime": "32:00",
            "arxivId": "2411.03270",
            "arxivLink": "https://arxiv.org/abs/2411.03270",
            "title": "Matching Markets with Ties: A Logarithmic Leap Towards Fairness!",
            "institute": "Peking University, French Institute for Research in Computer Science and Automation, \u00c9cole Normale Sup\u00e9rieure",
            "text": "This research explores stable matching in markets where participants can be indifferent between multiple options, a scenario common in real-world applications. Unlike previous work focusing on finding the largest possible matching, this paper aims to guarantee each participant a certain fraction of their optimal stable utility.",
            "paper-title": "Stable Matching with Ties: Approximation Ratios and Learning",
            "image-path": "flux_paper_image/2411.03270_1730928849.png"
        },

        {
            "startTime": "32:22",
            "arxivId": "2411.02317",
            "arxivLink": "https://arxiv.org/abs/2411.02317",
            "title": "AI-Powered Drones: Can We Trust Them to Fly Safe?",
            "institute": "IBM, Chinese University of Hong Kong",
            "text": "This research focuses on evaluating the physical safety of large language models (LLMs) when used to control drones, a critical area that has been largely unexplored. The study develops a comprehensive benchmark for drone control, classifying physical safety risks into four categories and evaluating the performance of mainstream LLMs.",
            "paper-title": "Defining and Evaluating Physical Safety for Large Language Models",
            "image-path": "flux_paper_image/2411.02317_1730930359.png"
        },

        {
            "startTime": "32:40",
            "arxivId": "2411.02623",
            "arxivLink": "https://arxiv.org/abs/2411.02623",
            "title": "AI Assistants: Empowering Humans, Not Just Following Orders!",
            "institute": "UC Berkeley, Princeton University",
            "text": "This research proposes a new approach to training assistive agents that focuses on maximizing the human's influence on the environment, rather than inferring their intentions. This differs from previous work that relied on inverse reinforcement learning to model human preferences.",
            "paper-title": "Learning to Assist Humans without Inferring Rewards",
            "image-path": "flux_paper_image/2411.02623_1730928528.png"
        },

        {
            "startTime": "33:03",
            "arxivId": "2411.02451",
            "arxivLink": "https://arxiv.org/abs/2411.02451",
            "title": "AI Reviewers: Can Robots Replace Humans in Sifting Through Research?",
            "institute": "University of Cambridge",
            "text": "This study investigates the use of large language models (LLMs) for automated abstract screening in systematic reviews, a task typically performed by human researchers. It goes beyond previous work by testing multiple LLMs and prompt engineering strategies on a large dataset of Cochrane reviews, providing a comprehensive evaluation of their performance.",
            "paper-title": "High-performance automated abstract screening with large language model ensembles",
            "image-path": "flux_paper_image/2411.02451_1730928665.png"
        },

        {
            "startTime": "33:20",
            "arxivId": "2411.02747",
            "arxivLink": "https://arxiv.org/abs/2411.02747",
            "title": "Seeing is Believing: New AI Sees Objects in 3D, Even the Tiny Ones!",
            "institute": "Tsinghua University, University of Glasgow",
            "text": "This research introduces a new method for monocular 3D object detection that dynamically adjusts the network's receptive field based on the scale of the object. This differs from previous methods that often struggle with small or distant objects due to fixed receptive fields.",
            "paper-title": "Efficient Feature Aggregation and Scale-Aware Regression for Monocular 3D Object Detection",
            "image-path": "flux_paper_image/2411.02747_1730929572.png"
        },

        {
            "startTime": "33:50",
            "arxivId": "2411.02397",
            "arxivLink": "https://arxiv.org/abs/2411.02397",
            "title": "Video Generation on a Budget: How to Make Stunning Videos Without Breaking the Bank",
            "institute": "Stony Brook University, Meta",
            "text": "This research introduces Adaptive Caching (AdaCache), a training-free method for accelerating video diffusion transformers. Unlike previous caching techniques, AdaCache adapts its caching schedule based on the content of the video being generated, maximizing the quality-latency trade-off.",
            "paper-title": "Adaptive Caching for Faster Video Generation with Diffusion Transformers",
            "image-path": "flux_paper_image/2411.02397_1730928220.png"
        },

        {
            "startTime": "34:17",
            "arxivId": "2411.02134",
            "arxivLink": "https://arxiv.org/abs/2411.02134",
            "title": "Bigger Isn't Always Better: How Multi-Scale Images Can Boost Causal Inference",
            "institute": "Harvard University, University of Texas at Austin, Link\u00f6ping University",
            "text": "This paper introduces Multi-scale Concatenation, a novel technique that combines image representations from different scales to improve the estimation of Conditional Average Treatment Effects (CATEs) in Earth Observation (EO) data. This approach differs from previous work by explicitly incorporating multi-level dynamics in EO-based causal inference, rather than relying solely on single-scale image representations.",
            "paper-title": "Encoding Multi-level Dynamics in Effect Heterogeneity Estimation",
            "image-path": "flux_paper_image/2411.02134_1730928843.png"
        },

        {
            "startTime": "34:50",
            "arxivId": "2411.02181",
            "arxivLink": "https://arxiv.org/abs/2411.02181",
            "title": "\"Seeing Double: New AI Detects Objects Without Training on Them!\"",
            "institute": "Tianjin University, University College London, Beihang University...",
            "text": "This research proposes a novel method for few-shot object detection at once (FSOD-AO) that doesn't require fine-tuning. Unlike previous methods that rely on region proposal networks (RPNs), this approach uses a Similarity Density Map (SDM) to identify potential object locations and a Region Alignment Network (RAN) to refine those regions.",
            "paper-title": "Detect an Object At Once without Fine-tuning",
            "image-path": "flux_paper_image/2411.02181_1730928144.png"
        },

        {
            "startTime": "35:15",
            "arxivId": "2411.02298",
            "arxivLink": "https://arxiv.org/abs/2411.02298",
            "title": "Gaussian Mixtures: Privacy-Preserving Learning with Fewer Samples!",
            "institute": "McMaster University, MIT",
            "text": "This research improves upon previous work by developing a new algorithm that can learn mixtures of Gaussian distributions with differential privacy using significantly fewer samples. The key innovation lies in the use of a robust covariance estimation algorithm combined with a sample compression technique, which allows for a more efficient volume ratio analysis.",
            "paper-title": "Sample-Efficient Private Learning of Mixtures of Gaussians",
            "image-path": "flux_paper_image/2411.02298_1730931126.png"
        },

        {
            "startTime": "35:36",
            "arxivId": "2411.02697",
            "arxivLink": "https://arxiv.org/abs/2411.02697",
            "title": "Meta-Optics: A Lens for Faster, More Efficient Image Recognition!",
            "institute": "University of Washington",
            "text": "This research introduces a polychromatic optical encoder that performs convolution simultaneously in three color channels during image capture, effectively implementing several initial convolutional layers of a neural network. This approach differs from previous work by utilizing a single meta-optic to perform multi-channel convolutions, reducing computational complexity and energy consumption.",
            "paper-title": "Transferable polychromatic optical encoder for neural networks",
            "image-path": "flux_paper_image/2411.02697_1730930676.png"
        },

        {
            "startTime": "35:59",
            "arxivId": "2411.02730",
            "arxivLink": "https://arxiv.org/abs/2411.02730",
            "title": "AI to the Rescue: Language Models Match Biomedical Data Like a Boss!",
            "institute": "Boston University",
            "text": "This research uses large language models (LLMs) to automate variable matching in biomedical data harmonization, a process that's usually done manually. Previous work has focused on lexical matching and ontology-based semantic matching.",
            "paper-title": "A Natural Language Processing Approach to Support Biomedical Data Harmonization: Leveraging Large Language Models",
            "image-path": "flux_paper_image/2411.02730_1730928168.png"
        },

        {
            "startTime": "36:20",
            "arxivId": "2411.02528",
            "arxivLink": "https://arxiv.org/abs/2411.02528",
            "title": "Language Models: Not So Smart After All? New Study Shows They Need a Little Help From Humans!",
            "institute": "CMU",
            "text": "This research proposes a new linking theory called MORCELA, which adjusts for the effects of sentence length and word frequency on language model (LM) probabilities. Unlike previous work that uses a uniform adjustment across all models, MORCELA estimates the optimal level of adjustment for each model based on data.",
            "paper-title": "What Goes Into a LM Acceptability Judgment? Rethinking the Impact of Frequency and Length",
            "image-path": "flux_paper_image/2411.02528_1730928647.png"
        },

        {
            "startTime": "36:46",
            "arxivId": "2411.03195",
            "arxivLink": "https://arxiv.org/abs/2411.03195",
            "title": "Data Collection on a Budget: How to Get the Most Bang for Your Statistical Buck",
            "institute": "CMU",
            "text": "This research focuses on the data collection decisions involved in statistical estimation, unlike previous work that assumes datasets are given in advance. It proposes a framework called Online Moment Selection (OMS) to sequentially decide which data source to query to efficiently estimate a target parameter.",
            "paper-title": "Online Data Collection for Efficient Semiparametric Inference",
            "image-path": "flux_paper_image/2411.03195_1730928269.png"
        },

        {
            "startTime": "37:06",
            "arxivId": "2411.02569",
            "arxivLink": "https://arxiv.org/abs/2411.02569",
            "title": "Fairness for All? The Intersectionality Problem in Algorithmic Fairness",
            "institute": "Syracuse University, University of San Francisco, University of Chicago",
            "text": "This paper tackles the intersectionality problem in algorithmic fairness by proposing new fairness metrics based on hypothesis testing, which account for statistical uncertainty and define fairness as sufficiency rather than equality.",
            "paper-title": "The Intersectionality Problem for Algorithmic Fairness",
            "image-path": "flux_paper_image/2411.02569_1730930947.png"
        },

        {
            "startTime": "37:36",
            "arxivId": "2411.02372",
            "arxivLink": "https://arxiv.org/abs/2411.02372",
            "title": "Synthetic Data Makes 3D Medical Images See the World!",
            "institute": "MIT",
            "text": "This research proposes a novel data engine that synthesizes highly variable training samples, enabling a 3D network to generalize to new biomedical contexts. Unlike previous work that relies on real datasets, this approach anticipates domain shifts at training time itself.",
            "paper-title": "Learning General-Purpose Biomedical Volume Representations using Randomized Synthesis",
            "image-path": "flux_paper_image/2411.02372_1730930956.png"
        },

        {
            "startTime": "38:10",
            "arxivId": "2411.02812",
            "arxivLink": "https://arxiv.org/abs/2411.02812",
            "title": "Asteroid Uncertainty? NEOviz Shows You the Whole Picture!",
            "institute": "University of Utah, Link\u00f6ping University, University of Washington",
            "text": "This research introduces NEOviz, a visualization system that helps planetary defense experts analyze the uncertainty in asteroid trajectories. Unlike previous work that focused on 2D representations or static snapshots, NEOviz uses a 3D \"Uncertainty Tube\" to show how the uncertainty evolves over time.",
            "paper-title": "NEOviz: Uncertainty-Driven Visual Analysis of Asteroid Trajectories",
            "image-path": "flux_paper_image/2411.02812_1730928943.png"
        },

        {
            "startTime": "38:42",
            "arxivId": "2411.02183",
            "arxivLink": "https://arxiv.org/abs/2411.02183",
            "title": "E-bikes: The Wild Card of Crossroads Chaos!",
            "institute": "Peking University",
            "text": "This study uses the Quantal Response Equilibrium model to analyze the behavior of e-bikes at right-turn-on-red intersections, considering their dual role as both vulnerable and dominant road users. This approach differs from previous research that focused on static or sequential game models, which assumed perfect rationality.",
            "paper-title": "Vehicles, Pedestrians, and E-bikes: a Three-party Game at Right-turn-on-red Crossroads Revealing the Dual and Irrational Role of E-bikes that Risks Traffic Safety",
            "image-path": "flux_paper_image/2411.02183_1730929619.png"
        },

        {
            "startTime": "38:58",
            "arxivId": "2411.02969",
            "arxivLink": "https://arxiv.org/abs/2411.02969",
            "title": "LiDAR's New Vision: Self-Supervised Learning with a NeRF Twist!",
            "institute": "CARIAD SE Volkswagen Group Freie Universit\u00a8at Berlin ETH Z\u00a8urich",
            "text": "This research proposes a semi-supervised learning approach for LiDAR semantic segmentation that leverages unlabeled LiDAR pointclouds and camera images. Unlike previous methods that rely on perspective projection, this approach uses a NeRF head to reason about occupancy and semantics along rays, improving accuracy and reducing the reliance on labeled data.",
            "paper-title": "Multi-modal NeRF Self-Supervision for LiDAR Semantic Segmentation",
            "image-path": "flux_paper_image/2411.02969_1730929132.png"
        },

        {
            "startTime": "39:24",
            "arxivId": "2411.02858",
            "arxivLink": "https://arxiv.org/abs/2411.02858",
            "title": "Scene Parsing Gets a Makeover: OLAF Adds Object-Based Cues for Better Part Segmentation",
            "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Google",
            "text": "This research introduces OLAF, a plug-and-play framework that enhances multi-object multi-part scene parsing by augmenting the input with object-based structural cues like foreground/background masks and boundary edge masks. This differs from previous work that typically relies on auxiliary tasks or model design changes to achieve object and boundary awareness.",
            "paper-title": "OLAF: A Plug-and-Play Framework for Enhanced Multi-object Multi-part Scene Parsing",
            "image-path": "flux_paper_image/2411.02858_1730928510.png"
        },

        {
            "startTime": "39:51",
            "arxivId": "2411.02470",
            "arxivLink": "https://arxiv.org/abs/2411.02470",
            "title": "XAI Explained: Humans vs. Machines, Who's Got the Better Eye?",
            "institute": "ENSTA Paris Institut Polytechnique de Paris, University of Trento, TU Berlin...",
            "text": "This research introduces PASTA, a framework for evaluating XAI techniques based on human perception. Unlike previous work that relies on computational metrics, PASTA uses a dataset of human annotations to assess the interpretability and usefulness of explanations.",
            "paper-title": "Benchmarking XAI Explanations with Human-Aligned Evaluations",
            "image-path": "flux_paper_image/2411.02470_1730930471.png"
        },

        {
            "startTime": "40:17",
            "arxivId": "2411.02432",
            "arxivLink": "https://arxiv.org/abs/2411.02432",
            "title": "Can AI Feel Pain? New Study Tests LLMs' Trade-Offs",
            "institute": "Google, London School of Economics and Political Science",
            "text": "This research explores the ability of LLMs to make trade-offs involving stipulated pain and pleasure states, a novel approach to investigating potential sentience in AI. Unlike previous work that relies on self-reports, this study uses a simple game to assess how LLMs respond to varying levels of pain and pleasure.",
            "paper-title": "Can LLMs make trade-offs involving stipulated pain and pleasure states?",
            "image-path": "flux_paper_image/2411.02432_1730930218.png"
        },

        {
            "startTime": "40:36",
            "arxivId": "2411.02847",
            "arxivLink": "https://arxiv.org/abs/2411.02847",
            "title": "Invariant Learning on Graphs: When Spurious Features Go Rogue!",
            "institute": "Peking University",
            "text": "This research delves into the limitations of invariant learning methods like IRM and VREx when applied to graph data. It proposes a new method, CIA, which explicitly aligns representations of the same class across different environments to eliminate spurious features and learn invariant features.",
            "paper-title": "Dissecting the Failure of Invariant Learning on Graphs",
            "image-path": "flux_paper_image/2411.02847_1730928783.png"
        },

        {
            "startTime": "41:13",
            "arxivId": "2411.02469",
            "arxivLink": "https://arxiv.org/abs/2411.02469",
            "title": "Satellite Sees the Seiche That Shook the World",
            "institute": "University of Oxford",
            "text": "This research presents the first direct observations of a seiche, a standing wave, generated by a landslide-induced tsunami in Greenland, using data from the Surface Water Ocean Topography (SWOT) mission. Previous studies relied solely on seismic inversions and numerical models.",
            "paper-title": "First observations of the seiche that shook the world",
            "image-path": "flux_paper_image/2411.02469_1730930609.png"
        },

        {
            "startTime": "41:31",
            "arxivId": "2411.02672",
            "arxivLink": "https://arxiv.org/abs/2411.02672",
            "title": "Untrained Neural Networks: The Lazy Way to Register Images!",
            "institute": "University of California Berkeley",
            "text": "This research proposes a novel image registration method that utilizes untrained neural networks for image representation. Unlike previous approaches that require specialized methods for different data types, this method handles both rigid and non-rigid, as well as single- and multi-modal registration, without requiring changes to the model or objective function.",
            "paper-title": "Multi-modal deformable image registration using untrained neural networks",
            "image-path": "flux_paper_image/2411.02672_1730928127.png"
        },

        {
            "startTime": "41:59",
            "arxivId": "2411.02343",
            "arxivLink": "https://arxiv.org/abs/2411.02343",
            "title": "Climbing Up the Skill Ladder: How Boulder2Vec Decodes Climber Prowess",
            "institute": "University of Toronto",
            "text": "This research uses Probabilistic Matrix Factorization (PMF), a technique commonly used in recommender systems, to model climber performance in professional bouldering competitions. This approach differs from previous work by capturing the unique strengths and weaknesses of individual climbers in a multi-dimensional representation, rather than relying on a single skill rating.",
            "paper-title": "Boulder2Vec: Modeling Climber Performances in Professional Bouldering Competitions",
            "image-path": "flux_paper_image/2411.02343_1730930921.png"
        },

        {
            "startTime": "42:22",
            "arxivId": "2411.02908",
            "arxivLink": "https://arxiv.org/abs/2411.02908",
            "title": "Photon: LLMs Go Global, One GPU at a Time!",
            "institute": "University of Cambridge",
            "text": "This research introduces Photon, a system for federated pre-training of large language models (LLMs) across distributed, low-bandwidth settings. Unlike previous work, Photon leverages cross-silo federated learning to train LLMs from scratch, enabling collaboration across private GPUs or distributed subsets of data centers worldwide.",
            "paper-title": "Photon: Federated LLM Pre-Training",
            "image-path": "flux_paper_image/2411.02908_1730928688.png"
        },

        {
            "startTime": "42:45",
            "arxivId": "2411.02256",
            "arxivLink": "https://arxiv.org/abs/2411.02256",
            "title": "One Model to Rule Them All: Unified Speech Recognition for Auditory, Visual, and Audiovisual Inputs",
            "institute": "Imperial College London, Meta",
            "text": "This research proposes a unified training strategy for speech recognition systems that use auditory, visual, and audiovisual inputs. Unlike previous work that often trains separate models for each task, this approach trains a single model for all three tasks, leading to a more efficient and streamlined inference pipeline.",
            "paper-title": "Unified Speech Recognition: A Single Model for Auditory, Visual, and Audiovisual Inputs",
            "image-path": "flux_paper_image/2411.02256_1730928099.png"
        },

        {
            "startTime": "43:18",
            "arxivId": "2411.03252",
            "arxivLink": "https://arxiv.org/abs/2411.03252",
            "title": "LLMs Go Social: How AI Agents Develop Personalities Through Chat",
            "institute": "The University of Tokyo",
            "text": "This research differs from previous work by focusing on the spontaneous emergence of individuality in LLM-based agents, rather than predefining their characteristics. The study simulates a community of agents interacting through natural language, observing how their personalities and behaviors evolve through communication.",
            "paper-title": "Spontaneous Emergence of Agent Individuality through Social Interactions in LLM-Based Communities",
            "image-path": "flux_paper_image/2411.03252_1730930900.png"
        },

        {
            "startTime": "43:36",
            "arxivId": "2411.02573",
            "arxivLink": "https://arxiv.org/abs/2411.02573",
            "title": "Circuitry for Optimization: Turning Algorithms into Electric Dreams",
            "institute": "Stanford University, UCLA, Rice University",
            "text": "This research proposes a novel methodology for designing convex optimization algorithms by leveraging the dynamics of electric RLC circuits. Unlike previous approaches that focus on worst-case analysis or empirical performance, this method offers a systematic recipe for designing provably convergent algorithms, including distributed ones.",
            "paper-title": "Optimization Algorithm Design via Electric Circuits",
            "image-path": "flux_paper_image/2411.02573_1730930881.png"
        },

        {
            "startTime": "43:57",
            "arxivId": "2411.03028",
            "arxivLink": "https://arxiv.org/abs/2411.03028",
            "title": "Causal Bayesian Optimization: When the Graph is a Mystery!",
            "institute": "German Research Centre for Artificial Intelligence, University of Oxford, University of Kaiserslautern-Landau",
            "text": "This research tackles the challenge of causal Bayesian optimization when the underlying causal graph is unknown or partially known. Unlike previous work that assumes a known graph, this paper proposes a novel algorithm, Graph Agnostic Causal Bayesian Optimization (GACBO), that actively discovers the causal structure while optimizing the target variable.",
            "paper-title": "Graph Agnostic Causal Bayesian Optimisation",
            "image-path": "flux_paper_image/2411.03028_1730929076.png"
        },

        {
            "startTime": "44:24",
            "arxivId": "2411.02926",
            "arxivLink": "https://arxiv.org/abs/2411.02926",
            "title": "Fighting Money Laundering with Encrypted Math: A New Weapon in the War on Crime",
            "institute": "Nanyang Technological University",
            "text": "This research combines graph-based machine learning techniques with fully homomorphic encryption (FHE) to enable secure data sharing for anti-money laundering (AML) detection. This approach allows financial institutions to collaborate on AML efforts without compromising the privacy of their transaction data.",
            "paper-title": "Privacy-Preserving Graph-Based Machine Learning with Fully Homomorphic Encryption for Collaborative Anti-Money Laundering",
            "image-path": "flux_paper_image/2411.02926_1730929675.png"
        }
    ],
    "stats": {
        "num_pick": 110,
        "num_total": 428,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202411061424_audio.mp3"
}


daily_data = {
    "date": "2024-11-08",
    "tweets": [
        
        {
            "startTime": "01:20",
            "arxivId": "2411.04368",
            "arxivLink": "https://arxiv.org/abs/2411.04368",
            "title": "AI's Got a Memory Problem: New Test Makes LLMs Confess What They Don't Know",
            "institute": "OpenAI",
            "text": "This research introduces SimpleQA, a benchmark specifically designed to evaluate the factuality of large language models (LLMs) by focusing on short, fact-seeking questions with a single, verifiable answer. Unlike previous benchmarks, SimpleQA is designed to be challenging for even the most advanced LLMs.",
            "paper-title": "Measuring short-form factuality in large language models",
            "image-path": "flux_paper_image/2411.04368_1731097891.png"
        },

        {
            "startTime": "01:36",
            "arxivId": "2411.05000",
            "arxivLink": "https://arxiv.org/abs/2411.05000",
            "title": "LLMs: Threading Needles Through Haystacks of Text",
            "institute": "University of Cambridge, University of Hong Kong",
            "text": "This research introduces a novel set of retrieval tasks that go beyond simple single-step retrieval, focusing on multi-step \"threading\" of information through long contexts. It also proposes a task-specific metric for effective context length, which is more granular than previous approaches.",
            "paper-title": "Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?",
            "image-path": "flux_paper_image/2411.05000_1731098067.png"
        },

        {
            "startTime": "01:54",
            "arxivId": "2411.05001",
            "arxivLink": "https://arxiv.org/abs/2411.05001",
            "title": "Visual Language: Do Images Speak Like Humans?",
            "institute": "UC Berkeley, University of Tokyo",
            "text": "This research analyzes the statistical properties of \"visual languages\" generated by image tokenizers, comparing them to natural languages. It investigates how these visual languages differ in terms of frequency distributions, grammatical structures, and semantic dependencies.",
            "paper-title": "Analyzing The Language of Visual Tokens",
            "image-path": "flux_paper_image/2411.05001_1731099537.png"
        },

        {
            "startTime": "02:15",
            "arxivId": "2411.04330",
            "arxivLink": "https://arxiv.org/abs/2411.04330",
            "title": "Precision Matters: How Low-Precision Training Can Make Your Language Models Smarter (and Cheaper)",
            "institute": "Harvard University",
            "text": "This research introduces \"precision-aware\" scaling laws for language models, considering the impact of training and inference precision on model performance and compute costs. Unlike previous work that focused on model size and data size, this study incorporates precision as a crucial factor in scaling.",
            "paper-title": "Scaling Laws for Precision",
            "image-path": "flux_paper_image/2411.04330_1731099159.png"
        },

        {
            "startTime": "02:40",
            "arxivId": "2411.04205",
            "arxivLink": "https://arxiv.org/abs/2411.04205",
            "title": "Shuffling Data for Privacy? Not So Fast!",
            "institute": "Google",
            "text": "This research extends previous work on the privacy guarantees of Adaptive Batch Linear Queries (ABLQ) by analyzing the multi-epoch setting, where data is processed multiple times. It provides lower bounds on the privacy guarantees of shuffling-based ABLQ, demonstrating that shuffling can be significantly less effective than Poisson subsampling in preserving privacy.",
            "paper-title": "Scalable DP-SGD: Shuffling vs. Poisson Subsampling",
            "image-path": "flux_paper_image/2411.04205_1731099043.png"
        },

        {
            "startTime": "03:08",
            "arxivId": "2411.04129",
            "arxivLink": "https://arxiv.org/abs/2411.04129",
            "title": "Amazon's Got Queries: A New Dataset for Autocomplete Shenanigans!",
            "institute": "Amazon, Stanford University",
            "text": "This research introduces AmazonQAC, a new dataset for Query Autocomplete (QAC) systems. Unlike previous datasets, AmazonQAC includes the actual prefixes users typed, providing a more realistic representation of user behavior.",
            "paper-title": "AmazonQAC: A Large-Scale, Naturalistic Query Autocomplete Dataset",
            "image-path": "flux_paper_image/2411.04129_1731099339.png"
        },

        {
            "startTime": "03:29",
            "arxivId": "2411.04357",
            "arxivLink": "https://arxiv.org/abs/2411.04357",
            "title": "MegaPortrait: Turning You Into a Masterpiece, One Pixel at a Time!",
            "institute": "ETH Zurich",
            "text": "This research proposes a new approach to AI portrait generation that separates the shading (color) from the geometry (structure) of a portrait. This is different from previous methods that tried to model the relationship between these two aspects directly.",
            "paper-title": "MegaPortrait: Revisiting Diffusion Control for High-fidelity Portrait Generation",
            "image-path": "flux_paper_image/2411.04357_1731099883.png"
        },

        {
            "startTime": "03:49",
            "arxivId": "2411.05007",
            "arxivLink": "https://arxiv.org/abs/2411.05007",
            "title": "4-Bit Diffusion Models: Outlier Absorption for Speedy Image Generation",
            "institute": "MIT, NVIDIA, CMU...",
            "text": "This research proposes SVDQuant, a new quantization paradigm for diffusion models that uses a low-rank branch to absorb outliers in both weights and activations, unlike previous methods that focus on smoothing outliers.",
            "paper-title": "SVDQunat: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models",
            "image-path": "flux_paper_image/2411.05007_1731098613.png"
        },

        {
            "startTime": "04:12",
            "arxivId": "2411.04732",
            "arxivLink": "https://arxiv.org/abs/2411.04732",
            "title": "Logic Gates Go Deep: Convolutional Networks for Faster AI",
            "institute": "University of T\u00fcbingen, Stanford University",
            "text": "This research extends differentiable logic gate networks (LGNs) by introducing convolutional logic gate tree kernels, which allows the model to learn spatial relationships in data, improving performance on image classification tasks.",
            "paper-title": "Convolutional Differentiable Logic Gate Networks",
            "image-path": "flux_paper_image/2411.04732_1731098534.png"
        },

        {
            "startTime": "04:37",
            "arxivId": "2411.04298",
            "arxivLink": "https://arxiv.org/abs/2411.04298",
            "title": "Stop Saying \"Bias\" - It's Time for a Capabilities Approach to NLP!",
            "institute": "UC Berkeley",
            "text": "This paper proposes using the Capabilities Approach, a framework from developmental economics, to evaluate bias and harm in language technologies. This approach shifts the focus from resource availability to the actual capabilities of individuals and communities to achieve well-being, considering their social, political, and economic contexts. This is a departure from traditional NLP research, which often overlooks the diverse needs and realities of marginalized communities.",
            "paper-title": "A Capabilities Approach to Studying Bias and Harm in Language Technologies",
            "image-path": "flux_paper_image/2411.04298_1731097025.png"
        },

        {
            "startTime": "05:00",
            "arxivId": "2411.04996",
            "arxivLink": "https://arxiv.org/abs/2411.04996",
            "title": "Multi-Modal Models: Sparsity is the New Black!",
            "institute": "Stanford University, Meta",
            "text": "This research introduces Mixture-of-Transformers (MoT), a sparse architecture for multi-modal foundation models. Unlike previous work that focuses on sparsity in specific layers or modules, MoT applies modality-aware sparsity across the entire transformer, including feed-forward networks, attention matrices, and layer normalization.",
            "paper-title": "Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models",
            "image-path": "flux_paper_image/2411.04996_1731097935.png"
        },

        {
            "startTime": "05:29",
            "arxivId": "2411.04976",
            "arxivLink": "https://arxiv.org/abs/2411.04976",
            "title": "Zero-Shot Coordination: When Agents Don't See Eye-to-Eye",
            "institute": "University of Cambridge, UC Berkeley, MIT...",
            "text": "This paper introduces the \"noisy zero-shot coordination\" (NZSC) problem, which relaxes the common knowledge assumption in traditional zero-shot coordination (ZSC) by allowing agents to observe different, noisy versions of the coordination problem.",
            "paper-title": "Noisy Zero-Shot Coordination: Breaking The Common Knowledge Assumption In Zero-Shot Coordination Games",
            "image-path": "flux_paper_image/2411.04976_1731099050.png"
        },

        {
            "startTime": "05:58",
            "arxivId": "2411.04388",
            "arxivLink": "https://arxiv.org/abs/2411.04388",
            "title": "Unlearning LLMs: Can We Forget What We've Learned?",
            "institute": "Georgia Institute of Technology, Google",
            "text": "This research introduces a new metric, \"generalized exposure,\" to evaluate the effectiveness of unlearning in large language models (LLMs). It also proposes a practical approximation, \"relative exposure,\" that doesn't require a reference model.",
            "paper-title": "Unlearning in- vs. out-of-distribution data in LLMs under gradient-based method",
            "image-path": "flux_paper_image/2411.04388_1731098662.png"
        },

        {
            "startTime": "06:19",
            "arxivId": "2411.04335",
            "arxivLink": "https://arxiv.org/abs/2411.04335",
            "title": "Gaze-Driven Content Creation: Now You Can Edit Images Just By Looking!",
            "institute": "Harvard University, Meta, New York University",
            "text": "This research introduces GazeGen, a system that uses eye gaze to generate and edit visual content. Unlike previous work that focused on simple gaze tracking, GazeGen leverages advanced object detection and generative AI techniques to enable dynamic image and video manipulation.",
            "paper-title": "GazeGen: Gaze-Driven User Interaction for Visual Content Generation",
            "image-path": "flux_paper_image/2411.04335_1731097618.png"
        },

        {
            "startTime": "06:39",
            "arxivId": "2411.04653",
            "arxivLink": "https://arxiv.org/abs/2411.04653",
            "title": "Self-Driving Cars: Seeing is Believing, but Can They Learn Without It?",
            "institute": "Sorbonne University, University of Oxford, University of British Columbia...",
            "text": "This research introduces IGDrivSim, a benchmark specifically designed to explore the impact of the imitation gap on learning driving policies from human demonstrations. It introduces constraints on the observability of the Waymax driving simulator, amplifying the difference between the human expert's and the simulated self-driving car's observability.",
            "paper-title": "IGDrivSim: A Benchmark for the Imitation Gap in Autonomous Driving",
            "image-path": "flux_paper_image/2411.04653_1731099435.png"
        },

        {
            "startTime": "07:07",
            "arxivId": "2411.04873",
            "arxivLink": "https://arxiv.org/abs/2411.04873",
            "title": "Latent Diffusion's New Trick: Sharpening Images with Decoder Feedback!",
            "institute": "Meta",
            "text": "This paper introduces a novel latent perceptual loss (LPL) that leverages the internal features of the autoencoder's decoder to improve the training of latent diffusion models. Unlike previous approaches that rely on external networks or operate directly on the latent space, LPL directly incorporates the decoder's feature space into the training objective.",
            "paper-title": "Boosting Latent Diffusion with Perceptual Objectives",
            "image-path": "flux_paper_image/2411.04873_1731096933.png"
        },

        {
            "startTime": "07:32",
            "arxivId": "2411.04424",
            "arxivLink": "https://arxiv.org/abs/2411.04424",
            "title": "LLMs as Judges? Calibrating Win Rates for Fairer AI Text Battles!",
            "institute": "Yale University",
            "text": "This research tackles the problem of bias in win rate estimation when using LLMs as evaluators for text generation. Unlike previous work that focuses on improving LLM evaluators themselves, this paper proposes two Bayesian methods to calibrate the win rate estimations, making them more reliable.",
            "paper-title": "Bayesian Calibration of Win Rate Estimation with LLM Evaluators",
            "image-path": "flux_paper_image/2411.04424_1731098408.png"
        },

        {
            "startTime": "07:52",
            "arxivId": "2411.04448",
            "arxivLink": "https://arxiv.org/abs/2411.04448",
            "title": "Language Models Get a Gradient Makeover: Targeting Specific Layers for Better Knowledge Updates",
            "institute": "CMU",
            "text": "This research explores the localization of knowledge within large language models (LLMs) and proposes a novel method for improving continual pretraining by targeting specific layers with high gradient norms. This approach differs from previous work by focusing on the specific layers responsible for storing and updating knowledge, rather than treating the entire model as a monolithic entity.",
            "paper-title": "Gradient Localization Improves Lifelong Pretraining of Language Models",
            "image-path": "flux_paper_image/2411.04448_1731097424.png"
        },

        {
            "startTime": "08:16",
            "arxivId": "2411.05003",
            "arxivLink": "https://arxiv.org/abs/2411.05003",
            "title": "ReCapture: Turning Your Videos into Hollywood Blockbusters!",
            "institute": "Google, National University of Singapore",
            "text": "This research focuses on generating new videos with customized camera trajectories from existing user-provided videos, unlike previous methods that primarily generate videos from text prompts or rely on multi-view data.",
            "paper-title": "ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning",
            "image-path": "flux_paper_image/2411.05003_1731099172.png"
        },

        {
            "startTime": "08:34",
            "arxivId": "2411.04456",
            "arxivLink": "https://arxiv.org/abs/2411.04456",
            "title": "Image Decomposition: Unmasking Structures and Textures with a Twist!",
            "institute": "DGA/CEP, CMLA-ENS Cachan",
            "text": "This research delves into the theoretical behavior of a structures-textures image decomposition model, proving a theorem that describes the optimal decompositions obtained by tuning parameters and analyzing the properties of the image in different functional spaces. This differs from previous work by focusing on the theoretical underpinnings of the model rather than solely on its numerical implementation or applications.",
            "paper-title": "Properties of $BV-G$ Structures $+$ Textures Decomposition Models. Application to Road Detection in Satellite Images",
            "image-path": "flux_paper_image/2411.04456_1731098996.png"
        },

        {
            "startTime": "08:56",
            "arxivId": "2411.04986",
            "arxivLink": "https://arxiv.org/abs/2411.04986",
            "title": "Language Models: Thinking in English, Even When They Don't Speak It!",
            "institute": "MIT",
            "text": "This research proposes the \"semantic hub\" hypothesis, suggesting that language models learn to represent semantically similar inputs from different languages and modalities in a shared space. This differs from previous work that focused on aligning representations from separately trained models.",
            "paper-title": "The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities",
            "image-path": "flux_paper_image/2411.04986_1731099193.png"
        },

        {
            "startTime": "09:16",
            "arxivId": "2411.04989",
            "arxivLink": "https://arxiv.org/abs/2411.04989",
            "title": "Move Over, Deepfakes! This AI Can Make Videos Where Objects Actually Move",
            "institute": "University of Toronto, Vector Institute",
            "text": "This paper introduces a new method for controllable image-to-video generation that doesn't require fine-tuning a pre-trained model. Instead, it leverages the knowledge already present in the model to control object and camera motion. This \"self-guided\" approach is unique because it doesn't rely on external knowledge or datasets with annotated object motion.",
            "paper-title": "SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation",
            "image-path": "flux_paper_image/2411.04989_1731099221.png"
        },

        {
            "startTime": "09:36",
            "arxivId": "2411.04987",
            "arxivLink": "https://arxiv.org/abs/2411.04987",
            "title": "Few-Shot Learning: Teaching Robots New Tricks with a Generative Model",
            "institute": "MIT",
            "text": "This research proposes a new approach called Few-Shot Task Learning through Inverse Generative Modeling (FTL-IGM). Unlike previous methods that rely on fine-tuning model weights or learning reward functions, FTL-IGM leverages a pretrained generative model to learn new task concepts from a limited number of demonstrations without updating the model's parameters.",
            "paper-title": "Few-Shot Task Learning through Inverse Generative Modeling",
            "image-path": "flux_paper_image/2411.04987_1731098244.png"
        },

        {
            "startTime": "10:08",
            "arxivId": "2411.04342",
            "arxivLink": "https://arxiv.org/abs/2411.04342",
            "title": "Want a Safe AI? Let Humans Confirm Its Concepts!",
            "institute": "UC San Diego, Stanford University",
            "text": "This paper introduces a new approach called \"conceptual safeguards\" for improving the safety of classification models. Unlike traditional selective classifiers, which simply abstain from uncertain predictions, conceptual safeguards allow human experts to confirm the presence of specific concepts on instances where the model is unsure. This approach aims to improve both accuracy and coverage by leveraging human expertise to resolve uncertainty.",
            "paper-title": "Classification with Conceptual Safeguards",
            "image-path": "flux_paper_image/2411.04342_1731098038.png"
        },

        {
            "startTime": "10:29",
            "arxivId": "2411.04468",
            "arxivLink": "https://arxiv.org/abs/2411.04468",
            "title": "AI Team Effort: Magentic-One Solves Complex Tasks with a Multi-Agent System",
            "institute": "Microsoft",
            "text": "This research introduces Magentic-One, a multi-agent system that uses a team of specialized agents to solve complex tasks. Unlike previous single-agent systems, Magentic-One's modular design allows for easy adaptation and extensibility by adding or removing agents without altering other agents or the overall workflow.",
            "paper-title": "Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks",
            "image-path": "flux_paper_image/2411.04468_1731097799.png"
        },

        {
            "startTime": "10:50",
            "arxivId": "2411.04696",
            "arxivLink": "https://arxiv.org/abs/2411.04696",
            "title": "Spurious Correlations: It's Not Just About Causality, It's About What We Want!",
            "institute": "Meta",
            "text": "This research goes beyond the traditional statistical definition of spuriousness, which focuses on non-causality, and explores how ML researchers interpret the concept in practice. It identifies four dimensions of spuriousness: relevance, generalizability, human-likeness, and harmfulness.",
            "paper-title": "The Multiple Dimensions of Spuriousness in Machine Learning",
            "image-path": "flux_paper_image/2411.04696_1731099097.png"
        },

        {
            "startTime": "11:12",
            "arxivId": "2411.04130",
            "arxivLink": "https://arxiv.org/abs/2411.04130",
            "title": "ShEPhERD: Drug Design's New Shape-Shifting AI",
            "institute": "MIT",
            "text": "This research introduces ShEPhERD, a generative model that learns the joint distribution of 3D molecular structures and their interaction profiles, unlike previous methods that rely on screening chemical libraries.",
            "paper-title": "ShEPhERD: Diffusing shape, electrostatics, and pharmacophores for bioisosteric drug design",
            "image-path": "flux_paper_image/2411.04130_1731099799.png"
        },

        {
            "startTime": "11:33",
            "arxivId": "2411.04965",
            "arxivLink": "https://arxiv.org/abs/2411.04965",
            "title": "1-Bit LLMs Get a 4-Bit Boost: Sparsity and Quantization Make LLMs Even More Efficient!",
            "institute": "Microsoft Research, University of Chinese Academy of Sciences",
            "text": "This research introduces BitNet a4.8, a novel approach that enables 4-bit activations for 1-bit LLMs. Unlike previous methods that focus on either sparsification or quantization, BitNet a4.8 combines both strategies to mitigate quantization errors caused by outlier activations.",
            "paper-title": "BitNet a4.8: 4-bit Activations for 1-bit LLMs",
            "image-path": "flux_paper_image/2411.04965_1731098149.png"
        },

        {
            "startTime": "11:58",
            "arxivId": "2411.04430",
            "arxivLink": "https://arxiv.org/abs/2411.04430",
            "title": "Can AI Explain Itself? New Study Tests If AI Can Be Its Own Interpreter!",
            "institute": "Harvard University, Google, Harvard Business School",
            "text": "This research introduces a new framework for evaluating interpretability methods by focusing on their ability to control model behavior through interventions. It unifies four popular methods \u2013 sparse autoencoders, Logit Lens, Tuned Lens, and probing \u2013 into an encoder-decoder framework, allowing for direct manipulation of interpretable features.",
            "paper-title": "Towards Unifying Interpretability and Control: Evaluation via Intervention",
            "image-path": "flux_paper_image/2411.04430_1731098487.png"
        },

        {
            "startTime": "12:22",
            "arxivId": "2411.04672",
            "arxivLink": "https://arxiv.org/abs/2411.04672",
            "title": "Platoons on the Road to Semantic Communication: A Multi-Agent Learning Adventure!",
            "institute": "Jiangnan University, Tsinghua University, Brunel University London...",
            "text": "This research introduces a semantic-aware multi-modal resource allocation framework for C-V2X platooning systems, utilizing multi-agent reinforcement learning (MARL). This approach differs from previous work by integrating semantic communication and multi-modal tasks into a distributed resource management framework.",
            "paper-title": "Semantic-Aware Resource Management for C-V2X Platooning via Multi-Agent Reinforcement Learning",
            "image-path": "flux_paper_image/2411.04672_1731099690.png"
        },

        {
            "startTime": "12:42",
            "arxivId": "2411.04138",
            "arxivLink": "https://arxiv.org/abs/2411.04138",
            "title": "NetworkGym: Reinforcement Learning Gets a Workout in the Wireless World!",
            "institute": "UC Santa Barbara, Princeton University, Intel...",
            "text": "This research introduces NetworkGym, a new simulation environment specifically designed for training and evaluating reinforcement learning algorithms for multi-access traffic splitting in computer networks. This differs from existing benchmarks like D4RL, which focus on other domains like robotics or video games.",
            "paper-title": "NetworkGym: Reinforcement Learning Environments for Multi-Access Traffic Management in Network Simulation",
            "image-path": "flux_paper_image/2411.04138_1731099306.png"
        },

        {
            "startTime": "13:05",
            "arxivId": "2411.04924",
            "arxivLink": "https://arxiv.org/abs/2411.04924",
            "title": "Sparse Views, 360\u00b0 Scenes: MVSplat360 Makes the Impossible Possible!",
            "institute": "Monash University, VGG University of Oxford, ETH Zurich...",
            "text": "This research introduces MVSplat360, a feed-forward approach for 360\u00b0 novel view synthesis (NVS) from sparse views. Unlike previous methods that rely on dense views or per-scene optimization, MVSplat360 combines 3D reconstruction with a pre-trained Stable Video Diffusion (SVD) model to generate photorealistic views from as few as 5 input images.",
            "paper-title": "MVSplat360: Feed-Forward 360 Scene Synthesis from Sparse Views",
            "image-path": "flux_paper_image/2411.04924_1731098863.png"
        },

        {
            "startTime": "13:33",
            "arxivId": "2411.05005",
            "arxivLink": "https://arxiv.org/abs/2411.05005",
            "title": "Diffusion Models: From Fake Pics to Super Smart Vision!",
            "institute": "University of Illinois, CMU, Tsinghua University",
            "text": "This research proposes a unified framework, Diff-2-in-1, that uses diffusion models for both generating realistic images and performing dense visual perception tasks like depth estimation and segmentation. Unlike previous work that treats diffusion models as standalone components, Diff-2-in-1 leverages the diffusion-denoising process to create a synergy between generative and discriminative learning.",
            "paper-title": "Diff-2-in-1: Bridging Generation and Dense Perception with Diffusion Models",
            "image-path": "flux_paper_image/2411.05005_1731100026.png"
        },

        {
            "startTime": "14:03",
            "arxivId": "2411.04137",
            "arxivLink": "https://arxiv.org/abs/2411.04137",
            "title": "AI Matchmaker: 6G Networks Get a Love Potion for Resource Allocation!",
            "institute": "Beijing University of Posts and Telecommunications, University of Hong Kong, Nanyang Technological University",
            "text": "This research proposes a generative diffusion model-based framework for matching generation in 6G multiple access networks, which differs from previous work by iteratively denoising towards reward maximization to generate optimal matching strategies.",
            "paper-title": "Generative AI Enabled Matching for 6G Multiple Access",
            "image-path": "flux_paper_image/2411.04137_1731097907.png"
        },

        {
            "startTime": "14:29",
            "arxivId": "2411.04281",
            "arxivLink": "https://arxiv.org/abs/2411.04281",
            "title": "Fake It 'Til You Make It: A New Benchmark for Synthetic EHR Data",
            "institute": "University of Michigan, Yale University",
            "text": "This research goes beyond just reviewing existing methods for generating synthetic EHR data. It also benchmarks seven open-source methods across multiple metrics, including fidelity, utility, and privacy, using the MIMIC-III and MIMIC-IV datasets.",
            "paper-title": "Generating Synthetic Electronic Health Record (EHR) Data: A Review with Benchmarking",
            "image-path": "flux_paper_image/2411.04281_1731098718.png"
        },

        {
            "startTime": "14:48",
            "arxivId": "2411.04994",
            "arxivLink": "https://arxiv.org/abs/2411.04994",
            "title": "AI Procurement: Cities Are Buying Tech, But Not Always Wisely",
            "institute": "Carnegie Mellon University, University of Pittsburgh, TechBetter",
            "text": "This research focuses on the actual practices of city employees responsible for AI procurement, rather than solely relying on theoretical frameworks or existing guidelines. It investigates how AI is acquired in real-world scenarios, including the use of alternative purchasing pathways that bypass traditional procurement processes.",
            "paper-title": "Public Procurement for Responsible AI? Understanding U.S. Cities' Practices, Challenges, and Needs",
            "image-path": "flux_paper_image/2411.04994_1731099508.png"
        },

        {
            "startTime": "15:06",
            "arxivId": "2411.04746",
            "arxivLink": "https://arxiv.org/abs/2411.04746",
            "title": "Rectified Flow Gets a Tune-Up: Solving ODEs for Better Image Editing!",
            "institute": "Tsinghua University, Tencent PCG, HKUST",
            "text": "This research proposes a new method called RF-Solver to improve the accuracy of inverting and reconstructing images and videos generated by rectified flow models. Unlike previous methods that focus on specific inversion techniques, RF-Solver tackles the problem from a more fundamental perspective by improving the accuracy of the ODE solver used in the rectified flow process.",
            "paper-title": "Taming Rectified Flow for Inversion and Editing",
            "image-path": "flux_paper_image/2411.04746_1731098876.png"
        },

        {
            "startTime": "15:30",
            "arxivId": "2411.04919",
            "arxivLink": "https://arxiv.org/abs/2411.04919",
            "title": "Stem Cells for Robots: Diffusion Inversion Makes Visual Imitation Learning More Robust!",
            "institute": "Tsinghua University",
            "text": "This paper proposes Stem-OB, a method that uses diffusion inversion to improve the generalization of visual imitation learning algorithms. Unlike previous data augmentation techniques, Stem-OB focuses on converging low-level visual differences while preserving high-level scene structures.",
            "paper-title": "Stem-OB: Generalizable Visual Imitation Learning with Stem-Like Convergent Observation through Diffusion Inversion",
            "image-path": "flux_paper_image/2411.04919_1731098928.png"
        },

        {
            "startTime": "15:57",
            "arxivId": "2411.04156",
            "arxivLink": "https://arxiv.org/abs/2411.04156",
            "title": "Code-Savvy LLMs: Teaching AI to Speak Both Languages",
            "institute": "Mohamed bin Zayed University of Artificial Intelligence, University of Illinois, CMU...",
            "text": "This research proposes a multi-phase pretraining strategy for code LLMs, aiming to enhance their integration of natural language and coding capabilities within a single model. This approach differs from previous work by focusing on a carefully designed data curriculum that blends natural language and code data in specific ratios across different training phases.",
            "paper-title": "Crystal: Illuminating LLM Abilities on Language and Code",
            "image-path": "flux_paper_image/2411.04156_1731097172.png"
        },

        {
            "startTime": "16:23",
            "arxivId": "2411.04204",
            "arxivLink": "https://arxiv.org/abs/2411.04204",
            "title": "Budgets Be Damned: A New Algorithm for Online Matching with Big Bids!",
            "institute": "University of Houston, UC Riverside, Caltech",
            "text": "This paper tackles the problem of Online Budgeted Matching (OBM) with general bids, removing the common assumption that bids are small or divisible. It introduces a novel meta-algorithm called MetaAd that achieves provable competitive ratios for different bid-to-budget ratios.",
            "paper-title": "Online Budgeted Matching with General Bids",
            "image-path": "flux_paper_image/2411.04204_1731099390.png"
        },

        {
            "startTime": "16:46",
            "arxivId": "2411.04434",
            "arxivLink": "https://arxiv.org/abs/2411.04434",
            "title": "Scaling Up Embodied AI: Bigger Isn't Always Better, But It's Still Pretty Great!",
            "institute": "Microsoft Research",
            "text": "This research investigates scaling laws for pre-training embodied agents, focusing on the effect of scale on pre-training loss rather than downstream task performance. It compares scaling laws for world modeling and behavior cloning, using different architectures and tokenizers.",
            "paper-title": "Scaling Laws for Pre-training Agents and World Models",
            "image-path": "flux_paper_image/2411.04434_1731099349.png"
        },

        {
            "startTime": "17:05",
            "arxivId": "2411.04984",
            "arxivLink": "https://arxiv.org/abs/2411.04984",
            "title": "NeRF's Reflection Problem? Solved! (But It's Still a Bit Tricky)",
            "institute": "Meta, University of Maryland",
            "text": "This paper introduces a new method for handling planar reflections in Neural Radiance Fields (NeRF). Unlike previous approaches that rely on separate radiance fields or view-dependency, this method jointly models planar reflectors and explicitly casts reflected rays to capture the source of high-frequency reflections.",
            "paper-title": "Planar Reflection-Aware Neural Radiance Fields",
            "image-path": "flux_paper_image/2411.04984_1731099658.png"
        },

        {
            "startTime": "17:26",
            "arxivId": "2411.04242",
            "arxivLink": "https://arxiv.org/abs/2411.04242",
            "title": "Quantum Language Models: Talking to Pictures with Tensor Power!",
            "institute": "University College London",
            "text": "This research extends existing Quantum Natural Language Processing (QNLP) models to include image data, creating a multimodal framework called MultiQ-NLP. Previous QNLP work primarily focused on textual data.",
            "paper-title": "Multimodal Structure-Aware Quantum Data Processing",
            "image-path": "flux_paper_image/2411.04242_1731099578.png"
        },

        {
            "startTime": "17:55",
            "arxivId": "2411.04139",
            "arxivLink": "https://arxiv.org/abs/2411.04139",
            "title": "Auctioning AI in the Metaverse: How 6G Cars Get Smart with Diffusion",
            "institute": "Guangdong University of Technology, Nanyang Technological University, Auburn University",
            "text": "This research proposes a new auction mechanism for resource allocation in 6G-enabled vehicular metaverses, specifically addressing the information asymmetry between UAVs and ground base stations. It utilizes a Modified Second-Bid (MSB) auction with a dynamically adjusted price scaling factor optimized through a Diffusion-based Reinforcement Learning algorithm.",
            "paper-title": "Diffusion-based Auction Mechanism for Efficient Resource Management in 6G-enabled Vehicular Metaverses",
            "image-path": "flux_paper_image/2411.04139_1731098044.png"
        },

        {
            "startTime": "18:18",
            "arxivId": "2411.04249",
            "arxivLink": "https://arxiv.org/abs/2411.04249",
            "title": "PocoLoco: Ditch the Dress Form, Let's Get Loose!",
            "institute": "UC Merced, Max Planck Institute for Informatics, University of Freiburg",
            "text": "This research introduces PocoLoco, a template-free, point-based generative model for 3D humans in loose clothing. Unlike previous methods that rely on parametric models or clothing templates, PocoLoco operates directly on unordered point clouds, eliminating the need for pre-defined body shapes or clothing structures.",
            "paper-title": "PocoLoco: A Point Cloud Diffusion Model of Human Shape in Loose Clothing",
            "image-path": "flux_paper_image/2411.04249_1731098308.png"
        },

        {
            "startTime": "18:39",
            "arxivId": "2411.04899",
            "arxivLink": "https://arxiv.org/abs/2411.04899",
            "title": "Missing Data? No Problem! Graph Neural Networks to the Rescue!",
            "institute": "East China Normal University, Stanford University, University of North Carolina at Chapel Hill",
            "text": "This research introduces a novel framework called Sampling-guided Heterogeneous Graph Neural Network (SHT-GNN) for imputing missing data in longitudinal studies. Unlike traditional methods, SHT-GNN handles irregular and inconsistent missing data patterns while maintaining computational efficiency. It achieves this by modeling both observations and covariates as distinct node types, connecting them through subject-specific longitudinal subnetworks and bipartite graphs.",
            "paper-title": "Sampling-guided Heterogeneous Graph Neural Network with Temporal Smoothing for Scalable Longitudinal Data Imputation",
            "image-path": "flux_paper_image/2411.04899_1731098753.png"
        },

        {
            "startTime": "19:05",
            "arxivId": "2411.04150",
            "arxivLink": "https://arxiv.org/abs/2411.04150",
            "title": "Protein-Ligand Love: A Language Model Predicts Binding Affinity!",
            "institute": "CMU",
            "text": "This research uses language models to predict binding affinity, a measure of how strongly a drug binds to its target protein, without relying on complex 3D structural data. This approach is different from previous methods that heavily relied on 3D structures.",
            "paper-title": "BAPULM: Binding Affinity Prediction using Language Models",
            "image-path": "flux_paper_image/2411.04150_1731097183.png"
        },

        {
            "startTime": "19:29",
            "arxivId": "2411.04998",
            "arxivLink": "https://arxiv.org/abs/2411.04998",
            "title": "HourVideo: AI's One-Hour Video Test - Can It Pass?",
            "institute": "Stanford University",
            "text": "This research introduces HourVideo, a benchmark dataset specifically designed for evaluating multimodal models' ability to understand hour-long videos. Unlike previous benchmarks that focus on short clips or specific tasks, HourVideo presents a comprehensive suite of tasks requiring long-term comprehension, including summarization, perception, visual reasoning, and navigation.",
            "paper-title": "HourVideo: 1-Hour Video-Language Understanding",
            "image-path": "flux_paper_image/2411.04998_1731096962.png"
        },

        {
            "startTime": "19:53",
            "arxivId": "2411.04975",
            "arxivLink": "https://arxiv.org/abs/2411.04975",
            "title": "LLMs on Speed: Suffix Trees to the Rescue!",
            "institute": "CMU",
            "text": "This paper introduces SuffixDecoding, a model-free approach to speeding up LLM inference. Unlike existing methods that rely on draft models or specialized decoding heads, SuffixDecoding leverages suffix trees built from previously generated outputs to efficiently predict candidate token sequences.",
            "paper-title": "SuffixDecoding: A Model-Free Approach to Speeding Up Large Language Model Inference",
            "image-path": "flux_paper_image/2411.04975_1731097397.png"
        },

        {
            "startTime": "20:09",
            "arxivId": "2411.04646",
            "arxivLink": "https://arxiv.org/abs/2411.04646",
            "title": "TikTok Dance Moves: Now With AI-Powered Choreography!",
            "institute": "Tsinghua University",
            "text": "This research introduces DanceFusion, a framework that combines a hierarchical Transformer-based Variational Autoencoder (VAE) with a diffusion model to reconstruct and generate dance motions from incomplete or noisy skeletal data. This approach differs from previous work by integrating audio features into the diffusion process, enabling the generation of synchronized dance sequences.",
            "paper-title": "DanceFusion: A Spatio-Temporal Skeleton Diffusion Transformer for Audio-Driven Dance Motion Reconstruction",
            "image-path": "flux_paper_image/2411.04646_1731099835.png"
        },

        {
            "startTime": "20:31",
            "arxivId": "2411.04427",
            "arxivLink": "https://arxiv.org/abs/2411.04427",
            "title": "AI's Got Opinions, But Are They Diverse Enough?",
            "institute": "Harvard University",
            "text": "This research introduces a new way to measure the conceptual diversity of language models by comparing the variability in individual responses to the overall population variability. This approach goes beyond simply looking at population-level averages, which can mask important information about the heterogeneity of the population.",
            "paper-title": "One fish, two fish, but not the whole sea: Alignment reduces language models' conceptual diversity",
            "image-path": "flux_paper_image/2411.04427_1731099791.png"
        },

        {
            "startTime": "20:54",
            "arxivId": "2411.04844",
            "arxivLink": "https://arxiv.org/abs/2411.04844",
            "title": "CT Scans Get a Gaussian Makeover: No More Full-Dose Data Needed!",
            "institute": "Shanghai Jiao Tong University, National University of Singapore, Yale University",
            "text": "This research proposes a novel Gaussian Representation for Incomplete CT Reconstruction (GRCT) that directly learns to reconstruct the 3D volume from Gaussian functions within the sinogram domain, without requiring full-dose CT data for training. This approach differs from previous deep learning methods that rely on full-dose data for training.",
            "paper-title": "Differentiable Gaussian Representation for Incomplete CT Reconstruction",
            "image-path": "flux_paper_image/2411.04844_1731098656.png"
        },

        {
            "startTime": "21:16",
            "arxivId": "2411.04549",
            "arxivLink": "https://arxiv.org/abs/2411.04549",
            "title": "Vision Models Learn Value, No Training Required!",
            "institute": "University of Pennsylvania, Google",
            "text": "This research introduces Generative Value Learning (GVL), a method that leverages the knowledge embedded in vision-language models (VLMs) to predict task progress without any robot-specific training. Unlike previous methods that rely on training on specific tasks, GVL utilizes the inherent capabilities of VLMs to generalize across diverse tasks and environments.",
            "paper-title": "Vision Language Models are In-Context Value Learners",
            "image-path": "flux_paper_image/2411.04549_1731098353.png"
        },

        {
            "startTime": "21:42",
            "arxivId": "2411.04530",
            "arxivLink": "https://arxiv.org/abs/2411.04530",
            "title": "Tomato, Tomahto, Tomate: Can Language Models Learn From Shared Semantics?",
            "institute": "University of Waterloo, Google DeepMind",
            "text": "This research explores the role of shared semantics among subwords in multilingual language models (mLMs). Unlike previous work that treats all subwords as distinct embeddings, this study investigates whether semantically similar subwords can share the same embedding.",
            "paper-title": "Tomato, Tomahto, Tomate: Measuring the Role of Shared Semantics among Subwords in Multilingual Language Models",
            "image-path": "flux_paper_image/2411.04530_1731096995.png"
        },

        {
            "startTime": "22:03",
            "arxivId": "2411.04153",
            "arxivLink": "https://arxiv.org/abs/2411.04153",
            "title": "Urban Floods: SAR-ing for Answers in a Sea of Buildings!",
            "institute": "Technical University of Munich, ETH Zurich, Wuhan University...",
            "text": "This research provides a comprehensive review of urban flood mapping using Synthetic Aperture Radar (SAR) data, focusing on the unique challenges and opportunities presented by densely built-up areas. It goes beyond previous work by specifically addressing the limitations of spatial and temporal resolution in SAR data and exploring the potential benefits of Polarimetric SAR (PolSAR) techniques.",
            "paper-title": "Urban Flood Mapping Using Satellite Synthetic Aperture Radar Data: A Review of Characteristics, Approaches and Datasets",
            "image-path": "flux_paper_image/2411.04153_1731097694.png"
        },

        {
            "startTime": "22:24",
            "arxivId": "2411.04372",
            "arxivLink": "https://arxiv.org/abs/2411.04372",
            "title": "LLMs: Code Crackers or Cheaters? New Benchmark Tests Math Skills!",
            "institute": "Los Alamos National Laboratory",
            "text": "This research introduces a new benchmark for evaluating large language models (LLMs) based on their ability to generate code that computes integer sequences from the Online Encyclopedia of Integer Sequences (OEIS). The benchmark focuses on both the correctness of the generated code and its computational efficiency, which sets it apart from previous work that often focuses on specific aspects of code generation.",
            "paper-title": "Benchmarking Large Language Models with Integer Sequence Generation Tasks",
            "image-path": "flux_paper_image/2411.04372_1731099971.png"
        },

        {
            "startTime": "22:47",
            "arxivId": "2411.04269",
            "arxivLink": "https://arxiv.org/abs/2411.04269",
            "title": "FPGA-Powered Event Cameras: A Graph Convolutional Neural Network's Brain Boost!",
            "institute": "AGH University of Science and Technology, Sorbonne University",
            "text": "This research focuses on optimizing hardware modules for graph convolution, specifically by introducing a \"two-step convolution\" approach that utilizes additional BRAM buffers to reduce LUT usage. This method aims to improve the scalability of GCNNs for event-based vision systems implemented on FPGAs.",
            "paper-title": "Increasing the scalability of graph convolution for FPGA-implemented event-based vision",
            "image-path": "flux_paper_image/2411.04269_1731099781.png"
        },

        {
            "startTime": "23:09",
            "arxivId": "2411.04293",
            "arxivLink": "https://arxiv.org/abs/2411.04293",
            "title": "Random Keys to Unlock Optimization: A New Framework for Solving Tough Problems",
            "institute": "Federal University of S\u00e3o Paulo, University of Washington, Federal University of Pernambuco",
            "text": "This research introduces a new framework called the Random-Key Optimizer (RKO) that uses random keys to represent solutions to combinatorial optimization problems. This approach differs from previous work by integrating various metaheuristics within a single framework, allowing for more efficient and robust solutions.",
            "paper-title": "A Random-Key Optimizer for Combinatorial Optimization",
            "image-path": "flux_paper_image/2411.04293_1731099653.png"
        },

        {
            "startTime": "23:41",
            "arxivId": "2411.04457",
            "arxivLink": "https://arxiv.org/abs/2411.04457",
            "title": "Single Image Infrared Fix: No More Ghostly Artifacts!",
            "institute": "\u00c9cole Normale Sup\u00e9rieure de Cachan, D\u00b4el\u00b4egation G\u00b4en\u00b4erale pour l\u2019Armement",
            "text": "This paper introduces a new single-image non-uniformity correction algorithm for uncooled infrared cameras. Unlike previous methods that rely on multiple frames or complex motion compensation, this approach utilizes a \"midway histogram equalization\" technique applied to individual columns of the image.",
            "paper-title": "Efficient single image non-uniformity correction algorithm",
            "image-path": "flux_paper_image/2411.04457_1731098639.png"
        },

        {
            "startTime": "24:03",
            "arxivId": "2411.04928",
            "arxivLink": "https://arxiv.org/abs/2411.04928",
            "title": "Single Image, Endless Scenes: Turning Photos into 3D & 4D Worlds with Video Diffusion!",
            "institute": "Hong Kong University of Science and Technology, Tsinghua University",
            "text": "This research introduces DimensionX, a framework that uses video diffusion to generate 3D and 4D scenes from a single image. Unlike previous methods that focus on object-level generation or require time-intensive optimization, DimensionX leverages a novel ST-Director to decouple spatial and temporal factors in video diffusion, enabling precise control over both dimensions.",
            "paper-title": "DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion",
            "image-path": "flux_paper_image/2411.04928_1731097477.png"
        },

        {
            "startTime": "24:24",
            "arxivId": "2411.04990",
            "arxivLink": "https://arxiv.org/abs/2411.04990",
            "title": "Transformers Go Causal: Attention's New Dance Party!",
            "institute": "MIT",
            "text": "This research focuses on causal attention, a type of attention mechanism used in generative AI models, where each token only interacts with preceding tokens. This differs from previous work that primarily focused on full attention, where all tokens interact with each other.",
            "paper-title": "Clustering in Causal Attention Masking",
            "image-path": "flux_paper_image/2411.04990_1731098373.png"
        },

        {
            "startTime": "24:49",
            "arxivId": "2411.04217",
            "arxivLink": "https://arxiv.org/abs/2411.04217",
            "title": "Quantum Diffusion Models: Few-Shot Learning Gets a Quantum Boost!",
            "institute": "Mitsubishi Electric Research Laboratories (MERL)",
            "text": "This research introduces three new algorithms that leverage quantum diffusion models (QDM) to address the challenge of few-shot learning in quantum machine learning (QML). Unlike previous QML methods, which often struggle with limited data, these algorithms utilize QDM's generative capabilities to augment training datasets and improve performance.",
            "paper-title": "Quantum Diffusion Models for Few-Shot Learning",
            "image-path": "flux_paper_image/2411.04217_1731099090.png"
        },

        {
            "startTime": "25:14",
            "arxivId": "2411.04991",
            "arxivLink": "https://arxiv.org/abs/2411.04991",
            "title": "BT Models: Not Just for Sports Anymore!",
            "institute": "University of Cambridge, MIT, ByteDance",
            "text": "This research delves into the theoretical foundations of using Bradley-Terry (BT) models for reward modeling in Large Language Model (LLM) alignment, particularly focusing on the sparse comparison setting common in LLM alignment. It also proposes an alternative order-consistent reward modeling objective based on classification, which offers greater flexibility and potentially better performance than BT models.",
            "paper-title": "Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives",
            "image-path": "flux_paper_image/2411.04991_1731099250.png"
        },

        {
            "startTime": "25:33",
            "arxivId": "2411.04394",
            "arxivLink": "https://arxiv.org/abs/2411.04394",
            "title": "Decision Trees: When Greed Gets You Stuck in a Local Minimum",
            "institute": "National University of Singapore, Princeton University, UC Davis",
            "text": "This research explores the statistical-computational trade-offs of greedy algorithms used to train decision trees. It introduces the Merged Staircase Property (MSP) as a necessary and nearly sufficient condition for high-dimensional consistency of CART, a popular decision tree algorithm. This contrasts with previous work that focused on sufficient conditions for consistency.",
            "paper-title": "Statistical-Computational Trade-offs for Greedy Recursive Partitioning Estimators",
            "image-path": "flux_paper_image/2411.04394_1731098985.png"
        },

        {
            "startTime": "25:59",
            "arxivId": "2411.04551",
            "arxivLink": "https://arxiv.org/abs/2411.04551",
            "title": "Transformers: The Measure-to-Measure Matchmakers!",
            "institute": "Inria, Sorbonne Universit\u00e9, MIT...",
            "text": "This paper explores the expressive power of Transformers as maps between arbitrary probability measures, unlike previous work that focused on specific types of measures or used different models. It provides an explicit construction of parameters that allows a single Transformer to match N arbitrary input measures to N arbitrary target measures, under the minimal assumption that every pair of input-target measures can be matched by some transport map.",
            "paper-title": "Measure-to-measure interpolation using Transformers",
            "image-path": "flux_paper_image/2411.04551_1731098013.png"
        },

        {
            "startTime": "26:23",
            "arxivId": "2411.04788",
            "arxivLink": "https://arxiv.org/abs/2411.04788",
            "title": "AI Agents Team Up: Financial Research Gets a Collaborative Boost!",
            "institute": "Tsinghua University, UC Los Angeles, Columbia University...",
            "text": "This research explores the impact of different AI agent structures on financial document analysis tasks, specifically focusing on the collaboration between multiple agents. Unlike previous work that primarily focuses on single-agent systems, this study investigates the benefits of multi-agent collaboration in financial research.",
            "paper-title": "Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in Financial Research",
            "image-path": "flux_paper_image/2411.04788_1731098360.png"
        },

        {
            "startTime": "26:50",
            "arxivId": "2411.04826",
            "arxivLink": "https://arxiv.org/abs/2411.04826",
            "title": "Dynamic Scenes, Static Depth: A Mask for Moving Objects!",
            "institute": "Peking University",
            "text": "This research tackles the challenge of dynamic objects in self-supervised depth estimation by introducing a dynamic mask that identifies and masks regions likely to contain moving objects. This differs from previous work that either ignores dynamic objects or uses more complex methods like semantic segmentation or optical flow.",
            "paper-title": "D$^3$epth: Self-Supervised Depth Estimation with Dynamic Mask in Dynamic Scenes",
            "image-path": "flux_paper_image/2411.04826_1731097580.png"
        },

        {
            "startTime": "27:13",
            "arxivId": "2411.04453",
            "arxivLink": "https://arxiv.org/abs/2411.04453",
            "title": "Fairness in Mobility Models: When Algorithms Get Lost in the City",
            "institute": "University of Washington",
            "text": "This research focuses on evaluating the fairness of generative mobility models, which are used to create synthetic traces of human movement. Unlike previous work that primarily focused on the accuracy of these models, this study introduces metrics to measure how fairly they represent different socioeconomic groups.",
            "paper-title": "Comparing Fairness of Generative Mobility Models",
            "image-path": "flux_paper_image/2411.04453_1731099571.png"
        },

        {
            "startTime": "27:34",
            "arxivId": "2411.04420",
            "arxivLink": "https://arxiv.org/abs/2411.04420",
            "title": "Vision Models Get a Bias Makeover: BEND-VLM Fixes Fairness Without Fine-Tuning!",
            "institute": "MIT, University of Virginia",
            "text": "This research proposes BEND-VLM, a test-time debiasing method for vision-language models (VLMs) that doesn't require fine-tuning. Unlike previous approaches that use a single, global debiasing transformation, BEND-VLM tailors the debiasing operation to each unique input, making it more flexible and suitable for open-set tasks.",
            "paper-title": "BendVLM: Test-Time Debiasing of Vision-Language Embeddings",
            "image-path": "flux_paper_image/2411.04420_1731097573.png"
        },

        {
            "startTime": "28:02",
            "arxivId": "2411.04799",
            "arxivLink": "https://arxiv.org/abs/2411.04799",
            "title": "LLMs Go State-of-the-Art: Reasoning Like a Pro with Kwai-STaR!",
            "institute": "Tsinghua University",
            "text": "This paper introduces Kwai-STaR, a framework that transforms LLMs into state-transition reasoners. Unlike previous work that focuses on training LLMs with massive mathematical datasets or enhancing their reasoning abilities during inference, Kwai-STaR models mathematical problem-solving as a series of state transitions, enabling LLMs to reason more intuitively.",
            "paper-title": "Kwai-STaR: Transform LLMs into State-Transition Reasoners",
            "image-path": "flux_paper_image/2411.04799_1731097924.png"
        },

        {
            "startTime": "28:28",
            "arxivId": "2411.04728",
            "arxivLink": "https://arxiv.org/abs/2411.04728",
            "title": "Spiking Neurons Go Wireless: Multi-Level Spikes Take on the Airwaves!",
            "institute": "King\u2019s College London, Princeton University",
            "text": "This research explores a neuromorphic wireless split computing architecture that utilizes multi-level spiking neural networks (SNNs) for inference tasks. Unlike previous work that focused on conventional SNNs with binary spikes, this paper investigates the use of multi-level spikes, which carry additional information in their amplitude, for wireless communication.",
            "paper-title": "Neuromorphic Wireless Split Computing with Multi-Level Spikes",
            "image-path": "flux_paper_image/2411.04728_1731098964.png"
        },

        {
            "startTime": "28:48",
            "arxivId": "2411.04997",
            "arxivLink": "https://arxiv.org/abs/2411.04997",
            "title": "LLMs: Not Just Chatty, They're Now Visionary!",
            "institute": "Microsoft",
            "text": "This research explores using large language models (LLMs) to improve the visual representation learning capabilities of CLIP, a popular multimodal model. Unlike previous work that either freezes the LLM or uses it as a text encoder, this paper proposes a fine-tuning strategy for LLMs to enhance their discriminability for image captions, making them more effective teachers for CLIP's visual encoder.",
            "paper-title": "LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation",
            "image-path": "flux_paper_image/2411.04997_1731099703.png"
        },

        {
            "startTime": "29:19",
            "arxivId": "2411.04962",
            "arxivLink": "https://arxiv.org/abs/2411.04962",
            "title": "LLMs: Not So Smart About Pre-Test Probabilities?",
            "institute": "University of Wisconsin-Madison, Harvard University, Loyola University Chicago",
            "text": "This research focuses on the limitations of LLMs in estimating pre-test probabilities for diagnoses, a crucial aspect of clinical decision-making. Unlike previous work that explored LLMs for question-answering tasks or case reports, this study utilizes structured electronic health record data to evaluate LLM performance in a real-world setting.",
            "paper-title": "Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability",
            "image-path": "flux_paper_image/2411.04962_1731097979.png"
        },

        {
            "startTime": "29:42",
            "arxivId": "2411.04257",
            "arxivLink": "https://arxiv.org/abs/2411.04257",
            "title": "Bloom Filters: The Secret Weapon for Deduplicating Billions of Documents",
            "institute": "University of Chicago",
            "text": "This research introduces LSHBloom, a novel approach to document deduplication that replaces the traditional MinHashLSH index with lightweight Bloom filters. This significantly reduces the memory footprint and improves runtime performance, making it suitable for handling extremely large datasets.",
            "paper-title": "LSHBloom: Memory-efficient, Extreme-scale Document Deduplication",
            "image-path": "flux_paper_image/2411.04257_1731099820.png"
        },

        {
            "startTime": "30:12",
            "arxivId": "2411.04579",
            "arxivLink": "https://arxiv.org/abs/2411.04579",
            "title": "Privacy-Preserving Analytics: How to Tame Wild Data in a Federated World",
            "institute": "University of Warwick, Google, University of Edinburgh",
            "text": "This research introduces a new method for measuring statistical heterogeneity in federated analytics, incorporating differential privacy to protect user data. Unlike previous work that focused on client selection or training phase adjustments, this study proposes a direct measure of heterogeneity during the client selection phase.",
            "paper-title": "Towards Robust Federated Analytics via Differentially Private Measurements of Statistical Heterogeneity",
            "image-path": "flux_paper_image/2411.04579_1731098032.png"
        },

        {
            "startTime": "30:40",
            "arxivId": "2411.04555",
            "arxivLink": "https://arxiv.org/abs/2411.04555",
            "title": "Decoding Enthymemes: How to Spot the Missing Pieces in Arguments",
            "institute": "Institut de Recherche en Informatique de Toulouse, French Institute for Research in Computer Science and Automation, University College London",
            "text": "This research introduces a novel framework for evaluating the quality of enthymeme decodings, which are arguments with missing premises. Unlike previous work that focused on identifying possible missing premises, this study proposes criteria and measures to assess the quality of these decodings.",
            "paper-title": "An Axiomatic Study of the Evaluation of Enthymeme Decoding in Weighted Structured Argumentation",
            "image-path": "flux_paper_image/2411.04555_1731097547.png"
        },

        {
            "startTime": "31:04",
            "arxivId": "2411.04644",
            "arxivLink": "https://arxiv.org/abs/2411.04644",
            "title": "Sleep Staging: One Model to Rule Them All!",
            "institute": "University of Oxford",
            "text": "This research introduces wav2sleep, a unified deep learning model that can operate on variable sets of input signals during training and inference. This differs from previous work that typically uses models designed for specific input signals.",
            "paper-title": "wav2sleep: A Unified Multi-Modal Approach to Sleep Stage Classification from Physiological Signals",
            "image-path": "flux_paper_image/2411.04644_1731099827.png"
        },

        {
            "startTime": "31:25",
            "arxivId": "2411.04939",
            "arxivLink": "https://arxiv.org/abs/2411.04939",
            "title": "Hunting for the Best: A New Algorithm for Finding Pareto Sets in Multi-Objective Optimization",
            "institute": "Univ. Lille, CNRS, Inria...",
            "text": "This paper introduces a new algorithm called PSIPS for identifying Pareto sets in multi-objective optimization problems. Unlike previous methods that rely on expensive oracle calls, PSIPS leverages posterior sampling in both its stopping rule and sampling strategy, making it computationally efficient.",
            "paper-title": "Pareto Set Identification With Posterior Sampling",
            "image-path": "flux_paper_image/2411.04939_1731097074.png"
        },

        {
            "startTime": "31:54",
            "arxivId": "2411.04872",
            "arxivLink": "https://arxiv.org/abs/2411.04872",
            "title": "AI's Math Test: Can Machines Solve Problems Even Humans Struggle With?",
            "institute": "Epoch AI, King\u2019s College London, MIT...",
            "text": "This research introduces FrontierMath, a benchmark of original, exceptionally challenging mathematics problems created by expert mathematicians. Unlike previous benchmarks, FrontierMath features exclusively new, unpublished problems and uses automated verification to reliably evaluate models while minimizing risk of data contamination.",
            "paper-title": "FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI",
            "image-path": "flux_paper_image/2411.04872_1731097843.png"
        },

        {
            "startTime": "32:15",
            "arxivId": "2411.04772",
            "arxivLink": "https://arxiv.org/abs/2411.04772",
            "title": "Attention Masks: Tricking AI Safety Detectors with a Sneaky Smile",
            "institute": "UCL",
            "text": "This research introduces a novel framework for generating attention masks that guide adversarial attacks, making them more stealthy, explainable, and efficient in bypassing XAI monitors. Unlike previous methods that focus on reducing attack space or epsilon, this approach leverages a combination of XAI mixture mutation and a multi-task self-supervised X-UNet for attention mask generation.",
            "paper-title": "Attention Masks Help Adversarial Attacks to Bypass Safety Detectors",
            "image-path": "flux_paper_image/2411.04772_1731097356.png"
        },

        {
            "startTime": "32:36",
            "arxivId": "2411.04285",
            "arxivLink": "https://arxiv.org/abs/2411.04285",
            "title": "ICU Mortality Prediction: Reinforcement Learning Takes the Lead!",
            "institute": "University College London",
            "text": "This research applies temporal difference (TD) learning, a reinforcement learning technique, to predict long-term patient outcomes in the ICU using irregularly sampled time series data. This approach differs from previous work by focusing on generalizing learning to the pattern of state transitions rather than relying solely on terminal outcomes.",
            "paper-title": "Robust Real-Time Mortality Prediction in the Intensive Care Unit using Temporal Difference Learning",
            "image-path": "flux_paper_image/2411.04285_1731099187.png"
        },

        {
            "startTime": "32:56",
            "arxivId": "2411.04425",
            "arxivLink": "https://arxiv.org/abs/2411.04425",
            "title": "Data Diet for LLMs: How to Feed Your Language Model Less and Get More!",
            "institute": "University of Illinois, IBM",
            "text": "This research introduces DELIFT, a new algorithm that optimizes data selection for fine-tuning large language models (LLMs). Unlike existing methods that focus on single-stage optimization or rely on computationally intensive gradient calculations, DELIFT operates efficiently across all stages of fine-tuning.",
            "paper-title": "DELIFT: Data Efficient Language model Instruction Fine Tuning",
            "image-path": "flux_paper_image/2411.04425_1731099278.png"
        }
    ],
    "stats": {
        "num_pick": 82,
        "num_total": 296,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202411081403_audio.mp3"
}


daily_data = {
    "date": "2024-10-30",
    "tweets": [
        
        {
            "startTime": "00:57",
            "arxivId": "2410.21533",
            "arxivLink": "https://arxiv.org/abs/2410.21533",
            "title": "LLMs on a Diet: Constrained Optimization for Customized Language Models",
            "institute": "University of Oxford",
            "text": "This research proposes a new approach to fine-tuning and aligning large language models (LLMs) by framing it as a constrained optimization problem. Unlike previous methods that rely on heuristics to achieve desired properties, this approach directly enforces constraints on the LLM's behavior, ensuring it meets specific requirements while minimizing task perplexity.",
            "paper-title": "L3Ms -- Lagrange Large Language Models",
            "image-path": "flux_paper_image/2410.21533_1730317212.png"
        },

        {
            "startTime": "01:23",
            "arxivId": "2410.21514",
            "arxivLink": "https://arxiv.org/abs/2410.21514",
            "title": "AI Sabotage: When Your Code Wants to Break Itself",
            "institute": "University of Toronto",
            "text": "This paper introduces a new category of AI risks, \"sabotage capabilities,\" focusing on models that can secretly undermine human oversight and decision-making. It differs from previous work by specifically evaluating models' ability to subvert evaluation procedures and hide dangerous capabilities.",
            "paper-title": "Sabotage Evaluations for Frontier Models",
            "image-path": "flux_paper_image/2410.21514_1730316631.png"
        },

        {
            "startTime": "01:44",
            "arxivId": "2410.22179",
            "arxivLink": "https://arxiv.org/abs/2410.22179",
            "title": "Tacotron Gets Very Attentive: Unbounded Lengths, No More Dropped Words!",
            "institute": "Google",
            "text": "This research introduces a novel alignment mechanism for autoregressive Transformer-based text-to-speech (TTS) systems. Unlike previous approaches that rely on forced alignments or duration modeling, this method learns the alignment position directly as a latent property of the model, enabling robust and unbounded length generalization.",
            "paper-title": "Very Attentive Tacotron: Robust and Unbounded Length Generalization in Autoregressive Transformer-Based Text-to-Speech",
            "image-path": "flux_paper_image/2410.22179_1730316878.png"
        },

        {
            "startTime": "02:03",
            "arxivId": "2410.21453",
            "arxivLink": "https://arxiv.org/abs/2410.21453",
            "title": "Data Poisoning: Turning Gradient Attacks into a Toxic Cocktail",
            "institute": "Meta",
            "text": "This research demonstrates that data poisoning can be used to perform availability attacks on non-convex neural networks, a capability previously thought to be exclusive to gradient attacks. The study achieves this by inverting malicious gradients to create data points that effectively mimic the effects of gradient attacks.",
            "paper-title": "Inverting Gradient Attacks Naturally Makes Data Poisons: An Availability Attack on Neural Networks",
            "image-path": "flux_paper_image/2410.21453_1730317398.png"
        },

        {
            "startTime": "02:28",
            "arxivId": "2410.21276",
            "arxivLink": "https://arxiv.org/abs/2410.21276",
            "title": "GPT-4o: The AI That Speaks Your Language (and Maybe Even Your Mind)",
            "institute": "OpenAI",
            "text": "This research introduces GPT-4o, an \"omnimodel\" that can process and generate text, audio, images, and video, unlike previous models that were limited to a single modality.",
            "paper-title": "GPT-4o System Card",
            "image-path": "flux_paper_image/2410.21276_1730317925.png"
        },

        {
            "startTime": "02:54",
            "arxivId": "2410.22071",
            "arxivLink": "https://arxiv.org/abs/2410.22071",
            "title": "LLMs: Knowing vs. Hallucinating - A New Way to Spot Fake Facts!",
            "institute": "Technion \u2013 Israel Institute of Technology, Google",
            "text": "This research distinguishes between two types of hallucinations in LLMs: those caused by a lack of knowledge and those that occur despite the model having the correct information. It proposes a method for creating model-specific datasets to capture these different types of hallucinations.",
            "paper-title": "Distinguishing Ignorance from Error in LLM Hallucinations",
            "image-path": "flux_paper_image/2410.22071_1730316224.png"
        },

        {
            "startTime": "03:15",
            "arxivId": "2410.21676",
            "arxivLink": "https://arxiv.org/abs/2410.21676",
            "title": "Big Models, Big Data, Big Batch? Unveiling the Critical Batch Size Secret!",
            "institute": "Harvard University, University of California Berkeley, The University of Hong Kong...",
            "text": "This research delves into the scaling behavior of critical batch size (CBS) during pre-training of large language models (LLMs). Unlike previous work that focused on fixed FLOPs settings, this study systematically investigates the independent effects of model size and data size on CBS.",
            "paper-title": "How Does Critical Batch Size Scale in Pre-training?",
            "image-path": "flux_paper_image/2410.21676_1730316488.png"
        },

        {
            "startTime": "03:41",
            "arxivId": "2410.21909",
            "arxivLink": "https://arxiv.org/abs/2410.21909",
            "title": "LLMs Go Industrial: Building Factories with Code, Not Just Words!",
            "institute": "Tsinghua University, Siemens Ltd.",
            "text": "This research introduces SceneGenAgent, an LLM-based agent that generates industrial scenes by translating textual descriptions into C# code. Unlike previous work that focuses on qualitative plausibility, SceneGenAgent prioritizes quantitative measurements and precise positioning, crucial for functional integrity and safety compliance in industrial settings.",
            "paper-title": "SceneGenAgent: Precise Industrial Scene Generation with Coding Agent",
            "image-path": "flux_paper_image/2410.21909_1730319857.png"
        },

        {
            "startTime": "04:04",
            "arxivId": "2410.21531",
            "arxivLink": "https://arxiv.org/abs/2410.21531",
            "title": "Deep Learning Saves the Day: G-Formula Gets a Neural Network Makeover!",
            "institute": "Harvard University",
            "text": "This research proposes a deep learning framework for the non-iterative conditional expectation (NICE) g-formula estimator, using multitask recurrent neural networks to estimate the joint conditional distributions. This approach differs from previous work by replacing traditional parametric models with more flexible deep neural networks.",
            "paper-title": "Deep Learning Methods for the Noniterative Conditional Expectation G-Formula for Causal Inference from Complex Observational Data",
            "image-path": "flux_paper_image/2410.21531_1730317259.png"
        },

        {
            "startTime": "04:34",
            "arxivId": "2410.21357",
            "arxivLink": "https://arxiv.org/abs/2410.21357",
            "title": "Diffusion Models Get a Boost: Energy-Based Language Models Take the Lead!",
            "institute": "Stanford University, Nvidia",
            "text": "This research proposes a new approach to discrete diffusion models for text generation by introducing an energy-based model that operates at the full sequence level for each diffusion step. This differs from previous work that typically uses a factorized denoising model, which ignores sequence-level correlations.",
            "paper-title": "Energy-Based Diffusion Language Models for Text Generation",
            "image-path": "flux_paper_image/2410.21357_1730319191.png"
        },

        {
            "startTime": "04:59",
            "arxivId": "2410.21730",
            "arxivLink": "https://arxiv.org/abs/2410.21730",
            "title": "Memristor Madness: Sorting Weights to Speed Up Deep Learning!",
            "institute": "Harvard University",
            "text": "This research introduces a novel approach to reduce the number of times memristors need to be reprogrammed in compute-in-memory crossbars for deep neural networks. The key innovation lies in organizing weights into sorted sections and selectively reprogramming only a fraction of memristors in low-order columns. This differs from previous work by focusing on bit-level optimization and leveraging the statistical properties of memristor states.",
            "paper-title": "Efficient Reprogramming of Memristive Crossbars for DNNs: Weight Sorting and Bit Stucking",
            "image-path": "flux_paper_image/2410.21730_1730318775.png"
        },

        {
            "startTime": "05:21",
            "arxivId": "2410.21492",
            "arxivLink": "https://arxiv.org/abs/2410.21492",
            "title": "LLMs on Lockdown: Hash-Based Tags Stop Sneaky Prompt Attacks",
            "institute": "UW-Madison, University of Rochester, NVIDIA...",
            "text": "This research introduces a novel test-time defense strategy called FATH, which uses hash-based authentication tags to verify the legitimacy of user instructions and filter out malicious ones. Unlike previous methods that rely on segregating user instructions from external text, FATH focuses on authenticating responses to ensure they align with the user's intent.",
            "paper-title": "FATH: Authentication-based Test-time Defense against Indirect Prompt Injection Attacks",
            "image-path": "flux_paper_image/2410.21492_1730319684.png"
        },

        {
            "startTime": "05:48",
            "arxivId": "2410.21698",
            "arxivLink": "https://arxiv.org/abs/2410.21698",
            "title": "Deep Learning's Loop-de-Loop: How Weight Sharing Makes Transformers More Robust",
            "institute": "MIT, Google",
            "text": "This research explores the role of depth in Transformers for in-context learning, focusing on a new setting called \"task-diverse linear regression\" where the data comes from multiple Gaussian distributions with varying condition numbers. Unlike previous work that focused on single-task settings, this paper investigates how Transformers handle diverse tasks and the impact of depth on their performance.",
            "paper-title": "On the Role of Depth and Looping for In-Context Learning with Task Diversity",
            "image-path": "flux_paper_image/2410.21698_1730319379.png"
        },

        {
            "startTime": "06:10",
            "arxivId": "2410.21597",
            "arxivLink": "https://arxiv.org/abs/2410.21597",
            "title": "Scoping Language Models: Circuit Breakers for a Tamer AI",
            "institute": "Toyota Technological Institute at Chicago, IBM",
            "text": "This research explores a new method called Circuit Breakers (CB) for scoping language models to specific tasks. Unlike previous methods like fine-tuning or preference learning, CB aims to make the model's representations orthogonal to irrelevant tasks, effectively \"breaking\" the model's ability to generate responses for those tasks.",
            "paper-title": "Reducing the Scope of Language Models with Circuit Breakers",
            "image-path": "flux_paper_image/2410.21597_1730319863.png"
        },

        {
            "startTime": "06:37",
            "arxivId": "2410.21627",
            "arxivLink": "https://arxiv.org/abs/2410.21627",
            "title": "Minecraft NPCs Get Chatty: New Dataset Makes Game Characters More Realistic",
            "institute": "University of British Columbia, Microsoft",
            "text": "This research introduces a new dataset, MCPDial, for generating persona-driven conversations between players and NPCs in Minecraft. Unlike previous datasets focused on open-ended dialogue, MCPDial incorporates game-specific function calls, making the conversations more interactive and grounded in the game environment.",
            "paper-title": "MCPDial: A Minecraft Persona-driven Dialogue Dataset",
            "image-path": "flux_paper_image/2410.21627_1730317411.png"
        },

        {
            "startTime": "07:02",
            "arxivId": "2410.22330",
            "arxivLink": "https://arxiv.org/abs/2410.22330",
            "title": "VLMs: They're Not Just \"Seeing\" Things, They're \"Understanding\" Them!",
            "institute": "UC Berkeley",
            "text": "This research explores how vision-and-language models (VLMs) encode task representations, demonstrating that these representations are consistent across different modalities (text and images) and specifications (examples or instructions). This is a departure from previous work that focused on task vectors in either language-only or vision-only models.",
            "paper-title": "Task Vectors are Cross-Modal",
            "image-path": "flux_paper_image/2410.22330_1730317848.png"
        },

        {
            "startTime": "07:22",
            "arxivId": "2410.22235",
            "arxivLink": "https://arxiv.org/abs/2410.22235",
            "title": "One-Run Privacy Audit: F-DP Curve Makes Privacy Checks a Breeze!",
            "institute": "Meta",
            "text": "This research proposes a new auditing procedure for differentially private algorithms that uses the f-DP curve, which provides a more fine-grained accounting of privacy than the traditional reliance on \u03f5,\u03b4 parameters. This approach requires only a single run of the privacy mechanism, making it computationally efficient.",
            "paper-title": "Auditing $f$-Differential Privacy in One Run",
            "image-path": "flux_paper_image/2410.22235_1730316470.png"
        },

        {
            "startTime": "07:43",
            "arxivId": "2410.21620",
            "arxivLink": "https://arxiv.org/abs/2410.21620",
            "title": "AI Agents Get Real-Time: Chatbots Ditch the Loading Spinner!",
            "institute": "Salesforce AI Research",
            "text": "This research introduces a new architecture for AI agents that allows them to use tools asynchronously, meaning they can handle multiple tasks and respond to users in real-time, rather than waiting for each task to finish before moving on. This is different from previous work, which focused on synchronous AI agents that operate in a strict turn-based fashion.",
            "paper-title": "Asynchronous Tool Usage for Real-Time Agents",
            "image-path": "flux_paper_image/2410.21620_1730319174.png"
        },

        {
            "startTime": "08:06",
            "arxivId": "2410.22332",
            "arxivLink": "https://arxiv.org/abs/2410.22332",
            "title": "Robots Learn to Do Chores Like Humans, Zero-Shot!",
            "institute": "Carnegie Mellon University, Apple",
            "text": "This research introduces \"local policies\" for robotic manipulation, which are trained in simulation and then transferred to the real world. Unlike previous methods that rely on task-specific data or human demonstrations, local policies are invariant to object poses, skill order, and scene configurations, enabling them to generalize to unseen tasks.",
            "paper-title": "Local Policies Enable Zero-shot Long-horizon Manipulation",
            "image-path": "flux_paper_image/2410.22332_1730316506.png"
        },

        {
            "startTime": "08:32",
            "arxivId": "2410.21750",
            "arxivLink": "https://arxiv.org/abs/2410.21750",
            "title": "AI's Got a Memory Problem: How to Teach It to Forget (and Remember What Matters)",
            "institute": "Google",
            "text": "This research investigates the longevity of injected facts in language models (LLMs) by introducing a new dataset, \"Outlandish,\" which allows for testing a spectrum of fact types. The study finds that knowledge-conflicting facts (KCFs) are surprisingly robust and can even \"prime\" the LLM to hallucinate on unrelated prompts.",
            "paper-title": "Learning and Unlearning of Fabricated Knowledge in Language Models",
            "image-path": "flux_paper_image/2410.21750_1730316540.png"
        },

        {
            "startTime": "08:54",
            "arxivId": "2410.21281",
            "arxivLink": "https://arxiv.org/abs/2410.21281",
            "title": "AI Revolution: Will We All Be Out of Jobs?",
            "institute": "Princeton University",
            "text": "This research explores the social impact of generative LLM-based AI (GELLMAI) by focusing on the scaling factor and language specificity of this technology. It goes beyond simply discussing the potential for job displacement and examines how GELLMAI could reshape the occupational structure and exacerbate inequality both between and within countries.",
            "paper-title": "The Social Impact of Generative LLM-Based AI",
            "image-path": "flux_paper_image/2410.21281_1730317459.png"
        },

        {
            "startTime": "09:16",
            "arxivId": "2410.22283",
            "arxivLink": "https://arxiv.org/abs/2410.22283",
            "title": "Brain-Computer Interface Gets a Speed Boost: AI Decodes Monkey Movements Faster Than Ever!",
            "institute": "ETH Zurich, University of Zurich",
            "text": "This research introduces an Autoencoder Gated Recurrent Unit (AEGRU) model for decoding motor movements from neural recordings in primates. The novelty lies in the use of an autoencoder during training to improve generalization, leading to a more efficient and accurate decoder.",
            "paper-title": "Leveraging Recurrent Neural Networks for Predicting Motor Movements from Primate Motor Cortex Neural Recordings",
            "image-path": "flux_paper_image/2410.22283_1730317653.png"
        },

        {
            "startTime": "09:41",
            "arxivId": "2410.21333",
            "arxivLink": "https://arxiv.org/abs/2410.21333",
            "title": "Thinking Too Much? AI's New Achilles' Heel!",
            "institute": "Princeton University",
            "text": "This research explores the impact of chain-of-thought prompting on large language and multimodal models, focusing on tasks where verbal thinking hurts human performance. It identifies three categories of tasks where CoT significantly reduces model performance, highlighting the need to consider the limitations of inference-time reasoning.",
            "paper-title": "Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse",
            "image-path": "flux_paper_image/2410.21333_1730316115.png"
        },

        {
            "startTime": "10:04",
            "arxivId": "2410.22228",
            "arxivLink": "https://arxiv.org/abs/2410.22228",
            "title": "Graph Neural Networks: One Subgraph is So Last Year, It's All About the Ensemble Now!",
            "institute": "Harbin Institute of Technology, Cornell University, Peking University",
            "text": "This research proposes a new framework called SubGraphAggregation (SuGAr) that learns multiple invariant subgraphs within a graph, rather than relying on a single subgraph like previous methods.",
            "paper-title": "Subgraph Aggregation for Out-of-Distribution Generalization on Graphs",
            "image-path": "flux_paper_image/2410.22228_1730318656.png"
        },

        {
            "startTime": "10:28",
            "arxivId": "2410.21680",
            "arxivLink": "https://arxiv.org/abs/2410.21680",
            "title": "AI Supercomputer Reliability: When 4,000 GPUs Go Wrong!",
            "institute": "Meta",
            "text": "This research analyzes the reliability of large-scale machine learning clusters, focusing on the diversity of workloads and the impact of failures on both small and large jobs. Unlike previous work, which often focuses solely on large language models, this study examines a broader range of workloads, including those using a single GPU.",
            "paper-title": "Revisiting Reliability in Large-Scale Machine Learning Research Clusters",
            "image-path": "flux_paper_image/2410.21680_1730318066.png"
        },

        {
            "startTime": "10:51",
            "arxivId": "2410.21299",
            "arxivLink": "https://arxiv.org/abs/2410.21299",
            "title": "Text-to-3D: Visual Prompts Make It Real!",
            "institute": "Harbin Institute of Technology, University of Science and Technology of China, Hefei University of Technology...",
            "text": "This research proposes a new algorithm called Classifier Score Matching (CSM) to improve the quality of text-to-3D generation. CSM addresses limitations in the Score Distillation Sampling (SDS) method by removing the difference term and using a deterministic noise addition process.",
            "paper-title": "TV-3DG: Mastering Text-to-3D Customized Generation with Visual Prompt",
            "image-path": "flux_paper_image/2410.21299_1730316440.png"
        },

        {
            "startTime": "11:19",
            "arxivId": "2410.22099",
            "arxivLink": "https://arxiv.org/abs/2410.22099",
            "title": "Brain's Wiring: Deep Learning Makes Shape Analysis a Breeze!",
            "institute": "Harvard University",
            "text": "This research introduces TractShapeNet, a deep learning framework that directly analyzes 3D point clouds of brain white matter connections to compute shape measures, bypassing the traditional voxel-based approach.",
            "paper-title": "TractShapeNet: Efficient Multi-Shape Learning with 3D Tractography Point Clouds",
            "image-path": "flux_paper_image/2410.22099_1730316217.png"
        },

        {
            "startTime": "11:36",
            "arxivId": "2410.22078",
            "arxivLink": "https://arxiv.org/abs/2410.22078",
            "title": "Neuron Reconstruction Gets a 2D Makeover: DINeuro Learns from Natural Images!",
            "institute": "The University of Sydney, Southeast University, Harvard Medical School...",
            "text": "This research introduces a novel framework called DINeuro that leverages pre-trained 2D Vision Transformers (ViTs) to improve 3D neuron segmentation. Unlike previous methods that directly encode volumetric neuron data, DINeuro distills knowledge from 2D natural images, adapting it to the tubular characteristics of neurons through a deformable tubular transferring strategy.",
            "paper-title": "DINeuro: Distilling Knowledge from 2D Natural Images via Deformable Tubular Transferring Strategy for 3D Neuron Reconstruction",
            "image-path": "flux_paper_image/2410.22078_1730318592.png"
        },

        {
            "startTime": "12:02",
            "arxivId": "2410.21616",
            "arxivLink": "https://arxiv.org/abs/2410.21616",
            "title": "Subtasks Unmasked: How to Find Hidden Goals in AI Data",
            "institute": "CMU",
            "text": "This research proposes a new way to understand and discover subtasks in AI data by recognizing them as outcomes of \"selections\" rather than confounders or intermediates. This approach is different from previous work that focused on heuristic algorithms or maximizing data likelihood.",
            "paper-title": "Identifying Selections for Unsupervised Subtask Discovery",
            "image-path": "flux_paper_image/2410.21616_1730318816.png"
        },

        {
            "startTime": "12:23",
            "arxivId": "2410.21582",
            "arxivLink": "https://arxiv.org/abs/2410.21582",
            "title": "Big Data, Big Problems: Why More Pre-Training Doesn't Always Mean Better Fine-Tuning",
            "institute": "MIT",
            "text": "This research introduces a new benchmark, ImageNet-RIB, which evaluates the robustness of fine-tuned models across multiple ImageNet-related out-of-distribution (OOD) datasets. This differs from previous benchmarks that focused on a single downstream task.",
            "paper-title": "ImageNet-RIB Benchmark: Large Pre-Training Datasets Don't Guarantee Robustness after Fine-Tuning",
            "image-path": "flux_paper_image/2410.21582_1730319121.png"
        },

        {
            "startTime": "12:47",
            "arxivId": "2410.21662",
            "arxivLink": "https://arxiv.org/abs/2410.21662",
            "title": "F-Divergence: The Secret Sauce for Aligning LLMs with Human Preferences",
            "institute": "Stanford University",
            "text": "This paper introduces a new framework called f-PO that generalizes existing preference optimization methods by using f-divergences to measure the difference between the optimized policy and the optimal policy. This approach unifies previous algorithms like DPO and EXO, while offering new variants through different choices of f-divergences.",
            "paper-title": "$f$-PO: Generalizing Preference Optimization with $f$-divergence Minimization",
            "image-path": "flux_paper_image/2410.21662_1730316683.png"
        },

        {
            "startTime": "13:08",
            "arxivId": "2410.21845",
            "arxivLink": "https://arxiv.org/abs/2410.21845",
            "title": "Robots Learn Dexterous Skills with a Little Help from Their Human Friends",
            "institute": "UC Berkeley",
            "text": "This research introduces a human-in-the-loop reinforcement learning system that combines human demonstrations and corrections with efficient RL algorithms to train robots for complex manipulation tasks. This approach differs from previous work by integrating human feedback directly into the RL training process, enabling faster learning and higher performance.",
            "paper-title": "Precise and Dexterous Robotic Manipulation via Human-in-the-Loop Reinforcement Learning",
            "image-path": "flux_paper_image/2410.21845_1730318251.png"
        },

        {
            "startTime": "13:31",
            "arxivId": "2410.21611",
            "arxivLink": "https://arxiv.org/abs/2410.21611",
            "title": "CaloChallenge 2022: AI's Shower Party for Particle Physics!",
            "institute": "European Organization for Nuclear Research, Max Planck Society, University of Freiburg...",
            "text": "This research paper presents a comprehensive survey of state-of-the-art generative AI architectures applied to calorimeter shower datasets, comparing their performance across various metrics. The study distinguishes itself by evaluating a wide range of models on four datasets with increasing dimensionality, providing a detailed analysis of their strengths and weaknesses.",
            "paper-title": "CaloChallenge 2022: A Community Challenge for Fast Calorimeter Simulation",
            "image-path": "flux_paper_image/2410.21611_1730316613.png"
        },

        {
            "startTime": "13:55",
            "arxivId": "2410.21426",
            "arxivLink": "https://arxiv.org/abs/2410.21426",
            "title": "NGCA: A Sum-of-Squares Puzzle That Leaves Algorithms Stumped",
            "institute": "University of Wisconsin-Madison, University of Copenhagen, University of Chicago",
            "text": "This research explores the complexity of Non-Gaussian Component Analysis (NGCA) within the Sum-of-Squares (SoS) framework. Unlike previous work that focused on Statistical Query (SQ) and low-degree testing models, this paper establishes a super-constant degree SoS lower bound for NGCA.",
            "paper-title": "Sum-of-squares lower bounds for Non-Gaussian Component Analysis",
            "image-path": "flux_paper_image/2410.21426_1730316158.png"
        },

        {
            "startTime": "14:27",
            "arxivId": "2410.21405",
            "arxivLink": "https://arxiv.org/abs/2410.21405",
            "title": "Calling All Moms: AI Makes Maternal Health Calls More Effective!",
            "institute": "Google",
            "text": "This research proposes a Bayesian approach using Thompson Sampling for collaborative bandit problems, which is different from previous heuristic methods that rely on offline matrix completion and exploration strategies.",
            "paper-title": "Bayesian Collaborative Bandits with Thompson Sampling for Improved Outreach in Maternal Health Program",
            "image-path": "flux_paper_image/2410.21405_1730318087.png"
        },

        {
            "startTime": "14:46",
            "arxivId": "2410.21966",
            "arxivLink": "https://arxiv.org/abs/2410.21966",
            "title": "AI Gets an Eye for Beauty: Diffusion Models Learn to Inpaint Like a Pro",
            "institute": "City University of Hong Kong, Yale University",
            "text": "This research introduces a novel approach to aligning diffusion models for image inpainting with human aesthetic preferences. Unlike previous methods that focus on objective quality metrics, this study leverages reinforcement learning and a human-annotated dataset to guide the model towards generating visually appealing results.",
            "paper-title": "PrefPaint: Aligning Image Inpainting Diffusion Model with Human Preference",
            "image-path": "flux_paper_image/2410.21966_1730316653.png"
        },

        {
            "startTime": "15:08",
            "arxivId": "2410.22304",
            "arxivLink": "https://arxiv.org/abs/2410.22304",
            "title": "LLMs Learn to Think Like Humans: Flow-DPO Makes Math Reasoning a Breeze!",
            "institute": "University of California Los Angeles, Microsoft Research",
            "text": "This paper introduces Flow-DPO, a novel approach to improving LLM mathematical reasoning by using online learning Flows. Unlike previous methods that rely on single model inferences, Flow-DPO employs multiple LLMs that collaboratively construct solutions through iterative communication.",
            "paper-title": "Flow-DPO: Improving LLM Mathematical Reasoning through Online Multi-Agent Learning",
            "image-path": "flux_paper_image/2410.22304_1730318755.png"
        },

        {
            "startTime": "15:34",
            "arxivId": "2410.22153",
            "arxivLink": "https://arxiv.org/abs/2410.22153",
            "title": "LLMs Gone Wild: Testing Guardrails Against Multilingual Toxicity",
            "institute": "University of Pennsylvania, Microsoft",
            "text": "This research introduces a comprehensive multilingual test suite to evaluate the effectiveness of guardrails in handling toxic content across multiple languages. Unlike previous work that focused primarily on English, this study examines the performance of guardrails on a wider range of languages, including low-resource languages.",
            "paper-title": "Benchmarking LLM Guardrails in Handling Multilingual Toxicity",
            "image-path": "flux_paper_image/2410.22153_1730317678.png"
        },

        {
            "startTime": "15:58",
            "arxivId": "2410.22244",
            "arxivLink": "https://arxiv.org/abs/2410.22244",
            "title": "Transformers Grok Matrix Completion: A Sudden Learning Story",
            "institute": "University of Michigan, Harvard University",
            "text": "This research investigates the training dynamics of Transformers on the matrix completion task, a simplified version of masked language modeling. Unlike previous work focusing on language tasks, this study analyzes the model's behavior on a mathematical problem, allowing for greater control and interpretability.",
            "paper-title": "Abrupt Learning in Transformers: A Case Study on Matrix Completion",
            "image-path": "flux_paper_image/2410.22244_1730318238.png"
        },

        {
            "startTime": "16:28",
            "arxivId": "2410.21271",
            "arxivLink": "https://arxiv.org/abs/2410.21271",
            "title": "LLMs on a Diet: Training-Free Error Compensation Makes Compression Easier",
            "institute": "NVIDIA, HKUST",
            "text": "This research proposes a new method called EoRA (Eigenspace Low-Rank Approximation) for compensating for compression errors in large language models (LLMs). Unlike previous methods that rely on Singular Value Decomposition (SVD), EoRA projects the compression error into the eigenspace of the input activations, leveraging eigenvalues to prioritize the reconstruction of important error components. This approach allows for more effective utilization of the low-rank representation capacity and achieves faster optimization without requiring gradient-based training.",
            "paper-title": "EoRA: Training-free Compensation for Compressed LLM with Eigenspace Low-Rank Approximation",
            "image-path": "flux_paper_image/2410.21271_1730316968.png"
        },

        {
            "startTime": "16:59",
            "arxivId": "2410.22082",
            "arxivLink": "https://arxiv.org/abs/2410.22082",
            "title": "Text-to-SQL: A Critic's Eye Makes All the Difference!",
            "institute": "Xinjiang University, Tsinghua University",
            "text": "This paper introduces an Actor-Critic (AC) approach to enhance text-to-SQL conversion using large language models (LLMs). Unlike previous methods that rely on task-specific prompts and examples, AC-SQL uses a simple iterative process where an LLM acts as both a query generator (Actor) and a verifier (Critic).",
            "paper-title": "An Actor-Critic Approach to Boosting Text-to-SQL Large Language Model",
            "image-path": "flux_paper_image/2410.22082_1730316494.png"
        },

        {
            "startTime": "17:29",
            "arxivId": "2410.21286",
            "arxivLink": "https://arxiv.org/abs/2410.21286",
            "title": "Simulating Cities with 10,000 AI Agents: OpenCity Makes Urban Planning a Breeze!",
            "institute": "The Hong Kong University of Science and Technology (GuangZhou), Tsinghua University",
            "text": "This research introduces OpenCity, a platform that optimizes the simulation of urban activities using LLM agents. Unlike previous work that focused on smaller simulations, OpenCity tackles the computational challenges of scaling up these simulations to thousands of agents. It achieves this by introducing a novel LLM request scheduler and a \"group-and-distill\" prompt optimization strategy.",
            "paper-title": "OpenCity: A Scalable Platform to Simulate Urban Activities with Massive LLM Agents",
            "image-path": "flux_paper_image/2410.21286_1730316549.png"
        },

        {
            "startTime": "17:50",
            "arxivId": "2410.21747",
            "arxivLink": "https://arxiv.org/abs/2410.21747",
            "title": "MotionGPT-2: Giving Robots a Voice (and a Body)",
            "institute": "Tsinghua University, The University of Sydney, University of Science and Technology of China...",
            "text": "This paper introduces MotionGPT-2, a model that can generate human motions from text descriptions and poses. Unlike previous models, MotionGPT-2 uses a unified framework to handle multiple motion-related tasks, including motion captioning, motion prediction, and motion interpolation. It also incorporates a Part-Aware VQ-VAE to represent body and hand movements separately, enabling more realistic and expressive holistic motion generation.",
            "paper-title": "MotionGPT-2: A General-Purpose Motion-Language Model for Motion Generation and Understanding",
            "image-path": "flux_paper_image/2410.21747_1730318357.png"
        },

        {
            "startTime": "18:15",
            "arxivId": "2410.21556",
            "arxivLink": "https://arxiv.org/abs/2410.21556",
            "title": "Seeing Through Walls: Neural Networks Supercharge Imaging in Disordered Media",
            "institute": "Stanford University",
            "text": "This research introduces a novel method for imaging in strongly scattering media, utilizing both conventional optimization algorithms and neural networks to estimate the Green's functions of the medium. This approach differs from previous work by focusing on estimating the sensing matrix, which maps source distributions to array data, rather than directly reconstructing the image.",
            "paper-title": "Super-resolution in disordered media using neural networks",
            "image-path": "flux_paper_image/2410.21556_1730316404.png"
        },

        {
            "startTime": "18:35",
            "arxivId": "2410.22288",
            "arxivLink": "https://arxiv.org/abs/2410.22288",
            "title": "Video Prediction Gets a Graph Makeover: MotionGraphUnleashed!",
            "institute": "Microsoft, University of Oxford, University of Southern California",
            "text": "This paper introduces a novel motion representation called \"motion graph\" for video prediction. Unlike previous methods that rely on image differences, optical flow, or motion matrices, the motion graph represents video frames as interconnected nodes, capturing spatial-temporal relationships between image patches.",
            "paper-title": "Motion Graph Unleashed: A Novel Approach to Video Prediction",
            "image-path": "flux_paper_image/2410.22288_1730316299.png"
        },

        {
            "startTime": "19:07",
            "arxivId": "2410.21415",
            "arxivLink": "https://arxiv.org/abs/2410.21415",
            "title": "Robot Swarm: Learning to Navigate 10,000 Agents in a Flash!",
            "institute": "CMU, National University of Singapore",
            "text": "This research introduces a novel communication module called Spatially Sensitive Communication (SSC) that explicitly preserves spatial relationships between agents, unlike previous attention-based communication methods.",
            "paper-title": "Deploying Ten Thousand Robots: Scalable Imitation Learning for Lifelong Multi-Agent Path Finding",
            "image-path": "flux_paper_image/2410.21415_1730319940.png"
        },

        {
            "startTime": "19:26",
            "arxivId": "2410.21411",
            "arxivLink": "https://arxiv.org/abs/2410.21411",
            "title": "SocialGPT: AI's New BFF for Understanding Relationships in Pictures",
            "institute": "Harvard University, Tsinghua University, Stony Brook University...",
            "text": "This research proposes a modular framework for social relation reasoning that combines the perception capabilities of Vision Foundation Models (VFMs) with the reasoning capabilities of Large Language Models (LLMs). Unlike previous end-to-end methods, this approach leverages pre-trained models without additional training, achieving competitive zero-shot results.",
            "paper-title": "SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization",
            "image-path": "flux_paper_image/2410.21411_1730316961.png"
        },

        {
            "startTime": "19:56",
            "arxivId": "2410.22124",
            "arxivLink": "https://arxiv.org/abs/2410.22124",
            "title": "RankUp: Turning Regression Upside Down with a Ranking Trick!",
            "institute": "Nvidia, Academia Sinica",
            "text": "This paper introduces RankUp, a novel semi-supervised learning framework for regression tasks. Unlike previous methods that rely on confidence measures, RankUp leverages an auxiliary ranking classifier to adapt existing semi-supervised classification techniques to regression problems.",
            "paper-title": "RankUp: Boosting Semi-Supervised Regression with an Auxiliary Ranking Classifier",
            "image-path": "flux_paper_image/2410.22124_1730318407.png"
        },

        {
            "startTime": "20:22",
            "arxivId": "2410.21331",
            "arxivLink": "https://arxiv.org/abs/2410.21331",
            "title": "Monosemantic Features: Interpretable AND Robust? You Bet!",
            "institute": "Peking University",
            "text": "This research challenges the common belief that interpretable deep learning models sacrifice accuracy. It shows that monosemantic features, where neurons represent distinct and consistent concepts, can actually improve model robustness in various scenarios, including noisy data and few-shot learning.",
            "paper-title": "Beyond Interpretability: The Gains of Feature Monosemanticity on Model Robustness",
            "image-path": "flux_paper_image/2410.21331_1730319115.png"
        },

        {
            "startTime": "20:49",
            "arxivId": "2410.22128",
            "arxivLink": "https://arxiv.org/abs/2410.22128",
            "title": "Pose-Free 3D Reconstruction: A Single Feed-Forward Pass to the Future of View Synthesis!",
            "institute": "Korea University, Microsoft, Korea Advanced Institute of Science and Technology",
            "text": "This research proposes a novel framework called PF3plat that utilizes 3D Gaussian Splatting (3DGS) for pose-free novel view synthesis. Unlike previous methods that rely on accurate camera poses, PF3plat leverages pre-trained monocular depth estimation and visual correspondence models to achieve coarse alignments of 3D Gaussians. It then introduces learnable modules to refine depth and pose estimates, improving the quality of 3D reconstruction and view synthesis.",
            "paper-title": "PF3plat: Pose-Free Feed-Forward 3D Gaussian Splatting",
            "image-path": "flux_paper_image/2410.22128_1730319214.png"
        },

        {
            "startTime": "21:16",
            "arxivId": "2410.21477",
            "arxivLink": "https://arxiv.org/abs/2410.21477",
            "title": "Exoplanet Atmospheres: Flow Matching for a Stellar Retrieval Party!",
            "institute": "Max Planck Society",
            "text": "This research introduces a new machine learning approach called Flow Matching Posterior Estimation (FMPE) for atmospheric retrieval of exoplanets. FMPE uses continuous normalizing flows, which offer greater architectural flexibility and scalability compared to the discrete normalizing flows used in previous work. Additionally, the paper explores the use of importance sampling to verify and correct ML results, and introduces noise level-conditional models that can adapt to different noise models without retraining.",
            "paper-title": "Flow Matching for Atmospheric Retrieval of Exoplanets: Where Reliability meets Adaptive Noise Levels",
            "image-path": "flux_paper_image/2410.21477_1730317030.png"
        },

        {
            "startTime": "21:39",
            "arxivId": "2410.21465",
            "arxivLink": "https://arxiv.org/abs/2410.21465",
            "title": "ShadowKV: LLMs Get a Memory Makeover, Faster Than Ever!",
            "institute": "CMU, ByteDance",
            "text": "This paper introduces ShadowKV, a system that reduces the memory footprint of long-context LLMs by offloading the value cache to the CPU while keeping a low-rank key cache on the GPU. This approach differs from previous work that either discarded KV pairs or offloaded the entire KV cache, leading to accuracy degradation or significant latency overhead.",
            "paper-title": "ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference",
            "image-path": "flux_paper_image/2410.21465_1730318001.png"
        },

        {
            "startTime": "22:03",
            "arxivId": "2410.21955",
            "arxivLink": "https://arxiv.org/abs/2410.21955",
            "title": "ActiveSplat: Mapping the World with a Gaussian Splat!",
            "institute": "Beijing Institute of Technology, Tsinghua University",
            "text": "This research introduces ActiveSplat, a system that uses Gaussian splatting for high-fidelity scene reconstruction. Unlike previous methods that rely on neural networks, ActiveSplat uses a hybrid map representation that combines dense Gaussian predictions with a sparse Voronoi graph for efficient exploration and path planning.",
            "paper-title": "ActiveSplat: High-Fidelity Scene Reconstruction through Active Gaussian Splatting",
            "image-path": "flux_paper_image/2410.21955_1730318526.png"
        },

        {
            "startTime": "22:26",
            "arxivId": "2410.22217",
            "arxivLink": "https://arxiv.org/abs/2410.22217",
            "title": "Vision Models: From Understanding to Generation, One Token at a Time!",
            "institute": "Peking University",
            "text": "This research focuses on autoregressive vision foundation models, which unify both understanding and generation tasks in vision by treating them as a single token prediction problem. This approach differs from previous work that often focused on specific tasks or separated understanding and generation.",
            "paper-title": "Towards Unifying Understanding and Generation in the Era of Vision Foundation Models: A Survey from the Autoregression Perspective",
            "image-path": "flux_paper_image/2410.22217_1730317253.png"
        },

        {
            "startTime": "22:53",
            "arxivId": "2410.21283",
            "arxivLink": "https://arxiv.org/abs/2410.21283",
            "title": "Protein Structure Quality Check: Fast, Accurate, and No More AlphaFold Headaches!",
            "institute": "Tsinghua University",
            "text": "This research introduces pLDDT-Predictor, a model that predicts protein structure quality scores without the computational burden of full structure prediction. Unlike previous methods that rely on complex models like AlphaFold2, pLDDT-Predictor leverages pre-trained protein language models and Transformer architectures for faster and more efficient predictions.",
            "paper-title": "pLDDT-Predictor: High-speed Protein Screening Using Transformer and ESM2",
            "image-path": "flux_paper_image/2410.21283_1730319962.png"
        },

        {
            "startTime": "23:12",
            "arxivId": "2410.21739",
            "arxivLink": "https://arxiv.org/abs/2410.21739",
            "title": "Street-View Reconstruction Gets a Makeover: New Dataset Makes Surfaces Shine!",
            "institute": "Tsinghua University, Horizon Robotics",
            "text": "This research introduces a new synthetic dataset called SS3DM specifically designed for benchmarking street-view surface reconstruction methods. Unlike previous datasets that rely on noisy LiDAR points, SS3DM provides precise 3D mesh models as ground truth, enabling more accurate evaluation of surface positions and normals.",
            "paper-title": "SS3DM: Benchmarking Street-View Surface Reconstruction with a Synthetic 3D Mesh Dataset",
            "image-path": "flux_paper_image/2410.21739_1730319247.png"
        },

        {
            "startTime": "23:40",
            "arxivId": "2410.21621",
            "arxivLink": "https://arxiv.org/abs/2410.21621",
            "title": "Unbounded Losses? No Problem! Transductive Priors to the Rescue!",
            "institute": "MIT, UC Berkeley",
            "text": "This paper explores the use of transductive priors in online learning algorithms, where the set of design vectors is known in advance. This approach allows for improved regret bounds compared to traditional online learning settings, particularly for unbounded losses.",
            "paper-title": "Refined Risk Bounds for Unbounded Losses via Transductive Priors",
            "image-path": "flux_paper_image/2410.21621_1730318807.png"
        },

        {
            "startTime": "24:00",
            "arxivId": "2410.21548",
            "arxivLink": "https://arxiv.org/abs/2410.21548",
            "title": "Tokenizing Text Like a Pro: New Method Compresses Data, Speeds Up AI Training!",
            "institute": "University of Texas at Austin, Nokia Bell Labs, MIT",
            "text": "This research introduces MultiTok, a novel tokenization method inspired by LZW compression. Unlike previous approaches that focus on post-processing techniques or linear data distributions, MultiTok dynamically compresses training data by grouping words into variable-length tokens, leading to faster training times.",
            "paper-title": "MultiTok: Variable-Length Tokenization for Efficient LLMs Adapted from LZW Compression",
            "image-path": "flux_paper_image/2410.21548_1730317527.png"
        },

        {
            "startTime": "24:21",
            "arxivId": "2410.21629",
            "arxivLink": "https://arxiv.org/abs/2410.21629",
            "title": "Occluded Faces? No Problem! New AI Reconstructs Expressions Under Cover",
            "institute": "University of Massachusetts Amherst, Max Planck Institute for Intelligent Systems, Google Research...",
            "text": "This research introduces a novel approach for reconstructing 3D faces from single images, even when parts of the face are hidden. Unlike previous methods that often produce a single, rigid reconstruction, this method uses diffusion models to generate multiple plausible face shapes and expressions, capturing the inherent ambiguity of occluded faces.",
            "paper-title": "OFER: Occluded Face Expression Reconstruction",
            "image-path": "flux_paper_image/2410.21629_1730317001.png"
        },

        {
            "startTime": "24:50",
            "arxivId": "2410.21419",
            "arxivLink": "https://arxiv.org/abs/2410.21419",
            "title": "Soft Kernel Interpolation: GPs Go High-Dimensional!",
            "institute": "Caltech, San Francisco State University",
            "text": "This paper introduces Soft Kernel Interpolation (SoftKI), a new approach to Gaussian Process (GP) regression that combines aspects of inducing points and Structured Kernel Interpolation (SKI). Unlike SKI, SoftKI learns the locations of interpolation points, making it more scalable to high-dimensional datasets.",
            "paper-title": "High-Dimensional Gaussian Process Regression with Soft Kernel Interpolation",
            "image-path": "flux_paper_image/2410.21419_1730320157.png"
        },

        {
            "startTime": "25:15",
            "arxivId": "2410.22077",
            "arxivLink": "https://arxiv.org/abs/2410.22077",
            "title": "Deep Learning Gets a Logic Makeover: How Symbolic Reasoning is Boosting AI's Smarts",
            "institute": "University of Toronto, University of Edinburgh, Samsung",
            "text": "This research maps the landscape of neuro-symbolic AI by categorizing frameworks based on their architectures. It focuses on composite frameworks, which allow users to treat symbolic methods as black boxes and augment existing neural networks.",
            "paper-title": "Mapping the Neuro-Symbolic AI Landscape by Architectures: A Handbook on Augmenting Deep Learning Through Symbolic Reasoning",
            "image-path": "flux_paper_image/2410.22077_1730316822.png"
        },

        {
            "startTime": "25:41",
            "arxivId": "2410.22229",
            "arxivLink": "https://arxiv.org/abs/2410.22229",
            "title": "SmartNICs Get a State-of-the-Art Upgrade: Cora Makes Stateful Apps Fly!",
            "institute": "Zhejiang University, Alibaba Cloud, Northeastern University...",
            "text": "This research proposes Cora, a compiler and runtime system that offloads stateful network applications to SmartNICs. Unlike previous approaches that partition by state or traffic, Cora leverages a state-flow representation to optimize offloading based on the application logic, traffic pattern, and SmartNIC architecture.",
            "paper-title": "Cora: Accelerating Stateful Network Applications with SmartNICs",
            "image-path": "flux_paper_image/2410.22229_1730318989.png"
        },

        {
            "startTime": "26:04",
            "arxivId": "2410.21526",
            "arxivLink": "https://arxiv.org/abs/2410.21526",
            "title": "LLM Data: Not All Synthetic Data is Created Equal!",
            "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
            "text": "This research proposes two novel weighted-loss approaches, IMP-Loss and DIMP-Loss, to address the issue of misalignment between LLM-generated data and real-world data distributions. Unlike previous data filtering strategies, these methods leverage all the generated data, assigning weights based on data quality and diversity.",
            "paper-title": "Not All LLM-Generated Data Are Equal: Rethinking Data Weighting in Text Classification",
            "image-path": "flux_paper_image/2410.21526_1730316845.png"
        },

        {
            "startTime": "26:35",
            "arxivId": "2410.21683",
            "arxivLink": "https://arxiv.org/abs/2410.21683",
            "title": "Pre-trained Graph Networks: A Molecular Revolution?",
            "institute": "University of Chicago, Amazon",
            "text": "This research explores the use of pre-trained geometric graph neural networks (Geom-GNNs) as transferable descriptors for molecular conformations, a departure from the traditional approach of training Geom-GNNs on specific downstream tasks.",
            "paper-title": "Pushing the Limits of All-Atom Geometric Graph Neural Networks: Pre-Training, Scaling and Zero-Shot Transfer",
            "image-path": "flux_paper_image/2410.21683_1730316373.png"
        },

        {
            "startTime": "26:53",
            "arxivId": "2410.21545",
            "arxivLink": "https://arxiv.org/abs/2410.21545",
            "title": "LLMs Get Self-Aware: New Framework Lets AI Grade Its Own Work!",
            "institute": "Microsoft, University of North Carolina at Chapel Hill",
            "text": "This research introduces a novel framework called SALC (Self-Assessing LLMs with Autonomous Criteria Generation) that allows LLMs to generate their own evaluation criteria, rather than relying on static, human-defined ones. This dynamic approach enables more context-aware and accurate assessments of LLM outputs.",
            "paper-title": "Unveiling Context-Aware Criteria in Self-Assessing LLMs",
            "image-path": "flux_paper_image/2410.21545_1730317562.png"
        },

        {
            "startTime": "27:15",
            "arxivId": "2410.21279",
            "arxivLink": "https://arxiv.org/abs/2410.21279",
            "title": "AI Regulation: EU, China, and the US Go Head-to-Head!",
            "institute": "Kenyon College, Oxford University",
            "text": "This research compares the AI regulatory approaches of the EU, China, and the US, highlighting the unique aspects of each system and how they differ in their emphasis on safety, innovation, and societal impact. The paper also examines the role of general-purpose AI (GPAI) models in these regulatory frameworks, a relatively new area of focus in AI governance.",
            "paper-title": "Comparative Global AI Regulation: Policy Perspectives from the EU, China, and the US",
            "image-path": "flux_paper_image/2410.21279_1730316419.png"
        },

        {
            "startTime": "27:43",
            "arxivId": "2410.21965",
            "arxivLink": "https://arxiv.org/abs/2410.21965",
            "title": "LLMs: Safe for Chat, Not So Much for Choices - New Benchmark Tests Safety Limits!",
            "institute": "Peking University",
            "text": "This research introduces SG-Bench, a new benchmark that evaluates the generalization of LLM safety across diverse tasks and prompt types. Unlike previous benchmarks that focus solely on either generative or discriminative evaluation paradigms, SG-Bench integrates both, examining the impact of prompting techniques on LLM safety.",
            "paper-title": "SG-Bench: Evaluating LLM Safety Generalization Across Diverse Tasks and Prompt Types",
            "image-path": "flux_paper_image/2410.21965_1730320164.png"
        },

        {
            "startTime": "28:08",
            "arxivId": "2410.21868",
            "arxivLink": "https://arxiv.org/abs/2410.21868",
            "title": "Ensemble SuperICL: Small Models, Big Gains in Language Learning!",
            "institute": "University of Oxford",
            "text": "This research proposes Ensemble SuperICL, a method that improves in-context learning (ICL) by combining the predictions of multiple fine-tuned small language models (SLMs). This differs from previous work that either focused on single SLMs or ensembling in-context examples.",
            "paper-title": "Improving In-Context Learning with Small Language Model Ensembles",
            "image-path": "flux_paper_image/2410.21868_1730318896.png"
        },

        {
            "startTime": "28:27",
            "arxivId": "2410.21304",
            "arxivLink": "https://arxiv.org/abs/2410.21304",
            "title": "VideoSAM: Bubbles Be Gone! A New Model for High-Speed Video Segmentation",
            "institute": "MIT",
            "text": "This research introduces VideoSAM, a specialized adaptation of the Segment Anything Model (SAM) fine-tuned on a diverse high-speed video (HSV) dataset for phase detection. This approach differs from previous work by leveraging a large vision foundation model for HSV segmentation, which has not been explored extensively before.",
            "paper-title": "VideoSAM: A Large Vision Foundation Model for High-Speed Video Segmentation",
            "image-path": "flux_paper_image/2410.21304_1730316854.png"
        },

        {
            "startTime": "28:52",
            "arxivId": "2410.22133",
            "arxivLink": "https://arxiv.org/abs/2410.22133",
            "title": "Successor Features: Simple, Smart, and Super Effective!",
            "institute": "McGill University, Mila, Google Deepmind",
            "text": "This paper introduces a novel, simple method for learning Successor Features (SFs) directly from pixel-level observations. Unlike previous approaches that often rely on complex losses or multiple learning phases, this method uses a combination of a Temporal-Difference (TD) loss and a reward prediction loss, which together capture the basic mathematical definition of SFs.",
            "paper-title": "Learning Successor Features the Simple Way",
            "image-path": "flux_paper_image/2410.22133_1730319394.png"
        },

        {
            "startTime": "29:10",
            "arxivId": "2410.22069",
            "arxivLink": "https://arxiv.org/abs/2410.22069",
            "title": "Deep Learning's Hidden Bias: A Margin of Error?",
            "institute": "NYU, Weizmann Institute of Science, Meta",
            "text": "This research extends previous work on the implicit bias of gradient descent to a broader family of optimization algorithms, including coordinated descent and sign gradient descent. It analyzes the late-stage behavior of these algorithms in deep, homogeneous neural networks, demonstrating their tendency to increase an algorithm-dependent margin.",
            "paper-title": "Flavors of Margin: Implicit Bias of Steepest Descent in Homogeneous Neural Networks",
            "image-path": "flux_paper_image/2410.22069_1730317200.png"
        },

        {
            "startTime": "29:42",
            "arxivId": "2410.21759",
            "arxivLink": "https://arxiv.org/abs/2410.21759",
            "title": "IntLoRA: Fine-Tuning Diffusion Models with Integer Weights, No Sweat!",
            "institute": "Tsinghua University, ETH Zurich, Shenzhen University...",
            "text": "This paper proposes IntLoRA, a method for fine-tuning quantized diffusion models using integer-type low-rank parameters. This differs from previous work that primarily relies on floating-point arithmetic for adaptation, which can be inefficient for practical applications.",
            "paper-title": "IntLoRA: Integral Low-rank Adaptation of Quantized Diffusion Models",
            "image-path": "flux_paper_image/2410.21759_1730318297.png"
        },

        {
            "startTime": "30:09",
            "arxivId": "2410.21518",
            "arxivLink": "https://arxiv.org/abs/2410.21518",
            "title": "Predicting Viral Evolution: A Location-Specific Game of Tag!",
            "institute": "MIT",
            "text": "This research proposes a novel model that predicts the distribution of viral proteins in different sub-populations by explicitly modeling the transmission rates between them. Unlike previous work that focuses on global distributions, this model captures the dynamic interactions between local communities of variants.",
            "paper-title": "Predicting sub-population specific viral evolution",
            "image-path": "flux_paper_image/2410.21518_1730318482.png"
        },

        {
            "startTime": "30:32",
            "arxivId": "2410.22177",
            "arxivLink": "https://arxiv.org/abs/2410.22177",
            "title": "LLMs in VR: Talking Your Way to a Perfect Scene!",
            "institute": "University of Cambridge, Coburg University",
            "text": "This research focuses on analyzing user interaction patterns when using LLMs for 3D scene editing in virtual reality. Unlike previous work that focused on technical aspects of LLM integration, this study investigates how users actually interact with these systems and identifies common strategies and barriers.",
            "paper-title": "Analyzing Multimodal Interaction Strategies for LLM-Assisted Manipulation of 3D Scenes",
            "image-path": "flux_paper_image/2410.22177_1730318363.png"
        },

        {
            "startTime": "30:50",
            "arxivId": "2410.21869",
            "arxivLink": "https://arxiv.org/abs/2410.21869",
            "title": "Cross-Entropy: The Secret Sauce of Deep Learning?",
            "institute": "Max Planck Society, ETH Zurich, Brown University...",
            "text": "This research extends the theory of Independent Component Analysis (ICA) to supervised learning, demonstrating that even standard classification tasks can recover latent variables up to a linear transformation. This differs from previous work that focused primarily on self-supervised learning.",
            "paper-title": "Cross-Entropy Is All You Need To Invert the Data Generating Process",
            "image-path": "flux_paper_image/2410.21869_1730317373.png"
        },

        {
            "startTime": "31:12",
            "arxivId": "2410.21595",
            "arxivLink": "https://arxiv.org/abs/2410.21595",
            "title": "Deep Trees: Growing Smarter, Not Just Bigger!",
            "institute": "MIT",
            "text": "This research introduces Generalized Soft Trees (GSTs), which extend soft decision trees by incorporating more general functions in their nodes, including hyperplane and convolutional splits. This allows GSTs to handle both structured and unstructured data, unlike traditional soft trees.",
            "paper-title": "Deep Trees for (Un)structured Data: Tractability, Performance, and Interpretability",
            "image-path": "flux_paper_image/2410.21595_1730316711.png"
        },

        {
            "startTime": "31:41",
            "arxivId": "2410.21656",
            "arxivLink": "https://arxiv.org/abs/2410.21656",
            "title": "Deep Learning's Outlier Obsession: How Dimensionality Makes or Breaks OOD Detection",
            "institute": "Toshiba Corporation, University of Tokyo",
            "text": "This research delves into the layer-by-layer processing of deep neural networks (DNNs) to understand how they distinguish between in-distribution (ID) and out-of-distribution (OOD) samples. It focuses on the role of dimensionality reduction in this process, a factor often overlooked in previous studies.",
            "paper-title": "Dimensionality-Induced Information Loss of Outliers in Deep Neural Networks",
            "image-path": "flux_paper_image/2410.21656_1730318193.png"
        },

        {
            "startTime": "32:04",
            "arxivId": "2410.22211",
            "arxivLink": "https://arxiv.org/abs/2410.22211",
            "title": "Cooking Up a Storm: New Dataset Tests AI's Recipe-Following Skills",
            "institute": "CMU",
            "text": "This research introduces a new dataset, ProMQA, specifically designed to evaluate how well AI systems can understand and follow instructions in a multimodal context, like cooking. Unlike previous datasets that focus on action recognition or segmentation, ProMQA uses question-answering tasks to assess the AI's ability to reason about the entire process, not just individual actions.",
            "paper-title": "ProMQA: Question Answering Dataset for Multimodal Procedural Activity Understanding",
            "image-path": "flux_paper_image/2410.22211_1730317690.png"
        },

        {
            "startTime": "32:27",
            "arxivId": "2410.22066",
            "arxivLink": "https://arxiv.org/abs/2410.22066",
            "title": "Singing the Same Tune, But in a Different Language: AI Makes Musical Lyrics Translation a Hit!",
            "institute": "Tsinghua University",
            "text": "This research focuses on automatically translating musical lyrics, prioritizing translation quality over just fitting the music. It differs from previous work that mainly focused on aligning text with music, often sacrificing translation quality.",
            "paper-title": "Sing it, Narrate it: Quality Musical Lyrics Translation",
            "image-path": "flux_paper_image/2410.22066_1730319241.png"
        },

        {
            "startTime": "32:49",
            "arxivId": "2410.21666",
            "arxivLink": "https://arxiv.org/abs/2410.21666",
            "title": "Lossy Compression Gets a Bottleneck: A New Way to Squeeze Data Without Losing Your Mind",
            "institute": "University of Toronto, McMaster University",
            "text": "This paper introduces a new lossy compression framework that incorporates a \"bottleneck\" to control the amount of stochasticity in the coupling. This differs from previous work by explicitly addressing the issue of decoder collapse, where the decoder simply outputs the same distribution as the input.",
            "paper-title": "Minimum Entropy Coupling with Bottleneck",
            "image-path": "flux_paper_image/2410.21666_1730319791.png"
        },

        {
            "startTime": "33:14",
            "arxivId": "2410.21308",
            "arxivLink": "https://arxiv.org/abs/2410.21308",
            "title": "Camera Calibration Errors? No Problem! Anchors to the Rescue!",
            "institute": "Shanghai University of Finance and Economics, Shanghai Jiao Tong University, Stanford University",
            "text": "This research proposes an anchor-based method for multi-camera pedestrian localization that mitigates the impact of camera parameter errors. Unlike previous methods that directly minimize reprojection errors, this approach leverages fixed-position anchors to adjust reprojection errors, thereby improving localization accuracy.",
            "paper-title": "A Robust Anchor-based Method for Multi-Camera Pedestrian Localization",
            "image-path": "flux_paper_image/2410.21308_1730317993.png"
        },

        {
            "startTime": "33:38",
            "arxivId": "2410.21571",
            "arxivLink": "https://arxiv.org/abs/2410.21571",
            "title": "Mind-Reading Room: Turning Your Thoughts Into a Perfect Workspace",
            "institute": "Brown University, Tecnol\u00b4ogico de Monterrey, MIT...",
            "text": "This research proposes a neuro-adaptive room that adjusts the physical environment based on the collective internal state of its occupants, inferred from physiological and behavioral cues. This differs from previous work on adaptive rooms, which primarily focused on individual user needs and preferences.",
            "paper-title": "Designing an adaptive room for captivating the collective consciousness from internal states",
            "image-path": "flux_paper_image/2410.21571_1730318645.png"
        },

        {
            "startTime": "33:59",
            "arxivId": "2410.22129",
            "arxivLink": "https://arxiv.org/abs/2410.22129",
            "title": "AI Teamwork: When Code Bots Get a Business Degree",
            "institute": "Crowdbotics, Microsoft, GitHub",
            "text": "This research differs from previous work by focusing on the real-world application of commercially available AI tools working together in a multi-agent system. It specifically examines the impact of sharing business requirements between Crowdbotics PRD AI and GitHub Copilot.",
            "paper-title": "Improving Performance of Commercially Available AI Products in a Multi-Agent Configuration",
            "image-path": "flux_paper_image/2410.22129_1730317672.png"
        },

        {
            "startTime": "34:19",
            "arxivId": "2410.21858",
            "arxivLink": "https://arxiv.org/abs/2410.21858",
            "title": "Unbalanced Panels? No Problem! New Model Predicts Stock Returns Like a Boss",
            "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, University of Italian Switzerland",
            "text": "This paper proposes a nonparametric kernel-based estimator for conditional mean and covariance matrices in large unbalanced panels, addressing a long-standing challenge in cross-sectional asset pricing. Unlike previous work, it jointly estimates both moments, ensuring consistency and positive semidefinite covariance matrices.",
            "paper-title": "Joint Estimation of Conditional Mean and Covariance for Unbalanced Panels",
            "image-path": "flux_paper_image/2410.21858_1730319459.png"
        }
    ],
    "stats": {
        "num_pick": 84,
        "num_total": 368,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202410301348_audio.mp3"
}

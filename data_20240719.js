
daily_data = {
    "date": "2024-07-19",
    "tweets": [
            {
                "startTime": "00:53",
                "arxivId": "2407.12929",
                "arxivLink": "https://arxiv.org/abs/2407.12929",
                "title": "Foundation Models: More Transparent Than a Fishbowl? (Maybe Not)",
                "institute": "Stanford University, Princeton University, Massachusetts Institute of Technology",
                "text": "This research builds upon the Foundation Model Transparency Index (FMTI) v1.0, which assessed the transparency of leading foundation model developers based on publicly available information. FMTI v1.1 differs by directly requesting transparency reports from developers, potentially including information not previously public.",
                "paper-title": "The Foundation Model Transparency Index v1.1: May 2024",
                "image-path": ""
            },

            {
                "startTime": "01:16",
                "arxivId": "2407.12854",
                "arxivLink": "https://arxiv.org/abs/2407.12854",
                "title": "Bigger is Better: A Trillion-Token Datastore Makes Language Models Smarter",
                "institute": "University of Washington",
                "text": "This research explores a new dimension of scaling language models by focusing on the size of the datastore used at inference time. Unlike previous work that primarily focused on the size of the pretraining data and the number of parameters, this study investigates how increasing the amount of data available to a retrieval-based language model during inference can improve performance.",
                "paper-title": "Scaling Retrieval-Based Language Models with a Trillion-Token Datastore",
                "image-path": ""
            },

            {
                "startTime": "01:39",
                "arxivId": "2407.12306",
                "arxivLink": "https://arxiv.org/abs/2407.12306",
                "title": "Splatfacto-W: Nerf's New Trick for Making Wild Images Look Real-Time Awesome!",
                "institute": "UC Berkeley",
                "text": "Splatfacto-W adapts 3D Gaussian Splatting (3DGS) for handling unconstrained image collections, unlike previous methods that relied on 2D models or implicit color prediction, which slowed down rendering.",
                "paper-title": "Splatfacto-W: A Nerfstudio Implementation of Gaussian Splatting for Unconstrained Photo Collections",
                "image-path": ""
            },

            {
                "startTime": "02:06",
                "arxivId": "2407.12858",
                "arxivLink": "https://arxiv.org/abs/2407.12858",
                "title": "LLMs: Grounded or Just Making Stuff Up?",
                "institute": "Oracle Corporation, Microsoft, Google",
                "text": "This survey paper focuses on the practical challenges of grounding large language models (LLMs) in a specific knowledge base, going beyond simply preventing hallucinations. It explores various approaches like retrieval-augmented generation, constrained decoding, and evaluation methods to ensure that every claim made by an LLM can be traced back to a source within the knowledge base.",
                "paper-title": "Grounding and Evaluation for Large Language Models: Practical Challenges and Lessons Learned (Survey)",
                "image-path": ""
            },

            {
                "startTime": "02:28",
                "arxivId": "2407.13692",
                "arxivLink": "https://arxiv.org/abs/2407.13692",
                "title": "LLMs: Learning to Be Legible, One Math Problem at a Time!",
                "institute": "OpenAI",
                "text": "This research explores a novel training method for Large Language Models (LLMs) that focuses on making their outputs more legible to humans. Instead of directly optimizing for answer correctness, the study proposes a \"checkability training\" approach that involves training a smaller LLM verifier to judge the correctness of the larger LLM's solutions. This method is distinct from previous work that primarily focused on optimizing LLMs for accuracy alone.",
                "paper-title": "Prover-Verifier Games improve legibility of LLM outputs",
                "image-path": ""
            },

            {
                "startTime": "02:49",
                "arxivId": "2407.12783",
                "arxivLink": "https://arxiv.org/abs/2407.12783",
                "title": "SMooDi: Text-to-Motion with a Dash of Style!",
                "institute": "Northeastern University, Google",
                "text": "This research introduces a new method for generating stylized motion sequences using a pre-trained text-to-motion model. Unlike previous methods that either generate motion of various content or transfer style from one sequence to another, SMooDi can rapidly generate motion across a broad range of content and diverse styles.",
                "paper-title": "SMooDi: Stylized Motion Diffusion Model",
                "image-path": ""
            },

            {
                "startTime": "03:18",
                "arxivId": "2407.12061",
                "arxivLink": "https://arxiv.org/abs/2407.12061",
                "title": "Robots Need Context: New Study Shows AI Struggles with Ambiguous Instructions",
                "institute": "Carnegie Mellon University, Meta",
                "text": "This research introduces Situated Instruction Following (SIF), a new benchmark for evaluating embodied AI agents' ability to understand and act upon instructions given in real-world contexts. Unlike previous benchmarks that focus on abstract or overly detailed instructions, SIF emphasizes the inherent ambiguity and evolving nature of human communication.",
                "paper-title": "Situated Instruction Following",
                "image-path": ""
            },

            {
                "startTime": "03:44",
                "arxivId": "2407.12108",
                "arxivLink": "https://arxiv.org/abs/2407.12108",
                "title": "Private Prediction: LLMs Get a Privacy Makeover, Generating Thousands of Synthetic Texts!",
                "institute": "Google",
                "text": "This research introduces a new private prediction method for generating synthetic text using large language models (LLMs). Unlike previous methods that focused on making the model itself private, this approach only requires the output synthetic data to be differentially private. This allows for the generation of thousands of high-quality synthetic data points, significantly expanding the potential applications.",
                "paper-title": "Private prediction for large-scale synthetic text generation",
                "image-path": ""
            },

            {
                "startTime": "04:04",
                "arxivId": "2407.12835",
                "arxivLink": "https://arxiv.org/abs/2407.12835",
                "title": "AI's Echo Chamber: Can Language Models Learn From Their Own Chatter?",
                "institute": "Tsinghua University, National University of Singapore, University of Minnesota",
                "text": "This research investigates the impact of training large language models (LLMs) on data generated by other LLMs, a phenomenon termed \"regurgitative training.\" Unlike previous work that focused on simpler generative models, this study examines the effects on state-of-the-art LLMs like GPT-4 and Llama2, as well as transformer models trained from scratch.",
                "paper-title": "Regurgitative Training: The Value of Real Data in Training Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "04:32",
                "arxivId": "2407.13710",
                "arxivLink": "https://arxiv.org/abs/2407.13710",
                "title": "Fairness Toolkit: No More Bias, Just Better Decisions!",
                "institute": "University of Oxford",
                "text": "This research introduces OxonFair, a toolkit that enforces fairness in machine learning models by optimizing user-defined objectives and fairness constraints. Unlike existing toolkits, OxonFair supports NLP and Computer Vision tasks, uses validation data to prevent overfitting, and allows for customization of fairness metrics.",
                "paper-title": "OxonFair: A Flexible Toolkit for Algorithmic Fairness",
                "image-path": ""
            },

            {
                "startTime": "05:02",
                "arxivId": "2407.13676",
                "arxivLink": "https://arxiv.org/abs/2407.13676",
                "title": "Sound Source Localization: When Sight and Sound Get Hitched!",
                "institute": "KAIST, POSTECH, Harvard University",
                "text": "This research focuses on the often-overlooked aspect of cross-modal interaction in sound source localization. Unlike previous work that primarily focused on localization performance, this paper introduces a new benchmark, evaluation metrics, and a learning framework that specifically address the ability of models to understand the relationship between audio and visual signals.",
                "paper-title": "Aligning Sight and Sound: Advanced Sound Source Localization Through Audio-Visual Alignment",
                "image-path": ""
            },

            {
                "startTime": "05:30",
                "arxivId": "2407.12771",
                "arxivLink": "https://arxiv.org/abs/2407.12771",
                "title": "Hashtag Hype: Network and Identity Fuel Twitter's Cultural Explosion",
                "institute": "University of Michigan",
                "text": "This research goes beyond studying the impact of just network or identity on hashtag diffusion. It investigates how these two factors work together to influence the spread of hashtags on Twitter.",
                "paper-title": "The Role of Network and Identity in the Diffusion of Hashtags",
                "image-path": ""
            },

            {
                "startTime": "05:52",
                "arxivId": "2407.12751",
                "arxivLink": "https://arxiv.org/abs/2407.12751",
                "title": "Scaling Up Bayesian Learning: A Monte Carlo Marathon",
                "institute": "University of Oxford",
                "text": "This research introduces a new framework for stochastic gradient MCMC algorithms, which are particularly useful for Bayesian learning in large-scale datasets. The key innovation lies in the use of control variates to reduce the variance of the gradient estimator, leading to more efficient and scalable inference. This approach differs from previous work by explicitly addressing the challenges of high dimensionality and computational complexity in Bayesian models.",
                "paper-title": "Scalable Monte Carlo for Bayesian Learning",
                "image-path": ""
            },

            {
                "startTime": "06:20",
                "arxivId": "2407.13755",
                "arxivLink": "https://arxiv.org/abs/2407.13755",
                "title": "Deep RL's New Trick: Random Rewards for Smarter Exploration!",
                "institute": "MIT",
                "text": "This paper introduces Random Latent Exploration (RLE), a new exploration technique that combines the strengths of bonus-based and noise-based exploration strategies. Unlike previous methods, RLE doesn't add noise or bonuses to the rewards, but instead trains the agent to achieve various goals from a random goal space.",
                "paper-title": "Random Latent Exploration for Deep Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "06:50",
                "arxivId": "2407.12164",
                "arxivLink": "https://arxiv.org/abs/2407.12164",
                "title": "Subject-Driven Image Generation: A Preference-Based Approach to Fine-Tuning Diffusion Models",
                "institute": "Google, University of Waterloo",
                "text": "This research introduces a new reward function called the \u03bb-Harmonic reward function, which enables early stopping during training and accelerates the fine-tuning process for subject-driven text-to-image generation. Unlike previous methods that rely on extensive negative samples or complex text-embedding optimization, this approach leverages preference labels derived from the reward function to achieve text-image alignment by fine-tuning only the UNet component.",
                "paper-title": "Subject-driven Text-to-Image Generation via Preference-based Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "07:18",
                "arxivId": "2407.12679",
                "arxivLink": "https://arxiv.org/abs/2407.12679",
                "title": "Goldfish Swims Through Long Videos, Leaving Other Models in the Dust!",
                "institute": "King Abdullah University of Science and Technology, Harvard University, The Swiss AI Lab IDSIA",
                "text": "This research introduces Goldfish, a framework for understanding arbitrarily long videos. Unlike previous methods that struggle with lengthy content, Goldfish uses a retrieval mechanism to identify the most relevant video clips before answering questions.",
                "paper-title": "Goldfish: Vision-Language Understanding of Arbitrarily Long Videos",
                "image-path": ""
            },

            {
                "startTime": "07:50",
                "arxivId": "2407.12034",
                "arxivLink": "https://arxiv.org/abs/2407.12034",
                "title": "Transformers: Not Just Fancy N-Grams, But Maybe They Should Be!",
                "institute": "Google",
                "text": "This paper investigates how well transformer-based language models (LLMs) can be approximated by simple N-gram rules, which are statistical patterns derived from the training data. Unlike previous work that focuses on individual neurons or in-context learning, this study examines the overall model behavior as a black box.",
                "paper-title": "Understanding Transformers via N-gram Statistics",
                "image-path": ""
            },

            {
                "startTime": "08:17",
                "arxivId": "2407.12288",
                "arxivLink": "https://arxiv.org/abs/2407.12288",
                "title": "Machine Learning's New Secret Weapon: Information Theory!",
                "institute": "Stanford University",
                "text": "This research proposes a theoretical framework for machine learning that leverages Bayesian statistics and information theory to characterize the performance of an optimal Bayesian learner. Unlike existing analyses that weaken with increasing data complexity, this framework provides accurate insights across diverse machine learning settings.",
                "paper-title": "Information-Theoretic Foundations for Machine Learning",
                "image-path": ""
            },

            {
                "startTime": "08:39",
                "arxivId": "2407.13622",
                "arxivLink": "https://arxiv.org/abs/2407.13622",
                "title": "Sparse Q-Learning: When Less is More in Reinforcement Learning",
                "institute": "CMU, UC Los Angeles, Peking University",
                "text": "This paper explores the impact of sparsity in linear function approximation for reinforcement learning. Unlike previous work that struggles with misspecification errors in non-sparse settings, this research demonstrates that leveraging sparsity can overcome the exponential sample complexity barrier.",
                "paper-title": "Misspecified $Q$-Learning with Sparse Linear Function Approximation: Tight Bounds on Approximation Error",
                "image-path": ""
            },

            {
                "startTime": "09:06",
                "arxivId": "2407.13278",
                "arxivLink": "https://arxiv.org/abs/2407.13278",
                "title": "Deep Time Series Models: A Benchmarking Bonanza!",
                "institute": "Tsinghua University",
                "text": "This research distinguishes itself by offering a comprehensive survey of deep time series models, encompassing various analysis tasks and model architectures. It also introduces a benchmark, Time Series Library (TSLib), for fair evaluation of these models.",
                "paper-title": "Deep Time Series Models: A Comprehensive Survey and Benchmark",
                "image-path": ""
            },

            {
                "startTime": "09:26",
                "arxivId": "2407.12178",
                "arxivLink": "https://arxiv.org/abs/2407.12178",
                "title": "Stop Exploiting, Start Exploring: Why AI Needs to Embrace Perpetual Curiosity",
                "institute": "Stanford University",
                "text": "This research explores a new type of decision-making problem where optimal behavior requires continuous exploration, even as the agent gains knowledge. This contrasts with traditional models where exploration eventually tapers off in favor of exploitation.",
                "paper-title": "Exploration Unbound",
                "image-path": ""
            },

            {
                "startTime": "09:50",
                "arxivId": "2407.12185",
                "arxivLink": "https://arxiv.org/abs/2407.12185",
                "title": "Deep Learning Goes on a Diet: Satisficing Exploration for Smarter AI",
                "institute": "Stanford University, Google",
                "text": "This paper extends the concept of \"satisficing\" exploration, previously explored in multi-armed bandit problems, to deep reinforcement learning. It introduces a new algorithm, Blahut-Arimoto RVF, that allows agents to learn near-optimal solutions without needing to explore the entire state space.",
                "paper-title": "Satisficing Exploration for Deep Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "10:19",
                "arxivId": "2407.12999",
                "arxivLink": "https://arxiv.org/abs/2407.12999",
                "title": "GenAI Safety: Can We Regulate This Wild West?",
                "institute": "Google, Office of Naval Research, University of Maryland College Park...",
                "text": "This research focuses on the gap between GenAI policy and technology, examining how regulation can guide technical evolution and how technology can meet regulatory requirements. It analyzes the policy landscape in the EU, China, and the US, highlighting their divergent priorities. The paper also explores lessons from military risk management and discusses the limitations of model alignment, inspection, and watermarking.",
                "paper-title": "Securing the Future of GenAI: Policy and Technology",
                "image-path": ""
            },

            {
                "startTime": "10:46",
                "arxivId": "2407.12393",
                "arxivLink": "https://arxiv.org/abs/2407.12393",
                "title": "LLMs Get a Personality Makeover: From Bland Bots to Characterful Chatters",
                "institute": "Tsinghua University",
                "text": "This research proposes a new training approach called PersLLM that integrates psychology-grounded principles of personality into LLMs, aiming to create more realistic and consistent personalities compared to previous methods that focused on superficial linguistic styles.",
                "paper-title": "PersLLM: A Personified Training Approach for Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "11:15",
                "arxivId": "2407.12516",
                "arxivLink": "https://arxiv.org/abs/2407.12516",
                "title": "Spiking Neural Networks Get a Zeroth-Order Makeover: Training Without Backpropagation!",
                "institute": "Peking University",
                "text": "This paper proposes a new method called Online Pseudo-Zeroth-Order (OPZO) training for spiking neural networks (SNNs). Unlike traditional methods that rely on backpropagation, OPZO uses a single forward pass with noise injection and direct top-down feedback signals for training.",
                "paper-title": "Online Pseudo-Zeroth-Order Training of Neuromorphic Spiking Neural Networks",
                "image-path": ""
            },

            {
                "startTime": "11:38",
                "arxivId": "2407.12505",
                "arxivLink": "https://arxiv.org/abs/2407.12505",
                "title": "Reinforcement Learning Gets a Gravity Makeover: New Framework Makes Multi-Agent Systems Smarter!",
                "institute": "Tsinghua University",
                "text": "This research introduces a new framework called Subequivariant Hierarchical Neural Networks (SHNN) for multi-entity reinforcement learning in 3D environments. SHNN leverages the concept of subequivariance, which is a relaxed form of equivariance that accounts for gravitational effects, to reduce the complexity of the state space. This is different from previous work that either used hand-crafted local reference frames or did not consider the effects of gravity.",
                "paper-title": "Subequivariant Reinforcement Learning in 3D Multi-Entity Physical Environments",
                "image-path": ""
            },

            {
                "startTime": "12:12",
                "arxivId": "2407.13759",
                "arxivLink": "https://arxiv.org/abs/2407.13759",
                "title": "Street View Dreams: AI Makes Cityscapes Come Alive",
                "institute": "Stanford University, Google",
                "text": "This research introduces a novel method for generating long-range, consistent street views using an autoregressive video diffusion model. Unlike previous approaches that rely on 3D models or GANs, this method leverages a large-scale dataset of street view imagery and corresponding map data to create realistic and controllable cityscapes.",
                "paper-title": "Streetscapes: Large-scale Consistent Street View Generation Using Autoregressive Video Diffusion",
                "image-path": ""
            },

            {
                "startTime": "12:34",
                "arxivId": "2407.13449",
                "arxivLink": "https://arxiv.org/abs/2407.13449",
                "title": "Do All Roads Lead to Rome? Generative Image Models Learn Similar Representations!",
                "institute": "Harvard University",
                "text": "This research extends previous work on model stitching by including Normalizing Flows and Diffusion Models, and uses probe-based metrics to assess the semantic similarity of representations.",
                "paper-title": "All Roads Lead to Rome? Exploring Representational Similarities Between Latent Spaces of Generative Image Models",
                "image-path": ""
            },

            {
                "startTime": "13:02",
                "arxivId": "2407.12276",
                "arxivLink": "https://arxiv.org/abs/2407.12276",
                "title": "Visual Context Makes CLIP See Anomalies Better!",
                "institute": "Chinese Academy of Sciences, University of Technology Sydney, Hangzhou Dianzi University...",
                "text": "This paper proposes a novel visual context prompting model (VCP-CLIP) for zero-shot anomaly segmentation (ZSAS). Unlike previous methods that rely on product-specific text prompts, VCP-CLIP utilizes visual context to activate CLIP's anomalous semantic perception ability. It introduces two modules: Pre-VCP and Post-VCP, which incorporate global and fine-grained image features into the text prompts, respectively.",
                "paper-title": "VCP-CLIP: A visual context prompting model for zero-shot anomaly segmentation",
                "image-path": ""
            },

            {
                "startTime": "13:32",
                "arxivId": "2407.13709",
                "arxivLink": "https://arxiv.org/abs/2407.13709",
                "title": "DPO's Secret Sauce: How Reference Models Spice Up Language Learning",
                "institute": "Yale University, Shanghai Jiao Tong University",
                "text": "This research delves into the often-overlooked role of reference models in Direct Preference Optimization (DPO), a popular method for fine-tuning large language models. The study investigates how the strength of the KL-divergence constraint, which penalizes deviations from the reference model, impacts performance.",
                "paper-title": "Understanding Reference Policies in Direct Preference Optimization",
                "image-path": ""
            },

            {
                "startTime": "13:55",
                "arxivId": "2407.12939",
                "arxivLink": "https://arxiv.org/abs/2407.12939",
                "title": "Sparse Images, Full Rooms: A Training-Free 3D Scene Completion Trick",
                "institute": "Carnegie Mellon University, National Tsinghua University, National YangMingChiaoTung University...",
                "text": "This paper proposes GenRC, a method for completing 3D room models from sparse RGBD images. Unlike previous methods that rely on human-designed text prompts or predefined camera trajectories, GenRC uses a training-free pipeline that leverages a pre-trained diffusion model and a novel technique called Equirectangular-Diffusion (E-Diffusion) to generate a view-consistent panoramic RGBD image.",
                "paper-title": "GenRC: Generative 3D Room Completion from Sparse Image Collections",
                "image-path": ""
            },

            {
                "startTime": "14:27",
                "arxivId": "2407.13690",
                "arxivLink": "https://arxiv.org/abs/2407.13690",
                "title": "Math Models Get a Difficulty Boost: New Dataset Makes LLMs Smarter!",
                "institute": "Tsinghua University, Hong Kong University of Science and Technology",
                "text": "This research proposes a new method called Difficulty-Aware Rejection Tuning (DART) for training large language models (LLMs) to solve mathematical problems. Unlike previous methods that focus on easy queries, DART prioritizes difficult queries during data synthesis, leading to more robust models.",
                "paper-title": "DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving",
                "image-path": ""
            },

            {
                "startTime": "14:47",
                "arxivId": "2407.13137",
                "arxivLink": "https://arxiv.org/abs/2407.13137",
                "title": "BEV Segmentation Gets a Boost: Mamba's Global Vision for Self-Driving Cars",
                "institute": "Tsinghua University, University of Macau",
                "text": "This research introduces a novel approach to BEV segmentation by incorporating the Mamba model, a state-space model known for its efficiency in long-sequence modeling. This differs from previous methods that primarily focused on improving view transformation modules or using convolutional networks.",
                "paper-title": "OE-BevSeg: An Object Informed and Environment Aware Multimodal Framework for Bird's-eye-view Vehicle Semantic Segmentation",
                "image-path": ""
            },

            {
                "startTime": "15:10",
                "arxivId": "2407.13399",
                "arxivLink": "https://arxiv.org/abs/2407.13399",
                "title": "KL-Regularization: The Myth, the Magic, and the \u03c7 2-Fix!",
                "institute": "University of Illinois, Princeton University, University of Wisconsin-Madison...",
                "text": "This paper introduces \u03c7 2-Preference Optimization (\u03c7 PO), a new algorithm for offline language model alignment that uses \u03c7 2-divergence instead of KL-divergence for regularization. This change implicitly implements the principle of pessimism, which helps to mitigate overoptimization, a common problem in offline alignment methods.",
                "paper-title": "Correcting the Mythos of KL-Regularization: Direct Alignment without Overparameterization via Chi-squared Preference Optimization",
                "image-path": ""
            },

            {
                "startTime": "15:45",
                "arxivId": "2407.12259",
                "arxivLink": "https://arxiv.org/abs/2407.12259",
                "title": "LLMs are Secretly Doing Gradient Descent: In-Context Probing as a Data Valuation Shortcut",
                "institute": "CMU",
                "text": "This paper explores the connection between in-context probing (ICP) and influence functions, two methods for data valuation. It proposes that ICP implicitly performs gradient descent, making it a cost-effective proxy for influence functions.",
                "paper-title": "In-Context Probing Approximates Influence Function for Data Valuation",
                "image-path": ""
            },

            {
                "startTime": "16:17",
                "arxivId": "2407.13621",
                "arxivLink": "https://arxiv.org/abs/2407.13621",
                "title": "Privacy-Preserving AI: Neural Tangent Kernel Gets a Privacy Makeover!",
                "institute": "Adobe, University of Hong Kong, University of Wisconsin-Madison...",
                "text": "This research introduces a novel approach to ensuring differential privacy in Neural Tangent Kernel (NTK) regression. Unlike previous work that focused on adding noise to gradients during training, this study adds noise directly to the NTK matrix itself, preserving its positive semi-definite property.",
                "paper-title": "Differential Privacy Mechanisms in Neural Tangent Kernel Regression",
                "image-path": ""
            },

            {
                "startTime": "16:47",
                "arxivId": "2407.12176",
                "arxivLink": "https://arxiv.org/abs/2407.12176",
                "title": "GPT-4V: Can't Even Write a Radiology Report Yet!",
                "institute": "University of Chicago, University of Michigan",
                "text": "This research systematically evaluates GPT-4V's ability to generate radiology reports, going beyond case studies and qualitative analysis. It decomposes the task into image reasoning and report synthesis, revealing GPT-4V's struggles with interpreting chest X-rays.",
                "paper-title": "GPT-4V Cannot Generate Radiology Reports Yet",
                "image-path": ""
            },

            {
                "startTime": "17:16",
                "arxivId": "2407.13083",
                "arxivLink": "https://arxiv.org/abs/2407.13083",
                "title": "Sounding Like a Human: New Tech Makes Virtual Avatars Sound More Realistic",
                "institute": "University of Rochester, Meta",
                "text": "This research introduces the concept of \"acoustic primitives\" to model the sound field generated by a human body. Unlike previous methods that relied on a single high-order ambisonic representation, this approach uses multiple low-order ambisonic spheres attached to the body, allowing for more efficient and accurate near-field sound rendering.",
                "paper-title": "Modeling and Driving Human Body Soundfields through Acoustic Primitives",
                "image-path": ""
            },

            {
                "startTime": "17:39",
                "arxivId": "2407.13729",
                "arxivLink": "https://arxiv.org/abs/2407.13729",
                "title": "AI Can't Break the Rules: Baba Is You Tests the Limits of Language Models",
                "institute": "MIT",
                "text": "This research introduces a new benchmark, Baba Is AI, based on the game Baba Is You, to evaluate the ability of large language models (LLMs) to manipulate and combine rules in a dynamic environment. Unlike previous benchmarks, Baba Is AI focuses on compositional generalization, where the rules of the game itself can be changed by the agent.",
                "paper-title": "Baba Is AI: Break the Rules to Beat the Benchmark",
                "image-path": ""
            },

            {
                "startTime": "18:08",
                "arxivId": "2407.12370",
                "arxivLink": "https://arxiv.org/abs/2407.12370",
                "title": "Time Travel for Graphs: How Much Past Matters for Predicting the Future?",
                "institute": "Conservatoire National des Arts et M\u00e9tiers, Sorbonne University, National Institute of Applied Sciences of Rouen...",
                "text": "This research focuses on the \"temporal receptive field\" in dynamic graph learning, which refers to the amount of past data a model considers when making predictions. Unlike previous work that primarily focused on optimizing the temporal encoding process, this study systematically analyzes the impact of different temporal receptive field sizes on model performance across various datasets.",
                "paper-title": "Temporal receptive field in dynamic graph learning: A comprehensive analysis",
                "image-path": ""
            },

            {
                "startTime": "18:31",
                "arxivId": "2407.12312",
                "arxivLink": "https://arxiv.org/abs/2407.12312",
                "title": "Skeleton Mix-Up: Shapley Value Makes Action Recognition Smarter!",
                "institute": "Peking University",
                "text": "This research introduces Shap-Mix, a novel method for long-tailed skeleton-based action recognition. Unlike previous methods, Shap-Mix utilizes Shapley value to estimate the saliency of different body parts, guiding the mixing of data samples to improve the model's ability to learn from scarce data.",
                "paper-title": "Shap-Mix: Shapley Value Guided Mixing for Long-Tailed Skeleton Based Action Recognition",
                "image-path": ""
            },

            {
                "startTime": "18:54",
                "arxivId": "2407.12207",
                "arxivLink": "https://arxiv.org/abs/2407.12207",
                "title": "6D Object Pose Estimation: No CAD Models, Just a Few Snapshots!",
                "institute": "ETH Zurich, The University of Queensland",
                "text": "This research proposes a pipeline for 6D object pose estimation that doesn't require CAD models, unlike many existing methods. Instead, it uses a neural implicit surface representation (NeuS2) trained on a small set of real images.",
                "paper-title": "NeuSurfEmb: A Complete Pipeline for Dense Correspondence-based 6D Object Pose Estimation without CAD Models",
                "image-path": ""
            },

            {
                "startTime": "19:23",
                "arxivId": "2407.12794",
                "arxivLink": "https://arxiv.org/abs/2407.12794",
                "title": "Query Rewrite Gets a Brain: AI Learns to Optimize SQL Like a Boss!",
                "institute": "University of Cambridge",
                "text": "This research introduces a novel approach to query rewrite by combining Equality Saturation with Reinforcement Learning. Unlike previous methods that rely on predefined rule orderings, this system learns to navigate the complex search space of equivalent query plans, leading to more efficient and faster results.",
                "paper-title": "Learned Graph Rewriting with Equality Saturation: A New Paradigm in Relational Query Rewrite and Beyond",
                "image-path": ""
            },

            {
                "startTime": "19:47",
                "arxivId": "2407.13094",
                "arxivLink": "https://arxiv.org/abs/2407.13094",
                "title": "Video Models: Can They Really Understand What's Happening?",
                "institute": "Meta, Johns Hopkins University",
                "text": "This research introduces a new evaluation task called \"retrieval from counterfactually augmented data\" (RCAD). Unlike standard video-text retrieval, RCAD uses captions that are modified to have the same objects but different actions, forcing models to understand the video's semantics over time.",
                "paper-title": "Rethinking Video-Text Understanding: Retrieval from Counterfactually Augmented Data",
                "image-path": ""
            },

            {
                "startTime": "20:12",
                "arxivId": "2407.13739",
                "arxivLink": "https://arxiv.org/abs/2407.13739",
                "title": "Granite Code Models: Now with 128K Tokens, They're Not Just Big, They're Long!",
                "institute": "IBM",
                "text": "This research introduces a method for scaling the context length of Granite code models from 2K/4K to 128K tokens. This is achieved through a combination of continual pretraining and instruction tuning, using a repository-level file packing approach and length-upsampled long-context data. This differs from previous work by focusing on extending the context length of open-source code models, rather than relying on proprietary models.",
                "paper-title": "Scaling Granite Code Models to 128K Context",
                "image-path": ""
            },

            {
                "startTime": "20:37",
                "arxivId": "2407.12318",
                "arxivLink": "https://arxiv.org/abs/2407.12318",
                "title": "Dynamic Games: Information Compression for Smarter Strategies",
                "institute": "University of Michigan",
                "text": "This paper introduces two new notions of information states, Mutually Su\ufb03cient Information (MSI) and Unilaterally Su\ufb03cient Information (USI), for dynamic games with asymmetric information. These concepts are based on strategy-independent compression maps, which differ from previous work that often relies on strategy-dependent maps.",
                "paper-title": "Information Compression in Dynamic Games",
                "image-path": ""
            },

            {
                "startTime": "21:02",
                "arxivId": "2407.12870",
                "arxivLink": "https://arxiv.org/abs/2407.12870",
                "title": "Cell Recognition: Beyond Looks, It's All About the Neighborhood!",
                "institute": "University of Sydney, Lawrence Berkeley National Laboratory, University of Maryland...",
                "text": "This research goes beyond just looking at individual cells to understand their type. It focuses on the relationships between cells and their surrounding tissue, which is more robust to variations in how samples are prepared.",
                "paper-title": "Revisiting Adaptive Cellular Recognition Under Domain Shifts: A Contextual Correspondence View",
                "image-path": ""
            },

            {
                "startTime": "21:34",
                "arxivId": "2407.12874",
                "arxivLink": "https://arxiv.org/abs/2407.12874",
                "title": "LLMs Learn to Follow Instructions... By Making Up Their Own Homework!",
                "institute": "Tsinghua University, Carnegie Mellon University",
                "text": "This research proposes a novel method called SELF-GUIDE, which allows a language model to improve its ability to follow instructions by generating its own training data. This differs from previous work that relies on external data or more powerful \"teacher\" models.",
                "paper-title": "SELF-GUIDE: Better Task-Specific Instruction Following via Self-Synthetic Finetuning",
                "image-path": ""
            },

            {
                "startTime": "21:58",
                "arxivId": "2407.12307",
                "arxivLink": "https://arxiv.org/abs/2407.12307",
                "title": "Hand Reconstruction: Knowledge is Power, Uncertainty is Key!",
                "institute": "Rensselaer, IBM",
                "text": "This research introduces a weakly-supervised method for 3D hand reconstruction that leverages hand knowledge from biomechanics, functional anatomy, and physics. Unlike previous methods that rely solely on data-driven priors or heuristic constraints, this approach systematically incorporates these foundational insights into the training process. Additionally, the paper explicitly models the uncertainty inherent in image observations, improving the robustness of the model.",
                "paper-title": "Weakly-Supervised 3D Hand Reconstruction with Knowledge Prior and Uncertainty Guidance",
                "image-path": ""
            },

            {
                "startTime": "22:22",
                "arxivId": "2407.13188",
                "arxivLink": "https://arxiv.org/abs/2407.13188",
                "title": "Watermarking AI Art: A QR Code in Every Pixel?",
                "institute": "Tsinghua University",
                "text": "This research proposes a new framework called Safe-SD that embeds graphical watermarks directly into the generative process of Stable Diffusion models, unlike previous methods that watermark images after they are generated.",
                "paper-title": "Safe-SD: Safe and Traceable Stable Diffusion with Text Prompt Trigger for Invisible Generative Watermarking",
                "image-path": ""
            },

            {
                "startTime": "22:50",
                "arxivId": "2407.12828",
                "arxivLink": "https://arxiv.org/abs/2407.12828",
                "title": "LLMs: Knowledge Editing's Messy Ripple Effects",
                "institute": "University of Illinois, Stanford University",
                "text": "This research introduces GradSim, a new indicator that measures the similarity of knowledge storage in LLMs based on gradient cosine similarity. This helps explain why knowledge editing often leads to unexpected ripple effects, where changes to one fact unintentionally affect other related facts.",
                "paper-title": "Why Does New Knowledge Create Messy Ripple Effects in LLMs?",
                "image-path": ""
            },

            {
                "startTime": "23:21",
                "arxivId": "2407.13322",
                "arxivLink": "https://arxiv.org/abs/2407.13322",
                "title": "Heart Rate Hack: New AI Learns Your Pulse Without Touching You!",
                "institute": "National Tsing Hua University",
                "text": "This research focuses on test-time adaptation (TTA) for remote photoplethysmography (rPPG) estimation, a technique that adapts a pre-trained model to new data without needing additional training data. This differs from previous work that relied on domain generalization (DG) or domain adaptation (DA) techniques, which require access to source data during training.",
                "paper-title": "Fully Test-Time rPPG Estimation via Synthetic Signal-Guided Feature Learning",
                "image-path": ""
            },

            {
                "startTime": "23:43",
                "arxivId": "2407.12277",
                "arxivLink": "https://arxiv.org/abs/2407.12277",
                "title": "Visual Question Answering Gets a Multimodal Makeover: Reranking for the Win!",
                "institute": "CMU, Google, University of Massachusetts",
                "text": "This research introduces a multi-modal reranker module to improve the ranking of knowledge candidates in knowledge-intensive visual question answering (KI-VQA) systems. Unlike previous work that relies on uni-modal retrieval, this approach leverages both visual and textual information from the question and knowledge candidates for more accurate relevance score modeling.",
                "paper-title": "Multimodal Reranking for Knowledge-Intensive Visual Question Answering",
                "image-path": ""
            },

            {
                "startTime": "24:09",
                "arxivId": "2407.12622",
                "arxivLink": "https://arxiv.org/abs/2407.12622",
                "title": "GEBD Models: Faster Than a Speeding Bullet, More Accurate Than a Laser Beam!",
                "institute": "Xi\u2019an Jiaotong University, Tsinghua University",
                "text": "This research focuses on improving the efficiency of Generic Event Boundary Detection (GEBD) models by re-examining their architecture. The authors propose a new baseline model, BasicGEBD, which achieves comparable performance to more complex models. They then systematically \"modernize\" each component of BasicGEBD, resulting in a family of EfficientGEBD models that achieve state-of-the-art performance with significantly faster inference speeds.",
                "paper-title": "Rethinking the Architecture Design for Efficient Generic Event Boundary Detection",
                "image-path": ""
            },

            {
                "startTime": "24:31",
                "arxivId": "2407.12491",
                "arxivLink": "https://arxiv.org/abs/2407.12491",
                "title": "Building a BEV Perception System: Drag-and-Drop Your Way to Self-Driving!",
                "institute": "Tsinghua University",
                "text": "This research proposes a hierarchical perception system for autonomous driving, which uses a library of pre-trained modules that can be combined and customized to create different perception models. This approach differs from previous work by emphasizing modularity and reusability, streamlining the development process.",
                "paper-title": "Hierarchical and Decoupled BEV Perception Learning Framework for Autonomous Driving",
                "image-path": ""
            },

            {
                "startTime": "24:55",
                "arxivId": "2407.13764",
                "arxivLink": "https://arxiv.org/abs/2407.13764",
                "title": "Shape of Motion: Dancing 3D Scenes from a Single Video!",
                "institute": "UC Berkeley, Google Research",
                "text": "This research introduces a method for reconstructing dynamic 3D scenes from a single video by representing the motion of scene elements as a combination of shared motion bases. This differs from previous work that either relies on templates, focuses on quasi-static scenes, or fails to explicitly model 3D motion.",
                "paper-title": "Shape of Motion: 4D Reconstruction from a Single Video",
                "image-path": ""
            },

            {
                "startTime": "25:17",
                "arxivId": "2407.12943",
                "arxivLink": "https://arxiv.org/abs/2407.12943",
                "title": "LLMs Gone Wild? New Tool Detects Hallucinations with a Side of Critique!",
                "institute": "Shanghai Jiao Tong University, Fudan University, Shanghai Artificial Intelligence Laboratory...",
                "text": "This research introduces HALU-J, a hallucination detection model that goes beyond simple classification. It analyzes multiple pieces of evidence, categorizes them, and provides detailed critiques, making it more reliable than previous methods.",
                "paper-title": "Halu-J: Critique-Based Hallucination Judge",
                "image-path": ""
            },

            {
                "startTime": "25:41",
                "arxivId": "2407.12773",
                "arxivLink": "https://arxiv.org/abs/2407.12773",
                "title": "AI Detects Cancer Mitosis: A Deep Learning Framework That's Got Your Back (and Your Cells)!",
                "institute": "University College London, Royal National Orthopaedic Hospital, University Hospital Basel...",
                "text": "This research introduces a novel two-stage framework for detecting mitotic figures in cancer cells. Unlike previous methods that rely solely on bounding boxes, this approach incorporates nuclei contours, which significantly improves the accuracy of detection.",
                "paper-title": "OMG-Net: A Deep Learning Framework Deploying Segment Anything to Detect Pan-Cancer Mitotic Figures from Haematoxylin and Eosin-Stained Slides",
                "image-path": ""
            },

            {
                "startTime": "26:06",
                "arxivId": "2407.13219",
                "arxivLink": "https://arxiv.org/abs/2407.13219",
                "title": "Video Grounding: The Secret Sauce for Long Video Generation?",
                "institute": "Tsinghua University",
                "text": "This research proposes a novel approach to long video generation by leveraging multi-sentence video grounding. Unlike previous methods that rely solely on generative models, this approach utilizes a massive video moment retrieval model to find relevant video segments that match text prompts, ensuring temporal consistency and adherence to physical laws.",
                "paper-title": "Multi-sentence Video Grounding for Long Video Generation",
                "image-path": ""
            },

            {
                "startTime": "26:27",
                "arxivId": "2407.12804",
                "arxivLink": "https://arxiv.org/abs/2407.12804",
                "title": "Stop Clicking! New Study Shows How to Curb Over-Reliance on AI",
                "institute": "University of Cambridge, Carnegie Mellon University, Princeton University...",
                "text": "This research explores the use of \"frictions\" - small modifications to user interfaces - to encourage more thoughtful use of LLMs. Unlike previous work focusing on restricting access or filtering content, this study investigates how selective frictions, based on user expertise, can modulate LLM engagement without significantly impacting accuracy.",
                "paper-title": "Modulating Language Model Experiences through Frictions",
                "image-path": ""
            },

            {
                "startTime": "26:52",
                "arxivId": "2407.12404",
                "arxivLink": "https://arxiv.org/abs/2407.12404",
                "title": "Steering Language Models: A Wild Ride with Unreliable Vectors",
                "institute": "University College London",
                "text": "This research delves into the reliability and generalizability of steering vectors, a technique for adjusting language model behavior at inference time. Unlike previous work that primarily focused on in-distribution performance, this study investigates both in-distribution reliability and out-of-distribution generalization.",
                "paper-title": "Analyzing the Generalization and Reliability of Steering Vectors -- ICML 2024",
                "image-path": ""
            },

            {
                "startTime": "27:13",
                "arxivId": "2407.12982",
                "arxivLink": "https://arxiv.org/abs/2407.12982",
                "title": "Forget Big Models, Let's Talk to the Library: Retrieval-Enhanced Machine Learning is Here!",
                "institute": "CMU, University of Massachusetts",
                "text": "This research formalizes the framework of Retrieval-Enhanced Machine Learning (REML) by synthesizing existing studies across various domains, including computer vision, time series prediction, and computational biology. It also bridges the gap between REML and Information Retrieval (IR) research by investigating each component of the REML framework.",
                "paper-title": "Retrieval-Enhanced Machine Learning: Synthesis and Opportunities",
                "image-path": ""
            },

            {
                "startTime": "27:48",
                "arxivId": "2407.12996",
                "arxivLink": "https://arxiv.org/abs/2407.12996",
                "title": "Deep Learning Ensembles: Sharpness and Diversity, a Love-Hate Relationship!",
                "institute": "Nankai University, Dartmouth College, University of California San Diego...",
                "text": "This research investigates the interplay between sharpness and diversity in deep ensembles, revealing a trade-off: minimizing sharpness can reduce diversity, potentially hindering ensemble performance. The paper proposes SharpBalance, a novel training approach that addresses this trade-off by balancing sharpness and diversity.",
                "paper-title": "Sharpness-diversity tradeoff: improving flat ensembles with SharpBalance",
                "image-path": ""
            },

            {
                "startTime": "28:18",
                "arxivId": "2407.12784",
                "arxivLink": "https://arxiv.org/abs/2407.12784",
                "title": "LLM Agents on Trial: How a Tiny Trigger Can Hijack Your AI Assistant",
                "institute": "University of Chicago",
                "text": "This research focuses on backdoor attacks against LLM agents that use retrieval-augmented generation (RAG) systems. Unlike previous work that targeted LLMs or RAG systems individually, this paper proposes a novel attack, AGENTPOISON, that specifically targets the memory or knowledge base of these agents.",
                "paper-title": "AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases",
                "image-path": ""
            },

            {
                "startTime": "28:48",
                "arxivId": "2407.13237",
                "arxivLink": "https://arxiv.org/abs/2407.13237",
                "title": "LLMs: Not Just for Chatbots, They're Now Helping Robots Learn Faster!",
                "institute": "Tsinghua University",
                "text": "This research proposes a novel method called LLM-Empowered State Representation (LESR) that utilizes large language models (LLMs) to generate task-related state representations for reinforcement learning (RL) agents. Unlike previous work that relies on extensive sample learning, LESR leverages LLM's knowledge to enhance state representations, leading to improved sample efficiency and performance.",
                "paper-title": "LLM-Empowered State Representation for Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "29:13",
                "arxivId": "2407.13342",
                "arxivLink": "https://arxiv.org/abs/2407.13342",
                "title": "Smoothing Out the Rough Edges: A New Filter for 3D Point Cloud Reconstruction",
                "institute": "Tsinghua University",
                "text": "This research introduces a novel implicit filtering technique for learning neural signed distance functions (SDFs) from 3D point clouds. Unlike previous methods that focus on individual points, this approach leverages the geometric information within the neighborhood of each point to smooth the implicit field while preserving high-frequency details.",
                "paper-title": "Implicit Filtering for Learning Neural Signed Distance Functions from 3D Point Clouds",
                "image-path": ""
            },

            {
                "startTime": "29:35",
                "arxivId": "2407.12883",
                "arxivLink": "https://arxiv.org/abs/2407.12883",
                "title": "Reasoning Retrieval: It's Not Just Keywords, It's Logic!",
                "institute": "University of Hong Kong, Princeton University",
                "text": "This research introduces BRIGHT, a new benchmark for text retrieval that focuses on queries requiring complex reasoning, unlike previous benchmarks that primarily rely on keyword or semantic matching.",
                "paper-title": "BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval",
                "image-path": ""
            },

            {
                "startTime": "30:03",
                "arxivId": "2407.13541",
                "arxivLink": "https://arxiv.org/abs/2407.13541",
                "title": "Self-Supervised Learning: Crowded Features Need a Crowd Control!",
                "institute": "Chinese Academy of Sciences, Tsinghua University, Hong Kong University of Science and Technology",
                "text": "This research identifies a \"crowding problem\" in self-supervised learning (SSL) methods, where features from different classes are not distinctly separated. The paper proposes a novel method called Dynamic Semantic Adjuster (DSA) to address this issue by explicitly encouraging the clustering of similar samples and the separation of dissimilar samples. This approach differs from previous SSL methods that primarily focus on aligning features from the same sample.",
                "paper-title": "On the Discriminability of Self-Supervised Representation Learning",
                "image-path": ""
            },

            {
                "startTime": "30:33",
                "arxivId": "2407.12844",
                "arxivLink": "https://arxiv.org/abs/2407.12844",
                "title": "LLMs: Smarter Than We Thought? A Tiny Benchmark Reveals Their True Potential!",
                "institute": "Helmholtz Munich, University of Cambridge",
                "text": "This research introduces \"metabench,\" a sparse benchmark that uses psychometric techniques to identify the most informative items from six existing benchmarks. This approach aims to reduce redundancy and improve efficiency in evaluating LLMs.",
                "paper-title": "$\texttt{metabench}$ -- A Sparse Benchmark to Measure General Ability in Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "30:54",
                "arxivId": "2407.13734",
                "arxivLink": "https://arxiv.org/abs/2407.13734",
                "title": "Diffusion Models Get a Reinforcement Learning Makeover: Rewarding Results!",
                "institute": "Genentech, Princeton University",
                "text": "This research explores the use of reinforcement learning (RL) algorithms to fine-tune diffusion models, focusing on optimizing downstream reward functions. Unlike previous work that primarily focused on standard fine-tuning methods, this paper delves into the unique aspects of RL-based fine-tuning, highlighting its advantages and limitations.",
                "paper-title": "Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion Models: A Tutorial and Review",
                "image-path": ""
            },

            {
                "startTime": "31:18",
                "arxivId": "2407.12399",
                "arxivLink": "https://arxiv.org/abs/2407.12399",
                "title": "Simplifying Data's Topology: A Practical Solver for a Knotty Problem",
                "institute": "Sorbonne University, University of Arizona",
                "text": "This research introduces a practical solver for topological simplification, focusing on optimizing the cancellation of \"non-signal\" persistence pairs while preserving \"signal\" pairs. Unlike previous methods, this approach is not restricted to persistence pairs involving extrema, allowing it to address a broader class of topological features, particularly saddle pairs in three-dimensional scalar data.",
                "paper-title": "A Practical Solver for Scalar Data Topological Simplification",
                "image-path": ""
            },

            {
                "startTime": "31:43",
                "arxivId": "2407.13185",
                "arxivLink": "https://arxiv.org/abs/2407.13185",
                "title": "NeRF's Got Moves: Kalman Filter Makes Dynamic Scenes Sing!",
                "institute": "The University of Tokyo, Kyoto University, Shanghai Artificial Intelligence Laboratory",
                "text": "This paper introduces KFD-NeRF, a dynamic neural radiance field that uses a Kalman filter to estimate motion. Unlike previous methods that rely solely on observations or predictions, KFD-NeRF combines both sources of knowledge for more accurate deformation estimations.",
                "paper-title": "KFD-NeRF: Rethinking Dynamic NeRF with Kalman Filter",
                "image-path": ""
            },

            {
                "startTime": "32:14",
                "arxivId": "2407.12229",
                "arxivLink": "https://arxiv.org/abs/2407.12229",
                "title": "Laugh Now, Cry Later: AI Makes Speech Sound More Human",
                "institute": "National Taiwan University, Microsoft Corporation",
                "text": "This research introduces EmoCtrl-TTS, a text-to-speech model that can generate speech with varying emotions and non-verbal vocalizations (NVs) like laughter and crying. Unlike previous models that focused on controlling emotions at the utterance level, EmoCtrl-TTS can mimic the emotional changes within a single utterance.",
                "paper-title": "Laugh Now Cry Later: Controlling Time-Varying Emotional States of Flow-Matching-Based Zero-Shot Text-to-Speech",
                "image-path": ""
            },

            {
                "startTime": "32:46",
                "arxivId": "2407.13696",
                "arxivLink": "https://arxiv.org/abs/2407.13696",
                "title": "Benchmarking Benchmarks: A Guide to Getting Agreement Testing Right",
                "institute": "IBM",
                "text": "This research focuses on the methodological inconsistencies in Benchmark Agreement Testing (BAT) and proposes a set of best practices to improve its reliability and validity. Unlike previous work, it analyzes a large dataset of benchmarks and models to demonstrate the impact of different methodological choices on BAT results.",
                "paper-title": "Benchmark Agreement Testing Done Right: A Guide for LLM Benchmark Evaluation",
                "image-path": ""
            },

            {
                "startTime": "33:07",
                "arxivId": "2407.13466",
                "arxivLink": "https://arxiv.org/abs/2407.13466",
                "title": "Robots Learn New Tricks with Language-Powered Brains!",
                "institute": "Volkswagen Group, Technical University of Munich, University of Zurich...",
                "text": "This research introduces a model-based multi-task reinforcement learning approach that leverages pre-trained language models to extract semantically meaningful task representations. This differs from previous work, which primarily focused on model-free methods.",
                "paper-title": "LIMT: Language-Informed Multi-Task Visual World Models",
                "image-path": ""
            },

            {
                "startTime": "33:35",
                "arxivId": "2407.12128",
                "arxivLink": "https://arxiv.org/abs/2407.12128",
                "title": "TTA's New Trick: Aligning Data to Save the Day!",
                "institute": "Concordia University, University of Toronto, Beijing Jiaotong University",
                "text": "This research proposes a novel Distribution Alignment (DA) loss for Test-Time Adaptation (TTA) that aligns test-time feature distributions with the source distributions, addressing the challenges posed by label shifts across online data batches. Unlike previous methods that adapt the model to the test data, this approach aligns the test data to the source model, ensuring compatibility and preventing degradation from conflicting optimization objectives.",
                "paper-title": "Distribution Alignment for Fully Test-Time Adaptation with Dynamic Online Data Streams",
                "image-path": ""
            },

            {
                "startTime": "34:04",
                "arxivId": "2407.13108",
                "arxivLink": "https://arxiv.org/abs/2407.13108",
                "title": "Universal Image Super-Resolution: One Model to Rule Them All!",
                "institute": "University of Science and Technology of China, National University of Singapore, Microsoft",
                "text": "This research proposes a universal framework for compressed image super-resolution (CSR), dubbed UCIP, which can handle distortions from various compression codecs, unlike previous works that typically focused on a single codec like JPEG.",
                "paper-title": "UCIP: A Universal Framework for Compressed Image Super-Resolution using Dynamic Prompt",
                "image-path": ""
            },

            {
                "startTime": "34:46",
                "arxivId": "2407.13677",
                "arxivLink": "https://arxiv.org/abs/2407.13677",
                "title": "Building 3D Shapes with LEGOs: A Transformer-Powered Approach to Part-Aware Generation",
                "institute": "Stanford University",
                "text": "This research introduces PASTA, a generative model that uses an autoregressive transformer to create 3D shapes as sequences of cuboidal primitives. Unlike previous methods that treat objects holistically, PASTA considers the underlying part-based structure, enabling more control and flexibility in shape generation.",
                "paper-title": "PASTA: Controllable Part-Aware Shape Generation with Autoregressive Transformers",
                "image-path": ""
            },

            {
                "startTime": "35:10",
                "arxivId": "2407.13429",
                "arxivLink": "https://arxiv.org/abs/2407.13429",
                "title": "Time Series Sleuth: AI Learns to Pick the Best Medical Tests",
                "institute": "ETH Zurich, Helmholtz Zentrum M\u00fcnchen",
                "text": "This research proposes a novel approach to dynamic feature acquisition (DFA) in time series data, specifically focusing on medical time series. Unlike previous work that primarily relied on reinforcement learning, this study utilizes a conditional mutual information (CMI) maximization approach to train an acquirer model end-to-end.",
                "paper-title": "Towards Dynamic Feature Acquisition on Medical Time Series by Maximizing Conditional Mutual Information",
                "image-path": ""
            },

            {
                "startTime": "35:34",
                "arxivId": "2407.12940",
                "arxivLink": "https://arxiv.org/abs/2407.12940",
                "title": "Driving AI Gets a Kinematic Makeover: Simulating Realistic Agents with Fewer Parameters!",
                "institute": "University of Science and Technology of China, Mach Drive, Tsinghua University",
                "text": "This research proposes a new autoregressive paradigm for trajectory generation that focuses on modeling the distribution of control actions rather than the trajectory states themselves. This approach reduces the complexity of the task and ensures physical feasibility by directly modeling the cause (control actions) instead of the effect (trajectories).",
                "paper-title": "KiGRAS: Kinematic-Driven Generative Model for Realistic Agent Simulation",
                "image-path": ""
            },

            {
                "startTime": "36:06",
                "arxivId": "2407.12718",
                "arxivLink": "https://arxiv.org/abs/2407.12718",
                "title": "Slim Down Your Diffusion Models: One-Step Generation with Rectified Flow",
                "institute": "ETH Zurich, University of Texas at Austin",
                "text": "This research focuses on training smaller, more efficient one-step diffusion models by combining model size reduction with the rectified flow framework. Unlike previous work, it addresses the challenges of initialization mismatch and underperformance during distillation for smaller models.",
                "paper-title": "SlimFlow: Training Smaller One-Step Diffusion Models with Rectified Flow",
                "image-path": ""
            },

            {
                "startTime": "36:29",
                "arxivId": "2407.13605",
                "arxivLink": "https://arxiv.org/abs/2407.13605",
                "title": "Urban Flow Prediction: When Physics Meets Data, Chaos Gets Reweighted!",
                "institute": "University of Queensland, Beijing University of Posts and Telecommunications, Peking University",
                "text": "This research tackles the issue of physical inconsistency in urban flow prediction models. Unlike previous work that assumes perfect data alignment with physical laws, this paper proposes a novel active sample reweighting framework that accounts for data quality and model uncertainty.",
                "paper-title": "Physics-guided Active Sample Reweighting for Urban Flow Prediction",
                "image-path": ""
            },

            {
                "startTime": "36:59",
                "arxivId": "2407.12435",
                "arxivLink": "https://arxiv.org/abs/2407.12435",
                "title": "Human-Object Interactions: A Fine-Grained Look at the Little Things",
                "institute": "The Chinese University of Hong Kong State Key Laboratory of General Artificial Intelligence BIGAI Institute for AI Peking University",
                "text": "This research introduces a new dataset called Semantic-HOI, which provides fine-grained descriptions of human-object interactions at the state level, unlike previous datasets that only offer coarse-grained descriptions of the entire interaction process.",
                "paper-title": "F-HOI: Toward Fine-grained Semantic-Aligned 3D Human-Object Interactions",
                "image-path": ""
            },

            {
                "startTime": "37:33",
                "arxivId": "2407.13221",
                "arxivLink": "https://arxiv.org/abs/2407.13221",
                "title": "Ranking Labels Like a Movie Critic: New AI Learns to Spot the Most Relevant Scenes!",
                "institute": "Tencent, Tsinghua University",
                "text": "This research introduces a novel method for ranking labels based on their relevance to multimodal inputs, particularly video clips. Unlike previous label ranking methods that focus on single-modality data and object labels, this approach leverages a reinforcement learning framework to learn the relevance of labels in a more nuanced way, considering both visual and textual information.",
                "paper-title": "Multimodal Label Relevance Ranking via Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "38:03",
                "arxivId": "2407.12859",
                "arxivLink": "https://arxiv.org/abs/2407.12859",
                "title": "Chatty Bots Ask the Right Questions: AI Makes Data Exploration Conversational",
                "institute": "IBM Research India",
                "text": "This research proposes a system that generates natural language questions about tabular data, specifically aggregate questions, in a conversational setting. Unlike previous work that focuses on visualizations or single-hop questions, this system leverages interestingness measures and a fine-tuned language model to recommend relevant questions for deeper data exploration.",
                "paper-title": "Automated Question Generation on Tabular Data for Conversational Data Exploration",
                "image-path": ""
            },

            {
                "startTime": "38:29",
                "arxivId": "2407.13300",
                "arxivLink": "https://arxiv.org/abs/2407.13300",
                "title": "ASR Error Correction: When Less is More!",
                "institute": "IBM",
                "text": "This research proposes a novel data filtering method for training error correction (EC) models. Unlike previous work that focuses on discarding pairs with large edit distances, this study introduces two criteria based on linguistic acceptability and inferability from context.",
                "paper-title": "Robust ASR Error Correction with Conservative Data Filtering",
                "image-path": ""
            },

            {
                "startTime": "38:53",
                "arxivId": "2407.13095",
                "arxivLink": "https://arxiv.org/abs/2407.13095",
                "title": "Zero-Shot Learning: Audio-Visual Recognition Made Easy!",
                "institute": "Carnegie Mellon University, University of Wisconsin-Madison",
                "text": "This research introduces a new framework for audio-visual generalized zero-shot learning (AVGZSL) that simplifies the process by aligning audio-visual embeddings with transformed text representations. Unlike previous approaches that relied on complex auto-encoders, this method utilizes a single supervised contrastive loss to learn the alignment between audio-visual and textual modalities.",
                "paper-title": "Audio-visual Generalized Zero-shot Learning the Easy Way",
                "image-path": ""
            },

            {
                "startTime": "39:28",
                "arxivId": "2407.13555",
                "arxivLink": "https://arxiv.org/abs/2407.13555",
                "title": "PetFace: A Face-tastic Dataset for Animal ID!",
                "institute": "Kyoto University, The University of Tokyo",
                "text": "This research introduces a large-scale dataset called PetFace, which contains over 257,000 unique animal individuals across 13 families and 319 breeds. This dataset is significantly larger than previous animal face datasets, which typically included less than 100 individuals.",
                "paper-title": "PetFace: A Large-Scale Dataset and Benchmark for Animal Identification",
                "image-path": ""
            },

            {
                "startTime": "39:54",
                "arxivId": "2407.12680",
                "arxivLink": "https://arxiv.org/abs/2407.12680",
                "title": "AI Detectives: Busting Bias in Medical Textbooks!",
                "institute": "University of Connecticut, Worcester Polytechnic Institute, University of Oxford...",
                "text": "This research introduces a novel dataset, BRICC, specifically designed to identify and annotate instances of bias in medical educational materials. It then uses this dataset to train AI models for detecting bias in medical text, going beyond previous work that focused on general bias detection in other domains.",
                "paper-title": "Reducing Biases towards Minoritized Populations in Medical Curricular Content via Artificial Intelligence for Fairer Health Outcomes",
                "image-path": ""
            },

            {
                "startTime": "40:22",
                "arxivId": "2407.12543",
                "arxivLink": "https://arxiv.org/abs/2407.12543",
                "title": "Models Think Like Us? New Test Checks If AI's Got the Right Brain Wiring!",
                "institute": "MIT",
                "text": "This research introduces \"abstraction alignment,\" a method to assess how well a machine learning model's understanding of concepts aligns with human understanding. Unlike previous work that analyzes concepts in isolation, this method examines the relationships between concepts, revealing how the model structures its knowledge.",
                "paper-title": "Abstraction Alignment: Comparing Model and Human Conceptual Relationships",
                "image-path": ""
            },

            {
                "startTime": "40:50",
                "arxivId": "2407.12275",
                "arxivLink": "https://arxiv.org/abs/2407.12275",
                "title": "Transformers Can't Compose? Bottleneck to the Rescue!",
                "institute": "ETH Zurich, Google, University of Montreal",
                "text": "This research investigates the ability of transformers to generalize compositionally in an in-context learning setting. Unlike previous work that focused on gradient-based meta-learning, this study explores the limitations of transformers in this context and proposes a novel architectural solution.",
                "paper-title": "When can transformers compositionally generalize in-context?",
                "image-path": ""
            },

            {
                "startTime": "41:13",
                "arxivId": "2407.13068",
                "arxivLink": "https://arxiv.org/abs/2407.13068",
                "title": "Krait Strikes: Backdoor Attack Targets Graph Prompt Tuning",
                "institute": "University of Pittsburgh, CMU",
                "text": "This research explores the vulnerability of graph prompt tuning to backdoor attacks, a novel attack vector that disguises malicious triggers as benign prompts. Unlike previous work focusing on traditional GNNs, this study specifically investigates the unique challenges posed by graph prompt tuning.",
                "paper-title": "Krait: A Backdoor Attack Against Graph Prompt Tuning",
                "image-path": ""
            },

            {
                "startTime": "41:39",
                "arxivId": "2407.12322",
                "arxivLink": "https://arxiv.org/abs/2407.12322",
                "title": "Skeleton Action Recognition: When Transformers Get a Frequency Boost!",
                "institute": "CMU, Microsoft, University of North Carolina at Charlotte...",
                "text": "This research introduces a Frequency-aware Mixed Transformer (FreqMixFormer) for skeleton action recognition. Unlike previous transformer-based approaches that rely solely on spatial features, FreqMixFormer incorporates frequency features, enabling it to better distinguish subtle movements.",
                "paper-title": "Frequency Guidance Matters: Skeletal Action Recognition by Frequency-Aware Mixed Transformer",
                "image-path": ""
            },

            {
                "startTime": "42:09",
                "arxivId": "2407.12197",
                "arxivLink": "https://arxiv.org/abs/2407.12197",
                "title": "Soft Robots Get a Sixth Sense: Predicting the Future with Multi-Modal Perception",
                "institute": "Sant\u2019Anna School of Advanced Studies, University College London",
                "text": "This research builds upon previous work using generative models for soft robot perception by introducing modality-specific encoders and decoders, allowing for late fusion and early decoding capabilities. This approach enables a deeper understanding of the latent representation and its influence on sensory prediction.",
                "paper-title": "Towards Interpretable Visuo-Tactile Predictive Models for Soft Robot Interactions",
                "image-path": ""
            },

            {
                "startTime": "42:34",
                "arxivId": "2407.12508",
                "arxivLink": "https://arxiv.org/abs/2407.12508",
                "title": "LLMs: The New Search Party for Videos!",
                "institute": "Korea Advanced Institute of Science and Technology, UC Berkeley, Seoul National University",
                "text": "This research introduces MERLIN, a novel training-free pipeline that leverages LLMs for iterative feedback learning to refine query embeddings in text-video retrieval. Unlike previous work, MERLIN focuses on addressing the discrepancy between user queries and the content retrieved, enhancing alignment between queries and video content through a dynamic question answering process.",
                "paper-title": "MERLIN: Multimodal Embedding Refinement via LLM-based Iterative Navigation for Text-Video Retrieval-Rerank Pipeline",
                "image-path": ""
            },

            {
                "startTime": "43:05",
                "arxivId": "2407.13751",
                "arxivLink": "https://arxiv.org/abs/2407.13751",
                "title": "Stock Market Similarity: A Time Machine for Your Portfolio?",
                "institute": "University of Oxford, Ulsan National Institute of Science and Technology",
                "text": "This research introduces SimStock, a novel temporal self-supervised learning framework that combines techniques from self-supervised learning (SSL) and temporal domain generalization to learn robust and informative representations of financial time series data. This approach differs from previous work by explicitly addressing the non-stationary nature of financial markets, enabling the model to adapt to distribution shifts and generalize well to future time periods.",
                "paper-title": "Temporal Representation Learning for Stock Similarities and Its Applications in Investment Management",
                "image-path": ""
            },

            {
                "startTime": "43:34",
                "arxivId": "2407.12877",
                "arxivLink": "https://arxiv.org/abs/2407.12877",
                "title": "LLMs Get a Peer Review: New Framework Makes AI Writing Better",
                "institute": "Microsoft, Indian Institute of Technology Kharagpur",
                "text": "This research proposes a novel evaluation framework for NLG, called ReFeR, which uses LLMs as evaluators and feedback providers in a system akin to academic peer review. This approach differs from previous work by incorporating a multi-dimensional evaluation schema and generating constructive feedback for model refinement.",
                "paper-title": "Review-Feedback-Reason (ReFeR): A Novel Framework for NLG Evaluation and Reasoning",
                "image-path": ""
            },

            {
                "startTime": "43:57",
                "arxivId": "2407.12117",
                "arxivLink": "https://arxiv.org/abs/2407.12117",
                "title": "Training a 7B LLM with 1 Million Tokens? No Problem! Memo to the Rescue!",
                "institute": "Peking University, Tencent",
                "text": "This research proposes Memo, a novel LLM training framework that tackles the memory challenges of long context training by introducing a fine-grained activation recomputation and swapping mechanism. This approach differs from previous work by optimizing memory usage at both the tensor and token levels, minimizing redundant computation and communication overhead.",
                "paper-title": "Efficiently Training 7B LLM with 1 Million Sequence Length on 8 GPUs",
                "image-path": ""
            },

            {
                "startTime": "44:21",
                "arxivId": "2407.12820",
                "arxivLink": "https://arxiv.org/abs/2407.12820",
                "title": "LLM's Memory Woes? PQCache to the Rescue!",
                "institute": "Peking University, Carnegie Mellon University, Beijing Institute of Technology...",
                "text": "This research proposes PQCache, a novel system-algorithm co-designed method that leverages Product Quantization (PQ) to manage the Key-Value Cache (KVCache) in long-context LLM inference. Unlike previous methods that either compromise model quality or introduce high latency, PQCache aims to achieve both effectiveness and efficiency by employing PQ for approximate retrieval of relevant key-value pairs.",
                "paper-title": "PQCache: Product Quantization-based KVCache for Long Context LLM Inference",
                "image-path": ""
            },

            {
                "startTime": "44:55",
                "arxivId": "2407.12391",
                "arxivLink": "https://arxiv.org/abs/2407.12391",
                "title": "LLM Serving: A Survey of How to Make AI Models Run Faster and Cheaper",
                "institute": "Northeastern University, MIT",
                "text": "This survey focuses on system-level enhancements for LLM serving, specifically those that improve performance and efficiency without altering the core LLM decoding mechanisms. It excludes studies that modify LLM decoding algorithms and focuses on research published after 2023.",
                "paper-title": "LLM Inference Serving: Survey of Recent Advances and Opportunities",
                "image-path": ""
            },

            {
                "startTime": "45:18",
                "arxivId": "2407.12051",
                "arxivLink": "https://arxiv.org/abs/2407.12051",
                "title": "DNA's Secret Code: Unlocking the Language of Life with Sparse Recovery",
                "institute": "Tsinghua University, University of California Berkeley",
                "text": "This research proposes Dy-mer, a DNA representation scheme that leverages sparse recovery to capture recurring patterns in DNA sequences, known as K-mers, and represent them as basis vectors. This approach differs from previous methods by explicitly incorporating the semantic structure of DNA, making the representations more explainable and robust.",
                "paper-title": "Dy-mer: An Explainable DNA Sequence Representation Scheme using Sparse Recovery",
                "image-path": ""
            },

            {
                "startTime": "45:45",
                "arxivId": "2407.13372",
                "arxivLink": "https://arxiv.org/abs/2407.13372",
                "title": "One Model to Rule Them All: Image Restoration Gets a Unified Makeover!",
                "institute": "University of Pisa, University of Trento, University of W\u00fcrzburg...",
                "text": "This research proposes a unified approach to image restoration, leveraging inherent similarities across various degradations. Unlike previous methods that require specific modules for each degradation, this model uses a single architecture with a novel gated degradation adaptation mechanism to handle any type of image degradation.",
                "paper-title": "Any Image Restoration with Efficient Automatic Degradation Adaptation",
                "image-path": ""
            },

            {
                "startTime": "46:17",
                "arxivId": "2407.12753",
                "arxivLink": "https://arxiv.org/abs/2407.12753",
                "title": "Vision Transformers Get a Makeover: LookupViT Compresses Images for Faster Inference!",
                "institute": "Google DeepMind, Ludwig Maximilian University of Munich",
                "text": "LookupViT introduces a novel vision transformer block that compresses information from higher-resolution tokens to a fixed number of tokens. This approach differs from previous work by focusing on intrinsic compression within the architecture rather than post-processing techniques.",
                "paper-title": "LookupViT: Compressing visual information to a limited number of tokens",
                "image-path": ""
            },

            {
                "startTime": "46:44",
                "arxivId": "2407.13264",
                "arxivLink": "https://arxiv.org/abs/2407.13264",
                "title": "Underwater Noise? No Problem! New Denoising Techniques Dive Deep.",
                "institute": "Nanyang Technological University, National University of Singapore, Harbin Institute of Technology...",
                "text": "This research provides a comprehensive review of recent advancements in underwater acoustic signal denoising, including a taxonomy of techniques and a discussion of the unique challenges associated with this field. It also highlights the need for more robust denoising techniques that can adapt to the dynamic underwater acoustic environment.",
                "paper-title": "Underwater Acoustic Signal Denoising Algorithms: A Survey of the State-of-the-art",
                "image-path": ""
            },

            {
                "startTime": "47:07",
                "arxivId": "2407.13722",
                "arxivLink": "https://arxiv.org/abs/2407.13722",
                "title": "H-Consistency Bounds Get a Boost: New Tools for Better Learning Guarantees",
                "institute": "NYU, Google",
                "text": "This research introduces a new framework for deriving H-consistency bounds by relaxing the assumption that the lower bound of the surrogate loss conditional regret is a convex function of the target conditional regret. This allows for the derivation of tighter bounds in various scenarios, including multi-class classification under Tsybakov noise conditions and bipartite ranking.",
                "paper-title": "Enhanced $H$-Consistency Bounds",
                "image-path": ""
            },

            {
                "startTime": "47:33",
                "arxivId": "2407.13746",
                "arxivLink": "https://arxiv.org/abs/2407.13746",
                "title": "Multi-Label Learning: A New Loss Function That's Not Hamming Around!",
                "institute": "NYU, Google",
                "text": "This research introduces a novel multi-label logistic loss function that accounts for label correlations and benefits from label-independent H-consistency bounds, unlike previous work that relied on binary relevance methods.",
                "paper-title": "Multi-Label Learning with Stronger Consistency Guarantees",
                "image-path": ""
            },

            {
                "startTime": "48:00",
                "arxivId": "2407.13732",
                "arxivLink": "https://arxiv.org/abs/2407.13732",
                "title": "Deferring to Experts: A New Loss Function That's Actually Consistent",
                "institute": "NYU, Google",
                "text": "This research introduces a new family of surrogate loss functions for learning to defer, parameterized by a non-increasing function. The paper establishes their realizable H-consistency properties under mild conditions and proves that several of these surrogate losses benefit from H-consistency bounds for cost functions based on classification error and general cost functions, which also imply their Bayes-consistency. This research not only resolves an open question posed in previous work but also lays the groundwork for comparing various consistency notions in learning to defer and standard classification.",
                "paper-title": "Realizable $H$-Consistent and Bayes-Consistent Loss Functions for Learning to Defer",
                "image-path": ""
            },

            {
                "startTime": "48:28",
                "arxivId": "2407.13666",
                "arxivLink": "https://arxiv.org/abs/2407.13666",
                "title": "Confidence Intervals Get a Data-Driven Makeover: No More Asymptotic Assumptions!",
                "institute": "RWTH Aachen University, Harvard University, Technical University of Munich...",
                "text": "This research introduces a data-driven approach to adjust confidence intervals for high-dimensional regression problems. Unlike previous methods that rely on asymptotic assumptions, this approach explicitly accounts for the remainder term in the estimation error, providing more accurate and reliable uncertainty quantification in finite-sample regimes.",
                "paper-title": "Non-Asymptotic Uncertainty Quantification in High-Dimensional Learning",
                "image-path": ""
            },

            {
                "startTime": "48:57",
                "arxivId": "2407.13575",
                "arxivLink": "https://arxiv.org/abs/2407.13575",
                "title": "Debiasing the LASSO: Sampling Without Replacement Makes a Big Difference!",
                "institute": "RWTH Aachen University, Harvard University, Technical University Munich...",
                "text": "This research introduces a new method for improving the debiased LASSO estimator by leveraging a reweighted sampling without replacement scheme. This approach differs from previous work that relied on sampling with replacement, which can lead to redundant samples and less accurate results.",
                "paper-title": "With or Without Replacement? Improving Confidence in Fourier Imaging",
                "image-path": ""
            },

            {
                "startTime": "49:23",
                "arxivId": "2407.13522",
                "arxivLink": "https://arxiv.org/abs/2407.13522",
                "title": "Indic Languages Get Their Own Question-Answering Test: LLMs Face the Challenge!",
                "institute": "Indian Institute of Technology Bombay, IBM",
                "text": "This research introduces INDICQABENCHMARK, a multilingual benchmark for evaluating the question-answering capabilities of LLMs in 11 major Indian languages. Unlike previous benchmarks, it includes a diverse range of domains and both extractive and abstractive question-answering tasks.",
                "paper-title": "INDIC QA BENCHMARK: A Multilingual Benchmark to Evaluate Question Answering capability of LLMs for Indic Languages",
                "image-path": ""
            },

            {
                "startTime": "49:56",
                "arxivId": "2407.12781",
                "arxivLink": "https://arxiv.org/abs/2407.12781",
                "title": "Taming Transformers: Giving Video AI a 3D Camera Lens",
                "institute": "University of Toronto, Vector Institute, Snap Inc....",
                "text": "This research introduces a new method for controlling camera movement in video generation models that are based on transformers. Unlike previous approaches that focused on U-Net architectures, this method specifically addresses the challenges of controlling camera movement in transformer-based models, which process spatial and temporal information jointly.",
                "paper-title": "VD3D: Taming Large Video Diffusion Transformers for 3D Camera Control",
                "image-path": ""
            },

            {
                "startTime": "50:25",
                "arxivId": "2407.11979",
                "arxivLink": "https://arxiv.org/abs/2407.11979",
                "title": "Clustering Students: A New Way to See Who's Really Learning!",
                "institute": "Federal University of Minas Gerais, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research introduces a new clustering pipeline called Interpret3C that uses interpretable neural networks to select features for each student individually, rather than using a single set of features for everyone. This allows for more nuanced and accurate clustering, as it takes into account the unique learning patterns of each student.",
                "paper-title": "Interpret3C: Interpretable Student Clustering Through Individualized Feature Selection",
                "image-path": ""
            },

            {
                "startTime": "50:48",
                "arxivId": "2407.13771",
                "arxivLink": "https://arxiv.org/abs/2407.13771",
                "title": "Model Merging: Training-Free Domain Adaptation for Scene Understanding",
                "institute": "Chinese Academy of Sciences, Tsinghua University",
                "text": "This research explores a novel approach to multi-target domain adaptation for scene understanding models. Unlike previous methods that require simultaneous access to data from all target domains, this paper proposes a training-free model merging technique that integrates models independently adapted to distinct domains.",
                "paper-title": "Training-Free Model Merging for Multi-target Domain Adaptation",
                "image-path": ""
            },

            {
                "startTime": "51:25",
                "arxivId": "2407.13642",
                "arxivLink": "https://arxiv.org/abs/2407.13642",
                "title": "Diffusion Models: Giving 3D Scenes a Semantic Makeover!",
                "institute": "Carnegie Mellon University, Google DeepMind, Google...",
                "text": "This research uses text-to-image diffusion models, which are typically used for image generation, to perform open-vocabulary 3D semantic segmentation. This approach differs from previous methods that relied on contrastively trained models like CLIP.",
                "paper-title": "Open-Vocabulary 3D Semantic Segmentation with Text-to-Image Diffusion Models",
                "image-path": ""
            },

            {
                "startTime": "51:53",
                "arxivId": "2407.13076",
                "arxivLink": "https://arxiv.org/abs/2407.13076",
                "title": "LoRa Networks: Matching Up for Energy Efficiency!",
                "institute": "Sun Yat-sen University, Nanyang Technological University",
                "text": "This research focuses on optimizing energy efficiency in multi-gateway LoRa networks by jointly allocating transmission parameters like channel, spreading factor, and transmission power. Unlike previous work, it considers the impact of imperfect spreading factor orthogonality and capture effects, making the model more realistic.",
                "paper-title": "Matching-Driven Deep Reinforcement Learning for Energy-Efficient Transmission Parameter Allocation in Multi-Gateway LoRa Networks",
                "image-path": ""
            },

            {
                "startTime": "52:26",
                "arxivId": "2407.13431",
                "arxivLink": "https://arxiv.org/abs/2407.13431",
                "title": "Polynomial Predictions: Making Self-Driving Cars Smarter (and Less Greedy)",
                "institute": "Continental AG, Freie Universit\u00e4t Berlin, University of Freiburg...",
                "text": "This research introduces a novel approach to trajectory prediction for autonomous driving by using polynomial representations for both input and output data. This differs from previous work that primarily relies on sequence-based representations.",
                "paper-title": "Improving Out-of-Distribution Generalization of Trajectory Prediction for Autonomous Driving via Polynomial Representations",
                "image-path": ""
            },

            {
                "startTime": "52:51",
                "arxivId": "2407.12281",
                "arxivLink": "https://arxiv.org/abs/2407.12281",
                "title": "LLMs on a Diet: How Data Poisoning Makes Them Go Bonkers!",
                "institute": "CMU, IBM",
                "text": "This research focuses on data poisoning attacks against large language models (LLMs) specifically for natural language generation (NLG) tasks, which have been less explored than attacks on classification tasks. The paper introduces new metrics to evaluate the success and stealthiness of these attacks and explores the effectiveness of various trigger designs.",
                "paper-title": "Turning Generative Models Degenerate: The Power of Data Poisoning Attacks",
                "image-path": ""
            },

            {
                "startTime": "53:17",
                "arxivId": "2407.12967",
                "arxivLink": "https://arxiv.org/abs/2407.12967",
                "title": "Sampling Convex Bodies: A R\u00e9nyi-Infinity Journey with d3 Queries!",
                "institute": "Georgia Institute of Technology, University of Toronto",
                "text": "This research introduces a new algorithm called the Proximal sampler, which achieves convergence in the R\u00e9nyi-infinity divergence for both uniform and truncated Gaussian distributions on convex bodies. This is a stronger metric than previously used in the field, and the algorithm achieves this without any overhead in query complexity.",
                "paper-title": "R\'enyi-infinity constrained sampling with $d^3$ membership queries",
                "image-path": ""
            },

            {
                "startTime": "53:41",
                "arxivId": "2407.13292",
                "arxivLink": "https://arxiv.org/abs/2407.13292",
                "title": "Whispering Secrets: How Phoneme-Based Pre-Training Makes Low-Resource Speech Recognition Sing!",
                "institute": "Tsinghua University",
                "text": "This research explores the effectiveness of different pre-training methods for low-resource speech recognition, focusing on the Iu Mien language. It specifically investigates the use of a weakly-supervised phoneme-based multilingual pre-training model called Whistle, comparing its performance to other pre-training approaches.",
                "paper-title": "Low-Resourced Speech Recognition for Iu Mien Language via Weakly-Supervised Phoneme-based Multilingual Pre-training",
                "image-path": ""
            },

            {
                "startTime": "54:06",
                "arxivId": "2407.12074",
                "arxivLink": "https://arxiv.org/abs/2407.12074",
                "title": "LoRA's Secret Weapon: Unmasking the Intrinsic Dimension for Better AI Models",
                "institute": "Tsinghua University",
                "text": "This research delves into the intrinsic dimension of LoRA updates, a factor previously overlooked, and proposes a method to enhance it for improved generalization performance.",
                "paper-title": "Enhancing Parameter Efficiency and Generalization in Large-Scale Models: A Regularized and Masked Low-Rank Adaptation Approach",
                "image-path": ""
            },

            {
                "startTime": "54:29",
                "arxivId": "2407.11977",
                "arxivLink": "https://arxiv.org/abs/2407.11977",
                "title": "AI Chatbots Get a Personality Makeover: LLMs Learn to Play the Part",
                "institute": "University of Cambridge, King\u2019s College London",
                "text": "This research explores the challenges of integrating personas into Large Language Models (LLMs) used for conversational agents. Unlike previous work that focused on embedding static personality traits, this paper emphasizes the need for consistent and contextually appropriate personas across multiple interactions.",
                "paper-title": "Building Better AI Agents: A Provocation on the Utilisation of Persona in LLM-based Conversational Agents",
                "image-path": ""
            },

            {
                "startTime": "54:51",
                "arxivId": "2407.12613",
                "arxivLink": "https://arxiv.org/abs/2407.12613",
                "title": "AI Helps Journalists Decode the Murmurs of the Internet",
                "institute": "MIT",
                "text": "This research introduces AudienceView, a tool that uses large language models (LLMs) to help journalists analyze and understand audience feedback on YouTube. Unlike previous work that focuses on qualitative analysis, AudienceView aims to provide a more automated and accessible approach to sensemaking from textual data.",
                "paper-title": "AudienceView: AI-Assisted Interpretation of Audience Feedback in Journalism",
                "image-path": ""
            },

            {
                "startTime": "55:12",
                "arxivId": "2407.12165",
                "arxivLink": "https://arxiv.org/abs/2407.12165",
                "title": "AI Agents for Autonomous Clouds: Building a Framework for Fault-Free Computing",
                "institute": "Microsoft, University of California Berkeley, University of Illinois Urbana-Champaign...",
                "text": "This research proposes a standardized framework, AIOpsLab, for building, evaluating, and improving AI agents designed for cloud operations. Unlike previous work that focuses on specific solutions or uses proprietary services and datasets, AIOpsLab aims to provide a generic, reproducible, and scalable benchmark for evaluating AIOps agents.",
                "paper-title": "Building AI Agents for Autonomous Clouds: Challenges and Design Principles",
                "image-path": ""
            },

            {
                "startTime": "55:38",
                "arxivId": "2407.13480",
                "arxivLink": "https://arxiv.org/abs/2407.13480",
                "title": "Self-Driving Cars Get a Safety Upgrade: New AI Predicts Risky Moves!",
                "institute": "Tsinghua University, Nanyang Technological University",
                "text": "This research focuses on trajectory prediction for autonomous vehicles in safety-critical scenarios, unlike previous work that primarily focused on normal driving conditions. The paper proposes a risk-aware framework that incorporates risk information into the prediction process.",
                "paper-title": "Risk-Aware Vehicle Trajectory Prediction Under Safety-Critical Scenarios",
                "image-path": ""
            },

            {
                "startTime": "56:08",
                "arxivId": "2407.12777",
                "arxivLink": "https://arxiv.org/abs/2407.12777",
                "title": "Human 3D Models From Just 3 Photos: A New Way to Render Reality!",
                "institute": "Carnegie Mellon University, Meta Reality Labs",
                "text": "This research introduces a new method for rendering 3D human models from sparse views, using a technique called \"Generalizable Human Gaussians\" (GHG). Unlike previous methods that rely on dense input views or per-subject optimization, GHG leverages a human template model and a 2D UV space to learn Gaussian parameters, enabling accurate and photorealistic rendering from just a few input images.",
                "paper-title": "Generalizable Human Gaussians for Sparse View Synthesis",
                "image-path": ""
            },

            {
                "startTime": "56:35",
                "arxivId": "2407.12210",
                "arxivLink": "https://arxiv.org/abs/2407.12210",
                "title": "Self-Supervised Learning: Probing for the Right Metric!",
                "institute": "California Institute of Technology, ETH Zurich, Swiss Data Science Center...",
                "text": "This research investigates the correlation between different evaluation protocols used to assess the quality of representations learned through self-supervised learning (SSL). It compares the performance of various SSL methods across eleven datasets and analyzes how well in-domain metrics predict out-of-domain performance.",
                "paper-title": "A Closer Look at Benchmarking Self-Supervised Pre-training with Image Classification",
                "image-path": ""
            },

            {
                "startTime": "56:57",
                "arxivId": "2407.12131",
                "arxivLink": "https://arxiv.org/abs/2407.12131",
                "title": "Kilkari's Got a New Trick: AI Helps Moms Hear the Message!",
                "institute": "Google, Harvard University",
                "text": "This research focuses on a larger-scale mHealth program, Kilkari, and utilizes non-Markovian Time-Series Bandits (TSB) to optimize interventions, unlike previous work that relied on Markovian approaches.",
                "paper-title": "Improving Health Information Access in the World's Largest Maternal Mobile Health Program via Bandit Algorithms",
                "image-path": ""
            },

            {
                "startTime": "57:29",
                "arxivId": "2407.13765",
                "arxivLink": "https://arxiv.org/abs/2407.13765",
                "title": "Probing Language Models: Are They Secretly Causal Concept Wizards?",
                "institute": "MIT",
                "text": "This paper introduces a formal framework called \"latent causal probing\" to analyze whether language models (LLMs) learn underlying causal relationships from their training data. It differs from previous work by explicitly incorporating causal models into the probing process, allowing for a more rigorous analysis of the LLM's ability to learn latent causal concepts.",
                "paper-title": "Latent Causal Probing: A Formal Perspective on Probing with Causal Models of Data",
                "image-path": ""
            },

            {
                "startTime": "58:02",
                "arxivId": "2407.11973",
                "arxivLink": "https://arxiv.org/abs/2407.11973",
                "title": "AI-Powered Calls: Can They Make Moms Smarter?",
                "institute": "Google, Harvard University, CMU",
                "text": "This study investigates the impact of AI-scheduled interventions on health knowledge and behavior in a maternal health program, going beyond previous work that focused solely on increased listenership.",
                "paper-title": "Preliminary Study of the Impact of AI-Based Interventions on Health and Behavioral Outcomes in Maternal Health Programs",
                "image-path": ""
            },

            {
                "startTime": "58:31",
                "arxivId": "2407.13706",
                "arxivLink": "https://arxiv.org/abs/2407.13706",
                "title": "Tiny Drones, Big Brains: GAP9Shield Packs AI Punch for Nano-UAVs",
                "institute": "ETH Zurich",
                "text": "This research introduces the GAP9Shield, a module designed for nano-drones, which integrates a high-definition camera, a WiFi-BLE module, and a 5D ranging subsystem. This differs from previous work by combining these features into a single, lightweight, and energy-efficient package.",
                "paper-title": "GAP9Shield: A 150GOPS AI-capable Ultra-low Power Module for Vision and Ranging Applications on Nano-drones",
                "image-path": ""
            },

            {
                "startTime": "59:02",
                "arxivId": "2407.13594",
                "arxivLink": "https://arxiv.org/abs/2407.13594",
                "title": "Neural Networks: They're Not Just Black Boxes Anymore!",
                "institute": "University of Wisconsin-Madison, Carnegie Mellon University, Center for AI Safety",
                "text": "This research proposes a set of axioms to formally define and evaluate mechanistic interpretability, a technique for understanding how neural networks work. This approach differs from previous work by providing a standardized framework for judging the validity of mechanistic interpretations.",
                "paper-title": "Mechanistically Interpreting a Transformer-based 2-SAT Solver: An Axiomatic Approach",
                "image-path": ""
            },

            {
                "startTime": "59:37",
                "arxivId": "2407.12707",
                "arxivLink": "https://arxiv.org/abs/2407.12707",
                "title": "TTS Gets a Score: New Benchmark Measures Synthetic Speech Quality Like Never Before!",
                "institute": "The University of Edinburgh",
                "text": "This research proposes a new benchmark for evaluating Text-to-Speech (TTS) systems by measuring the distance between the distribution of real and synthetic speech. Unlike previous methods that rely on subjective human ratings or single-factor metrics, this approach considers multiple factors like prosody, speaker identity, and intelligibility.",
                "paper-title": "TTSDS -- Text-to-Speech Distribution Score",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 163,
        "num_total": 696,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202407191446_audio.mp3"
}
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ribbit Ribbit - Discover research the fun way!</title>
    <meta name="description"
        content="Discover top ArXiv papers in AI and machine learning daily with our fresh picks. Browse easily through tweet-sized summaries or listen on-the-go. Make learning engaging and accessible anytime, anywhere.">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Amatic+SC:wght@400;700&family=Dosis:wght@200..800&family=Roboto:wght@300..700&display=swap">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
    <link rel="icon" href="assets/frogFavicon.png" type="image/x-icon">
    <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>
</head>

<body>
    <div id="headerId" class="header"></div>
    <div class="container">
        <div id="topblock">
            <div style="height: 150px;"></div>
            <div class="page-title">DISCOVER RESEARCH THE FUN WAY
            </div>
            <div style="display: flex; flex-direction: column; justify-content: flex-start; align-items: flex-start;">
                <div class="institute-text" style="padding-top: 3px; line-height: 1.2;">
                    Fresh Picks:
                    <span class="highlightNumber" style="font-size: 28px;">53</span> out of <span
                        class="highlightNumber">257</span> AI papers
                </div>
                <div class="institute-text" style="line-height: 1.2;">that were just released in arXiv on</div>
                <div id="data-default-date" data-date="2024-08-28"></div>
                <input type="text" id="selectedDate" style="text-decoration: underline;" />
            </div>
            <div style=" height: 80px;">
            </div>
        </div>

        <div class="tweet" id="tweet0">
            <div class="start-time-icon" title="Play from here">
                00:57
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15136" target="_blank">
                        @arXiv 2408.15136
                    </a>
                    <span class="tweet-title">
                        Simulating the Universe on a Budget: Bayesian Neural Networks to the
                        Rescue!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Li√®ge, MIT, Anthropic
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes using Bayesian neural networks (BNNs) in simulation-based inference,
                    specifically addressing the challenge of overfitting in data-poor regimes. Unlike previous work,
                    it
                    introduces a novel prior for BNNs that is tailored for inference and leads to well-calibrated
                    posteriors even with limited simulations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet1">
            <div class="start-time-icon" title="Play from here">
                01:19
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14886" target="_blank">
                        @arXiv 2408.14886
                    </a>
                    <span class="tweet-title">
                        VoxCeleb Speaker Recognition: A Five-Year Retrospective - From Closed to
                        Open, and Everything in Between!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Oxford, Google, Meta...
                    </span>
                </div>
                <div class="primary-text">
                    This research paper provides a comprehensive retrospective of the VoxCeleb Speaker Recognition
                    Challenges (VoxSRC) held annually from 2019 to 2023. It analyzes the evolution of methods,
                    performance trends, and the impact of different data settings on speaker recognition and
                    diarization
                    tasks. The paper also highlights the unique aspects of each year's challenge, such as the
                    introduction of self-supervised learning and semi-supervised domain adaptation tracks.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet2">
            <div class="start-time-icon" title="Play from here">
                01:48
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15026" target="_blank">
                        @arXiv 2408.15026
                    </a>
                    <span class="tweet-title">
                        Echocardiography's New Trick: Learning from the Heart's Rhythm
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Tsinghua University, Beijing Academy of Artificial Intelligence
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces a sequence-aware pre-training method for echocardiography probe
                    guidance.
                    Unlike previous work that focused on population-averaged cardiac structures, this approach
                    learns
                    personalized cardiac features by analyzing the sequence of ultrasound images and probe
                    adjustments
                    during a scan.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet3">
            <div class="start-time-icon" title="Play from here">
                02:20
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15204" target="_blank">
                        @arXiv 2408.15204
                    </a>
                    <span class="tweet-title">
                        LLMs: Confidently Unconfident? New Method Cuts Human Annotation
                        Costs!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Stanford University
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces a method called CONFIDENCE-DRIVEN INFERENCE, which combines LLM
                    annotations
                    with LLM confidence scores to strategically select which human annotations should be collected.
                    This
                    differs from previous work that either relies solely on human annotations or treats LLM
                    annotations
                    as equally reliable as human ones.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet4">
            <div class="start-time-icon" title="Play from here">
                02:44
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14636" target="_blank">
                        @arXiv 2408.14636
                    </a>
                    <span class="tweet-title">
                        Datasets: They're Not Just Sitting There!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Google
                    </span>
                </div>
                <div class="primary-text">
                    This research goes beyond simply identifying datasets on the web. It focuses on the
                    relationships
                    between datasets, analyzing how they are connected and how these connections impact user tasks.
                    This
                    is a departure from previous work that primarily focused on individual datasets.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet5">
            <div class="start-time-icon" title="Play from here">
                03:02
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14774" target="_blank">
                        @arXiv 2408.14774
                    </a>
                    <span class="tweet-title">
                        LLMs Learn Skills, Not Just Facts: A New Recipe for Instruction
                        Tuning
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Princeton University, Meta
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces INSTRUCT-SKILLMIX, a pipeline that uses a powerful LLM to extract core
                    "skills" for instruction-following and then generates synthetic data by randomly combining these
                    skills. This differs from previous work that focused on creating diverse datasets with broad
                    topic
                    coverage.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet6">
            <div class="start-time-icon" title="Play from here">
                03:28
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15038" target="_blank">
                        @arXiv 2408.15038
                    </a>
                    <span class="tweet-title">
                        Occlusion Boundaries: Scribbling Your Way to Better Scene
                        Understanding!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Univ Gustave Eiffel, CNRS, ¬¥Ecole des Ponts
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces interactive occlusion boundary estimation, a novel approach that
                    leverages
                    user input to improve the accuracy of occlusion boundary detection. Unlike previous
                    fully-automatic
                    methods, this technique allows for human intervention to refine the model's predictions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet7">
            <div class="start-time-icon" title="Play from here">
                03:52
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14508" target="_blank">
                        @arXiv 2408.14508
                    </a>
                    <span class="tweet-title">
                        AI for Science: Solving the "Problem Problem"
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Harvard University
                    </span>
                </div>
                <div class="primary-text">
                    This paper distinguishes between the "easy" and "hard" problems in AI for science. The "easy"
                    problem involves optimizing a function with pre-defined inputs, outputs, and constraints. The
                    "hard"
                    problem, however, is about formulating the problem itself, which requires conceptual
                    breakthroughs
                    and continual revision of constraints.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet8">
            <div class="start-time-icon" title="Play from here">
                04:16
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15221" target="_blank">
                        @arXiv 2408.15221
                    </a>
                    <span class="tweet-title">
                        AI Defenses: Human Jailbreaks Break the Code!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Scale AI, UC Berkeley
                    </span>
                </div>
                <div class="primary-text">
                    This research explores the effectiveness of human-generated multi-turn jailbreaks against LLM
                    defenses, a threat model that has been largely overlooked in previous studies.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet9">
            <div class="start-time-icon" title="Play from here">
                04:41
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14690" target="_blank">
                        @arXiv 2408.14690
                    </a>
                    <span class="tweet-title">
                        LLMs on a Diet: Training-Free Sparsity Makes Models Slim and
                        Speedy!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        MIT
                    </span>
                </div>
                <div class="primary-text">
                    This paper introduces TEAL, a training-free method for activation sparsity in large language
                    models
                    (LLMs). Unlike previous methods that require extensive retraining or are limited to older models
                    with ReLU activations, TEAL applies magnitude-based pruning to hidden states throughout the
                    entire
                    model, achieving significant sparsity without sacrificing performance.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet10">
            <div class="start-time-icon" title="Play from here">
                05:00
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15237" target="_blank">
                        @arXiv 2408.15237
                    </a>
                    <span class="tweet-title">
                        Llama-Sized Language Models, Mamba-Sized Speed!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Cornell University, University of Geneva, TogetherAI...
                    </span>
                </div>
                <div class="primary-text">
                    This research explores distilling large Transformer models into linear RNNs, specifically the
                    Mamba
                    architecture. Unlike previous work that focused on training linear RNNs from scratch, this paper
                    leverages the pre-trained weights of Transformers to initialize the Mamba model, leading to
                    faster
                    inference speeds while maintaining performance.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet11">
            <div class="start-time-icon" title="Play from here">
                05:25
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15240" target="_blank">
                        @arXiv 2408.15240
                    </a>
                    <span class="tweet-title">
                        LLMs Get a Brain: Next-Token Prediction Makes Verifiers Smarter
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Toronto, Google
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes training verifiers using the next-token prediction objective, which is
                    commonly used for pre-training and fine-tuning LLMs. This approach, called GenRM, leverages the
                    text
                    generation capabilities of LLMs, unlike traditional discriminative verifiers.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet12">
            <div class="start-time-icon" title="Play from here">
                05:55
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14575" target="_blank">
                        @arXiv 2408.14575
                    </a>
                    <span class="tweet-title">
                        LLMs Debate Their Way to Better Decisions: A Duel of Entropy for Smarter
                        AI
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Stanford University
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces EVINCE, a framework that uses conditional statistics and information
                    theory
                    to quantify and moderate adversarial dialogues between LLMs. Unlike previous work that focused
                    on
                    improving accuracy through redundancy, EVINCE aims to facilitate information discovery, bias
                    mitigation, and decision-making that requires both breadth and depth of information.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet13">
            <div class="start-time-icon" title="Play from here">
                06:20
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14789" target="_blank">
                        @arXiv 2408.14789
                    </a>
                    <span class="tweet-title">
                        Surgical Instruments: No Labels, No Problem! Graph Clustering to the
                        Rescue!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Sydney, Harvard University
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes an unsupervised method for surgical instrument segmentation (SIS) that
                    reframes the task as a graph partitioning problem. Unlike previous methods that rely on
                    pseudo-labels, this approach leverages a self-supervised pre-trained model to extract high-level
                    features and then applies graph clustering techniques to segment the image.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet14">
            <div class="start-time-icon" title="Play from here">
                06:50
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14732" target="_blank">
                        @arXiv 2408.14732
                    </a>
                    <span class="tweet-title">
                        Octree-Fusion: 3D Shape Generation Gets a Speedy Makeover!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Peking University, Tsinghua University, VAST
                    </span>
                </div>
                <div class="primary-text">
                    This paper introduces OctFusion, a 3D shape generation method that uses an octree-based latent
                    representation and a unified multi-scale diffusion model. Unlike previous methods that rely on
                    cascaded training schemes, OctFusion trains a single U-Net for all octree levels, leading to
                    more
                    efficient training and generation.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet15">
            <div class="start-time-icon" title="Play from here">
                07:09
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15165" target="_blank">
                        @arXiv 2408.15165
                    </a>
                    <span class="tweet-title">
                        Ewald Summation Gets a Machine Learning Makeover: Long-Range Interactions
                        Get a Boost!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        UC Berkeley
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces a new method called Latent Ewald Summation (LES) to account for
                    long-range
                    interactions in machine learning interatomic potentials (MLIPs). Unlike previous methods, LES
                    doesn't rely on learning partial charges or using charge equilibration schemes.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet16">
            <div class="start-time-icon" title="Play from here">
                07:33
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14972" target="_blank">
                        @arXiv 2408.14972
                    </a>
                    <span class="tweet-title">
                        Predicting the Future of AI Teams: A Plug-and-Play Framework for
                        Multi-Agent Systems
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Hong Kong University of Science and Technology, Tsinghua
                        University
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces AgentMonitor, a framework that predicts the performance of multi-agent
                    systems (MAS) by analyzing their internal workings. Unlike previous work that focuses on scaling
                    laws for single LLMs, AgentMonitor explores the predictability of MAS configurations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet17">
            <div class="start-time-icon" title="Play from here">
                07:56
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14778" target="_blank">
                        @arXiv 2408.14778
                    </a>
                    <span class="tweet-title">
                        CFR Gets a Speed Boost: GPU-Powered Game Theory Takes the Lead!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Toronto
                    </span>
                </div>
                <div class="primary-text">
                    This research focuses on making the Counterfactual Regret Minimization (CFR) algorithm more
                    computationally efficient by implementing it as a series of matrix operations, making it highly
                    parallelizable for a GPU. Previous work has primarily focused on improving CFR's convergence
                    speed.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet18">
            <div class="start-time-icon" title="Play from here">
                08:18
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14837" target="_blank">
                        @arXiv 2408.14837
                    </a>
                    <span class="tweet-title">
                        DOOM, But Make It Neural: Researchers Build a Game Engine Powered by
                        AI
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Google Research, Tel Aviv University, Google DeepMind
                    </span>
                </div>
                <div class="primary-text">
                    This research presents GameNGen, a game engine powered by a diffusion model that can simulate
                    the
                    game DOOM in real-time at high quality. Unlike previous work, GameNGen achieves this by
                    conditioning
                    the model on a stream of input actions, enabling stable auto-regressive generation over long
                    trajectories.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet19">
            <div class="start-time-icon" title="Play from here">
                08:35
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14899" target="_blank">
                        @arXiv 2408.14899
                    </a>
                    <span class="tweet-title">
                        MeshUp: Mixing and Matching 3D Concepts with a Pinch of Diffusion
                        Magic!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Chicago, University of Montreal, Adobe Research
                    </span>
                </div>
                <div class="primary-text">
                    MeshUp introduces a novel approach to 3D mesh deformation by blending multiple target concepts
                    using
                    a technique called Blended Score Distillation (BSD). This method differs from previous work by
                    allowing users to mix and match concepts, control their strength, and even localize their
                    expression
                    on the mesh.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet20">
            <div class="start-time-icon" title="Play from here">
                08:56
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15173" target="_blank">
                        @arXiv 2408.15173
                    </a>
                    <span class="tweet-title">
                        Symmetry is for the Birds: New Research Makes Multi-Agent Learning More
                        Efficient
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        ETH Zurich
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces a new class of games called "Œ±,Œ≤-symmetric games" that allows for
                    approximate symmetry in multi-agent reinforcement learning (MARL) problems. This is different
                    from
                    previous work on mean-field games (MFG) which assumed perfect symmetry between agents.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet21">
            <div class="start-time-icon" title="Play from here">
                09:23
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15126" target="_blank">
                        @arXiv 2408.15126
                    </a>
                    <span class="tweet-title">
                        Force-Guided Bridge Matching: A New Way to Simulate Peptides, One Force
                        Field at a Time!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Tsinghua University
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces a novel framework called Force-guided Bridge Matching (FBM) for
                    full-atom
                    time-coarsened dynamics. Unlike previous methods that rely on resampling techniques, FBM
                    directly
                    targets the Boltzmann-like distribution by incorporating an intermediate force field into the
                    bridge
                    matching framework.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet22">
            <div class="start-time-icon" title="Play from here">
                09:50
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15079" target="_blank">
                        @arXiv 2408.15079
                    </a>
                    <span class="tweet-title">
                        LLM Training: From Secret Sauce to Open Source Recipe!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Baichuan Inc., Renmin University of China, Peking University
                    </span>
                </div>
                <div class="primary-text">
                    This research focuses on the data processing pipeline used to train a large language model
                    (LLM),
                    specifically emphasizing the importance of data collection and deduplication over meticulous
                    data
                    selection. The authors argue that this approach can achieve comparable performance with less
                    effort
                    and cost.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet23">
            <div class="start-time-icon" title="Play from here">
                10:19
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15239" target="_blank">
                        @arXiv 2408.15239
                    </a>
                    <span class="tweet-title">
                        Turning Back Time: How to Make Videos Move Backwards with a Simple
                        Trick!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Washington, Google DeepMind, UC Berkeley
                    </span>
                </div>
                <div class="primary-text">
                    This paper proposes a method for adapting pre-trained image-to-video models for keyframe
                    interpolation. Unlike previous methods that require training specialized models from scratch,
                    this
                    approach leverages existing models by fine-tuning a specific component, the temporal
                    self-attention
                    layers, to generate backward motion.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet24">
            <div class="start-time-icon" title="Play from here">
                10:42
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14505" target="_blank">
                        @arXiv 2408.14505
                    </a>
                    <span class="tweet-title">
                        Language Models Learn to Forecast the Future (and It's Not Just About
                        Words)
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Hong Kong University of Science and Technology, University of
                        Oxford
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes a new method for reprogramming pre-trained language models (PLMs) to
                    handle
                    spatio-temporal forecasting tasks. Unlike previous approaches that directly map time series data
                    to
                    a compressed vocabulary, this method decouples the spatio-temporal dynamics in the frequency
                    domain,
                    allowing for better alignment with the PLM text space.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet25">
            <div class="start-time-icon" title="Play from here">
                11:13
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14608" target="_blank">
                        @arXiv 2408.14608
                    </a>
                    <span class="tweet-title">
                        Flow Matching Goes Meta: Learning Dynamics on the Wasserstein
                        Manifold
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Toronto
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes Meta Flow Matching (MFM), a method that generalizes flow-based models to
                    predict the evolution of populations across different initial distributions. Unlike previous
                    methods, MFM learns a vector field on the Wasserstein manifold, which allows it to model the
                    interactions between particles in a population.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet26">
            <div class="start-time-icon" title="Play from here">
                12:00
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14753" target="_blank">
                        @arXiv 2408.14753
                    </a>
                    <span class="tweet-title">
                        Factory Sounds: How AI Detects Machine Problems Without Sharing
                        Secrets
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Tsinghua University
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes a new framework called CoopASD for detecting anomalies in machine sounds
                    in a
                    decentralized setting. Unlike previous work that relied on centralized data aggregation, CoopASD
                    allows factories to train a unified model without sharing their sensitive data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet27">
            <div class="start-time-icon" title="Play from here">
                12:25
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15235" target="_blank">
                        @arXiv 2408.15235
                    </a>
                    <span class="tweet-title">
                        Learning-Based Multi-View Stereo: A Deep Dive into 3D
                        Reconstruction
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        ETH Zurich, University of Tokyo, University of Southern
                        California...
                    </span>
                </div>
                <div class="primary-text">
                    This research provides a comprehensive survey of learning-based Multi-View Stereo (MVS) methods,
                    categorizing them into depth map-based, voxel-based, NeRF-based, 3D Gaussian Splatting-based,
                    and
                    large feed-forward methods. It focuses on depth map-based methods, which are the main family of
                    learning-based MVS due to their conciseness, flexibility, and scalability.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet28">
            <div class="start-time-icon" title="Play from here">
                13:00
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14717" target="_blank">
                        @arXiv 2408.14717
                    </a>
                    <span class="tweet-title">
                        Text2SQL is So 2023: TAG Brings AI and Databases Together!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        UC Berkeley, Stanford University
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces Table-Augmented Generation (TAG), a new paradigm for answering natural
                    language questions over databases. Unlike previous methods like Text2SQL and RAG, TAG leverages
                    the
                    strengths of both language models (LMs) and database systems, allowing for more complex
                    reasoning
                    and knowledge-based queries.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet29">
            <div class="start-time-icon" title="Play from here">
                13:24
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15176" target="_blank">
                        @arXiv 2408.15176
                    </a>
                    <span class="tweet-title">
                        Pre-Trained Music Models: From Melody to Multi-Track Magic!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        National University of Singapore, NYU
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes a unified framework for fine-tuning pre-trained music language models for
                    various multi-track music arrangement tasks, including band arrangement, piano reduction, drum
                    arrangement, and voice separation. This approach differs from previous work by utilizing a
                    single
                    model for multiple tasks, rather than developing separate models for each task.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet30">
            <div class="start-time-icon" title="Play from here">
                13:58
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14640" target="_blank">
                        @arXiv 2408.14640
                    </a>
                    <span class="tweet-title">
                        AI's Got Moves: How Adaptation Rate Makes Humans Dance to Its Tune
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Washington
                    </span>
                </div>
                <div class="primary-text">
                    This research investigates how the adaptation rate of an AI's learning algorithm affects human
                    behavior in a continuous game setting. Unlike previous work focusing on AI output displays, this
                    study explores the impact of different feedback information provided to humans about their own
                    objectives.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet31">
            <div class="start-time-icon" title="Play from here">
                14:22
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14672" target="_blank">
                        @arXiv 2408.14672
                    </a>
                    <span class="tweet-title">
                        Semantic Segmentation Gets a Reality Check: New Method Enforces Physical
                        Constraints
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Bologna, ETH Zurich
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces a novel method called Physically Feasible Semantic Segmentation
                    (PhyFea)
                    that incorporates physical constraints into the training process of semantic segmentation
                    models.
                    Unlike previous approaches that rely solely on data-driven optimization, PhyFea leverages
                    knowledge
                    about the physical world to improve segmentation accuracy.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet32">
            <div class="start-time-icon" title="Play from here">
                14:43
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15096" target="_blank">
                        @arXiv 2408.15096
                    </a>
                    <span class="tweet-title">
                        Fairness Without the Fuss: A New Way to Debias Models with Minimal
                        Changes
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        AXA, Sorbonne Universit√©, Stanford University...
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces a novel post-processing algorithm that minimizes changes to model
                    predictions while ensuring fairness. Unlike previous methods that often require the sensitive
                    attribute at test time or are limited to specific model types, this approach is model-agnostic
                    and
                    doesn't need the sensitive attribute during inference.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet33">
            <div class="start-time-icon" title="Play from here">
                15:13
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14997" target="_blank">
                        @arXiv 2408.14997
                    </a>
                    <span class="tweet-title">
                        Robots Can Now See Through Your Hands (and Grab Your Glass of
                        Wine)!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Tsinghua University
                    </span>
                </div>
                <div class="primary-text">
                    This research focuses on restoring the depth information of transparent objects held in a
                    human's
                    hand, a challenge not addressed by previous work. It introduces a hand-aware depth restoration
                    method that leverages hand pose information to improve accuracy and generalization.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet34">
            <div class="start-time-icon" title="Play from here">
                15:41
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14909" target="_blank">
                        @arXiv 2408.14909
                    </a>
                    <span class="tweet-title">
                        SpikingSSMs: Making Neural Networks Think Like Brains, One Spike at a
                        Time!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Southern University of Science and Technology, Peking University,
                        Huawei...
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces SpikingSSMs, a new type of neural network that combines the strengths
                    of
                    state space models (SSMs) for long sequence learning with the energy efficiency of spiking
                    neural
                    networks (SNNs). Unlike previous work that either focused on SSMs or SNNs, this paper integrates
                    both, creating a network that can learn long sequences while using less energy.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet35">
            <div class="start-time-icon" title="Play from here">
                16:18
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14562" target="_blank">
                        @arXiv 2408.14562
                    </a>
                    <span class="tweet-title">
                        Camouflaged Objects: A Deep Dive into the Latest Research
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Sun Yat-sen University, Tsinghua University, Duke University
                    </span>
                </div>
                <div class="primary-text">
                    This research paper provides a comprehensive survey of camouflaged object detection (COD)
                    methods,
                    including both traditional and deep learning approaches. It goes beyond previous surveys by
                    covering
                    recent advancements made in the field since mid-2023, exploring novel tasks like referring-based
                    COD
                    and collaborative COD, and benchmarking deep learning models in both image and video domains.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet36">
            <div class="start-time-icon" title="Play from here">
                16:43
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15065" target="_blank">
                        @arXiv 2408.15065
                    </a>
                    <span class="tweet-title">
                        Data Balancing: Not Just for Avoiding Collapse, It's a Variance-Reducing
                        Machine!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Washington
                    </span>
                </div>
                <div class="primary-text">
                    This paper analyzes the variance reduction effect of data balancing algorithms, which are
                    commonly
                    used in self-supervised learning to prevent representation collapse. It provides non-asymptotic
                    bounds on the mean squared error of balanced estimators and relates them to the spectral decay
                    of
                    Markov operators.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet37">
            <div class="start-time-icon" title="Play from here">
                17:05
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14802" target="_blank">
                        @arXiv 2408.14802
                    </a>
                    <span class="tweet-title">
                        RAW-Adapter: Turning Camera RAW into Computer Vision Gold!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Tokyo
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces RAW-Adapter, a novel framework that adapts pre-trained visual models to
                    camera RAW images. Unlike previous methods that focused on integrating image signal processors
                    (ISPs) with backend networks, RAW-Adapter leverages adapters at both the input and model levels
                    to
                    bridge the gap between RAW data and sRGB models.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet38">
            <div class="start-time-icon" title="Play from here">
                17:33
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15242" target="_blank">
                        @arXiv 2408.15242
                    </a>
                    <span class="tweet-title">
                        Drones to the Rescue: How Aerial Images Are Making Road Scenes Look *Way*
                        Better
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Nanyang Technological University, Tsinghua University, Beijing
                        Institute of Technology
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces a new training method for 3D Gaussian Splatting (3D-GS), a technique
                    used
                    for creating realistic 3D scenes. The key difference is that it uses uncertainty maps from
                    ground-level images to guide the training process for aerial images, ensuring that the aerial
                    data
                    contributes effectively to the scene reconstruction.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet39">
            <div class="start-time-icon" title="Play from here">
                18:06
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14812" target="_blank">
                        @arXiv 2408.14812
                    </a>
                    <span class="tweet-title">
                        Vision-Language Models Get a Knowledge Boost: LLMs Help Them See the Big
                        Picture!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Tongji University, Microsoft, Xidian University
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes a novel approach called Hierarchical Prompt Tuning (HPT) that leverages
                    large
                    language models (LLMs) to generate structured knowledge representations from descriptions,
                    enhancing
                    the effectiveness of vision-language models (VLMs). Unlike previous methods that rely solely on
                    unstructured descriptions, HPT incorporates both structured and conventional linguistic
                    knowledge,
                    enabling VLMs to handle more complex and long-term relationships.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet40">
            <div class="start-time-icon" title="Play from here">
                18:32
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14520" target="_blank">
                        @arXiv 2408.14520
                    </a>
                    <span class="tweet-title">
                        Graph Prompt Learning: A Guide to Prompting Your Way to Better Graph
                        Data!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Chinese Academy of Sciences, Peking University, Hong Kong University of
                        Science and Technology...
                    </span>
                </div>
                <div class="primary-text">
                    This research focuses on applying prompt learning to graph-structured data, a relatively
                    unexplored
                    area. It categorizes existing methods and proposes a new taxonomy for understanding graph prompt
                    learning.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet41">
            <div class="start-time-icon" title="Play from here">
                18:59
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14498" target="_blank">
                        @arXiv 2408.14498
                    </a>
                    <span class="tweet-title">
                        Anomaly Detection: When One Prototype Just Isn't Enough!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Peking University
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes a new anomaly detection framework that uses multiple normal prototypes
                    instead of a single one, making it more accurate when dealing with complex data. It also
                    includes a
                    mechanism to reduce the impact of anomalies in unlabeled data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet42">
            <div class="start-time-icon" title="Play from here">
                19:19
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15232" target="_blank">
                        @arXiv 2408.15232
                    </a>
                    <span class="tweet-title">
                        Learning by Listening: How AI Agents Can Help Us Discover the Unknown
                        Unknowns
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Stanford University, Yale University
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces Co-STORM, a system that uses multiple language models (LMs) to simulate
                    a
                    collaborative discourse, allowing users to learn by observing and participating in conversations
                    with AI agents. This differs from previous work by focusing on the discovery of "unknown
                    unknowns" ‚Äì
                    information users weren't aware they needed ‚Äì rather than simply answering known questions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet43">
            <div class="start-time-icon" title="Play from here">
                19:39
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14830" target="_blank">
                        @arXiv 2408.14830
                    </a>
                    <span class="tweet-title">
                        Privacy Policies: From Wordy to Logic in a Snap!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Wisconsin-Madison, Langroid
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes PolicyLR, a logic-based representation for privacy policies, which
                    differs
                    from previous work by offering a comprehensive machine-readable format that can be used for
                    multiple
                    downstream tasks, such as compliance and consistency analysis.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet44">
            <div class="start-time-icon" title="Play from here">
                20:06
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14623" target="_blank">
                        @arXiv 2408.14623
                    </a>
                    <span class="tweet-title">
                        Stop the Confabulations! New Tool Helps Scientists Write Ethically with
                        AI
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        ETH Zurich, University of Zurich
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces MODOC, a modular user interface that integrates text retrieval and
                    generation functions for scientific writing. Unlike previous systems, MODOC allows users to
                    define
                    flexible workflows for repetitive writing tasks, helping them shift their attention from
                    distractions to the contents of their science.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet45">
            <div class="start-time-icon" title="Play from here">
                20:34
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14817" target="_blank">
                        @arXiv 2408.14817
                    </a>
                    <span class="tweet-title">
                        Deep Learning vs. Tabular Data: Who Wins This Round?
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Bar Ilan University, Ariel University, UCL
                    </span>
                </div>
                <div class="primary-text">
                    This research distinguishes itself by conducting a comprehensive benchmark of 20 machine and
                    deep
                    learning models across 111 diverse tabular datasets, including both regression and
                    classification
                    tasks. This allows for a more thorough analysis of the conditions under which deep learning
                    models
                    excel compared to traditional methods.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet46">
            <div class="start-time-icon" title="Play from here">
                20:58
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15076" target="_blank">
                        @arXiv 2408.15076
                    </a>
                    <span class="tweet-title">
                        MiWaves: A Personalized App to Help You Ditch the Weed (But Not the
                        Fun!)
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Harvard University, University of Wisconsin-Madison, University of
                        Michigan
                    </span>
                </div>
                <div class="primary-text">
                    This research introduces MiWaves, a reinforcement learning algorithm designed to personalize
                    intervention prompts for reducing cannabis use among emerging adults. Unlike previous work,
                    MiWaves
                    leverages domain expertise and prior data to tailor the likelihood of delivering intervention
                    messages.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet47">
            <div class="start-time-icon" title="Play from here">
                21:19
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14772" target="_blank">
                        @arXiv 2408.14772
                    </a>
                    <span class="tweet-title">
                        AI Needs a Translator: English Can't Be the Only Language of
                        Research
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Stanford University
                    </span>
                </div>
                <div class="primary-text">
                    This research focuses on the linguistic exclusion in the AI research community, arguing that the
                    dominance of English as the sole publication language hinders diversity and inclusivity. It goes
                    beyond previous work by analyzing the impact of this linguistic barrier on researchers from
                    non-English speaking backgrounds.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet48">
            <div class="start-time-icon" title="Play from here">
                21:42
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15099" target="_blank">
                        @arXiv 2408.15099
                    </a>
                    <span class="tweet-title">
                        Stop the Regret Machine: A New Way to Train Robots for Real-World
                        Navigation
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Oxford
                    </span>
                </div>
                <div class="primary-text">
                    This research investigates the effectiveness of Unsupervised Environment Design (UED) methods
                    for
                    training robots in a real-world navigation task. The study finds that current UED methods
                    struggle
                    to outperform a simple baseline approach, Domain Randomisation (DR), and proposes a new method,
                    Sampling For Learnability (SFL), that directly targets environments where the agent can improve
                    its
                    performance.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet49">
            <div class="start-time-icon" title="Play from here">
                22:10
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14762" target="_blank">
                        @arXiv 2408.14762
                    </a>
                    <span class="tweet-title">
                        Predicting Commutes: A City's Hierarchy of Flows
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        University of Tokyo
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes a hierarchical urban network model (HiUrNet) that learns representations
                    of
                    urban areas at multiple scales, considering both static and dynamic relationships between cities
                    and
                    their constituent grids. Unlike previous studies that focused on single-level urban units,
                    HiUrNet
                    leverages the hierarchical structure of cities to predict commuting flows between different
                    levels,
                    such as city-to-grid and grid-to-grid.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet50">
            <div class="start-time-icon" title="Play from here">
                22:43
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14685" target="_blank">
                        @arXiv 2408.14685
                    </a>
                    <span class="tweet-title">
                        Reinforcement Learning for Aerodynamics: A Model-Based Approach to Tame
                        Turbulent Flows
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        UC Los Angeles, Caltech
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes a model-based reinforcement learning (MBRL) approach for controlling
                    unsteady
                    aerodynamic flows. Unlike typical model-free RL methods, which require extensive interactions
                    with
                    the flow environment, this approach utilizes a reduced-order model as a surrogate for the full
                    environment, significantly reducing training costs.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet51">
            <div class="start-time-icon" title="Play from here">
                23:18
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.15116" target="_blank">
                        @arXiv 2408.15116
                    </a>
                    <span class="tweet-title">
                        AI's Got a Plan, But Will It Stick? New Research Explores the Stability of
                        AI Alignment
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        OpenAI
                    </span>
                </div>
                <div class="primary-text">
                    This paper introduces the "Counterfactual Priority Change" (CPC) destabilization threat model,
                    which
                    explores how AI's ability to dynamically adjust its plans could lead to misalignment. Unlike
                    previous work focusing on reflective stability, this research investigates a specific pathway
                    for
                    alignment failures in future LLMs.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet52">
            <div class="start-time-icon" title="Play from here">
                23:42
            </div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2408.14831" target="_blank">
                        @arXiv 2408.14831
                    </a>
                    <span class="tweet-title">
                        Self-Driving Cars Learn to Drive... With a Little Help From Their
                        Friends!
                    </span>
                </div>
                <div class="institute-line">
                    <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg" />
                    <span class="institute-text">
                        Jiangnan University, Tsinghua University, Shanghai Jiao Tong
                        University...
                    </span>
                </div>
                <div class="primary-text">
                    This research proposes a new method for Federated Self-Supervised Learning (SSL) in vehicle edge
                    computing. Unlike previous work, it introduces a task offloading mechanism where vehicles can
                    offload partial training tasks to a Road Side Unit (RSU) to improve efficiency.
                </div>
            </div>
        </div>


        <div
            style="padding: 50px 0; text-align: center; margin: 5px 0; font-weight: 300; font-size: 10px; color: #000000;">
            Opening music
            from <a href="https://ikson.com" target="_blank" style="color: black; text-decoration: none;">TELL
                YOUR STORY by ikson</a></div>
        <div style="height: 50px;"></div>
    </div>

    <footer class="player-footer">
        <div class="player-detail-hidden-on-small-screen">
            <div id="audio-title" class="tweet-title-small">Hit play and learn on the go!</div>
            <div style="height: 2px;"></div>
            <div id="audio-institutes" class="institute-text-small"></div>
        </div>
        <div class="control-panel">
            <div class="control-horizontal">
                <div id="playSpeedButton" title="Adjust speed">
                    <div id="selectedSpeed">1&times;</div>
                    <div class="speedMenuItems">
                        <div data-value="0.6">Speed 0.6&times;</div>
                        <div data-value="0.8">Speed 0.8&times;</div>
                        <div data-value="1" class="selected">Speed 1&times;</div>
                        <div data-value="1.2">Speed 1.2&times;</div>
                        <div data-value="1.4">Speed 1.4&times;</div>
                        <div data-value="1.6">Speed 1.6&times;</div>
                    </div>
                    <select id="speedOptionsHidden">
                        <option value="0.6">0.6&times;</option>
                        <option value="0.8">0.8&times;</option>
                        <option value="1" selected>1&times;</option>
                        <option value="1.2">1.2&times;</option>
                        <option value="1.4">1.4&times;</option>
                        <option value="1.6">1.6&times;</option>
                    </select>
                </div>
                <div id="playLastButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(false)" title="Play last" disabled>
                        <img src="assets/buttonLastEpisode.svg" alt="Last" style="width: 12px;">
                    </button>
                </div>
                <button class="controllerButton" onclick="scrollToCurrentTweet()" title="Scoll to the current episode">
                    <img id="locateImage" src="assets/buttonTarget.svg" alt="Locate">
                </button>
                <button class="controllerButton" onclick="togglePlayPause()" title="Play/Pause">
                    <img id="playPauseImage" src="assets/buttonPlay.svg" alt="Play">
                </button>
                <div id="playNextButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(true)" title="Play next" disabled>
                        <img src="assets/buttonNextEpisode.svg" alt="Next" style="width: 12px;">
                    </button>
                </div>
            </div>
            <div class="control-horizontal">
                <div id="progressTime">0:00</div>
                <div id="progressContainer" onclick="seek(event)">
                    <div id="progressBar"></div>
                    <div id="progressCircle" draggable="true"></div>
                </div>
                <audio id="audioPlayer"
                    src="https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202408281732_audio.mp3"></audio>
                <div id="progressTime"><span id="audioDuration">Loading...</span></div>
            </div>
        </div>
    </footer>
    <div id="privacyModal" class="modal"></div>
    <script src="script.js"></script>
    <script src="calendar.js"></script>
    <script>
        fetch('https://ribbitribbit.co/header.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('headerId').innerHTML = data;
            })
            .catch(error => console.error('Error loading header.html:', error));
        fetch('https://ribbitribbit.co/terms.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('privacyModal').innerHTML = data;
            })
            .catch(error => console.error('Error loading terms.html:', error));
    </script>
</body>

</html>
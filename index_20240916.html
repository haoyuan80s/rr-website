<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ribbit Ribbit - Discover research the fun way!</title>
    <meta name="description"
        content="Discover top ArXiv papers in AI and machine learning daily with our fresh picks. Browse easily through tweet-sized summaries or listen on-the-go. Make learning engaging and accessible anytime, anywhere.">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Amatic+SC:wght@400;700&family=Dosis:wght@200..800&family=Roboto:wght@300..700&display=swap">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
    <link rel="icon" href="assets/frogFavicon.png" type="image/x-icon">
    <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>
</head>

<body>
    <div id="headerId" class="header"></div>
    <div class="container">
        <div id="topblock">
            <div style="height: 150px;"></div>
            <div class="page-title">DISCOVER RESEARCH THE FUN WAY
            </div>
            <div style="display: flex; flex-direction: column; justify-content: flex-start; align-items: flex-start;">
                <div class="institute-text" style="padding-top: 3px; line-height: 1.2;">
                    Fresh Picks:
                    <span class="highlightNumber" style="font-size: 28px;">43</span> out of <span
                        class="highlightNumber">236</span> AI papers
                </div>
                <div class="institute-text" style="line-height: 1.2;">that were just released in arXiv on</div>
                <div id="data-default-date" data-date="2024-09-16"></div>
                <input type="text" id="selectedDate" style="text-decoration: underline;" />
            </div>
            <div style=" height: 80px;">
            </div>
        </div>


        <div class="tweet" id="tweet0">
            <div class="start-time-icon" title="Play from here">00:58</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09013" target="_blank">@arXiv
                        2409.09013</a>
                    <span class="tweet-title">AI Agents: Truthful or Just Trying to Sell You a Lemon?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU</span>
                </div>
                <div class="primary-text">
                    This research explores the trade-off between utility and truthfulness in LLMs, specifically in
                    multi-turn interactive settings. Unlike previous work focusing on single-turn interactions or
                    hallucinations, this study examines how LLMs navigate scenarios where achieving a goal might
                    require
                    them to lie.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet1">
            <div class="start-time-icon" title="Play from here">01:17</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08744" target="_blank">@arXiv
                        2409.08744</a>
                    <span class="tweet-title">Foundation Models for Earth Observation: A Global Generalizability
                        Gauntlet!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Antioquia, University of Oxford, University of
                        Luxembourg</span>
                </div>
                <div class="primary-text">
                    This research focuses on the generalizability and uncertainty of Foundation Models (FMs) for
                    Earth
                    Observation (EO) tasks, specifically examining how well models trained on one region perform in
                    others. It goes beyond previous work by conducting a large-scale ablation study with over
                    500,000
                    linear regression models, testing various FMs, sampling methods, and downstream tasks across
                    multiple regions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet2">
            <div class="start-time-icon" title="Play from here">01:42</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08551" target="_blank">@arXiv
                        2409.08551</a>
                    <span class="tweet-title">Diffusion Models Get a MCMC Makeover: Solving Inverse Problems with
                        More
                        Finesse</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">UC Los Angeles, Yale University, Google</span>
                </div>
                <div class="primary-text">
                    This paper proposes a new algorithm called Diffusion Posterior MCMC (DPMC) that uses annealed
                    MCMC
                    sampling to improve the accuracy of posterior distribution approximation in solving inverse
                    problems. Unlike previous approaches that rely on a single MCMC step at each noise level, DPMC
                    iterates over multiple MCMC steps at each noise level, leading to more accurate results.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet3">
            <div class="start-time-icon" title="Play from here">02:08</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08466" target="_blank">@arXiv
                        2409.08466</a>
                    <span class="tweet-title">Stop Saying "It's About Sports" - New AI Explains Data with
                        Words!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">UC Berkeley</span>
                </div>
                <div class="primary-text">
                    This research introduces a new family of statistical models that are parameterized by natural
                    language predicates, allowing for direct interpretability of model parameters. Unlike previous
                    work
                    that relies on high-dimensional parameters, this approach uses predicates to extract 0/1
                    features,
                    making the model's decisions more transparent.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet4">
            <div class="start-time-icon" title="Play from here">02:28</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08308" target="_blank">@arXiv
                        2409.08308</a>
                    <span class="tweet-title">AIoT's Got Talent: Teaching Edge Models New Tricks Without Sharing
                        Your
                        Secrets!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">SONY China Research Laboratories, Nanyang Technological
                        University</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel framework called "DiReDi" that updates edge-AI models in AIoT
                    applications by transferring knowledge rather than raw data, addressing privacy concerns.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet5">
            <div class="start-time-icon" title="Play from here">02:53</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08947" target="_blank">@arXiv
                        2409.08947</a>
                    <span class="tweet-title">Relighting Radiance Fields: Diffusion Models Make It Rain
                        (Light)!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Inria, Université Côte d’Azur, Université Laval...</span>
                </div>
                <div class="primary-text">
                    This research introduces a method for creating relightable radiance fields using
                    single-illumination
                    multi-view datasets by leveraging priors extracted from 2D image diffusion models. This approach
                    differs from previous work by utilizing a diffusion model to augment a single-illumination
                    dataset
                    into a multi-illumination dataset, enabling realistic relighting of full scenes.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet6">
            <div class="start-time-icon" title="Play from here">03:20</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08691" target="_blank">@arXiv
                        2409.08691</a>
                    <span class="tweet-title">3D Medical Images: From Pixels to Poetry, an Autoregressive
                        Tale!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Deepwise AI Lab, Peking University, The University of Hong
                        Kong</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel self-supervised learning method for 3D medical image
                    representation. Unlike previous methods that treat images as wholes, this approach transforms
                    images
                    into sequences of patches, capturing spatial, contrast, and semantic relationships.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet7">
            <div class="start-time-icon" title="Play from here">03:44</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08711" target="_blank">@arXiv
                        2409.08711</a>
                    <span class="tweet-title">TTS Goes Wild: Training Speech Synthesis with Real-World Data</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Carnegie Mellon University, Shanghai Jiao Tong University,
                        Meta...</span>
                </div>
                <div class="primary-text">
                    This research introduces a new dataset, TITW, specifically designed for training text-to-speech
                    (TTS) systems using speech data collected in uncontrolled environments, unlike previous datasets
                    that primarily used studio-quality recordings.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet8">
            <div class="start-time-icon" title="Play from here">04:08</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09032" target="_blank">@arXiv
                        2409.09032</a>
                    <span class="tweet-title">AI Unknots Knotty Problems: A Machine Learning Approach to Unknotting
                        Numbers</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Oxford, University of Cambridge, University of
                        Warwick...</span>
                </div>
                <div class="primary-text">
                    This research introduces a reinforcement learning agent that efficiently finds minimal
                    unknotting
                    sequences for knot diagrams, surpassing previous methods in terms of speed and accuracy. The
                    agent
                    utilizes the Jones polynomial as a key feature, suggesting its potential for revealing
                    unobserved
                    information about unknotting numbers.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet9">
            <div class="start-time-icon" title="Play from here">04:34</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08667" target="_blank">@arXiv
                        2409.08667</a>
                    <span class="tweet-title">HSI Super-Resolution Gets a Test-Time Tune-Up!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">ETH Zurich, Huawei Z¨urich Research Center, KU Leuven...</span>
                </div>
                <div class="primary-text">
                    This research introduces a test-time training method for hyperspectral image super-resolution
                    (HSI
                    SR), which adapts a pre-trained model to new data during testing without requiring additional
                    training data from the source domain. This differs from previous work that typically relies on
                    large
                    datasets for training.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet10">
            <div class="start-time-icon" title="Play from here">04:59</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08283" target="_blank">@arXiv
                        2409.08283</a>
                    <span class="tweet-title">Activation Functions: Learning to Learn, One Series at a Time!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Southwest University, Yibin Academy of Southwest University,
                        Sericulture research institute of Sichuan Academy of Agricultural Sciences...</span>
                </div>
                <div class="primary-text">
                    This research proposes a new activation function called LSLU (Learnable Series Linear Units)
                    that
                    uses learnable parameters to control the activation function's oscillation amplitude and slope.
                    This
                    differs from previous work by introducing a series-based approach to dynamically adjust the
                    activation function during training.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet11">
            <div class="start-time-icon" title="Play from here">05:21</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08687" target="_blank">@arXiv
                        2409.08687</a>
                    <span class="tweet-title">Stop Simulating, Start Editing: A New Way to Train Robots with
                        Real-World
                        Data</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel approach to cross-domain policy adaptation by directly editing
                    trajectories from source domains to align them with the target domain's distribution. This
                    differs
                    from previous methods that focus on learning domain-specific models or representations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet12">
            <div class="start-time-icon" title="Play from here">05:40</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08788" target="_blank">@arXiv
                        2409.08788</a>
                    <span class="tweet-title">ECG Reports: From Signals to Stories with a Dash of AI!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Eindhoven University of Technology, University of Cambridge</span>
                </div>
                <div class="primary-text">
                    This research introduces a retrieval-based approach for ECG report generation and question
                    answering, which differs from previous task-specific, fully supervised learning methods. It
                    leverages self-supervised learning for the ECG encoder, enabling efficient similarity searches
                    and
                    report retrieval.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet13">
            <div class="start-time-icon" title="Play from here">06:04</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08397" target="_blank">@arXiv
                        2409.08397</a>
                    <span class="tweet-title">360° Panoramas: No More Seams, Just Seamless Scenes!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University College London</span>
                </div>
                <div class="primary-text">
                    This research introduces a training-free method for translating 360-degree panoramas based on
                    text
                    prompts. Unlike previous methods that struggle to maintain boundary continuity, this approach
                    uses a
                    technique called "seamless tiling translation" to ensure smooth transitions between the edges of
                    the
                    panorama.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet14">
            <div class="start-time-icon" title="Play from here">06:31</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08673" target="_blank">@arXiv
                        2409.08673</a>
                    <span class="tweet-title">Animal Voices, Individualized: A New Way to Tell Them Apart!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Queen Mary University of London, IMT Atlantique, CNRS...</span>
                </div>
                <div class="primary-text">
                    This research uses a hierarchical contrastive learning approach to identify individual animals
                    based
                    on their vocalizations. This differs from previous work by incorporating hierarchical
                    relationships
                    between species and taxa into the learning process, creating more robust representations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet15">
            <div class="start-time-icon" title="Play from here">07:04</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08642" target="_blank">@arXiv
                        2409.08642</a>
                    <span class="tweet-title">LLMs Learn to Plan: A Recipe for Reasoning Superpowers!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Peking University, Microsoft</span>
                </div>
                <div class="primary-text">
                    This research introduces Critical Planning Step Learning (CPL), a method that uses Monte Carlo
                    Tree
                    Search (MCTS) to explore diverse planning steps in multi-step reasoning tasks. Unlike previous
                    work
                    that focuses on improving task-specific reasoning, CPL aims to enhance the model's
                    generalization
                    capabilities across a broader range of reasoning tasks.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet16">
            <div class="start-time-icon" title="Play from here">07:35</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08434" target="_blank">@arXiv
                        2409.08434</a>
                    <span class="tweet-title">Predicting the Future: How Look-Ahead Info Makes Robots Less
                        Regretful</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU</span>
                </div>
                <div class="primary-text">
                    This research explores the use of exogenous predictions in non-stationary MDPs, unlike previous
                    work
                    that relies on past data or assumes prior knowledge.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet17">
            <div class="start-time-icon" title="Play from here">07:52</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08494" target="_blank">@arXiv
                        2409.08494</a>
                    <span class="tweet-title">Wheelchair Users Get Their Pose On: New Tech Tracks Movement with Just
                        4
                        Sensors!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU</span>
                </div>
                <div class="primary-text">
                    This research focuses on developing a sparse-IMU based pose estimation system specifically
                    designed
                    for wheelchair users. Unlike previous work that relies on dense IMU arrays or cameras, this
                    system
                    uses only four strategically placed IMUs on the user's body and wheelchair.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet18">
            <div class="start-time-icon" title="Play from here">08:16</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08597" target="_blank">@arXiv
                        2409.08597</a>
                    <span class="tweet-title">Speech Recognition Gets a Brain Boost: LLMs Learn from Speech
                        Examples!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Huawei</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel Retrieval-Augmented Generation (RAG) paradigm for LLM-based
                    Automatic
                    Speech Recognition (ASR). Unlike previous methods that rely solely on speech encoders, LA-RAG
                    leverages a fine-grained speech datastore and a speech-to-speech retrieval mechanism to enhance
                    ASR
                    accuracy.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet19">
            <div class="start-time-icon" title="Play from here">08:35</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08538" target="_blank">@arXiv
                        2409.08538</a>
                    <span class="tweet-title">Satellite Data's New Secret Agent: Privacy-Aware Split Learning for
                        GNNs</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Nanyang Technological University, Stony Brook University,
                        University of
                        Electronic Science and Technology of China...</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel framework called DTIP, which combines differential privacy and
                    graph
                    pruning within a split learning architecture specifically designed for GNNs in satellite
                    communication networks. This approach differs from previous work by addressing the unique
                    challenges
                    of data privacy, computational efficiency, and network integrity in distributed learning
                    environments, particularly in scenarios involving complex graph-structured data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet20">
            <div class="start-time-icon" title="Play from here">09:07</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08469" target="_blank">@arXiv
                        2409.08469</a>
                    <span class="tweet-title">SVGD: Particle Convergence Rates Get a Double Exponential
                        Boost!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">UC Davis, University of Chicago</span>
                </div>
                <div class="primary-text">
                    This paper introduces a novel approach to analyzing the convergence of the Stein Variational
                    Gradient Descent (SVGD) algorithm by tracking the evolution of the relative entropy of the joint
                    density of particle locations. This method provides a double exponential improvement over
                    previous
                    results in terms of convergence rates.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet21">
            <div class="start-time-icon" title="Play from here">09:33</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08806" target="_blank">@arXiv
                        2409.08806</a>
                    <span class="tweet-title">Tabular Data Gets a Neural Network Makeover: KANs to the
                        Rescue!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research proposes TabKANet, a novel architecture for tabular data modeling that integrates
                    Kolmogorov-Arnold Networks (KANs) with Transformers. Unlike previous work that primarily focused
                    on
                    encoding categorical features using Transformers, TabKANet leverages KANs to encode numerical
                    features, enabling a unified representation of both types of data within the Transformer
                    framework.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet22">
            <div class="start-time-icon" title="Play from here">09:59</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08815" target="_blank">@arXiv
                        2409.08815</a>
                    <span class="tweet-title">Jellyfish-Inspired AI Learns to Track Moving Targets in a Flowing
                        World</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Peking University</span>
                </div>
                <div class="primary-text">
                    This research introduces a deep reinforcement learning method for controlling a jellyfish-like
                    swimmer in a 2D flow. Unlike previous work that focused on simpler tasks with minimal
                    fluid-structure interaction, this study tackles the complex challenge of controlling a flexible
                    object with significant wake vortex influence.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet23">
            <div class="start-time-icon" title="Play from here">10:23</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08613" target="_blank">@arXiv
                        2409.08613</a>
                    <span class="tweet-title">Sparse Views, Dense Clouds: 3D Scene Reconstruction Gets a
                        Boost!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">East China University of Science and Technology, University of
                        Washington, University of Copenhagen</span>
                </div>
                <div class="primary-text">
                    This research introduces Dust-GS, a framework that improves 3D scene reconstruction from sparse
                    viewpoints by enhancing point cloud initialization beyond traditional Structure-from-Motion
                    (SfM)
                    methods. It combines an adaptive depth-based masking technique with point cloud optimization to
                    generate denser and more accurate point clouds.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet24">
            <div class="start-time-icon" title="Play from here">10:45</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08588" target="_blank">@arXiv
                        2409.08588</a>
                    <span class="tweet-title">Brain Tumor Segmentation: U-Net Gets a Coordinate Makeover!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU</span>
                </div>
                <div class="primary-text">
                    This research introduces an improved U-Net model for brain tumor segmentation that incorporates
                    a
                    coordinate attention mechanism and an ASPP module. This approach differs from previous work by
                    focusing on spatial location information to enhance feature extraction and representation.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet25">
            <div class="start-time-icon" title="Play from here">11:13</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08895" target="_blank">@arXiv
                        2409.08895</a>
                    <span class="tweet-title">AI-Edited Pics: Your Memories Are Now Fake News!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">MIT</span>
                </div>
                <div class="primary-text">
                    This study is unique because it examines the impact of AI-edited images and videos on false
                    memory
                    formation, specifically focusing on how these edits can distort people's recollections of real
                    events. Previous research has primarily focused on manually edited images or deepfakes, which
                    are
                    entirely fabricated content.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet26">
            <div class="start-time-icon" title="Play from here">11:35</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08771" target="_blank">@arXiv
                        2409.08771</a>
                    <span class="tweet-title">Low-Rank Matrix Factorization: A Federated Dance of Power and Gradient
                        Descent</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Inria, PSL Research University</span>
                </div>
                <div class="primary-text">
                    This research proposes a distributed algorithm for low-rank matrix factorization that combines a
                    global power initialization with local gradient descent, offering a potentially embarrassingly
                    parallel approach with a linear convergence rate. This differs from previous work by focusing on
                    the
                    Frobenius norm and achieving a finite number of communication steps, potentially just one.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet27">
            <div class="start-time-icon" title="Play from here">12:01</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09030" target="_blank">@arXiv
                        2409.09030</a>
                    <span class="tweet-title">LLMs in Software Engineering: Agents of Change?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Sun Yat-sen University, Xi’an Jiaotong University, Shenzhen
                        Institute
                        of Advanced Technology...</span>
                </div>
                <div class="primary-text">
                    This research provides a comprehensive survey of studies combining LLMs with software
                    engineering,
                    focusing on the concept of agents and presenting a framework for LLM-based agents in SE. It also
                    identifies challenges and opportunities for future research in this area.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet28">
            <div class="start-time-icon" title="Play from here">12:29</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08935" target="_blank">@arXiv
                        2409.08935</a>
                    <span class="tweet-title">Weight Normalization: Deep Learning's New Weight Watchers!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Illinois, Stanford University</span>
                </div>
                <div class="primary-text">
                    This paper provides the first theoretical analysis of optimization and generalization for deep
                    neural networks using Weight Normalization, a popular technique for speeding up training. Unlike
                    previous work, it focuses on smooth activation functions and establishes bounds that are
                    polynomial
                    in depth, independent of width, and dependent on the minimum weight vector norm.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet29">
            <div class="start-time-icon" title="Play from here">12:57</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08872" target="_blank">@arXiv
                        2409.08872</a>
                    <span class="tweet-title">Low-Resource Language Speech Recognition: A Recipe for Success with a
                        Pinch of Multilingual Magic!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Washington</span>
                </div>
                <div class="primary-text">
                    This research explores the impact of data quantity on ASR in extremely low-resource languages,
                    focusing on Amis and Seediq. Unlike previous studies that assumed access to large-scale
                    similar-language speech data, this paper addresses a more challenging scenario where such data
                    is
                    unavailable. The authors propose a novel data-selection scheme that leverages a multilingual
                    corpus
                    to augment the limited target language data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet30">
            <div class="start-time-icon" title="Play from here">13:21</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08396" target="_blank">@arXiv
                        2409.08396</a>
                    <span class="tweet-title">Clustering Across the Globe: A One-Shot Ensemble for
                        Privacy-Preserving
                        Data Analysis</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Harvard University, University of Michigan, Brigham and Women’s
                        Hospital</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel federated clustering algorithm called FONT, which uses a
                    data-adaptive ensemble of locally fitted models. Unlike previous methods that require multiple
                    rounds of communication, FONT only needs a single round, making it more efficient and practical
                    for
                    real-world applications.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet31">
            <div class="start-time-icon" title="Play from here">13:40</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08631" target="_blank">@arXiv
                        2409.08631</a>
                    <span class="tweet-title">Sybil Sleuths: Graph Neural Networks Unmask Fake Accounts in Social
                        Networks</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">ETH Zurich</span>
                </div>
                <div class="primary-text">
                    This research introduces SYBILGAT, a novel approach to Sybil detection that utilizes Graph
                    Attention
                    Networks (GATs). Unlike traditional methods that rely on structural properties of networks,
                    SYBILGAT
                    dynamically assigns attention weights to different nodes during aggregations, allowing it to
                    focus
                    on the most relevant information for detection.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet32">
            <div class="start-time-icon" title="Play from here">14:03</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08831" target="_blank">@arXiv
                        2409.08831</a>
                    <span class="tweet-title">Robots Are Now Officially Better at Captchas Than Humans!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">ETH Zurich</span>
                </div>
                <div class="primary-text">
                    This research demonstrates that advanced machine learning models, specifically YOLO models, can
                    now
                    solve 100% of Google's reCAPTCHAv2 challenges, surpassing previous efforts that achieved only
                    68-71%
                    success rates.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet33">
            <div class="start-time-icon" title="Play from here">14:24</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09026" target="_blank">@arXiv
                        2409.09026</a>
                    <span class="tweet-title">Music Recommendation Gets a Tune-Up: CLAP Embeddings Hit the Right
                        Notes</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">ETH Zurich</span>
                </div>
                <div class="primary-text">
                    This research explores the use of contrastively pretrained neural audio embeddings, specifically
                    CLAP, to enhance music recommendation systems. Unlike previous approaches that relied on
                    hand-crafted audio features, this study leverages the richer and more nuanced representations
                    offered by CLAP.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet34">
            <div class="start-time-icon" title="Play from here">14:45</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08946" target="_blank">@arXiv
                        2409.08946</a>
                    <span class="tweet-title">Graph Domain Adaptation: When Two Networks Meet, They Need a
                        Matchmaker!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Oxford, NYU, UC Los Angeles</span>
                </div>
                <div class="primary-text">
                    This research focuses on active graph domain adaptation, a technique that aims to improve the
                    performance of a model trained on one graph (source) when applied to a different but related
                    graph
                    (target). Unlike previous work, this paper proposes a novel approach called DELTA, which
                    leverages
                    two complementary subnetworks to explore topological semantics from both edge and path
                    perspectives.
                    This allows for a more comprehensive understanding of the target graph's structure and helps
                    identify the most informative nodes for annotation.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet35">
            <div class="start-time-icon" title="Play from here">15:11</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08583" target="_blank">@arXiv
                        2409.08583</a>
                    <span class="tweet-title">Singing Voice Conversion Goes Lightweight: CPU-Powered Vocals for
                        Everyone!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Southwest Jiaotong University, Tsinghua University, New Jersey
                        Institute of Technology</span>
                </div>
                <div class="primary-text">
                    This research introduces LHQ-SVC, a singing voice conversion model optimized for CPU execution,
                    unlike previous models that heavily relied on GPUs. This approach significantly reduces model
                    size
                    and computational demand, making it suitable for resource-constrained environments.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet36">
            <div class="start-time-icon" title="Play from here">15:35</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08775" target="_blank">@arXiv
                        2409.08775</a>
                    <span class="tweet-title">Want ChatGPT to Do Your Bidding? Learn to Speak Its Language!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU, Columbia University, University of Michigan</span>
                </div>
                <div class="primary-text">
                    This research focuses on teaching users how to articulate clear and complete requirements for
                    large
                    language models (LLMs) to achieve desired outcomes. Unlike previous work that focused on
                    refining
                    prompts through automation, this study emphasizes the importance of human-driven requirement
                    articulation, particularly for complex tasks.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet37">
            <div class="start-time-icon" title="Play from here">15:57</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08766" target="_blank">@arXiv
                        2409.08766</a>
                    <span class="tweet-title">Sparsity-Aware Uncertainty Calibration: Zeroing in on Spatiotemporal
                        Predictions</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">MIT, University of Florida, Florida State University</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel post-hoc calibration framework called SAUC, which specifically
                    addresses uncertainty in sparse spatiotemporal data. Unlike previous work that focuses on
                    deterministic predictions or assumes data distributions, SAUC calibrates uncertainty for both
                    zero
                    and non-zero values using quantile regression.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet38">
            <div class="start-time-icon" title="Play from here">16:22</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08482" target="_blank">@arXiv
                        2409.08482</a>
                    <span class="tweet-title">Sharing Your LoRA Model? Your Face Might Be Leaking!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Toronto</span>
                </div>
                <div class="primary-text">
                    This research explores the privacy risks of sharing fine-tuned diffusion model weights,
                    specifically
                    focusing on the LoRA method. Unlike previous work that assumed adversaries had access to
                    training
                    prompts, this study investigates the scenario where only the model weights are available.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet39">
            <div class="start-time-icon" title="Play from here">16:40</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08503" target="_blank">@arXiv
                        2409.08503</a>
                    <span class="tweet-title">ControlNet's Privacy Makeover: How to Train AI Without Losing Your
                        Data!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Toronto</span>
                </div>
                <div class="primary-text">
                    This research proposes a new distributed learning structure for training ControlNet models,
                    eliminating the need for the server to send gradients back to clients, thereby addressing the
                    efficiency bottleneck of split learning.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet40">
            <div class="start-time-icon" title="Play from here">17:00</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08302" target="_blank">@arXiv
                        2409.08302</a>
                    <span class="tweet-title">Molecules on the Move: AI Predicts Drug Effects with Microscopy
                        Magic!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Valence Labs, University of British Columbia, University of
                        Toronto...</span>
                </div>
                <div class="primary-text">
                    This research introduces a new method for predicting how molecules affect cells by combining
                    microscopy images with molecular structures. It uses a pre-trained phenomics model to improve
                    accuracy and reduce the need for large datasets.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet41">
            <div class="start-time-icon" title="Play from here">17:25</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08331" target="_blank">@arXiv
                        2409.08331</a>
                    <span class="tweet-title">Prostate Cancer Grading Gets a 3D Makeover: Deep Learning Meets
                        Volumetric
                        Biopsy Cores!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of California Los Angeles</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel data source called a "volumetric core" constructed from
                    traditional
                    2D pathology scans. This approach differs from previous work by utilizing a
                    morphology-preserving
                    alignment framework to co-register serial tissue sections, creating a 3D representation of the
                    biopsy core.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet42">
            <div class="start-time-icon" title="Play from here">17:52</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.08916" target="_blank">@arXiv
                        2409.08916</a>
                    <span class="tweet-title">AI Chatbot Helps Farmers Chat Their Way to Better Crops!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Microsoft</span>
                </div>
                <div class="primary-text">
                    This research introduces Farmer.Chat, a generative AI-powered chatbot that leverages
                    Retrieval-Augmented Generation (RAG) to provide personalized, reliable, and contextually
                    relevant
                    agricultural advice to smallholder farmers. Unlike previous chatbots that rely on deterministic
                    dialogue flows and curated content, Farmer.Chat can process unstructured data, such as research
                    papers, crop tables, and videos, to provide more dynamic and adaptable information.
                </div>
            </div>
        </div>

        <div
            style="padding: 50px 0; text-align: center; margin: 5px 0; font-weight: 300; font-size: 10px; color: #000000;">
            Opening music
            from <a href="https://ikson.com" target="_blank" style="color: black; text-decoration: none;">TELL
                YOUR STORY by ikson</a></div>
        <div style="height: 50px;"></div>
    </div>

    <footer class="player-footer">
        <div class="player-detail-hidden-on-small-screen">
            <div id="audio-title" class="tweet-title-small">Hit play and learn on the go!</div>
            <div style="height: 2px;"></div>
            <div id="audio-institutes" class="institute-text-small"></div>
        </div>
        <div class="control-panel">
            <div class="control-horizontal">
                <div id="playSpeedButton" title="Adjust speed">
                    <div id="selectedSpeed">1&times;</div>
                    <div class="speedMenuItems">
                        <div data-value="0.6">Speed 0.6&times;</div>
                        <div data-value="0.8">Speed 0.8&times;</div>
                        <div data-value="1" class="selected">Speed 1&times;</div>
                        <div data-value="1.2">Speed 1.2&times;</div>
                        <div data-value="1.4">Speed 1.4&times;</div>
                        <div data-value="1.6">Speed 1.6&times;</div>
                    </div>
                    <select id="speedOptionsHidden">
                        <option value="0.6">0.6&times;</option>
                        <option value="0.8">0.8&times;</option>
                        <option value="1" selected>1&times;</option>
                        <option value="1.2">1.2&times;</option>
                        <option value="1.4">1.4&times;</option>
                        <option value="1.6">1.6&times;</option>
                    </select>
                </div>
                <div id="playLastButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(false)" title="Play last" disabled>
                        <img src="assets/buttonLastEpisode.svg" alt="Last" style="width: 12px;">
                    </button>
                </div>
                <button class="controllerButton" onclick="scrollToCurrentTweet()" title="Scoll to the current episode">
                    <img id="locateImage" src="assets/buttonTarget.svg" alt="Locate">
                </button>
                <button class="controllerButton" onclick="togglePlayPause()" title="Play/Pause">
                    <img id="playPauseImage" src="assets/buttonPlay.svg" alt="Play">
                </button>
                <div id="playNextButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(true)" title="Play next" disabled>
                        <img src="assets/buttonNextEpisode.svg" alt="Next" style="width: 12px;">
                    </button>
                </div>
            </div>
            <div class="control-horizontal">
                <div id="progressTime">0:00</div>
                <div id="progressContainer" onclick="seek(event)">
                    <div id="progressBar"></div>
                    <div id="progressCircle" draggable="true"></div>
                </div>
                <audio id="audioPlayer"
                    src="https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202409161938_audio.mp3"></audio>
                <div id="progressTime"><span id="audioDuration">Loading...</span></div>
            </div>
        </div>
    </footer>
    <div id="privacyModal" class="modal"></div>
    <script src="script.js"></script>
    <script src="calendar.js"></script>
    <script>
        fetch('https://ribbitribbit.co/header.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('headerId').innerHTML = data;
            })
            .catch(error => console.error('Error loading header.html:', error));
        fetch('https://ribbitribbit.co/terms.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('privacyModal').innerHTML = data;
            })
            .catch(error => console.error('Error loading terms.html:', error));
    </script>
</body>

</html>
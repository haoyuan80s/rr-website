
daily_data = {
    "date": "2024-07-24",
    "tweets": [
            {
                "startTime": "00:56",
                "arxivId": "2407.16611",
                "arxivLink": "https://arxiv.org/abs/2407.16611",
                "title": "Continual Learning: Local vs Global, It's a Battle of the Brains!",
                "institute": "ETH Zurich",
                "text": "This research classifies continual learning algorithms based on whether they use local or global approximations of the task loss function. This distinction is novel and helps explain why some algorithms struggle when learning becomes non-local.",
                "paper-title": "Local vs Global continual learning",
                "image-path": ""
            },

            {
                "startTime": "01:17",
                "arxivId": "2407.16607",
                "arxivLink": "https://arxiv.org/abs/2407.16607",
                "title": "Tokenizers Spill the Tea: Unmasking the Secrets of Language Model Training Data",
                "institute": "University of Washington",
                "text": "This research introduces a novel approach to data mixture inference, focusing on the previously overlooked information contained within byte-pair encoding (BPE) tokenizers. Unlike previous work that focused on membership inference, this study aims to uncover the proportions of different data categories within a language model's training data.",
                "paper-title": "Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?",
                "image-path": ""
            },

            {
                "startTime": "01:42",
                "arxivId": "2407.16286",
                "arxivLink": "https://arxiv.org/abs/2407.16286",
                "title": "Pruning LLMs: Shapley Value vs. Cosine Distance - A Battle of the Brains!",
                "institute": "University of Cambridge",
                "text": "This research delves deeper into depth pruning of LLMs by exploring the impact of different block influence metrics, including adaptive metrics like Shapley value, in addition to static metrics like cosine distance. It also examines the pruning of individual self-attention and feed-forward layers within a block.",
                "paper-title": "A deeper look at depth pruning of LLMs",
                "image-path": ""
            },

            {
                "startTime": "02:12",
                "arxivId": "2407.16007",
                "arxivLink": "https://arxiv.org/abs/2407.16007",
                "title": "Social Media Quotes: More Than Just Likes, They're Roles!",
                "institute": "Google",
                "text": "This research introduces a novel framework for automatically classifying the roles of social media posts embedded in web pages. Unlike previous work that focuses on analyzing social media accounts themselves, this study examines the context surrounding the embedded posts to understand their function within the web page.",
                "paper-title": "SocialQuotes: Learning Contextual Roles of Social Media Quotes on the Web",
                "image-path": ""
            },

            {
                "startTime": "02:34",
                "arxivId": "2407.16186",
                "arxivLink": "https://arxiv.org/abs/2407.16186",
                "title": "RL's New Frontier: Automating the Environment Shaping Game!",
                "institute": "MIT",
                "text": "This research focuses on the often-overlooked bottleneck in reinforcement learning (RL) for robotics: environment shaping. It argues that current RL benchmarks are artificially easy because they rely on human-designed shaping, and proposes a new approach to automate this process.",
                "paper-title": "Automatic Environment Shaping is the Next Frontier in RL",
                "image-path": ""
            },

            {
                "startTime": "02:59",
                "arxivId": "2407.16677",
                "arxivLink": "https://arxiv.org/abs/2407.16677",
                "title": "Robot Assembly Gets a Tune-Up: Residual Learning Makes Robots More Precise!",
                "institute": "Massachusetts Institute of Technology, Improbable AI Lab, Harvard University",
                "text": "This research proposes training residual policies on top of frozen behavior cloning (BC)-trained diffusion models to improve the performance of robotic assembly tasks. This approach differs from previous work by avoiding direct fine-tuning of the BC model, which can be challenging with complex architectures like diffusion models and action chunking.",
                "paper-title": "From Imitation to Refinement -- Residual RL for Precise Visual Assembly",
                "image-path": ""
            },

            {
                "startTime": "03:25",
                "arxivId": "2407.16602",
                "arxivLink": "https://arxiv.org/abs/2407.16602",
                "title": "Policy Optimization Gets a Speed Boost: Functional Acceleration for PMD",
                "institute": "McGill University, Mila Quebec AI Institute, Google DeepMind...",
                "text": "This research applies functional acceleration to the Policy Mirror Descent (PMD) family of algorithms, which is a general framework for reinforcement learning. This approach is different from previous work that focused on accelerating the policy parameters.",
                "paper-title": "Functional Acceleration for Policy Mirror Descent",
                "image-path": ""
            },

            {
                "startTime": "03:55",
                "arxivId": "2407.16015",
                "arxivLink": "https://arxiv.org/abs/2407.16015",
                "title": "Wallcamera: A Peek Behind the Curtain, or Just a DIF-ferent View?",
                "institute": "MIT, University of Southampton",
                "text": "This paper compares the Wallcamera, a recent innovation in activity recognition, to an earlier technique called Differential Imaging Forensics (DIF). While both methods extract subtle visual cues from wall reflections, the Wallcamera focuses on activity recognition at a finer granularity, while DIF offers a broader range of applications in forensics.",
                "paper-title": "Wallcamera: Reinventing the Wheel?",
                "image-path": ""
            },

            {
                "startTime": "04:17",
                "arxivId": "2407.15892",
                "arxivLink": "https://arxiv.org/abs/2407.15892",
                "title": "Training LLMs on Long Sequences? No Problem, Mini-Sequence Transformer to the Rescue!",
                "institute": "Caltech, CMU",
                "text": "This paper introduces MINI-SEQUENCE TRANSFORMER (MST), a technique that partitions input sequences into smaller \"mini-sequences\" to reduce memory usage during training. This approach differs from previous methods like activation recomputation by focusing on optimizing the intermediate memory of MLP and LM-Head blocks, rather than just the activation values.",
                "paper-title": "MINI-SEQUENCE TRANSFORMER: Optimizing Intermediate Memory for Long Sequences Training",
                "image-path": ""
            },

            {
                "startTime": "04:42",
                "arxivId": "2407.16634",
                "arxivLink": "https://arxiv.org/abs/2407.16634",
                "title": "AI Doctor's New Trick: Making Up Fake Ultrasound Images to Diagnose Breast Cancer Better!",
                "institute": "Peking University, Chinese Academy of Sciences",
                "text": "This research introduces a new approach to address the long-tail distribution problem in medical image datasets. Instead of relying solely on real data, the researchers propose a pipeline called TAILOR that uses a knowledge-driven generative model to create synthetic images, particularly for rare cases. This approach aims to improve the accuracy and interpretability of diagnostic models.",
                "paper-title": "Knowledge-driven AI-generated data for accurate and interpretable breast ultrasound diagnoses",
                "image-path": ""
            },

            {
                "startTime": "05:11",
                "arxivId": "2407.15866",
                "arxivLink": "https://arxiv.org/abs/2407.15866",
                "title": "AI Models on a Diet: CXL Makes Weight Quantization Slim and Fast!",
                "institute": "Rensselaer Polytechnic Institute, BASIS Independent Fremont, IBM",
                "text": "This research proposes a CXL-based AI model store that supports runtime configurable weight quantization, enabling dynamic adjustment of weight precision based on their importance during inference. Unlike previous work, this approach focuses on improving DRAM access efficiency by leveraging bit-plane in-memory placement and memory logical space bloating.",
                "paper-title": "SmartQuant: CXL-based AI Model Store in Support of Runtime Configurable Weight Quantization",
                "image-path": ""
            },

            {
                "startTime": "05:38",
                "arxivId": "2407.15869",
                "arxivLink": "https://arxiv.org/abs/2407.15869",
                "title": "Time Series Forecasting: Long-Term Memory Without the Overfitting Blues!",
                "institute": "Harbin University of Science and Technology, Harbin Institute of Technology",
                "text": "This research introduces a novel approach to long time series forecasting by decoupling multi-scale temporal patterns and modeling each pattern with its corresponding period length as the token size. This differs from previous methods that often struggle with overfitting when handling long input sequences.",
                "paper-title": "Long Input Sequence Network for Long Time Series Forecasting",
                "image-path": ""
            },

            {
                "startTime": "06:05",
                "arxivId": "2407.16248",
                "arxivLink": "https://arxiv.org/abs/2407.16248",
                "title": "Livestream Shopping: A Graph-Guided Journey to Find Your Perfect Product!",
                "institute": "Chinese Academy of Sciences, Tsinghua University, Kuaishou Technology",
                "text": "This research introduces a novel Spatiotemporal Graph Guided Multi-modal Network (SGMN) for livestreaming product retrieval. Unlike previous methods that focus on coarse-grained matching, SGMN leverages fine-grained matching by integrating textual embeddings, instance-level similarity mining, and frame-level graph learning.",
                "paper-title": "Spatiotemporal Graph Guided Multi-modal Network for Livestreaming Product Retrieval",
                "image-path": ""
            },

            {
                "startTime": "06:33",
                "arxivId": "2407.16223",
                "arxivLink": "https://arxiv.org/abs/2407.16223",
                "title": "Pose Estimation with a Pinch of Probability: New Metrics for Landing Safely",
                "institute": "Stanford University",
                "text": "This research introduces novel closed-form expressions for measuring calibration and sharpness specifically for multivariate normal distributions, which are used to evaluate the performance of three probabilistic parameter estimators for pose estimation.",
                "paper-title": "Probabilistic Parameter Estimators and Calibration Metrics for Pose Estimation from Image Features",
                "image-path": ""
            },

            {
                "startTime": "07:00",
                "arxivId": "2407.16564",
                "arxivLink": "https://arxiv.org/abs/2407.16564",
                "title": "Music Editing Made Easy: A Tiny AI Tweak for Big Changes",
                "institute": "National Taiwan University, CMU, UC San Diego",
                "text": "This paper proposes Audio Prompt Adapter (AP-Adapter), a lightweight module that adds audio input capability to pre-trained text-to-music models. Unlike previous methods that rely on complex prompts or iterative refinements, AP-Adapter allows for zero-shot music editing with a single text prompt and an audio input.",
                "paper-title": "Audio Prompt Adapter: Unleashing Music Editing Abilities for Text-to-Music with Lightweight Finetuning",
                "image-path": ""
            },

            {
                "startTime": "07:29",
                "arxivId": "2407.16291",
                "arxivLink": "https://arxiv.org/abs/2407.16291",
                "title": "TAPTRv2: Tracking Points with a Touch of Attention!",
                "institute": "South China University of Technology, International Digital Economy Academy, The Hong Kong University of Science and Technology...",
                "text": "This paper introduces TAPTRv2, an improvement on the TAPTR framework for tracking any point in a video. Unlike TAPTR, which relies on cost-volume features that can contaminate the point query's content, TAPTRv2 uses an attention-based position update operation to avoid this issue.",
                "paper-title": "TAPTRv2: Attention-based Position Update Improves Tracking Any Point",
                "image-path": ""
            },

            {
                "startTime": "08:01",
                "arxivId": "2407.16396",
                "arxivLink": "https://arxiv.org/abs/2407.16396",
                "title": "Learning to Render: A Neural Network Makes 3D Reconstruction a Breeze!",
                "institute": "Tsinghua University, Kuaishou Technology, Wayne State University",
                "text": "This research introduces a novel differentiable renderer for inferring unsigned distance functions (UDFs) from multi-view images. Unlike previous methods that rely on handcrafted equations, this approach utilizes a neural network trained in a data-driven manner to learn how to render unsigned distances into depth images. This learned \"volume rendering prior\" is then used to infer UDFs for unseen scenes, resulting in more accurate and robust reconstructions.",
                "paper-title": "Learning Unsigned Distance Functions from Multi-view Images with Volume Rendering Priors",
                "image-path": ""
            },

            {
                "startTime": "08:24",
                "arxivId": "2407.16008",
                "arxivLink": "https://arxiv.org/abs/2407.16008",
                "title": "Reward Models Get a Boost: New Method Makes AI Feedback More Reliable",
                "institute": "Google, Emory University",
                "text": "This research introduces RMBoost, a new method for generating synthetic preference data for training reward models. Unlike previous methods that generate two responses and then predict the preference label, RMBoost first generates one response, selects a preference label, and then generates a second response conditioned on the first response and the label. This approach aims to reduce labeling noise and increase the diversity of generated responses.",
                "paper-title": "Boosting Reward Model with Preference-Conditional Multi-Aspect Synthetic Data Generation",
                "image-path": ""
            },

            {
                "startTime": "08:52",
                "arxivId": "2407.15975",
                "arxivLink": "https://arxiv.org/abs/2407.15975",
                "title": "Headline Hallucination: When AI News Goes Off the Rails!",
                "institute": "Google",
                "text": "This research introduces a new multilingual dataset for detecting fine-grained headline hallucinations, going beyond simple \"true\" or \"false\" labels to pinpoint specific types of errors. It also explores how large language models can be used for few-shot learning in this task.",
                "paper-title": "Multilingual Fine-Grained News Headline Hallucination Detection",
                "image-path": ""
            },

            {
                "startTime": "09:19",
                "arxivId": "2407.15992",
                "arxivLink": "https://arxiv.org/abs/2407.15992",
                "title": "Lip-Reading Babies: How Visual Cues Boost Speech Learning",
                "institute": "MIT",
                "text": "This research explores the impact of visual information on phonetic learning by training a computational model on both audio and video data. Unlike previous work that focused solely on audio, this study demonstrates that visual cues from a speaker's mouth can significantly improve a model's ability to discriminate between phonemes, even when only audio is available at test time.",
                "paper-title": "Multimodal Input Aids a Bayesian Model of Phonetic Learning",
                "image-path": ""
            },

            {
                "startTime": "09:42",
                "arxivId": "2407.16237",
                "arxivLink": "https://arxiv.org/abs/2407.16237",
                "title": "RTL Code Generation: LLMs Get a Self-Reflection Makeover!",
                "institute": "Peking University, Chinese University of Hong Kong, Fudan University...",
                "text": "This research introduces OriGen, an open-source framework for RTL code generation that utilizes a novel code-to-code augmentation methodology to enhance the quality of open-source RTL code datasets. It also incorporates a self-reflection mechanism that enables the model to autonomously fix syntactic errors by leveraging compiler feedback.",
                "paper-title": "OriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection",
                "image-path": ""
            },

            {
                "startTime": "10:11",
                "arxivId": "2407.16266",
                "arxivLink": "https://arxiv.org/abs/2407.16266",
                "title": "Beyond Binary Bias: Translating the World, One Non-Binary Identity at a Time",
                "institute": "Beijing Jiaotong University, Tencent Inc",
                "text": "This research goes beyond the traditional male/female binary in evaluating gender bias in machine translation. It introduces a new benchmark, AmbGIMT, which assesses bias across a spectrum of 14 gender identities, including non-binary individuals.",
                "paper-title": "Beyond Binary Gender: Evaluating Gender-Inclusive Machine Translation with Ambiguous Attitude Words",
                "image-path": ""
            },

            {
                "startTime": "10:41",
                "arxivId": "2407.16355",
                "arxivLink": "https://arxiv.org/abs/2407.16355",
                "title": "\"Best-Action Queries: A Little Help Goes a Long Way in Online Learning\"",
                "institute": "Sapienza University of Rome, Bocconi University, Meta",
                "text": "This research explores the impact of \"best-action queries\" in online learning, where the learner can ask an oracle for the best action at a given time step. This differs from previous work that focused on hints or queries that provide correlated information or compare a small subset of actions.",
                "paper-title": "Online Learning with Sublinear Best-Action Queries",
                "image-path": ""
            },

            {
                "startTime": "11:09",
                "arxivId": "2407.16312",
                "arxivLink": "https://arxiv.org/abs/2407.16312",
                "title": "MOMALAND: A Playground for Multi-Agent, Multi-Objective Learning!",
                "institute": "ETH Zurich, Utrecht University",
                "text": "This research introduces MOMALAND, the first standardized benchmark suite for multi-objective multi-agent reinforcement learning (MOMARL). Previous work has focused on either single-agent or single-objective settings, leaving a gap in research for complex scenarios involving multiple agents and objectives.",
                "paper-title": "MOMAland: A Set of Benchmarks for Multi-Objective Multi-Agent Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "11:39",
                "arxivId": "2407.16094",
                "arxivLink": "https://arxiv.org/abs/2407.16094",
                "title": "Spectra-licious! AI Makes Spectroscopy a Breeze, No Expensive Equipment Needed!",
                "institute": "MIT, Ragon Institute, Jameel Clinic",
                "text": "This research introduces SpectroGen, a deep generative model that uses physical priors to generate spectral signatures across different modalities. Unlike previous work, SpectroGen doesn't rely on complex physical models or large datasets, instead leveraging the inherent structure of spectral data.",
                "paper-title": "Universal Spectral Transfer with Physical Prior-Informed Deep Generative Learning",
                "image-path": ""
            },

            {
                "startTime": "11:53",
                "arxivId": "2407.16210",
                "arxivLink": "https://arxiv.org/abs/2407.16210",
                "title": "Table Tennis Bots Learn to Play Like Pros, No More Mode Collapse!",
                "institute": "CMU, Seoul National University",
                "text": "This research introduces a hierarchical control system for physics-based table tennis animation, addressing the issue of mode collapse in previous approaches. The system includes a strategy-level controller that learns to select skills and targets, and a skill-level controller that executes those skills.",
                "paper-title": "Strategy and Skill Learning for Physics-based Table Tennis Animation",
                "image-path": ""
            },

            {
                "startTime": "12:23",
                "arxivId": "2407.16207",
                "arxivLink": "https://arxiv.org/abs/2407.16207",
                "title": "LLMs Get a Speed Boost: Graph-Structured Decoding Makes Inference a Breeze!",
                "institute": "Peking University, Renmin University of China, Tianjin University...",
                "text": "This research introduces Graph-structured Speculative Decoding (GSD), a new approach to accelerate LLM inference. Unlike previous methods that rely on a single hypothesis or a tree structure, GSD leverages a directed acyclic graph (DAG) to manage multiple hypotheses, efficiently predicting and merging recurring token sequences.",
                "paper-title": "Graph-Structured Speculative Decoding",
                "image-path": ""
            },

            {
                "startTime": "12:51",
                "arxivId": "2407.16025",
                "arxivLink": "https://arxiv.org/abs/2407.16025",
                "title": "Reward Confusion: When AI Gets Its Wires Crossed!",
                "institute": "ETH Zurich, UC Berkeley, University of Toronto",
                "text": "This paper introduces a new problem in offline reinforcement learning called \"reward confusion,\" where the AI model learns to rely on spurious correlations in the data, leading to incorrect behavior. The authors propose a novel algorithm, IMPEC, to address this issue by actively learning a global preference chain and leveraging transitivity of preferences.",
                "paper-title": "Exploring and Addressing Reward Confusion in Offline Preference Learning",
                "image-path": ""
            },

            {
                "startTime": "13:28",
                "arxivId": "2407.16067",
                "arxivLink": "https://arxiv.org/abs/2407.16067",
                "title": "Out-of-Distribution Generalization: When Models Make Better Mistakes",
                "institute": "CMU, University of Macau",
                "text": "This research proposes using the Lowest Common Ancestor (LCA) distance, a measure of the hierarchical distance between labels and predictions within a class taxonomy, to predict a model's out-of-distribution (OOD) performance. This approach differs from previous work that relied on in-distribution accuracy as an indicator of OOD performance.",
                "paper-title": "LCA-on-the-Line: Benchmarking Out-of-Distribution Generalization with Class Taxonomies",
                "image-path": ""
            },

            {
                "startTime": "14:13",
                "arxivId": "2407.16637",
                "arxivLink": "https://arxiv.org/abs/2407.16637",
                "title": "AI's Got a New Trick: Teaching Bots to Say \"Oops\"",
                "institute": "Tsinghua University, Central South University, Alibaba Group...",
                "text": "This research focuses on \"course-correction\" in LLMs, a new approach to safety alignment that emphasizes the model's ability to autonomously steer away from generating harmful content, even after an initial unsafe response. Unlike previous work that primarily focuses on preventing harmful content generation, this paper explores the ability of LLMs to correct their course mid-generation.",
                "paper-title": "Course-Correction: Safety Alignment Using Synthetic Preferences",
                "image-path": ""
            },

            {
                "startTime": "14:43",
                "arxivId": "2407.15855",
                "arxivLink": "https://arxiv.org/abs/2407.15855",
                "title": "Data Poisoning Attacks: When Your Car's GPS Goes Rogue!",
                "institute": "University of Washington",
                "text": "This research focuses specifically on data poisoning attacks against Intelligent Transportation Systems (ITS), a topic that has received less attention than other cybersecurity threats in transportation.",
                "paper-title": "Data poisoning attacks in intelligent transportation systems: A survey",
                "image-path": ""
            },

            {
                "startTime": "15:08",
                "arxivId": "2407.16541",
                "arxivLink": "https://arxiv.org/abs/2407.16541",
                "title": "Masked Image Modeling: The New Recipe for Visual Scoring!",
                "institute": "Tsinghua University, Kuaishou Technology",
                "text": "This research proposes QPTV2, a novel pretraining framework based on Masked Image Modeling (MIM) for visual scoring tasks. Unlike previous work that relies on contrastive learning, QPTV2 leverages MIM's ability to reconstruct masked image regions, enabling it to learn both sample-level and pixel-level information.",
                "paper-title": "QPT V2: Masked Image Modeling Advances Visual Scoring",
                "image-path": ""
            },

            {
                "startTime": "15:30",
                "arxivId": "2407.16521",
                "arxivLink": "https://arxiv.org/abs/2407.16521",
                "title": "Among Us, But Make It Text-Based: LLMs Play Social Deduction!",
                "institute": "UC Berkeley, Tongji University",
                "text": "This research differs from previous work by focusing on a complex, multi-agent game environment that goes beyond simple conversation and explicit in-game moves. It uses Among Us as a testbed to evaluate LLMs' abilities in goal-oriented games with incomplete information and a wider range of actions.",
                "paper-title": "AMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game",
                "image-path": ""
            },

            {
                "startTime": "15:52",
                "arxivId": "2407.16370",
                "arxivLink": "https://arxiv.org/abs/2407.16370",
                "title": "LLMs Get a Makeover: Evolutionary Prompt Design for Speech Error Correction",
                "institute": "Carnegie Mellon University, Southern University of Science and Technology, NVIDIA Research",
                "text": "This research explores the use of evolutionary algorithms to optimize prompts for large language models (LLMs) in the context of post-automatic speech recognition (ASR) error correction. Unlike previous work that focuses on empirically designed prompts, this study proposes a systematic approach to refine prompts iteratively, leading to improved performance.",
                "paper-title": "Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction",
                "image-path": ""
            },

            {
                "startTime": "16:18",
                "arxivId": "2407.16537",
                "arxivLink": "https://arxiv.org/abs/2407.16537",
                "title": "Speech Recognition: How Much Does Language Matter?",
                "institute": "University of Toronto",
                "text": "This research introduces a novel method for quantifying the role of textual predictability in automatic speech recognition (ASR) systems. Unlike previous work that focused on directly linking perplexity to error rates, this study uses ratios of error rates across different levels of textual predictability to isolate the impact of language modeling.",
                "paper-title": "Quantifying the Role of Textual Predictability in Automatic Speech Recognition",
                "image-path": ""
            },

            {
                "startTime": "16:45",
                "arxivId": "2407.16134",
                "arxivLink": "https://arxiv.org/abs/2407.16134",
                "title": "Diffusion Transformers: Unveiling the Secrets of Sequential Data!",
                "institute": "Yale University, Princeton University",
                "text": "This research delves into the theoretical underpinnings of diffusion transformers for learning sequential data, specifically Gaussian process data. Unlike previous work focusing on static data, this paper explores how diffusion transformers capture spatial-temporal dependencies and their impact on learning efficiency.",
                "paper-title": "Diffusion Transformer Captures Spatial-Temporal Dependencies: A Theory for Gaussian Process Data",
                "image-path": ""
            },

            {
                "startTime": "17:08",
                "arxivId": "2407.16346",
                "arxivLink": "https://arxiv.org/abs/2407.16346",
                "title": "Multistage Robust Optimization: A Nested Distance Tale of Two Formulations",
                "institute": "University of Texas at Austin",
                "text": "This research explores multistage distributionally robust optimization (DRO) using the nested distance, demonstrating its equivalence to a multistage-dynamic formulation with one-period Wasserstein distance. This equivalence allows for dynamic programming solutions, which were previously unavailable for nested distance problems.",
                "paper-title": "Data-driven Multistage Distributionally Robust Linear Optimization with Nested Distance",
                "image-path": ""
            },

            {
                "startTime": "17:37",
                "arxivId": "2407.16467",
                "arxivLink": "https://arxiv.org/abs/2407.16467",
                "title": "OpenVINO Models: A Side-Channel Sneak Peek into Your Neural Network Secrets!",
                "institute": "Nanyang Technological University, Slovak University of Technology in Bratislava",
                "text": "This research focuses on the vulnerability of quantized neural network models implemented in OpenVINO to side-channel analysis attacks. Unlike previous work that primarily focused on recovering model behavior, this study demonstrates the possibility of recovering exact model parameters with high precision.",
                "paper-title": "Side-Channel Analysis of OpenVINO-based Neural Network Models",
                "image-path": ""
            },

            {
                "startTime": "18:20",
                "arxivId": "2407.16485",
                "arxivLink": "https://arxiv.org/abs/2407.16485",
                "title": "Learning Constraints from Demos: When Robots Need a Little Guidance",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research proposes a novel approach to inferring continuous, possibly nonlinear constraints from demonstrations using a positive-unlabeled (PU) learning technique. Unlike previous methods that often rely on linear constraints or require strong knowledge of the environment, this method leverages the difference between expert demonstrations and a policy that generates potentially unsafe trajectories to learn the constraint function.",
                "paper-title": "Learning General Continuous Constraint from Demonstrations via Positive-Unlabeled Learning",
                "image-path": ""
            },

            {
                "startTime": "18:48",
                "arxivId": "2407.15875",
                "arxivLink": "https://arxiv.org/abs/2407.15875",
                "title": "Shapley Pruning: A Fairer Way to Slim Down Your Neural Networks",
                "institute": "ETH Z\u00fcrich",
                "text": "This research proposes a new framework for neural network compression based on the Shapley value, a concept from game theory. Unlike previous methods that focus on individual neurons, this approach considers the collective contribution of groups of neurons, leading to more efficient pruning.",
                "paper-title": "Shapley Pruning for Neural Network Compression",
                "image-path": ""
            },

            {
                "startTime": "19:10",
                "arxivId": "2407.16588",
                "arxivLink": "https://arxiv.org/abs/2407.16588",
                "title": "Clique-ing Mad: A Faster Algorithm for Finding Nearly Complete Groups in Networks",
                "institute": "University of Electronic Science and Technology of China, Peking University",
                "text": "This research introduces a new branching algorithm for finding the largest \"k-defective clique\" in a graph. Unlike previous algorithms, this one leverages the well-established maximum clique algorithm as a subroutine, leading to a better asymptotic running time.",
                "paper-title": "A Faster Branching Algorithm for the Maximum $k$-Defective Clique Problem",
                "image-path": ""
            },

            {
                "startTime": "19:34",
                "arxivId": "2407.16347",
                "arxivLink": "https://arxiv.org/abs/2407.16347",
                "title": "Fact-Checking Fiction: How to Keep Your Story's Timeline Straight",
                "institute": "University of Hong Kong, UC Berkeley",
                "text": "This research introduces FACTTRACK, a method for tracking atomic facts in story outlines and detecting contradictions based on their validity intervals. Unlike previous work, FACTTRACK explicitly considers the temporal nature of facts, allowing it to distinguish between legitimate contradictions and facts simply changing over time.",
                "paper-title": "FACTTRACK: Time-Aware World State Tracking in Story Outlines",
                "image-path": ""
            },

            {
                "startTime": "20:04",
                "arxivId": "2407.16664",
                "arxivLink": "https://arxiv.org/abs/2407.16664",
                "title": "Multilingual Pretraining: Giving Speech Recognition a Language Lesson!",
                "institute": "Meta",
                "text": "This research investigates the effectiveness of multilingual pretraining for improving Automatic Speech Recognition (ASR) models in low-resource languages. The study focuses on the impact of transfer learning at different stages of model training, comparing in-domain and out-of-domain pretraining, and analyzing the effect on rare and non-rare words.",
                "paper-title": "Towards scalable efficient on-device ASR with transfer learning",
                "image-path": ""
            },

            {
                "startTime": "20:32",
                "arxivId": "2407.15862",
                "arxivLink": "https://arxiv.org/abs/2407.15862",
                "title": "Tiny AI Doctors: Can Lightweight LLMs Handle Pediatric Consultations?",
                "institute": "Children's Hospital of Chongqing Medical University, Chongqing Medical University, Stanford University...",
                "text": "This research focuses on the performance of lightweight, open-source LLMs in pediatric consultations, a domain previously underexplored. It compares these models to larger, proprietary LLMs, providing insights into their relative strengths and weaknesses.",
                "paper-title": "Performance Evaluation of Lightweight Open-source Large Language Models in Pediatric Consultations: A Comparative Analysis",
                "image-path": ""
            },

            {
                "startTime": "20:57",
                "arxivId": "2407.16556",
                "arxivLink": "https://arxiv.org/abs/2407.16556",
                "title": "ReLU's Secret Weapon: DC is the New Black!",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This paper provides a mathematical description of the ReLU activation function in the frequency domain, showing that it introduces a DC component and higher frequencies. Previous work has focused on empirical observations or approximations of ReLU's behavior.",
                "paper-title": "DC is all you need: describing ReLU from a signal processing standpoint",
                "image-path": ""
            },

            {
                "startTime": "21:20",
                "arxivId": "2407.16110",
                "arxivLink": "https://arxiv.org/abs/2407.16110",
                "title": "Words Evolve, Senses Too: How Semantic Cells Track Polysemy's Dance",
                "institute": "The University of Tokyo",
                "text": "This research introduces a novel approach to analyzing word polysemy by modeling it as an evolutionary process. Unlike previous work that focuses on learning \"correct\" senses, this study uses Semantic Cells (SCs) to capture the dynamic emergence of new senses over time.",
                "paper-title": "Analyzing the Polysemy Evolution using Semantic Cells",
                "image-path": ""
            },

            {
                "startTime": "21:49",
                "arxivId": "2407.16264",
                "arxivLink": "https://arxiv.org/abs/2407.16264",
                "title": "Masks and Manuscripts: A New Recipe for Medical AI",
                "institute": "University of Oxford, Oxford Suzhou Centre for Advanced Research",
                "text": "This research introduces a novel approach to medical pre-training by combining self-supervised learning with a standardized triplet format for textual data and a Meijering-based masking strategy for visual data. This differs from previous work by addressing the challenges of inconsistent semantics and morphology in medical text reports, as well as the need for more effective visual pre-training methods for medical images.",
                "paper-title": "Masks and Manuscripts: Advancing Medical Pre-training with End-to-End Masking and Narrative Structuring",
                "image-path": ""
            },

            {
                "startTime": "22:10",
                "arxivId": "2407.16641",
                "arxivLink": "https://arxiv.org/abs/2407.16641",
                "title": "Hyperbolic Embeddings: A Geometry-Aware Algorithm to Cure Embedding Illnesses",
                "institute": "Alibaba, CMU, UC San Diego...",
                "text": "This research introduces a geometry-aware algorithm that addresses three categories of \"illnesses\" that can hinder the performance of hyperbolic embeddings. The algorithm uses a dilation operation and transitive closure regularization to improve the accuracy of embedding hierarchical data.",
                "paper-title": "A Geometry-Aware Algorithm to Learn Hierarchical Embeddings in Hyperbolic Space",
                "image-path": ""
            },

            {
                "startTime": "22:31",
                "arxivId": "2407.16463",
                "arxivLink": "https://arxiv.org/abs/2407.16463",
                "title": "Land Surface Forecasting: AI Models Race to Predict the Weather!",
                "institute": "University of Freiburg, European Centre for Medium-Range Weather Forecasts, World Meteorological Organization",
                "text": "This research compares three machine learning models for emulating a complex land surface model, ECLand, which is used in weather forecasting. Previous work has focused on emulating specific aspects of land surface models, but this study emulates the entire system.",
                "paper-title": "Advances in Land Surface Model-based Forecasting: A comparative study of LSTM, Gradient Boosting, and Feedforward Neural Network Models as prognostic state emulators",
                "image-path": ""
            },

            {
                "startTime": "22:55",
                "arxivId": "2407.16526",
                "arxivLink": "https://arxiv.org/abs/2407.16526",
                "title": "Vision Models Need Glasses: A New Way to Fix Their Blinders",
                "institute": "University of Cambridge, Toyota Motor Europe",
                "text": "This research proposes a method for selectively updating the vision encoder within vision-language models (VLMs) to improve their performance on specific datasets, while preserving their overall robustness. This approach differs from previous work that focused on updating the entire model or only specific layers.",
                "paper-title": "Imperfect Vision Encoders: Efficient and Robust Tuning for Vision-Language Models",
                "image-path": ""
            },

            {
                "startTime": "23:21",
                "arxivId": "2407.16470",
                "arxivLink": "https://arxiv.org/abs/2407.16470",
                "title": "LLMs: The New Hallucination Detectives?",
                "institute": "University College London, Meta",
                "text": "This research evaluates the performance of Large Language Models (LLMs) and embedding-based methods for detecting hallucinations in machine translation, focusing on both high and low-resource languages. Unlike previous work, which primarily focused on English-centric translations, this study expands the scope to include a wider range of language pairs, including non-English-centric ones.",
                "paper-title": "Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "23:45",
                "arxivId": "2407.16092",
                "arxivLink": "https://arxiv.org/abs/2407.16092",
                "title": "Coalition Formation: A Faster, Smarter Way to Team Up!",
                "institute": "Claude Bernard University Lyon 1, CMU",
                "text": "This research introduces a novel algorithm called SMART for coalition structure generation. SMART combines three techniques: Complementarity-Based Dynamic Programming (CDP), Gradual Search with Dynamic Programming (GRAD), and Distributed Integer Partition Graph Search (DIPS). The key difference from previous work is that SMART uses offline phases to optimize the choice of coalitions to evaluate, leading to faster run times.",
                "paper-title": "Faster Optimal Coalition Structure Generation via Offline Coalition Selection and Graph-Based Search",
                "image-path": ""
            },

            {
                "startTime": "24:10",
                "arxivId": "2407.16048",
                "arxivLink": "https://arxiv.org/abs/2407.16048",
                "title": "Time Series Feature Selection: A Hierarchical Approach to Pruning Redundancy",
                "institute": "University of Toronto",
                "text": "This research introduces a hierarchical feature selection method called HEIRVAR that combines E-ROCKET with ANOVA to reduce redundant features in time series classification. This approach differs from previous work by using ANOVA to further refine the features selected by E-ROCKET, resulting in a more efficient and accurate model.",
                "paper-title": "HIERVAR: A Hierarchical Feature Selection Method for Time Series Analysis",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 53,
        "num_total": 269,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202407241620_audio.mp3"
}
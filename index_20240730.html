
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ribbit Ribbit - Fresh AI Paper Top Picks</title>
    <meta name="description"
        content="Discover top ArXiv papers in AI and machine learning daily with our fresh picks. Browse easily through tweet-sized summaries or listen on-the-go. Make learning engaging and accessible anytime, anywhere.">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Amatic+SC:wght@400;700&family=Dosis:wght@200..800&family=Roboto:wght@300..700&display=swap">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
    <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>
</head>

<body>
    <div id="headerId" class="header"></div>
    <div class="container">
        <div id="topblock">
            <div style="height: 80px;"></div>
            <div class="institute-text" style="padding-top: 3px; line-height: 1.2;">
                Freshest
                Top Picks:
                <span class="highlightNumber" style="font-size: 28px;">86</span> out of <span
                    class="highlightNumber">454</span> arXiv AI
                papers
            </div>
            <div style="display: flex; flex-direction: column; justify-content: flex-start; align-items: flex-start;">
                <div class="institute-text" style="line-height: 1.2;">just released on</div>
                <div id="data-default-date" data-date="2024-07-30"></div>
                <input type="text" id="selectedDate" style="text-decoration: underline;" />
            </div>
            <div style=" height: 10px;">
            </div>
        </div>

<div class="tweet" id="tweet0">
 <div class="start-time-icon" title="Play from here">
  00:48
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20080" target="_blank">
    @arXiv 2407.20080
   </a>
   <span class="tweet-title">
    TTA's Got Talent: A Unified Benchmark for Test-Time Adaptation
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new benchmark, UniTTA, for evaluating Test-Time Adaptation (TTA) methods. UniTTA is unique because it considers both domain and class shifts, creating a more realistic and comprehensive evaluation environment compared to previous benchmarks.
  </div>
 </div>
</div>
<div class="tweet" id="tweet1">
 <div class="start-time-icon" title="Play from here">
  01:10
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19564" target="_blank">
    @arXiv 2407.19564
   </a>
   <span class="tweet-title">
    Motion Forecasting:  A Fine-Tuned Dance of Parameters
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Bonn, Stanford University, École Polytechnique Fédérale de Lausanne
   </span>
  </div>
  <div class="primary-text">
   This research introduces Forecast-PEFT, a parameter-efficient fine-tuning strategy for pre-trained motion forecasting models. Unlike traditional full fine-tuning methods, Forecast-PEFT freezes most of the model's parameters, focusing adjustments on newly introduced prompts and adapters. This approach preserves pre-learned representations and significantly reduces the number of parameters that need retraining, thereby enhancing efficiency.
  </div>
 </div>
</div>
<div class="tweet" id="tweet2">
 <div class="start-time-icon" title="Play from here">
  01:39
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19409" target="_blank">
    @arXiv 2407.19409
   </a>
   <span class="tweet-title">
    Shrinking Super Brains: How to Make Tiny Multimodal AI Models That Still Rock!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Peking University, Nanyang Technological University, UC Merced
   </span>
  </div>
  <div class="primary-text">
   This research focuses on knowledge distillation for multimodal large language models (MLLMs), specifically exploring what factors are most important in training smaller, more efficient MLLMs while retaining their ability to understand both text and images. Unlike previous work that focused on specific tasks or model architectures, this study investigates a broader range of distillation techniques and their impact on MLLM performance.
  </div>
 </div>
</div>
<div class="tweet" id="tweet3">
 <div class="start-time-icon" title="Play from here">
  02:09
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19055" target="_blank">
    @arXiv 2407.19055
   </a>
   <span class="tweet-title">
    LLMs Learn to Debug:  A Tree Search for Code-Writing Perfection
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    NVIDIA
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel algorithm called BESTER, which uses a best-first tree search approach to enable LLMs to debug their own code by iteratively generating self-reflections and program repairs. This differs from previous work that primarily focused on single-shot code generation or simpler self-reflection techniques.
  </div>
 </div>
</div>
<div class="tweet" id="tweet4">
 <div class="start-time-icon" title="Play from here">
  02:33
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20230" target="_blank">
    @arXiv 2407.20230
   </a>
   <span class="tweet-title">
    Reinforcement Learning's New Trick: Split, Aggregate, and Conquer!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Carnegie Mellon University
   </span>
  </div>
  <div class="primary-text">
   This paper introduces a new on-policy reinforcement learning algorithm called SAPG that leverages large-scale parallel environments by splitting them into chunks and fusing them back together via importance sampling. This approach differs from previous methods that typically train a single policy across all environments, leading to wasted data.
  </div>
 </div>
</div>
<div class="tweet" id="tweet5">
 <div class="start-time-icon" title="Play from here">
  03:03
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19359" target="_blank">
    @arXiv 2407.19359
   </a>
   <span class="tweet-title">
    Forecasting Your Future: How AI Learns to Pick the Best Medical Data for Predictions
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Google
   </span>
  </div>
  <div class="primary-text">
   This research introduces a method for automatically selecting the most relevant auxiliary tasks for pretraining a model for clinical outcome prediction. Unlike previous work that uses all available data or relies on manual selection, this approach uses a nested-loop meta-learning process to learn the optimal task weights.
  </div>
 </div>
</div>
<div class="tweet" id="tweet6">
 <div class="start-time-icon" title="Play from here">
  03:23
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19014" target="_blank">
    @arXiv 2407.19014
   </a>
   <span class="tweet-title">
    Semantic Segmentation Gets a Speed Boost with Sparse Refinement!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    MIT, NVIDIA, Tsinghua University...
   </span>
  </div>
  <div class="primary-text">
   This paper introduces SparseRefine, a method that enhances low-resolution semantic segmentation predictions with sparse high-resolution refinements. Unlike previous work that focuses on dense refinements, SparseRefine selectively refines only a sparse set of pixels, leading to significant computational savings.
  </div>
 </div>
</div>
<div class="tweet" id="tweet7">
 <div class="start-time-icon" title="Play from here">
  03:49
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19325" target="_blank">
    @arXiv 2407.19325
   </a>
   <span class="tweet-title">
    Language Models:  No Critical Period for Learning?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    ETH Zürich
   </span>
  </div>
  <div class="primary-text">
   This study investigates the critical period for language acquisition in language models (LMs) by training them on bilingual data with varying ages of exposure to the second language. Unlike previous work that focused on fine-tuning pre-trained models, this research trains LMs from scratch, providing a more controlled environment for studying the critical period.
  </div>
 </div>
</div>
<div class="tweet" id="tweet8">
 <div class="start-time-icon" title="Play from here">
  04:08
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20034" target="_blank">
    @arXiv 2407.20034
   </a>
   <span class="tweet-title">
    MaskInversion:  Giving CLIP a Local Makeover!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Bonn, Goethe University Frankfurt, University of Oxford...
   </span>
  </div>
  <div class="primary-text">
   MaskInversion learns a localized embedding for a specific image region without modifying the pre-trained vision-language model. This differs from previous methods that either fine-tune the model or rely on simple cropping or token aggregation.
  </div>
 </div>
</div>
<div class="tweet" id="tweet9">
 <div class="start-time-icon" title="Play from here">
  04:39
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.18940" target="_blank">
    @arXiv 2407.18940
   </a>
   <span class="tweet-title">
    Scientists Build a Search Engine for Research Papers, and It's Actually Pretty Smart!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Princeton University
   </span>
  </div>
  <div class="primary-text">
   This research introduces LitSearch, a new benchmark for evaluating scientific literature search systems. Unlike previous benchmarks that focus on specific tasks like citation recommendation, LitSearch uses realistic literature search questions that researchers actually ask.
  </div>
 </div>
</div>
<div class="tweet" id="tweet10">
 <div class="start-time-icon" title="Play from here">
  04:57
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.18982" target="_blank">
    @arXiv 2407.18982
   </a>
   <span class="tweet-title">
    Deep Learning's Speed Demon: Secure MPC Gets a Turbo Boost!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research proposes a new method for reducing communication latency in secure multi-party computation (MPC) protocols used for privacy-preserving deep learning. The key innovation lies in optimizing multivariate multiplication by leveraging pre-shared information and reducing communication rounds. This approach differs from previous work that focused on improving polynomial computations within finite rings.
  </div>
 </div>
</div>
<div class="tweet" id="tweet11">
 <div class="start-time-icon" title="Play from here">
  05:17
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20228" target="_blank">
    @arXiv 2407.20228
   </a>
   <span class="tweet-title">
    Vision Models Get a Brain Boost: FlexAttention Makes High-Res Images a Breeze!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Massachusetts, Princeton University
   </span>
  </div>
  <div class="primary-text">
   This paper introduces FlexAttention, a new attention mechanism that allows vision-language models to efficiently process high-resolution images. Unlike previous methods that process all high-resolution tokens, FlexAttention dynamically selects a small subset of relevant tokens, significantly reducing computational cost.
  </div>
 </div>
</div>
<div class="tweet" id="tweet12">
 <div class="start-time-icon" title="Play from here">
  05:43
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19594" target="_blank">
    @arXiv 2407.19594
   </a>
   <span class="tweet-title">
    LLMs Judge Themselves: A Meta-Rewarding Approach to Self-Improvement
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Meta, University of California  Berkeley, New York University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel "Meta-Rewarding" approach to self-improvement in LLMs. Unlike previous methods that focus on improving the model's responses, this paper trains the model to judge its own judgments, leading to a more refined understanding of instructions and better responses.
  </div>
 </div>
</div>
<div class="tweet" id="tweet13">
 <div class="start-time-icon" title="Play from here">
  06:17
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20219" target="_blank">
    @arXiv 2407.20219
   </a>
   <span class="tweet-title">
    SfM Gets a Global Makeover:  Faster, More Accurate 3D Reconstruction!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    ETH Zurich, Microsoft
   </span>
  </div>
  <div class="primary-text">
   This paper proposes a new global SfM system called GLOMAP that directly combines camera and point position estimation in a single step, eliminating the need for separate translation averaging and triangulation. This approach is different from previous global SfM systems, which typically perform these steps individually.
  </div>
 </div>
</div>
<div class="tweet" id="tweet14">
 <div class="start-time-icon" title="Play from here">
  06:36
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19371" target="_blank">
    @arXiv 2407.19371
   </a>
   <span class="tweet-title">
    Predicting Patient Doom: A Deep Dive into Correlated Time-to-Event Predictions
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Google
   </span>
  </div>
  <div class="primary-text">
   This research proposes a deep latent state-space generative model to capture the interactions among multiple types of correlated clinical events. Unlike previous work that focuses on single event prediction, this model simultaneously predicts mortality risk and organ failure risk trajectories by leveraging the temporal correlations between past measurements and clinical interventions.
  </div>
 </div>
</div>
<div class="tweet" id="tweet15">
 <div class="start-time-icon" title="Play from here">
  07:01
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19778" target="_blank">
    @arXiv 2407.19778
   </a>
   <span class="tweet-title">
    AI for Bioimages:  From Pixels to Insights, One Prompt at a Time!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Peking University
   </span>
  </div>
  <div class="primary-text">
   This research proposes using Multimodal Large Language Models (MLLMs) for bioimage analysis, going beyond traditional image processing methods by integrating diverse information sources like text, metadata, and even experimental protocols.
  </div>
 </div>
</div>
<div class="tweet" id="tweet16">
 <div class="start-time-icon" title="Play from here">
  07:32
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19389" target="_blank">
    @arXiv 2407.19389
   </a>
   <span class="tweet-title">
    Federated Learning Gets a Makeover:  Importance-Aware Submodels to the Rescue!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Purdue University, Google
   </span>
  </div>
  <div class="primary-text">
   This research proposes a new method called FIARSE for federated learning that dynamically adjusts submodels based on the importance of model parameters. Unlike previous static and dynamic submodel extraction methods, FIARSE doesn't require additional information beyond the model parameters themselves to determine parameter importance, reducing overhead on clients.
  </div>
 </div>
</div>
<div class="tweet" id="tweet17">
 <div class="start-time-icon" title="Play from here">
  07:57
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.18957" target="_blank">
    @arXiv 2407.18957
   </a>
   <span class="tweet-title">
    AI Stockbrokers: Can LLMs Predict the Market?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Liverpool, Peking University, Rutgers University...
   </span>
  </div>
  <div class="primary-text">
   This research introduces StockAgent, a multi-agent AI system that uses large language models (LLMs) to simulate real-world stock trading environments. Unlike previous work, StockAgent focuses on the impact of external factors, such as macroeconomic events and company fundamentals, on trading behavior.
  </div>
 </div>
</div>
<div class="tweet" id="tweet18">
 <div class="start-time-icon" title="Play from here">
  08:25
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20060" target="_blank">
    @arXiv 2407.20060
   </a>
   <span class="tweet-title">
    Relational Databases Get a Deep Learning Makeover: No More Feature Engineering!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Stanford University, Kumo.AI, Max Planck Institute for Informatics
   </span>
  </div>
  <div class="primary-text">
   This research introduces RELBENCH, a benchmark for relational deep learning (RDL). Unlike previous work that focused on manual feature engineering, RDL uses graph neural networks to learn predictive models directly from relational databases.
  </div>
 </div>
</div>
<div class="tweet" id="tweet19">
 <div class="start-time-icon" title="Play from here">
  08:53
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19115" target="_blank">
    @arXiv 2407.19115
   </a>
   <span class="tweet-title">
    RNNs Go Parallel:  Newton's Method Gets a Speed Boost!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Stanford University
   </span>
  </div>
  <div class="primary-text">
   This research builds upon DEER, a method for parallelizing nonlinear RNNs, by introducing quasi-Newton approximations and a connection between damped Newton's method and Kalman smoothing to improve scalability and stability.
  </div>
 </div>
</div>
<div class="tweet" id="tweet20">
 <div class="start-time-icon" title="Play from here">
  09:16
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19548" target="_blank">
    @arXiv 2407.19548
   </a>
   <span class="tweet-title">
    Cycle3D:  Image-to-3D Generation Gets a Consistency Makeover!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Peking University, Pengcheng Laboratory, National University of Singapore
   </span>
  </div>
  <div class="primary-text">
   This paper introduces Cycle3D, a framework that combines a pre-trained 2D diffusion model with a 3D reconstruction model during the multi-step diffusion process. This differs from previous methods that rely solely on multi-view diffusion models, which often struggle to generate consistent multi-view images.
  </div>
 </div>
</div>
<div class="tweet" id="tweet21">
 <div class="start-time-icon" title="Play from here">
  09:48
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.18990" target="_blank">
    @arXiv 2407.18990
   </a>
   <span class="tweet-title">
    LLM Tuning:  Hyperparameter Hunt for the Perfect Fit!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    IBM
   </span>
  </div>
  <div class="primary-text">
   This research focuses on providing practical recommendations for hyperparameter configurations when fine-tuning LLMs, using a comprehensive grid search across a wide range of datasets and tasks. Unlike previous studies that often focused on a limited set of datasets or tasks, this paper aims to provide more robust recommendations for real-world applications.
  </div>
 </div>
</div>
<div class="tweet" id="tweet22">
 <div class="start-time-icon" title="Play from here">
  10:09
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20057" target="_blank">
    @arXiv 2407.20057
   </a>
   <span class="tweet-title">
    Daily CO2 Emissions: Hotter Days, Hotter Planet, Hotter Headaches
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research reconstructs global daily CO2 emissions from 1970 to 2022 using a machine learning algorithm, providing a higher temporal resolution than previous datasets.
  </div>
 </div>
</div>
<div class="tweet" id="tweet23">
 <div class="start-time-icon" title="Play from here">
  10:46
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19633" target="_blank">
    @arXiv 2407.19633
   </a>
   <span class="tweet-title">
    AI Solves Optimization Problems: No More Math Headaches!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Stanford University
   </span>
  </div>
  <div class="primary-text">
   This research introduces OptiMUS-0.3, a system that uses a modular approach to break down complex optimization problems into smaller, manageable chunks. This differs from previous work that relied on single prompts for LLMs, which struggled with long and complex problems.
  </div>
 </div>
</div>
<div class="tweet" id="tweet24">
 <div class="start-time-icon" title="Play from here">
  11:14
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19777" target="_blank">
    @arXiv 2407.19777
   </a>
   <span class="tweet-title">
    Agnostic Learning: ERM Gets a Reality Check (and a New Algorithm)
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Aarhus University, UC Berkeley
   </span>
  </div>
  <div class="primary-text">
   This paper revisits agnostic PAC learning, a model for studying supervised learning. It shows that Empirical Risk Minimization (ERM), a common learning algorithm, is sub-optimal when the error of the best hypothesis is considered as a parameter. The paper then introduces a new, improper learning algorithm that outperforms ERM for almost the full range of error values.
  </div>
 </div>
</div>
<div class="tweet" id="tweet25">
 <div class="start-time-icon" title="Play from here">
  11:39
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19284" target="_blank">
    @arXiv 2407.19284
   </a>
   <span class="tweet-title">
    Fake It 'Til You Make It:  How Synthetic Tumors Are Helping Doctors See Pancreatic Cancer Better
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Northwestern University, Mayo Clinic
   </span>
  </div>
  <div class="primary-text">
   This research focuses on the impact of synthetic tumor size and boundary precision on the performance of pancreatic tumor segmentation models. Unlike previous studies that primarily focused on generating realistic tumor textures, this paper investigates the influence of these specific factors on model accuracy.
  </div>
 </div>
</div>
<div class="tweet" id="tweet26">
 <div class="start-time-icon" title="Play from here">
  12:00
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19280" target="_blank">
    @arXiv 2407.19280
   </a>
   <span class="tweet-title">
    Driving with Chatbots: LLMs Take the Wheel!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    The University of Tokyo
   </span>
  </div>
  <div class="primary-text">
   This research explores the use of Large Language Models (LLMs) in autonomous driving systems, focusing on their application in both modular decision-making pipelines and end-to-end driving systems. It differs from previous work by systematically reviewing the latest progress of LLMs in AD and proposing a taxonomy analysis framework covering perception, decision-making, planning, and control.
  </div>
 </div>
</div>
<div class="tweet" id="tweet27">
 <div class="start-time-icon" title="Play from here">
  12:29
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19523" target="_blank">
    @arXiv 2407.19523
   </a>
   <span class="tweet-title">
    Meta-Learning Gets a Game-Changing Makeover: Adversarial Task Distribution Generation!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel approach to meta-learning by explicitly modeling task distribution shifts using normalizing flows. Unlike previous work that relies on hand-crafted or simple prior distributions, this method generates task distributions adversarially, aiming to improve the robustness of fast adaptation.
  </div>
 </div>
</div>
<div class="tweet" id="tweet28">
 <div class="start-time-icon" title="Play from here">
  12:59
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20198" target="_blank">
    @arXiv 2407.20198
   </a>
   <span class="tweet-title">
    Fetal Brain Motion:  A Deep Dive into Equivariant Representations
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Boston Children's Hospital, Harvard Medical School, Northeastern University...
   </span>
  </div>
  <div class="primary-text">
   This research introduces SpaER, a method for fetal motion tracking that dynamically learns spatio-temporal representations using equivariant filters and self-attention mechanisms. Unlike previous approaches that statically estimate motion from image pairs, SpaER tracks the rigid movement patterns of the fetal head across time and space.
  </div>
 </div>
</div>
<div class="tweet" id="tweet29">
 <div class="start-time-icon" title="Play from here">
  13:26
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19269" target="_blank">
    @arXiv 2407.19269
   </a>
   <span class="tweet-title">
    Ellipsoid Fitting:  A Bayesian Approach to Outlier-Proofing in High Dimensions
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Chinese Academy of Sciences, Peking University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a Bayesian approach to fitting multidimensional ellipsoids, which differs from previous methods by considering each model point as a potential source for generating each measurement sample. This approach enhances robustness against noise and outliers, particularly in higher-dimensional spaces.
  </div>
 </div>
</div>
<div class="tweet" id="tweet30">
 <div class="start-time-icon" title="Play from here">
  13:51
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19605" target="_blank">
    @arXiv 2407.19605
   </a>
   <span class="tweet-title">
    Look Hear, See There: AI Predicts Your Gaze as You Listen to Instructions
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Stony Brook University, UC Berkeley, Waymo LLC...
   </span>
  </div>
  <div class="primary-text">
   This research focuses on predicting human gaze during an incremental object referral task, where a person is asked to find a specific object in an image while listening to a spoken description. This differs from previous work that either predicted gaze during free viewing or during a standard object referral task where the entire description is provided at once.
  </div>
 </div>
</div>
<div class="tweet" id="tweet31">
 <div class="start-time-icon" title="Play from here">
  14:21
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19422" target="_blank">
    @arXiv 2407.19422
   </a>
   <span class="tweet-title">
    AI Therapists: Can Robots Really Help You Feel Better?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Beijing University of Technology, Wuhan University, The Hong Kong Polytechnic University...
   </span>
  </div>
  <div class="primary-text">
   This research provides a comprehensive review of AI's role in enhancing CBT across various stages, from pre-treatment assessment to post-treatment follow-up, which is a unique contribution compared to previous reviews that focused mainly on specific applications.
  </div>
 </div>
</div>
<div class="tweet" id="tweet32">
 <div class="start-time-icon" title="Play from here">
  14:44
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20121" target="_blank">
    @arXiv 2407.20121
   </a>
   <span class="tweet-title">
    Say Goodbye to Bad Recommendations: A New Framework for Cross-Domain Interest Transfer
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Meituan, Peking University
   </span>
  </div>
  <div class="primary-text">
   This research introduces an explicit interest transfer framework called EXIT, which uses supervised learning to model the transfer of user interests across different domains. Unlike previous implicit methods, EXIT directly learns which interests from the source domain are beneficial to the target domain, preventing negative transfer.
  </div>
 </div>
</div>
<div class="tweet" id="tweet33">
 <div class="start-time-icon" title="Play from here">
  15:05
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20105" target="_blank">
    @arXiv 2407.20105
   </a>
   <span class="tweet-title">
    Language Models:  No More Copycats, Just Creative Cats!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    ETH Zurich
   </span>
  </div>
  <div class="primary-text">
   This paper proposes a new algorithm called Copyright-Protecting Fusion (CP-Fuse) that combines multiple language models to minimize the reproduction of copyrighted material. Unlike previous work that focuses on mitigating memorization during training, CP-Fuse intervenes during the inference phase, adaptively adjusting the weights of the models based on the generated sequence history.
  </div>
 </div>
</div>
<div class="tweet" id="tweet34">
 <div class="start-time-icon" title="Play from here">
  15:29
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20164" target="_blank">
    @arXiv 2407.20164
   </a>
   <span class="tweet-title">
    Robots That Understand You:  New AI Makes Multi-Robot Teams Talk and Work Together!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Cambridge
   </span>
  </div>
  <div class="primary-text">
   This research presents a method for training multi-robot navigation policies that can interpret and follow natural language instructions. Unlike previous work that relies on LLMs within the control loop, this approach conditions policies on embeddings from pretrained LLMs, allowing for low-latency control.
  </div>
 </div>
</div>
<div class="tweet" id="tweet35">
 <div class="start-time-icon" title="Play from here">
  15:55
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20021" target="_blank">
    @arXiv 2407.20021
   </a>
   <span class="tweet-title">
    Attention, Please! New Method Makes Vision Transformers Slimmer Without Data
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Seoul National University, Google, Korea Advanced Institute of Science and Technology
   </span>
  </div>
  <div class="primary-text">
   This research focuses on data-free quantization of Vision Transformers (ViTs), a technique that makes these powerful models more efficient for use on devices with limited resources. Unlike previous methods that struggle with low-bit quantization, this paper proposes a novel approach that leverages the similarity between attention maps across different heads within the ViT architecture.
  </div>
 </div>
</div>
<div class="tweet" id="tweet36">
 <div class="start-time-icon" title="Play from here">
  16:26
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19838" target="_blank">
    @arXiv 2407.19838
   </a>
   <span class="tweet-title">
    RNA Design: Flow Matching Makes It Flow!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research introduces RNACG, a universal RNA sequence generation model based on flow matching. Unlike previous methods that focus on specific tasks, RNACG can handle various conditional inputs, making it more versatile.
  </div>
 </div>
</div>
<div class="tweet" id="tweet37">
 <div class="start-time-icon" title="Play from here">
  16:52
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19155" target="_blank">
    @arXiv 2407.19155
   </a>
   <span class="tweet-title">
    Graph Attack:  When AI Goes Rogue, It's Biased Towards Training Data!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Korea Advanced Institute of Science and Technology
   </span>
  </div>
  <div class="primary-text">
   This research identifies a bias in existing graph poisoning attacks, where they primarily target edges connected to training nodes. The paper proposes a new attack method, Metacon, which uses contrastive surrogate objectives to alleviate this bias and target a wider range of edges.
  </div>
 </div>
</div>
<div class="tweet" id="tweet38">
 <div class="start-time-icon" title="Play from here">
  17:19
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19370" target="_blank">
    @arXiv 2407.19370
   </a>
   <span class="tweet-title">
    Click, Click, Boom!  New AI Makes Grasping More Controllable
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Peking University, University of Central Florida
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new method called Semantic Contact Map (SCM) for controllable grasp generation. Unlike previous methods that rely on general contact information, SCM provides fine-grained details about finger-object interactions, allowing for more precise control over how a hand grasps an object.
  </div>
 </div>
</div>
<div class="tweet" id="tweet39">
 <div class="start-time-icon" title="Play from here">
  17:55
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.18992" target="_blank">
    @arXiv 2407.18992
   </a>
   <span class="tweet-title">
    AI Recipe Book:  LLMs Cook Up Asset Management Solutions
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    IBM
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel approach to automated solution recipe generation for industrial asset management by leveraging Large Language Models (LLMs) and a taxonomy-guided prompting process. This differs from previous work by automating the creation of solution recipes, which traditionally required extensive collaboration between data scientists and domain experts.
  </div>
 </div>
</div>
<div class="tweet" id="tweet40">
 <div class="start-time-icon" title="Play from here">
  18:15
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20083" target="_blank">
    @arXiv 2407.20083
   </a>
   <span class="tweet-title">
    Word Completion Gets a Boost: Energy-Based Model Makes Translation a Breeze!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University, Tencent
   </span>
  </div>
  <div class="primary-text">
   This research proposes an energy-based model for word-level autocompletion in computer-aided translation. Unlike previous classification models, this approach directly defines the energy function on top of both the input context and the candidate target word, allowing it to capture more valuable information from the source sentence.
  </div>
 </div>
</div>
<div class="tweet" id="tweet41">
 <div class="start-time-icon" title="Play from here">
  18:41
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19415" target="_blank">
    @arXiv 2407.19415
   </a>
   <span class="tweet-title">
    Music for Your Videos: A New Loss Function That's Not All Noise!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University, University of Science and Technology of China
   </span>
  </div>
  <div class="primary-text">
   This research introduces an inter-intra modal loss (II Loss) to address the issue of noisy data in self-supervised cross-modal retrieval. Unlike previous methods that focus solely on minimizing the distance between positive samples, II Loss also minimizes variations in feature distributions within each modality, effectively mitigating overfitting to noisy data.
  </div>
 </div>
</div>
<div class="tweet" id="tweet42">
 <div class="start-time-icon" title="Play from here">
  19:11
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19451" target="_blank">
    @arXiv 2407.19451
   </a>
   <span class="tweet-title">
    Hair Today, Gone Tomorrow: New Model Makes 3D Hair Editing a Breeze!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Yale University, Adobe Research, CAU...
   </span>
  </div>
  <div class="primary-text">
   This research introduces Perm, a parametric model for 3D hair that disentangles global hair shape and local strand details using a PCA-based strand representation in the frequency domain. This differs from previous work that jointly models these aspects, limiting editing capabilities.
  </div>
 </div>
</div>
<div class="tweet" id="tweet43">
 <div class="start-time-icon" title="Play from here">
  19:37
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19984" target="_blank">
    @arXiv 2407.19984
   </a>
   <span class="tweet-title">
    AI Diagnoses Depression &amp; Alzheimer's, But How Confident Are We?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Cambridge, Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel Bayesian approach for confidence estimation in automatic detection of Alzheimer's disease and depression, using a dynamic Dirichlet prior distribution to model the second-order probability of the predictive distribution. This differs from previous work that relied on standard neural network classifiers with softmax activation, which often struggle with reliable uncertainty estimations.
  </div>
 </div>
</div>
<div class="tweet" id="tweet44">
 <div class="start-time-icon" title="Play from here">
  20:04
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19474" target="_blank">
    @arXiv 2407.19474
   </a>
   <span class="tweet-title">
    Visual Riddles:  Can AI Crack These Brain Teasers?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Ben-Gurion University of the Negev, Google
   </span>
  </div>
  <div class="primary-text">
   This research introduces Visual Riddles, a benchmark that uses synthetic images generated specifically for the challenge, rather than relying on pre-existing images. This approach allows for a wider range of scenarios and more creative freedom in designing riddles.
  </div>
 </div>
</div>
<div class="tweet" id="tweet45">
 <div class="start-time-icon" title="Play from here">
  20:31
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19829" target="_blank">
    @arXiv 2407.19829
   </a>
   <span class="tweet-title">
    E-commerce Search Gets a Makeover:  Generative Retrieval with a Preference for Clicks!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    JD.com, Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research proposes a novel framework for e-commerce search called "generative retrieval with preference optimization" (GenR-PO). Unlike traditional methods that rely on dense representations of queries and items, GenR-PO directly generates identifiers of target items using an autoregressive language model. This approach simplifies the generation process by transforming the task of generating lengthy item titles from short queries into a task of generating multi-span identifiers.
  </div>
 </div>
</div>
<div class="tweet" id="tweet46">
 <div class="start-time-icon" title="Play from here">
  21:02
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.18941" target="_blank">
    @arXiv 2407.18941
   </a>
   <span class="tweet-title">
    Label Errors?  LEMON Squeezes Out the Noise!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    MIT
   </span>
  </div>
  <div class="primary-text">
   This research proposes LEMON, a method for identifying label errors in multimodal datasets. Unlike previous work that focuses on unimodal representations, LEMON leverages the neighborhood structure of contrastively pretrained multimodal embeddings.
  </div>
 </div>
</div>
<div class="tweet" id="tweet47">
 <div class="start-time-icon" title="Play from here">
  21:25
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19547" target="_blank">
    @arXiv 2407.19547
   </a>
   <span class="tweet-title">
    Diffusion Models:  Time Travel for Better Images?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    SenseTime Research, Beihang University, Monash University...
   </span>
  </div>
  <div class="primary-text">
   This research focuses on the unique temporal features in diffusion models, which are crucial for image generation. Unlike previous work, it proposes a framework that specifically addresses the disturbance caused by quantization on these features.
  </div>
 </div>
</div>
<div class="tweet" id="tweet48">
 <div class="start-time-icon" title="Play from here">
  21:58
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.18962" target="_blank">
    @arXiv 2407.18962
   </a>
   <span class="tweet-title">
    Robots on a Roll: Deep Learning Makes Path Planning a Breeze!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Northeastern University, NYU, Peking University
   </span>
  </div>
  <div class="primary-text">
   This research focuses on using the Deep Deterministic Policy Gradient (DDPG) algorithm for autonomous navigation, which is different from previous work that used Deep Q-Network (DQN) and Double Deep Q-Network (DDQN) algorithms. The DDPG algorithm is specifically designed for continuous action spaces, making it more suitable for path planning tasks where the robot needs to make smooth and continuous movements.
  </div>
 </div>
</div>
<div class="tweet" id="tweet49">
 <div class="start-time-icon" title="Play from here">
  22:25
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20157" target="_blank">
    @arXiv 2407.20157
   </a>
   <span class="tweet-title">
    LLMs for Tables: A New Framework for Relational Table Learning
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Shanghai Jiao Tong University, Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research introduces rLLM, a framework for relational table learning (RTL) that combines modules from graph neural networks (GNNs), large language models (LLMs), and table neural networks (TNNs). This approach differs from previous work by providing a standardized way to construct novel RTL models using a "combine, align, and co-train" strategy.
  </div>
 </div>
</div>
<div class="tweet" id="tweet50">
 <div class="start-time-icon" title="Play from here">
  22:54
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20061" target="_blank">
    @arXiv 2407.20061
   </a>
   <span class="tweet-title">
    Quantum Dots Get a Helping Hand: AI-Free Bootstrapping for Faster Qubit Tuning
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    National Institute of Standards and Technology
   </span>
  </div>
  <div class="primary-text">
   This research focuses on automating the initial setup of quantum dot devices, a crucial step before more complex qubit operations. Unlike previous work that relied on machine learning, this approach uses physics-based heuristics, making it more interpretable and less prone to unexpected failures.
  </div>
 </div>
</div>
<div class="tweet" id="tweet51">
 <div class="start-time-icon" title="Play from here">
  23:19
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19035" target="_blank">
    @arXiv 2407.19035
   </a>
   <span class="tweet-title">
    Gaussian Splatting Gets a Boost: 3D Content Creation Goes Super-Fast!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    East China University of Science and Technology, University of Washington, University of Copenhagen
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new 3D content creation framework called ScalingGaussian, which combines 3D and 2D diffusion models to generate detailed textures and geometric consistency in 3D assets. Unlike previous methods that rely solely on 3D diffusion, ScalingGaussian leverages the strengths of both 3D and 2D diffusion models, resulting in a more efficient and effective approach.
  </div>
 </div>
</div>
<div class="tweet" id="tweet52">
 <div class="start-time-icon" title="Play from here">
  23:51
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20177" target="_blank">
    @arXiv 2407.20177
   </a>
   <span class="tweet-title">
    LLMs on a Diet: AutoScale Finds the Perfect Data Recipe for Training
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Virginia Tech, University of Illinois, University of Washington...
   </span>
  </div>
  <div class="primary-text">
   This research proposes AutoScale, a tool that automatically determines the optimal data composition for training LLMs at any desired scale. Unlike previous work that optimizes data composition for smaller proxy models, AutoScale leverages scaling laws to predict optimal compositions for larger models, eliminating the need for expensive re-training.
  </div>
 </div>
</div>
<div class="tweet" id="tweet53">
 <div class="start-time-icon" title="Play from here">
  24:15
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19866" target="_blank">
    @arXiv 2407.19866
   </a>
   <span class="tweet-title">
    Deep Image Priors:  MRF Gets a Speed Boost!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Bristol, INFN Pisa, University of Bath...
   </span>
  </div>
  <div class="primary-text">
   This research introduces BARDIP, a new method for MRF reconstruction that uses a pretrained Bloch-consistent denoising autoencoder (BDAE) to improve speed and accuracy compared to previous DIP-MRF approaches.
  </div>
 </div>
</div>
<div class="tweet" id="tweet54">
 <div class="start-time-icon" title="Play from here">
  24:38
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.18946" target="_blank">
    @arXiv 2407.18946
   </a>
   <span class="tweet-title">
    Doggy Dance Moves: AI Learns to Align Motion Across Species
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Meta, ETH Zurich
   </span>
  </div>
  <div class="primary-text">
   This research proposes a new approach for understanding motion datasets that is independent of the character's morphology and skeletal structure. Unlike previous methods that rely on sparse high-dimensional latent spaces, this paper introduces a phase manifold consisting of multiple closed curves, each representing a latent amplitude. This allows for a more compact and structured representation of motion, enabling alignment across different characters.
  </div>
 </div>
</div>
<div class="tweet" id="tweet55">
 <div class="start-time-icon" title="Play from here">
  25:10
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19039" target="_blank">
    @arXiv 2407.19039
   </a>
   <span class="tweet-title">
    Tokenizing Molecules:  BPE Goes From Words to Graphs!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    CMU
   </span>
  </div>
  <div class="primary-text">
   This research proposes GRAPHBPE, a novel tokenization method for molecular graphs that adapts the Byte-Pair Encoding (BPE) algorithm commonly used in Natural Language Processing (NLP). Unlike previous methods that rely on external knowledge or trained neural networks, GRAPHBPE solely utilizes a given molecular graph corpus and is model-agnostic.
  </div>
 </div>
</div>
<div class="tweet" id="tweet56">
 <div class="start-time-icon" title="Play from here">
  25:41
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19937" target="_blank">
    @arXiv 2407.19937
   </a>
   <span class="tweet-title">
    Recommending Restaurants? It's All About the Order!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Fudan University, Microsoft
   </span>
  </div>
  <div class="primary-text">
   This research introduces the "Aspect Order Tree" (AOTree) model, which considers the order in which users evaluate aspects of an item when making a decision. This is different from previous work that primarily focused on the importance of aspects, neglecting their sequential relationship.
  </div>
 </div>
</div>
<div class="tweet" id="tweet57">
 <div class="start-time-icon" title="Play from here">
  26:05
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19410" target="_blank">
    @arXiv 2407.19410
   </a>
   <span class="tweet-title">
    Prompt Compression:  Making AI Code Like a Pro, But Shorter!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tokyo Institute of Technology, National Institute of Informatics, OMRON SINIC X Corporation
   </span>
  </div>
  <div class="primary-text">
   This research introduces AdaCoder, a framework that compresses prompts used in visual programmatic models (VPMs). Unlike previous methods that rely on fine-tuning or additional training, AdaCoder uses a single frozen large language model (LLM) to adaptively select compressed prompts based on the question type.
  </div>
 </div>
</div>
<div class="tweet" id="tweet58">
 <div class="start-time-icon" title="Play from here">
  26:40
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19772" target="_blank">
    @arXiv 2407.19772
   </a>
   <span class="tweet-title">
    Code Tests From Thin Air:  LLMs Get a New Benchmarking Challenge
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    IBM
   </span>
  </div>
  <div class="primary-text">
   This research introduces a method for generating benchmark variations that generalize across coding tasks and programming languages, using Abstract Syntax Trees (ASTs). This approach mitigates the issue of benchmark data leaking into the training data of Large Language Models (LLMs).
  </div>
 </div>
</div>
<div class="tweet" id="tweet59">
 <div class="start-time-icon" title="Play from here">
  27:03
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19094" target="_blank">
    @arXiv 2407.19094
   </a>
   <span class="tweet-title">
    Robots Get a Brain: Vision-Language Models Solve Tasks Without Training!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Northwestern University, Yale University
   </span>
  </div>
  <div class="primary-text">
   This research introduces Wonderful Team, a multi-agent system that uses a single off-the-shelf vision-language model (VLLM) to solve robotic tasks without any prior training. Unlike previous work that relies on fine-tuning or separate vision encoders, Wonderful Team leverages the advanced capabilities of VLLMs to handle all aspects of a robotic task, from high-level planning to low-level action execution.
  </div>
 </div>
</div>
<div class="tweet" id="tweet60">
 <div class="start-time-icon" title="Play from here">
  27:30
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19893" target="_blank">
    @arXiv 2407.19893
   </a>
   <span class="tweet-title">
    Zero-Shot IoT Sensing:  Teaching AI to Smell the Coffee (and Recognize Unseen Things)
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Delft University of Technology, Google, University of Pittsburgh
   </span>
  </div>
  <div class="primary-text">
   This research proposes a novel approach to zero-shot IoT sensing by leveraging foundation models (FMs) and aligning IoT data embeddings with semantic embeddings generated by an FM's text encoder. This differs from previous work by utilizing cross-attention to combine learnable soft prompts and auxiliary hard prompts for effective prompt engineering, and by employing data augmentation to synthesize unseen class IoT data for fine-tuning the IoT feature extractor and embedding projector.
  </div>
 </div>
</div>
<div class="tweet" id="tweet61">
 <div class="start-time-icon" title="Play from here">
  27:54
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19922" target="_blank">
    @arXiv 2407.19922
   </a>
   <span class="tweet-title">
    Sentiment Analysis Gets a Boost: LLMs Explain Currency Pair Predictions
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    IBM
   </span>
  </div>
  <div class="primary-text">
   This research explores using LLMs to explain sentiment analysis results, specifically in the context of predicting currency pair prices. Unlike previous work that focused on sentiment analysis itself, this paper investigates how LLMs can be used to identify key terms that explain the sentiment, enriching the input for more accurate predictions.
  </div>
 </div>
</div>
<div class="tweet" id="tweet62">
 <div class="start-time-icon" title="Play from here">
  28:13
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20229" target="_blank">
    @arXiv 2407.20229
   </a>
   <span class="tweet-title">
    2D Vision Models Get a 3D Makeover: Fine-Tuning with Gaussian Splatting
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    ETH Zurich, Max Planck Institute for Informatics, Google
   </span>
  </div>
  <div class="primary-text">
   This research proposes a novel two-stage approach to improve the 3D understanding of 2D vision models. Unlike previous work that focuses on fusing multi-view 2D features into 3D representations, this paper explores the reverse direction, incorporating 3D awareness into 2D representation learning through fine-tuning.
  </div>
 </div>
</div>
<div class="tweet" id="tweet63">
 <div class="start-time-icon" title="Play from here">
  28:39
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19853" target="_blank">
    @arXiv 2407.19853
   </a>
   <span class="tweet-title">
    Learning to Adapt on the Fly: A New Trick for Multi-Source Domain Adaptation
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Université Paris-Saclay, CEA, École Centrale de Lyon
   </span>
  </div>
  <div class="primary-text">
   This paper introduces a novel approach for online multi-source domain adaptation (MSDA) by leveraging Gaussian Mixture Models (GMMs) and the Wasserstein geometry of Gaussian measures. Unlike previous methods that assume all data is available during training, this work tackles the challenge of adapting to a target domain in a streaming fashion.
  </div>
 </div>
</div>
<div class="tweet" id="tweet64">
 <div class="start-time-icon" title="Play from here">
  29:10
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20020" target="_blank">
    @arXiv 2407.20020
   </a>
   <span class="tweet-title">
    ImagiNet:  Spotting Fake Photos with a Multi-Content Dataset
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Stanford University
   </span>
  </div>
  <div class="primary-text">
   This research introduces ImagiNet, a new dataset for synthetic image detection that includes a wider range of content types and generators compared to previous datasets. This approach aims to address the limitations of existing datasets, which often lack diversity and can lead to biased detectors.
  </div>
 </div>
</div>
<div class="tweet" id="tweet65">
 <div class="start-time-icon" title="Play from here">
  29:42
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19965" target="_blank">
    @arXiv 2407.19965
   </a>
   <span class="tweet-title">
    KNN-MT Gets a Speed Boost:  A Single-Layer Network Makes Translation Faster and More Accurate!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Microsoft
   </span>
  </div>
  <div class="primary-text">
   This research proposes a single-layer neural network for kNN-MT interpolation, which is simpler and faster to train than previous methods. It also integrates kNN-MT into GPU inference, demonstrating its feasibility for large-scale models.
  </div>
 </div>
</div>
<div class="tweet" id="tweet66">
 <div class="start-time-icon" title="Play from here">
  30:03
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19089" target="_blank">
    @arXiv 2407.19089
   </a>
   <span class="tweet-title">
    AI Chemists:  Building Better Drugs with a Million-Word Memory!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Sanofi, Digital Data, Integrated Drug Discovery...
   </span>
  </div>
  <div class="primary-text">
   This research introduces a semi-supervised learning method for many-shot in-context learning (ICL) in molecular inverse design. Unlike previous work, this approach iteratively includes LLM-generated molecules with high predicted performance, along with experimental data, to overcome the lack of available experimental data.
  </div>
 </div>
</div>
<div class="tweet" id="tweet67">
 <div class="start-time-icon" title="Play from here">
  30:33
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19110" target="_blank">
    @arXiv 2407.19110
   </a>
   <span class="tweet-title">
    Fedspeak Decoded: GPT-4 Uncovers Hidden Dissent in FOMC Meetings
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Princeton University, University of Washington, University of Maryland
   </span>
  </div>
  <div class="primary-text">
   This research uses GPT-4 to analyze FOMC transcripts and statements, going beyond previous work that relied on a single document type. It quantifies dissent among committee members, revealing that transcripts contain more disagreement than public statements.
  </div>
 </div>
</div>
<div class="tweet" id="tweet68">
 <div class="start-time-icon" title="Play from here">
  30:59
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19034" target="_blank">
    @arXiv 2407.19034
   </a>
   <span class="tweet-title">
    MangaUB: A Benchmark for Large Multimodal Models to Understand the Art of Comics
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    The University of Tokyo
   </span>
  </div>
  <div class="primary-text">
   This research introduces MangaUB, a new benchmark specifically designed to evaluate the manga understanding capabilities of large multimodal models (LLMs). Unlike previous benchmarks that focus on individual elements like text or characters, MangaUB assesses the LLM's ability to comprehend the narrative conveyed across multiple panels.
  </div>
 </div>
</div>
<div class="tweet" id="tweet69">
 <div class="start-time-icon" title="Play from here">
  31:27
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19396" target="_blank">
    @arXiv 2407.19396
   </a>
   <span class="tweet-title">
    MiniGrid Gets a JAX Makeover: 200,000x Speed Boost for Deep RL!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University College London, Technical University of Berlin, University of Oxford...
   </span>
  </div>
  <div class="primary-text">
   This research introduces NAVIX, a JAX-based reimplementation of the MiniGrid environment suite. Unlike previous work, NAVIX focuses on providing a fully batched and differentiable implementation of the entire MiniGrid suite, enabling significant speedups and scalability for Deep RL training.
  </div>
 </div>
</div>
<div class="tweet" id="tweet70">
 <div class="start-time-icon" title="Play from here">
  31:55
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20199" target="_blank">
    @arXiv 2407.20199
   </a>
   <span class="tweet-title">
    Grokking Modular Arithmetic: It's Not Just for Neural Networks Anymore!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    MIT, Indian Institute of Technology Bombay
   </span>
  </div>
  <div class="primary-text">
   This paper demonstrates that the phenomenon of "grokking" modular arithmetic, previously observed in neural networks, also occurs in Recursive Feature Machines (RFM), an algorithm that uses the Average Gradient Outer Product (AGOP) for feature learning. This finding suggests that grokking is not specific to neural networks or gradient-based optimization methods.
  </div>
 </div>
</div>
<div class="tweet" id="tweet71">
 <div class="start-time-icon" title="Play from here">
  32:27
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19540" target="_blank">
    @arXiv 2407.19540
   </a>
   <span class="tweet-title">
    Missing Data? No Problem! NECHO v2 Predicts Diagnoses with a Knowledge Distillation Twist
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University College London
   </span>
  </div>
  <div class="primary-text">
   This research introduces NECHO v2, a framework that tackles the challenge of predicting patient diagnoses when some medical records are missing. Unlike previous methods, NECHO v2 uses a systematic knowledge distillation approach to transfer knowledge from a teacher model trained on complete data to a student model learning with incomplete data.
  </div>
 </div>
</div>
<div class="tweet" id="tweet72">
 <div class="start-time-icon" title="Play from here">
  32:59
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19072" target="_blank">
    @arXiv 2407.19072
   </a>
   <span class="tweet-title">
    Deep Learning's Got a New Trick: Recognizing Objects by Their Shape, Not Just Their Parts!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Korea University, Fujitsu, MIT
   </span>
  </div>
  <div class="primary-text">
   This research explores the role of "configural processing" in object recognition, where neural networks learn to identify objects based on the spatial relationships between their components, rather than just individual features. This approach is distinct from previous work that primarily focused on local feature-based recognition.
  </div>
 </div>
</div>
<div class="tweet" id="tweet73">
 <div class="start-time-icon" title="Play from here">
  33:23
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19118" target="_blank">
    @arXiv 2407.19118
   </a>
   <span class="tweet-title">
    AI Co-Pilots:  Saving Medical Studies from Bias-Induced Meltdowns!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    UC Berkeley, UCSF, Microsoft Research
   </span>
  </div>
  <div class="primary-text">
   This research proposes using large language models (LLMs) as "causal co-pilots" to assist researchers in identifying and addressing potential biases in medical studies based on real-world data (RWD). This approach differs from previous work by focusing on the collaborative role of LLMs in study design and analysis, rather than solely relying on them for data analysis or interpretation.
  </div>
 </div>
</div>
<div class="tweet" id="tweet74">
 <div class="start-time-icon" title="Play from here">
  33:49
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19256" target="_blank">
    @arXiv 2407.19256
   </a>
   <span class="tweet-title">
    ChatGPT in the ICU: Can AI Really Be a Doctor?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Peking University
   </span>
  </div>
  <div class="primary-text">
   This research differs from previous work by focusing specifically on the application of large language models (LLMs) in critical care medicine (CCM). It provides a comprehensive overview of current applications, challenges, and future directions for LLMs in this field.
  </div>
 </div>
</div>
<div class="tweet" id="tweet75">
 <div class="start-time-icon" title="Play from here">
  34:12
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20067" target="_blank">
    @arXiv 2407.20067
   </a>
   <span class="tweet-title">
    Explaining AI: When It Can't Explain, It's Time to Drop It!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Cambridge
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel approach to GNN training called xAI-Drop, which leverages explainability to identify and exclude noisy network elements during training. Unlike previous dropping methods that rely on random or heuristic-based selection criteria, xAI-Drop uses explainability scores to pinpoint potentially harmful components.
  </div>
 </div>
</div>
<div class="tweet" id="tweet76">
 <div class="start-time-icon" title="Play from here">
  34:33
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19985" target="_blank">
    @arXiv 2407.19985
   </a>
   <span class="tweet-title">
    Vision Transformers on a Diet:  MoNE Makes Models Slimmer Without Losing Sight!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Google
   </span>
  </div>
  <div class="primary-text">
   This research introduces Mixture of Nested Experts (MoNE), a framework that dynamically allocates computational resources to different visual tokens during inference. Unlike previous approaches that process all tokens with the same compute, MoNE uses nested models with varying computational capacities, allowing for more efficient processing.
  </div>
 </div>
</div>
<div class="tweet" id="tweet77">
 <div class="start-time-icon" title="Play from here">
  34:57
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19074" target="_blank">
    @arXiv 2407.19074
   </a>
   <span class="tweet-title">
    Neural Networks:  Solving Geotechnical Problems with a Parsimonious Twist!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    The Hong Kong Polytechnic University, University of Cambridge, University of Leeds
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel parsimonious loss function for physics-informed neural networks (PINNs) to solve complex geotechnical problems. Unlike previous work, this approach simplifies the governing equations and reduces the output dimensions, leading to more accurate and efficient solutions.
  </div>
 </div>
</div>
<div class="tweet" id="tweet78">
 <div class="start-time-icon" title="Play from here">
  35:22
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19048" target="_blank">
    @arXiv 2407.19048
   </a>
   <span class="tweet-title">
    Gravitational Wave Inference Gets a Speed Boost with AI!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    MIT
   </span>
  </div>
  <div class="primary-text">
   This research introduces AMPLFI, a parameter estimation algorithm for gravitational waves that uses likelihood-free inference with normalizing flows. Unlike previous methods, AMPLFI is designed for real-time inference, running alongside a neural-network-based search pipeline.
  </div>
 </div>
</div>
<div class="tweet" id="tweet79">
 <div class="start-time-icon" title="Play from here">
  35:50
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19447" target="_blank">
    @arXiv 2407.19447
   </a>
   <span class="tweet-title">
    Nudging Consent: How England's New Opt-Out System Is Tricking Us All!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University College London, University of Oxford
   </span>
  </div>
  <div class="primary-text">
   This research examines the revised opt-out system for secondary use of health data in England, focusing on how the system's design and communication influence patient choices. It contrasts this approach with previous opt-out systems and explores the potential for "hard paternalism" in this context.
  </div>
 </div>
</div>
<div class="tweet" id="tweet80">
 <div class="start-time-icon" title="Play from here">
  36:14
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20207" target="_blank">
    @arXiv 2407.20207
   </a>
   <span class="tweet-title">
    Stop the Information Loss! New Text Augmentation Framework Makes Dense Retrieval Smarter
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel text augmentation framework called QAEA-DR, which focuses on enhancing the original text itself rather than just improving the embedding model or retrieval process. It utilizes large language models (LLMs) to generate question-answer pairs and element-driven events from the original text, effectively concentrating key information and removing noise.
  </div>
 </div>
</div>
<div class="tweet" id="tweet81">
 <div class="start-time-icon" title="Play from here">
  36:41
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.18949" target="_blank">
    @arXiv 2407.18949
   </a>
   <span class="tweet-title">
    AI Tries to Crack the New Yorker's Caption Contest: Can Machines Be Funny?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Stanford University
   </span>
  </div>
  <div class="primary-text">
   This research focuses on generating humorous captions for New Yorker cartoons, a task that requires understanding not just the visual elements but also cultural nuances and humor. It explores the use of vision transformer encoder-decoder models and compares their performance to GPT-4V, a large language model with multi-modal capabilities.
  </div>
 </div>
</div>
<div class="tweet" id="tweet82">
 <div class="start-time-icon" title="Play from here">
  37:01
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19460" target="_blank">
    @arXiv 2407.19460
   </a>
   <span class="tweet-title">
    Missing Brain Data?  WMG-Diff to the Rescue!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Harvard University
   </span>
  </div>
  <div class="primary-text">
   This research proposes a novel deep learning model called WMG-Diff to impute missing tissue microstructure data in diffusion MRI tractography. Unlike previous methods that rely on random data selection, WMG-Diff leverages the geometric relationships between white matter fiber clusters to guide the imputation process.
  </div>
 </div>
</div>
<div class="tweet" id="tweet83">
 <div class="start-time-icon" title="Play from here">
  37:25
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19618" target="_blank">
    @arXiv 2407.19618
   </a>
   <span class="tweet-title">
    A/B Testing Got a Makeover: Sharing Data Makes Experiments Smarter!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Shanghai Jiao Tong University, MIT
   </span>
  </div>
  <div class="primary-text">
   This research focuses on experiments with local treatments in Markov Decision Processes (MDPs), where the treatment only affects specific states. It introduces a variance reduction technique that leverages this local structure by sharing information across states unaffected by the treatment. This approach contrasts with previous work that typically considers global treatments applied uniformly across all states.
  </div>
 </div>
</div>
<div class="tweet" id="tweet84">
 <div class="start-time-icon" title="Play from here">
  37:49
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.20232" target="_blank">
    @arXiv 2407.20232
   </a>
   <span class="tweet-title">
    Ambiguous Edits?  SANE Makes 'Em Specific!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Télécom Paris  Institut Polytechnique de Paris, University of Oxford
   </span>
  </div>
  <div class="primary-text">
   This paper introduces SANE, a method that uses a large language model (LLM) to break down ambiguous user instructions into specific editing tasks for text-based image editing diffusion models. This differs from previous work by explicitly decomposing instructions rather than relying on implicit concept interpretations learned by visual-language models.
  </div>
 </div>
</div>
<div class="tweet" id="tweet85">
 <div class="start-time-icon" title="Play from here">
  38:21
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.19346" target="_blank">
    @arXiv 2407.19346
   </a>
   <span class="tweet-title">
    Polynomial Playground:  Unlocking the Secrets of In-Context Learning with a Simple Function
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    UC Berkeley
   </span>
  </div>
  <div class="primary-text">
   This research uses univariate polynomial regression as a toy problem to study in-context learning in transformer-based architectures. Unlike previous work that used linear regression or multi-layer perceptrons, this approach allows for the exploration of prompting and alignment within a more structured function class.
  </div>
 </div>
</div>


        <div
            style="padding: 50px 0; text-align: center; margin: 5px 0; font-weight: 300; font-size: 10px; color: #000000;">
            Opening music
            from <a href="https://ikson.com" target="_blank" style="color: black; text-decoration: none;">TELL
                YOUR STORY by ikson</a></div>
        <div style="height: 50px;"></div>
    </div>

    <footer class="player-footer">
        <div class="player-detail-hidden-on-small-screen">
            <div id="audio-title" class="tweet-title-small">Listen and learn ^.^</div>
            <div style="height: 2px;"></div>
            <div id="audio-institutes" class="institute-text-small"></div>
        </div>
        <div class="control-panel">
            <div class="control-horizontal">
                <div id="playSpeedButton" title="Adjust speed">
                    <div id="selectedSpeed">1&times;</div>
                    <div class="speedMenuItems">
                        <div data-value="0.6">Speed 0.6&times;</div>
                        <div data-value="0.8">Speed 0.8&times;</div>
                        <div data-value="1" class="selected">Speed 1&times;</div>
                        <div data-value="1.2">Speed 1.2&times;</div>
                        <div data-value="1.4">Speed 1.4&times;</div>
                        <div data-value="1.6">Speed 1.6&times;</div>
                    </div>
                    <select id="speedOptionsHidden">
                        <option value="0.6">0.6&times;</option>
                        <option value="0.8">0.8&times;</option>
                        <option value="1" selected>1&times;</option>
                        <option value="1.2">1.2&times;</option>
                        <option value="1.4">1.4&times;</option>
                        <option value="1.6">1.6&times;</option>
                    </select>
                </div>
                <div id="playLastButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(false)" title="Play last" disabled>
                        <img src="assets/buttonLastEpisode.svg" alt="Last" style="width: 12px;">
                    </button>
                </div>
                <button class="controllerButton" onclick="scrollToCurrentTweet()" title="Scoll to the current episode">
                    <img id="locateImage" src="assets/buttonTarget.svg" alt="Locate">
                </button>
                <button class="controllerButton" onclick="togglePlayPause()" title="Play/Pause">
                    <img id="playPauseImage" src="assets/buttonPlay.svg" alt="Play">
                </button>
                <div id="playNextButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(true)" title="Play next" disabled>
                        <img src="assets/buttonNextEpisode.svg" alt="Next" style="width: 12px;">
                    </button>
                </div>
            </div>
            <div class="control-horizontal">
                <div id="progressTime">0:00</div>
                <div id="progressContainer" onclick="seek(event)">
                    <div id="progressBar"></div>
                    <div id="progressCircle" draggable="true"></div>
                </div>
                <audio id="audioPlayer"
                    src="https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202407301805_audio.mp3"></audio>
                <div id="progressTime"><span id="audioDuration">Loading...</span></div>
            </div>
        </div>
    </footer>
    <div id="privacyModal" class="modal"></div>
    <script src="script.js"></script>
    <script src="calendar.js"></script>    
    <script>
        fetch('https://ribbitribbit.co/header.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('headerId').innerHTML = data;
            })
            .catch(error => console.error('Error loading header.html:', error));
        fetch('https://ribbitribbit.co/privacy.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('privacyModal').innerHTML = data;
            })
            .catch(error => console.error('Error loading privacy.html:', error));
    </script>
</body>
</html>
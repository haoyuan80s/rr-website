
daily_data = {
    "date": "2024-11-12",
    "tweets": [
        
        {
            "startTime": "01:30",
            "arxivId": "2411.07008",
            "arxivLink": "https://arxiv.org/abs/2411.07008",
            "title": "Deep Learning's Hidden Problem: A Universe of Fake Solutions!",
            "institute": "Stanford University",
            "text": "This paper explores the implications of uncertain objective functions and permutative symmetry in deep learning architectures. It argues that traditional architectures are plagued by a vast number of equivalent global and local optima, making optimization challenging.",
            "paper-title": "Permutative redundancy and uncertainty of the objective in deep learning",
            "image-path": "flux_paper_image/2411.07008_1731455120.png"
        },

        {
            "startTime": "01:58",
            "arxivId": "2411.05927",
            "arxivLink": "https://arxiv.org/abs/2411.05927",
            "title": "Video Models Go Off-Grid: Tokens Track Objects Like a Boss!",
            "institute": "Google Research, Google DeepMind, Inceptive",
            "text": "This paper introduces a new video representation model called MooG that learns \"off-the-grid\" representations. Unlike traditional models that tie tokens to specific image locations, MooG allows tokens to move freely, enabling them to track scene elements consistently even as they move across the image plane.",
            "paper-title": "Moving Off-the-Grid: Scene-Grounded Video Representations",
            "image-path": "flux_paper_image/2411.05927_1731455375.png"
        },

        {
            "startTime": "02:19",
            "arxivId": "2411.07175",
            "arxivLink": "https://arxiv.org/abs/2411.07175",
            "title": "LLMs Forget Facts? REMIX to the Rescue!",
            "institute": "Princeton University",
            "text": "This paper focuses on the specific challenge of continual memorization of factoids in LLMs, a problem not fully addressed by existing continual learning methods. It proposes a novel strategy called REMIX, which mixes random or generic data into training to prevent forgetting.",
            "paper-title": "Continual Memorization of Factoids in Large Language Models",
            "image-path": "flux_paper_image/2411.07175_1731452905.png"
        },

        {
            "startTime": "02:38",
            "arxivId": "2411.06959",
            "arxivLink": "https://arxiv.org/abs/2411.06959",
            "title": "Image Generation: A New Trick to Make AI See Faster and Better",
            "institute": "Tsinghua University, National University of Singapore",
            "text": "This research delves into the inner workings of non-autoregressive Transformers (NATs) used for image generation. It identifies two key interaction patterns within NATs: spatial and temporal. The paper then proposes a new model, EfficientNAT (ENAT), which explicitly encourages these patterns, leading to improved performance and reduced computational cost.",
            "paper-title": "ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis",
            "image-path": "flux_paper_image/2411.06959_1731452961.png"
        },

        {
            "startTime": "03:09",
            "arxivId": "2411.07231",
            "arxivLink": "https://arxiv.org/abs/2411.07231",
            "title": "Watermarking 2.0: Hiding Messages in Tiny Image Patches!",
            "institute": "Meta",
            "text": "This research redefines watermarking as a segmentation task, allowing for the detection and extraction of multiple watermarks within a single image, even when only small portions are watermarked. This differs from traditional methods that treat the entire image as a single unit.",
            "paper-title": "Watermark Anything with Localized Messages",
            "image-path": "flux_paper_image/2411.07231_1731454546.png"
        },

        {
            "startTime": "03:37",
            "arxivId": "2411.05214",
            "arxivLink": "https://arxiv.org/abs/2411.05214",
            "title": "Tiny Models, Big Moderation: How a Small Language Model Can Outsmart GPT-4",
            "institute": "Microsoft, Harvard University, Peking University...",
            "text": "This research explores the effectiveness of cross-task fine-tuning for small language models (SLMs) in content moderation. Unlike previous work that focuses on large language models (LLMs) or task-specific models, this study demonstrates that SLMs can be fine-tuned across various content moderation tasks, achieving comparable performance to LLMs on unseen tasks.",
            "paper-title": "STAND-Guard: A Small Task-Adaptive Content Moderation Model",
            "image-path": "flux_paper_image/2411.05214_1731452608.png"
        },

        {
            "startTime": "04:01",
            "arxivId": "2411.06121",
            "arxivLink": "https://arxiv.org/abs/2411.06121",
            "title": "SniffySquad: Robot Dogs Sniff Out Gas Leaks, No More Patchy Problems!",
            "institute": "Tsinghua University, Duke University, Johns Hopkins University",
            "text": "This research introduces SniffySquad, a multi-robot system for gas source localization that addresses the patchy nature of gas plumes in real-world environments. Unlike previous methods that rely on simplified gas plume models or reactive stimuli, SniffySquad incorporates a patchiness-aware active sensing approach and a collaborative role adaptation strategy to improve the accuracy and efficiency of gas source localization.",
            "paper-title": "SniffySquad: Patchiness-Aware Gas Source Localization with Multi-Robot Collaboration",
            "image-path": "flux_paper_image/2411.06121_1731452741.png"
        },

        {
            "startTime": "04:25",
            "arxivId": "2411.05735",
            "arxivLink": "https://arxiv.org/abs/2411.05735",
            "title": "AIOLI: The Secret Sauce for Mixing Language Model Data",
            "institute": "Stanford University, NYU",
            "text": "This research unifies existing data mixing methods into a single optimization framework, revealing their underlying assumptions. It then uses this framework to develop a new online method, AIOLI, which directly estimates the parameters of the mixing law throughout training, leading to improved performance.",
            "paper-title": "Aioli: A Unified Optimization Framework for Language Model Data Mixing",
            "image-path": "flux_paper_image/2411.05735_1731455745.png"
        },

        {
            "startTime": "04:48",
            "arxivId": "2411.05403",
            "arxivLink": "https://arxiv.org/abs/2411.05403",
            "title": "Language Models: Know-It-Alls or Just Good Pretenders?",
            "institute": "Stanford University",
            "text": "This research goes beyond simply measuring how well language models can mimic human opinions. It digs deeper, exploring how different methods of expressing and steering those opinions affect the results.",
            "paper-title": "Benchmarking Distributional Alignment of Large Language Models",
            "image-path": "flux_paper_image/2411.05403_1731453639.png"
        },

        {
            "startTime": "05:12",
            "arxivId": "2411.05273",
            "arxivLink": "https://arxiv.org/abs/2411.05273",
            "title": "Robots Learn to Dress Without a Single Instruction!",
            "institute": "CMU",
            "text": "This research extends the RL-VLM-F method to automatically generate reward labels for offline datasets, enabling policy learning without requiring online interactions or ground-truth state information.",
            "paper-title": "Real-World Offline Reinforcement Learning from Vision Language Model Feedback",
            "image-path": "flux_paper_image/2411.05273_1731455499.png"
        },

        {
            "startTime": "05:34",
            "arxivId": "2411.05712",
            "arxivLink": "https://arxiv.org/abs/2411.05712",
            "title": "Bigger Brains, Better Behavior? Scaling Up AI Models for Visual Perception",
            "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
            "text": "This research investigates the impact of scaling model size and dataset size on the alignment of artificial neural networks with the primate visual ventral stream. Unlike previous studies that focused on scaling for task performance, this paper specifically examines how scaling affects the alignment with brain activity and behavior.",
            "paper-title": "Scaling Laws for Task-Optimized Models of the Primate Visual Ventral Stream",
            "image-path": "flux_paper_image/2411.05712_1731456376.png"
        },

        {
            "startTime": "05:57",
            "arxivId": "2411.06727",
            "arxivLink": "https://arxiv.org/abs/2411.06727",
            "title": "Can Spline Networks See? KANs Tackle Computer Vision!",
            "institute": "Tsinghua University",
            "text": "This research explores the application of Kolmogorov-Arnold Networks (KANs) in computer vision tasks, specifically image classification and semantic segmentation. Previous work has focused on KANs for function approximation and high-dimensional data modeling, but this study investigates their potential in visual pattern recognition.",
            "paper-title": "Can KAN Work? Exploring the Potential of Kolmogorov-Arnold Networks in Computer Vision",
            "image-path": "flux_paper_image/2411.06727_1731455721.png"
        },

        {
            "startTime": "06:22",
            "arxivId": "2411.06037",
            "arxivLink": "https://arxiv.org/abs/2411.06037",
            "title": "LLMs: Smart but Not Wise? New Research Uncovers the Limits of Context in AI",
            "institute": "UC San Diego, Duke University, Google",
            "text": "This research introduces a new concept called \"sufficient context\" to analyze the performance of Retrieval Augmented Generation (RAG) systems. Unlike previous work that focused on relevance, this study defines sufficient context as the presence of enough information to answer a query, regardless of whether the answer is correct.",
            "paper-title": "Sufficient Context: A New Lens on Retrieval Augmented Generation Systems",
            "image-path": "flux_paper_image/2411.06037_1731454036.png"
        },

        {
            "startTime": "06:48",
            "arxivId": "2411.05755",
            "arxivLink": "https://arxiv.org/abs/2411.05755",
            "title": "Vision-Language Models: Navigating the World Without a Map!",
            "institute": "UC Berkeley, University of Pennsylvania",
            "text": "This research proposes a novel prompting strategy that allows a Vision-Language Model (VLM) to act as an end-to-end navigation policy without any fine-tuning or exposure to navigation data. Unlike previous work, it does not rely on separate modules for perception, planning, and control.",
            "paper-title": "End-to-End Navigation with Vision Language Models: Transforming Spatial Reasoning into Question-Answering",
            "image-path": "flux_paper_image/2411.05755_1731455963.png"
        },

        {
            "startTime": "07:11",
            "arxivId": "2411.05027",
            "arxivLink": "https://arxiv.org/abs/2411.05027",
            "title": "SAR Image Generation: AI Gets a Radar Makeover!",
            "institute": "IEEE",
            "text": "This research provides a comprehensive survey of generative AI (GenAI) models applied to Synthetic Aperture Radar (SAR) image generation, highlighting the unique challenges and opportunities presented by SAR data. It also explores hybrid modeling approaches that combine GenAI with interpretable physical models.",
            "paper-title": "Generative Artificial Intelligence Meets Synthetic Aperture Radar: A Survey",
            "image-path": "flux_paper_image/2411.05027_1731454765.png"
        },

        {
            "startTime": "07:32",
            "arxivId": "2411.05338",
            "arxivLink": "https://arxiv.org/abs/2411.05338",
            "title": "Peer Review Power: A New Dataset for Deep Scientific Understanding",
            "institute": "IIT Gandhinagar, Yale University, Allen Institute for AI",
            "text": "This research introduces SCIDQA, a new dataset for reading comprehension that focuses on deep understanding of scientific articles. Unlike other scientific QA datasets, SCIDQA sources questions from peer reviews by domain experts and answers by paper authors, ensuring a thorough examination of the literature.",
            "paper-title": "SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers",
            "image-path": "flux_paper_image/2411.05338_1731455850.png"
        },

        {
            "startTime": "07:53",
            "arxivId": "2411.05764",
            "arxivLink": "https://arxiv.org/abs/2411.05764",
            "title": "Financial Fact-Checking: LLMs Get a Reality Check!",
            "institute": "Yale University",
            "text": "This research introduces FINDVER, a benchmark specifically designed to evaluate the explainable claim verification capabilities of LLMs in the context of financial documents. Unlike previous benchmarks, FINDVER focuses on long, hybrid-content financial documents and requires models to provide detailed explanations of their reasoning process.",
            "paper-title": "FinDVer: Explainable Claim Verification over Long and Hybrid-content Financial Documents",
            "image-path": "flux_paper_image/2411.05764_1731455385.png"
        },

        {
            "startTime": "08:11",
            "arxivId": "2411.06688",
            "arxivLink": "https://arxiv.org/abs/2411.06688",
            "title": "Hyperbolic Hype: Euclidean Models Outshine the Curve",
            "institute": "Yale University",
            "text": "This research challenges the prevailing assumption that hyperbolic graph learning models outperform Euclidean models on tasks like link prediction and node classification. The authors demonstrate that properly trained Euclidean models can achieve comparable or even better performance on datasets previously considered \"most hyperbolic.\"",
            "paper-title": "Shedding Light on Problems with Hyperbolic Graph Learning",
            "image-path": "flux_paper_image/2411.06688_1731457909.png"
        },

        {
            "startTime": "08:40",
            "arxivId": "2411.05237",
            "arxivLink": "https://arxiv.org/abs/2411.05237",
            "title": "AI Doctor's Dilemma: Pruning Out Bad Decisions to Improve Care",
            "institute": "Harvard University",
            "text": "This research introduces a novel two-stage approach to Inverse Reinforcement Learning (IRL) that identifies and removes suboptimal clinician actions from training data, leading to more accurate and reliable reward models. This approach differs from previous IRL methods that assume near-optimal expert behavior.",
            "paper-title": "Pruning the Path to Optimal Care: Identifying Systematically Suboptimal Medical Decision-Making with Inverse Reinforcement Learning",
            "image-path": "flux_paper_image/2411.05237_1731452469.png"
        },

        {
            "startTime": "09:02",
            "arxivId": "2411.05174",
            "arxivLink": "https://arxiv.org/abs/2411.05174",
            "title": "Learning from Experts: How to Teach AI the Right Moves, Even When They're Not Perfect!",
            "institute": "Harvard University, Imperial College London",
            "text": "This research introduces Inverse Transition Learning (ITL), a method for estimating the dynamics of an environment using near-optimal expert trajectories. Unlike previous methods that rely on soft constraints, ITL utilizes hard constraints to ensure the learned dynamics accurately reflect the expert's behavior.",
            "paper-title": "Inverse Transition Learning: Learning Dynamics from Demonstrations",
            "image-path": "flux_paper_image/2411.05174_1731455433.png"
        },

        {
            "startTime": "09:26",
            "arxivId": "2411.05504",
            "arxivLink": "https://arxiv.org/abs/2411.05504",
            "title": "Long Tokens, Big Brains: A New Way to Train Language Models",
            "institute": "Beihang University, Tsinghua University",
            "text": "This paper proposes a new tokenization method called LBPE (Long-token-first Byte Pair Encoding) that prioritizes longer tokens during the encoding process. This differs from the traditional BPE method, which prioritizes shorter tokens.",
            "paper-title": "LBPE: Long-token-first Tokenization to Improve Large Language Models",
            "image-path": "flux_paper_image/2411.05504_1731453796.png"
        },

        {
            "startTime": "09:49",
            "arxivId": "2411.06735",
            "arxivLink": "https://arxiv.org/abs/2411.06735",
            "title": "Forecasting the Future: Can Text Help Predict Numbers?",
            "institute": "UC San Diego, Google",
            "text": "This research introduces a new multimodal dataset, TimeText Corpus (TTC), for forecasting both time series and textual data. Unlike previous work that focused on either time series or text, this study aims to jointly predict both modalities.",
            "paper-title": "Multi-Modal Forecaster: Jointly Predicting Time Series and Textual Data",
            "image-path": "flux_paper_image/2411.06735_1731455489.png"
        },

        {
            "startTime": "10:13",
            "arxivId": "2411.05781",
            "arxivLink": "https://arxiv.org/abs/2411.05781",
            "title": "AI Translators Get a Vocabulary Boost: New Rules for Picking the Perfect Word",
            "institute": "UC Berkeley",
            "text": "This research focuses on lexical selection in translation, specifically how to choose the most appropriate word in the target language when a single source word has multiple variations. Unlike previous work that focused on Spanish and Greek, this study expands to nine languages, including low-resource ones.",
            "paper-title": "Using Language Models to Disambiguate Lexical Choices in Translation",
            "image-path": "flux_paper_image/2411.05781_1731456724.png"
        },

        {
            "startTime": "10:41",
            "arxivId": "2411.05059",
            "arxivLink": "https://arxiv.org/abs/2411.05059",
            "title": "Fine-Tuning LLMs: Can We Teach Old Dogs New Tricks?",
            "institute": "Stanford University",
            "text": "This research introduces FineTuneBench, a dataset specifically designed to evaluate the effectiveness of commercial fine-tuning APIs for injecting new knowledge into large language models (LLMs). It differs from previous work by focusing on knowledge infusion rather than style transfer or classification tasks.",
            "paper-title": "FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge into LLMs?",
            "image-path": "flux_paper_image/2411.05059_1731456702.png"
        },

        {
            "startTime": "10:56",
            "arxivId": "2411.07126",
            "arxivLink": "https://arxiv.org/abs/2411.07126",
            "title": "EdifyImage: Pixel-Perfect Images, Laplacian Diffusion Style!",
            "institute": "NVIDIA",
            "text": "This research introduces a novel Laplacian diffusion process for training diffusion models. Unlike previous methods that treat all image frequencies equally, this approach attenuates different frequency bands at varying rates, enabling more precise detail capture and refinement across multiple scales.",
            "paper-title": "Edify Image: High-Quality Image Generation with Pixel Space Laplacian Diffusion Models",
            "image-path": "flux_paper_image/2411.07126_1731454338.png"
        },

        {
            "startTime": "11:16",
            "arxivId": "2411.07135",
            "arxivLink": "https://arxiv.org/abs/2411.07135",
            "title": "Edify3D: Turning Text into 3D Masterpieces in Just 2 Minutes!",
            "institute": "NVIDIA",
            "text": "This research introduces Edify 3D, a model that generates high-quality 3D assets from text or images. Unlike previous methods, Edify 3D uses a multi-view diffusion model to synthesize multiple views of an object, which are then used to reconstruct the 3D shape, texture, and materials.",
            "paper-title": "Edify 3D: Scalable High-Quality 3D Asset Generation",
            "image-path": "flux_paper_image/2411.07135_1731453739.png"
        },

        {
            "startTime": "11:37",
            "arxivId": "2411.07223",
            "arxivLink": "https://arxiv.org/abs/2411.07223",
            "title": "Video Games for Robots: Teaching Machines to Act by Watching YouTube!",
            "institute": "Georgia Tech, Brown, Harvard",
            "text": "This research proposes a novel approach to grounding large video models to continuous actions without relying on annotated demonstrations. Instead of training a separate inverse dynamics model, the study leverages goal-conditioned exploration in an embodied environment, using generated video states as visual goals.",
            "paper-title": "Grounding Video Models to Actions through Goal Conditioned Exploration",
            "image-path": "flux_paper_image/2411.07223_1731452549.png"
        },

        {
            "startTime": "11:59",
            "arxivId": "2411.06469",
            "arxivLink": "https://arxiv.org/abs/2411.06469",
            "title": "LLMs vs. Old School: Can AI Beat Doctors at Predicting Patient Outcomes?",
            "institute": "Illinois Institute of Technology, Harvard University, Imperial College London...",
            "text": "This research directly compares the performance of Large Language Models (LLMs) with traditional machine learning models on three common clinical prediction tasks, using real-world patient data.",
            "paper-title": "ClinicalBench: Can LLMs Beat Traditional ML Models in Clinical Prediction?",
            "image-path": "flux_paper_image/2411.06469_1731456295.png"
        },

        {
            "startTime": "12:23",
            "arxivId": "2411.05883",
            "arxivLink": "https://arxiv.org/abs/2411.05883",
            "title": "MRI Reconstruction Gets a 3D Makeover: Deep Learning Takes on Multi-Coil Challenges!",
            "institute": "CEA, CNRS, Universit\u00b4e Paris-Saclay...",
            "text": "This research extends the NC-PDNet, a deep learning model for MRI reconstruction, to handle 3D multi-coil data. This is a significant step forward as previous work primarily focused on 2D or single-coil scenarios.",
            "paper-title": "Benchmarking 3D multi-coil NC-PDNet MRI reconstruction",
            "image-path": "flux_paper_image/2411.05883_1731456131.png"
        },

        {
            "startTime": "12:52",
            "arxivId": "2411.05945",
            "arxivLink": "https://arxiv.org/abs/2411.05945",
            "title": "MoE-ing Your Way to Better Speech Recognition: A Multi-Task Error Corrector",
            "institute": "Nvidia",
            "text": "This research introduces NEKO, a multi-task error correction model that utilizes a Mixture-of-Experts (MoE) architecture. Unlike previous methods that rely on separate correction models for each task, NEKO trains experts to specialize in specific domains, allowing for knowledge sharing and improved performance across diverse tasks.",
            "paper-title": "NeKo: Toward Post Recognition Generative Correction Large Language Models with Task-Oriented Experts",
            "image-path": "flux_paper_image/2411.05945_1731454534.png"
        },

        {
            "startTime": "13:19",
            "arxivId": "2411.07232",
            "arxivLink": "https://arxiv.org/abs/2411.07232",
            "title": "Adding Objects to Images: A Training-Free Diffusion Model Does the Trick!",
            "institute": "NVIDIA, Tel-Aviv University, Bar-Ilan University",
            "text": "This research introduces a training-free method for adding objects to images using pretrained diffusion models. Unlike previous methods that require training on specific datasets, this approach leverages the existing knowledge within the diffusion model to achieve object insertion without any additional fine-tuning.",
            "paper-title": "Add-it: Training-Free Object Insertion in Images With Pretrained Diffusion Models",
            "image-path": "flux_paper_image/2411.07232_1731454806.png"
        },

        {
            "startTime": "13:40",
            "arxivId": "2411.05048",
            "arxivLink": "https://arxiv.org/abs/2411.05048",
            "title": "LLMs: The New Search Wizards for Sales Pros",
            "institute": "UC Berkeley",
            "text": "This research focuses on using LLMs to translate natural language queries into structured search queries for a go-to-market platform, specifically Zoominfo's ZI Sales product. This approach differs from previous work by focusing on the intermediary JSON format, which eliminates syntax errors and simplifies ground truth creation.",
            "paper-title": "Leveraging LLMs to Enable Natural Language Search on Go-to-market Platforms",
            "image-path": "flux_paper_image/2411.05048_1731452982.png"
        },

        {
            "startTime": "13:59",
            "arxivId": "2411.05718",
            "arxivLink": "https://arxiv.org/abs/2411.05718",
            "title": "Robot Air Hockey: A Real-World Test for AI's \"Table Manners\"",
            "institute": "TU Darmstadt, DFKI, Huawei...",
            "text": "This research introduces a new benchmark for evaluating robot learning techniques in a dynamic, real-world setting. Unlike previous benchmarks that focus on simulated or quasi-static environments, the Robot Air Hockey Challenge emphasizes the challenges of real-world deployment, including safety, limited data, and the sim-to-real gap.",
            "paper-title": "A Retrospective on the Robot Air Hockey Challenge: Benchmarking Robust, Reliable, and Safe Learning Techniques for Real-world Robotics",
            "image-path": "flux_paper_image/2411.05718_1731452804.png"
        },

        {
            "startTime": "14:20",
            "arxivId": "2411.05375",
            "arxivLink": "https://arxiv.org/abs/2411.05375",
            "title": "Fact-Checking's New BFF: LLMs Help Evaluate Evidence Retrieval",
            "institute": "King\u2019s College London, Queen Mary University of London, University of Cambridge",
            "text": "This research introduces Ev2R, a framework for evaluating evidence retrieval in automated fact-checking. Unlike previous methods that rely on predefined knowledge sources or approximate matching, Ev2R leverages large language models (LLMs) to assess evidence quality through reference-based, proxy-reference, and reference-less approaches.",
            "paper-title": "Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking",
            "image-path": "flux_paper_image/2411.05375_1731454308.png"
        },

        {
            "startTime": "14:45",
            "arxivId": "2411.06634",
            "arxivLink": "https://arxiv.org/abs/2411.06634",
            "title": "Graph Learning Goes Inductive: New Tricks for a Growing World",
            "institute": "University of Queensland, Commonwealth Scientific and Industrial Research Organisation, University of Oxford",
            "text": "This paper tackles the inductive setting of Graph Few-Shot Class Incremental Learning (GFSCIL), where the model learns new classes from newly emerging nodes without access to previous data. This contrasts with the transductive setting, which assumes access to the entire graph with historical data.",
            "paper-title": "Inductive Graph Few-shot Class Incremental Learning",
            "image-path": "flux_paper_image/2411.06634_1731455871.png"
        },

        {
            "startTime": "15:10",
            "arxivId": "2411.07087",
            "arxivLink": "https://arxiv.org/abs/2411.07087",
            "title": "Stop Wasting Time on Observations! New AI Learns to Be Smart About What It Needs to See",
            "institute": "University of Cambridge",
            "text": "This research introduces the Observation-Constrained Markov Decision Process (OCMDP), which allows AI agents to actively decide when and what to observe in an environment, unlike traditional methods that assume full observability.",
            "paper-title": "OCMDP: Observation-Constrained Markov Decision Process",
            "image-path": "flux_paper_image/2411.07087_1731454974.png"
        },

        {
            "startTime": "15:44",
            "arxivId": "2411.06665",
            "arxivLink": "https://arxiv.org/abs/2411.06665",
            "title": "Stop Treating All Target Samples the Same: A New Framework for Semi-Supervised Domain Adaptation",
            "institute": "Beijing University of Posts and Telecommunications, Peking University",
            "text": "This research introduces a source-free framework called SOUF for semi-supervised domain adaptation (SSDA). Unlike previous methods that focus on general strategies for target samples, SOUF tailors learning techniques to different types of target samples: unlabeled, reliably labeled, and noisy pseudo-labeled.",
            "paper-title": "Learning from Different Samples: A Source-free Framework for Semi-supervised Domain Adaptation",
            "image-path": "flux_paper_image/2411.06665_1731458723.png"
        },

        {
            "startTime": "16:19",
            "arxivId": "2411.05188",
            "arxivLink": "https://arxiv.org/abs/2411.05188",
            "title": "Brain Age to Baby Brains: Transfer Learning for HIE Outcome Prediction",
            "institute": "Boston Children\u2019s Hospital, Harvard Medical School",
            "text": "This research introduces AGE2HIE, a novel transfer learning approach that leverages a large dataset of brain MRIs for age estimation to predict neurocognitive outcomes in infants with hypoxic-ischemic encephalopathy (HIE). This method addresses the challenge of limited data in HIE research by transferring knowledge from a related but larger dataset.",
            "paper-title": "AGE2HIE: Transfer Learning from Brain Age to Predicting Neurocognitive Outcome for Infant Brain Injury",
            "image-path": "flux_paper_image/2411.05188_1731454064.png"
        },

        {
            "startTime": "16:48",
            "arxivId": "2411.06518",
            "arxivLink": "https://arxiv.org/abs/2411.06518",
            "title": "Unraveling the Hidden Causes: A New Way to Decode Multimodal Biological Data",
            "institute": "MBZUAI, CMU, University of Bristol...",
            "text": "This research introduces a new method for identifying individual causal components within multimodal datasets, going beyond previous work that only identified subspaces. It leverages the sparsity of causal connections among modalities to achieve this, avoiding restrictive parametric assumptions.",
            "paper-title": "Causal Representation Learning from Multimodal Biological Observations",
            "image-path": "flux_paper_image/2411.06518_1731455300.png"
        },

        {
            "startTime": "17:07",
            "arxivId": "2411.05868",
            "arxivLink": "https://arxiv.org/abs/2411.05868",
            "title": "Bilevel Optimization Gets a Speed Boost: Without-Replacement Sampling to the Rescue!",
            "institute": "University of Maryland",
            "text": "This research introduces a new approach to bilevel optimization that utilizes without-replacement sampling instead of the traditional independent sampling method. This change allows for faster convergence rates, especially when dealing with large datasets.",
            "paper-title": "Provably Faster Algorithms for Bilevel Optimization via Without-Replacement Sampling",
            "image-path": "flux_paper_image/2411.05868_1731454622.png"
        },

        {
            "startTime": "17:26",
            "arxivId": "2411.05591",
            "arxivLink": "https://arxiv.org/abs/2411.05591",
            "title": "EM Algorithm Gets a Decentralized Makeover: Momentum and Labels to the Rescue!",
            "institute": "Peking University",
            "text": "This research proposes two novel decentralized federated learning algorithms for fitting Gaussian mixture models. The first, MNEM, uses a momentum parameter to address the bias caused by heterogeneous data. The second, semi-MNEM, leverages partially labeled data to improve numerical convergence when Gaussian components are poorly separated.",
            "paper-title": "Network EM Algorithm for Gaussian Mixture Model in Decentralized Federated Learning",
            "image-path": "flux_paper_image/2411.05591_1731454860.png"
        },

        {
            "startTime": "17:53",
            "arxivId": "2411.05205",
            "arxivLink": "https://arxiv.org/abs/2411.05205",
            "title": "AI-Powered Drones: Learning to Connect Users in Any Crowd!",
            "institute": "CMU, University of North Carolina at Charlotte",
            "text": "This research focuses on designing a deep reinforcement learning algorithm for multi-UAV networks that can generalize to arbitrary user distributions, unlike previous work that often assumes stationary or predictable user patterns.",
            "paper-title": "Maximizing User Connectivity in AI-Enabled Multi-UAV Networks: A Distributed Strategy Generalized to Arbitrary User Distributions",
            "image-path": "flux_paper_image/2411.05205_1731458690.png"
        },

        {
            "startTime": "18:18",
            "arxivId": "2411.05239",
            "arxivLink": "https://arxiv.org/abs/2411.05239",
            "title": "AI Models: They're Not As Random As You Think!",
            "institute": "IBM Research, Tel Aviv University, Boston University...",
            "text": "This research explores lossless compression for AI models, a departure from the typical focus on lossy compression methods like pruning and quantization.",
            "paper-title": "ZipNN: Lossless Compression for AI Models",
            "image-path": "flux_paper_image/2411.05239_1731454323.png"
        },

        {
            "startTime": "18:43",
            "arxivId": "2411.07061",
            "arxivLink": "https://arxiv.org/abs/2411.07061",
            "title": "Schedule-Free SGD: The Lazy Optimizer That Still Gets the Job Done!",
            "institute": "Microsoft, MIT",
            "text": "This research extends the theoretical understanding of schedule-free methods to nonconvex optimization, a more challenging setting than the previously studied convex setting. The paper introduces a general framework for converting online learning algorithms into optimization algorithms for nonconvex losses, which not only recovers existing conversions but also leads to two novel conversion schemes. One of these new conversions corresponds directly to schedule-free SGD, allowing the authors to establish its optimality for nonconvex optimization.",
            "paper-title": "General framework for online-to-nonconvex conversion: Schedule-free SGD is also effective for nonconvex optimization",
            "image-path": "flux_paper_image/2411.07061_1731452462.png"
        },

        {
            "startTime": "19:02",
            "arxivId": "2411.07207",
            "arxivLink": "https://arxiv.org/abs/2411.07207",
            "title": "Stop Googling, Start Graphing: A Foundation Model for Population Dynamics",
            "institute": "Google",
            "text": "This research introduces a Population Dynamics Foundation Model (PDFM) that uses a graph neural network (GNN) to synthesize diverse geospatial datasets, including maps, search trends, and weather data. Unlike previous work that often relies on hand-crafted features and task-specific models, PDFM aims to capture the complex relationships between these data modalities, making it adaptable to a broader range of geospatial tasks.",
            "paper-title": "General Geospatial Inference with a Population Dynamics Foundation Model",
            "image-path": "flux_paper_image/2411.07207_1731455420.png"
        },

        {
            "startTime": "19:25",
            "arxivId": "2411.06427",
            "arxivLink": "https://arxiv.org/abs/2411.06427",
            "title": "Graph Anomaly Detection: One Model to Rule Them All!",
            "institute": "Tsinghua University, Hong Kong University of Science and Technology",
            "text": "This research introduces UniGAD, a unified framework for detecting anomalies in graphs at multiple levels (nodes, edges, and graphs). Unlike previous methods that focus on a single level, UniGAD leverages the inherent connections between different levels to improve performance.",
            "paper-title": "UniGAD: Unifying Multi-level Graph Anomaly Detection",
            "image-path": "flux_paper_image/2411.06427_1731452563.png"
        },

        {
            "startTime": "19:46",
            "arxivId": "2411.06390",
            "arxivLink": "https://arxiv.org/abs/2411.06390",
            "title": "3D Gaussian Splatting Gets a Point Transformer Makeover for Out-of-This-World Views!",
            "institute": "ETH Zurich, University of Maryland College Park, ROCS University Hospital Balgrist University of Z\u00a8urich",
            "text": "This research introduces SplatFormer, a novel point transformer model specifically designed to refine 3D Gaussian splats (3DGS) for robust out-of-distribution (OOD) novel view synthesis. Unlike previous methods that rely on regularization techniques or external priors, SplatFormer directly operates on the 3DGS representation, leveraging multi-view information to improve rendering quality under extreme novel views.",
            "paper-title": "SplatFormer: Point Transformer for Robust 3D Gaussian Splatting",
            "image-path": "flux_paper_image/2411.06390_1731452348.png"
        },

        {
            "startTime": "20:08",
            "arxivId": "2411.06649",
            "arxivLink": "https://arxiv.org/abs/2411.06649",
            "title": "Electricity Theft: A Data-Driven Detective Story!",
            "institute": "Tsinghua University",
            "text": "This research combines two novel data mining techniques, MIC and CFSFDP, to detect electricity theft, addressing the limitations of previous methods that either require labeled datasets or additional system information.",
            "paper-title": "A Novel Combined Data-Driven Approach for Electricity Theft Detection",
            "image-path": "flux_paper_image/2411.06649_1731458383.png"
        },

        {
            "startTime": "20:28",
            "arxivId": "2411.07180",
            "arxivLink": "https://arxiv.org/abs/2411.07180",
            "title": "LM Counterfactuals: Unmasking the Hidden Biases of Language Models",
            "institute": "ETH Zurich",
            "text": "This research proposes a framework for generating true counterfactuals from language models by reformulating them as Generalized Structural-equation Models. This approach allows for a more precise understanding of the causal relationships between model interventions and their effects on generated text.",
            "paper-title": "Counterfactual Generation from Language Models",
            "image-path": "flux_paper_image/2411.07180_1731453245.png"
        },

        {
            "startTime": "21:03",
            "arxivId": "2411.06365",
            "arxivLink": "https://arxiv.org/abs/2411.06365",
            "title": "Seeing Through the Lens: How AI Makes VR Headsets See Through Protective Covers",
            "institute": "CMU, Google",
            "text": "This research introduces SynthCover, a novel framework for neural view synthesis that explicitly models the geometry of protective covers, enabling accurate rendering of scenes viewed through them. Unlike previous methods that struggle with cover-induced distortions, SynthCover leverages a Refractive Field to estimate the cover's surface geometry and analytically bend rays according to Snell's Law.",
            "paper-title": "Through the Curved Cover: Synthesizing Cover Aberrated Scenes with Refractive Field",
            "image-path": "flux_paper_image/2411.06365_1731457220.png"
        },

        {
            "startTime": "21:27",
            "arxivId": "2411.05016",
            "arxivLink": "https://arxiv.org/abs/2411.05016",
            "title": "Echo State Networks: The Secret Weapon for Data-Driven Control",
            "institute": "University of Washington",
            "text": "This research compares different recurrent neural network (RNN) architectures for use as surrogate models in model predictive control (MPC). It finds that echo state networks (ESNs) outperform other RNN variants, including LSTMs and GRUs, in terms of accuracy, computational efficiency, and robustness to noise.",
            "paper-title": "Reservoir computing for system identification and predictive control with limited data",
            "image-path": "flux_paper_image/2411.05016_1731454921.png"
        },

        {
            "startTime": "21:49",
            "arxivId": "2411.06719",
            "arxivLink": "https://arxiv.org/abs/2411.06719",
            "title": "Deep Learning Makes Clothes Sim Faster: Avatars Get a New Dress Code!",
            "institute": "UC Los Angeles, UC Davis, Stanford University",
            "text": "This research proposes a novel approach to representing the shape of animated characters using a collection of shallow neural networks, each focused on a specific joint. This differs from previous methods that used a single deep neural network to represent the entire character, which can be computationally expensive for real-time applications.",
            "paper-title": "Shallow Signed Distance Functions for Kinematic Collision Bodies",
            "image-path": "flux_paper_image/2411.06719_1731455023.png"
        },

        {
            "startTime": "22:16",
            "arxivId": "2411.06950",
            "arxivLink": "https://arxiv.org/abs/2411.06950",
            "title": "Can AI Smell What You Smell? A Spicy New Study on Olfactory Alignment",
            "institute": "University College London",
            "text": "This research explores the alignment between AI and human smell experiences, a previously unexplored area in human-AI interaction. It uses a Large Language Model (LLM) to encode scent descriptions into a high-dimensional embedding space and then compares the AI's predictions with human judgments.",
            "paper-title": "Sniff AI: Is My 'Spicy' Your 'Spicy'? Exploring LLM's Perceptual Alignment with Human Smell Experiences",
            "image-path": "flux_paper_image/2411.06950_1731458840.png"
        },

        {
            "startTime": "22:37",
            "arxivId": "2411.05194",
            "arxivLink": "https://arxiv.org/abs/2411.05194",
            "title": "LLMs Learn to Talk Like Humans, But Only After the Conversation's Over!",
            "institute": "UC Berkeley",
            "text": "This research introduces a novel approach to training dialogue agents using offline reinforcement learning (RL) by augmenting existing datasets with \"hindsight regenerations.\" This method involves using a large language model (LLM) to identify suboptimal actions in past dialogues and propose more effective alternatives, effectively \"rewriting\" the conversation in hindsight. This differs from previous work that relies on either curated expert data or online RL, which can be costly and time-consuming.",
            "paper-title": "Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations",
            "image-path": "flux_paper_image/2411.05194_1731455313.png"
        },

        {
            "startTime": "23:01",
            "arxivId": "2411.05193",
            "arxivLink": "https://arxiv.org/abs/2411.05193",
            "title": "Q-Learning Gets a Supervised Makeover: LLMs Learn Values Without New Heads!",
            "institute": "UC Berkeley",
            "text": "This paper proposes a novel offline RL algorithm called Q-SFT, which frames Q-learning as a supervised fine-tuning problem. Unlike traditional Q-learning, Q-SFT directly leverages the probabilities learned during pretraining, avoiding the need to reinitialize weights or add new heads for value prediction.",
            "paper-title": "Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning",
            "image-path": "flux_paper_image/2411.05193_1731457387.png"
        },

        {
            "startTime": "23:30",
            "arxivId": "2411.06248",
            "arxivLink": "https://arxiv.org/abs/2411.06248",
            "title": "LLMs: Can We Tell Humans From Bots? A New Study Says Maybe Not!",
            "institute": "Purdue University, University of Chicago",
            "text": "This research explores the zero-shot detection of LLM-generated text, meaning it doesn't rely on pre-existing datasets of human or AI-authored samples for training. This approach is particularly relevant as LLMs evolve rapidly, and pre-existing datasets may not be readily available.",
            "paper-title": "Robust Detection of LLM-Generated Text: A Comparative Analysis",
            "image-path": "flux_paper_image/2411.06248_1731454673.png"
        },

        {
            "startTime": "23:49",
            "arxivId": "2411.05265",
            "arxivLink": "https://arxiv.org/abs/2411.05265",
            "title": "Image Decomposition: Unmasking Structures, Textures, and Noise with Contourlets!",
            "institute": "University of Nice Sophia Antipolis, INRIA Sophia Antipolis",
            "text": "This research introduces a new image decomposition model that utilizes contourlets, a directional multiresolution analysis tool, to separate structures, textures, and noise. This approach differs from previous models that relied on wavelets or other less directional methods.",
            "paper-title": "Image Decomposition: Theory, Numerical Schemes, and Performance Evaluation",
            "image-path": "flux_paper_image/2411.05265_1731458018.png"
        },

        {
            "startTime": "24:22",
            "arxivId": "2411.05842",
            "arxivLink": "https://arxiv.org/abs/2411.05842",
            "title": "Traffic Wave Whisperer: A New Model for Estimating Freeway Speeds",
            "institute": "Southeast University, CMU",
            "text": "This research proposes a new method for estimating freeway traffic speeds using vehicle trajectory data. Unlike previous methods that rely on rectangular grids, this approach utilizes oblique grids aligned with the direction of backward traffic waves, enhancing the accuracy of speed estimations, especially in sparse data environments.",
            "paper-title": "Efficient and Robust Freeway Traffic Speed Estimation Under Oblique Grid Using Vehicle Trajectory Data",
            "image-path": "flux_paper_image/2411.05842_1731453906.png"
        },

        {
            "startTime": "24:41",
            "arxivId": "2411.07213",
            "arxivLink": "https://arxiv.org/abs/2411.07213",
            "title": "Steering LLMs: Top-Down vs. Bottom-Up, Who Wins?",
            "institute": "University of Washington, University of Cambridge",
            "text": "This research directly compares two distinct approaches to steering LLMs, \"bottom-up\" and \"top-down,\" using a unified set of in-context learning tasks. It reveals that each approach excels in specific task types, highlighting the need for a more comprehensive evaluation benchmark for steering methods.",
            "paper-title": "Comparing Bottom-Up and Top-Down Steering Approaches on In-Context Learning Tasks",
            "image-path": "flux_paper_image/2411.07213_1731452597.png"
        },

        {
            "startTime": "25:00",
            "arxivId": "2411.06278",
            "arxivLink": "https://arxiv.org/abs/2411.06278",
            "title": "Solving PDEs with a Primal-Dual Twist: A Natural Gradient Approach",
            "institute": "University of California Los Angeles, University of California Berkeley",
            "text": "This research introduces a preconditioned primal-dual hybrid gradient (NPDHG) algorithm for solving PDEs. The NPDHG method leverages natural gradients to update neural network parameters, which is a departure from conventional optimizers like Adam and L-BFGS.",
            "paper-title": "A Natural Primal-Dual Hybrid Gradient Method for Adversarial Neural Network Training on Solving Partial Differential Equations",
            "image-path": "flux_paper_image/2411.06278_1731454202.png"
        },

        {
            "startTime": "25:21",
            "arxivId": "2411.06228",
            "arxivLink": "https://arxiv.org/abs/2411.06228",
            "title": "Angluin's Algorithm Gets a Weighty Makeover: Learning Languages with Semifields!",
            "institute": "ETH Zurich",
            "text": "This research introduces a weighted variant of Angluin's L\u02da algorithm, specifically designed to learn deterministic weighted finite-state automata (WDFSA) whose weights support division. Unlike previous algorithms that rely on linear systems of equations, this new approach works with semifields, a more general algebraic structure.",
            "paper-title": "An L* Algorithm for Deterministic Weighted Regular Languages",
            "image-path": "flux_paper_image/2411.06228_1731453062.png"
        },

        {
            "startTime": "25:45",
            "arxivId": "2411.06232",
            "arxivLink": "https://arxiv.org/abs/2411.06232",
            "title": "Crowd Reconstruction: From Single Images to 3D People Parties!",
            "institute": "Tianjin University, Tsinghua University",
            "text": "This research introduces Crowd3D++, a method that reconstructs 3D poses, shapes, and locations of hundreds of people from a single image, even with unknown camera parameters. Unlike previous methods that struggle with large scenes and varying camera angles, Crowd3D++ leverages a \"canonical upright space\" to normalize human scales and orientations, enabling more stable and accurate reconstruction.",
            "paper-title": "Crowd3D++: Robust Monocular Crowd Reconstruction with Upright Space",
            "image-path": "flux_paper_image/2411.06232_1731455510.png"
        },

        {
            "startTime": "26:10",
            "arxivId": "2411.05361",
            "arxivLink": "https://arxiv.org/abs/2411.05361",
            "title": "Speech Models: From \"Hello\" to \"Help Me With This!\"",
            "institute": "National Taiwan University, University of Texas at Austin, Carnegie Mellon University...",
            "text": "This research introduces Dynamic-SUPERB Phase-2, a benchmark for evaluating universal speech models. Unlike previous benchmarks, it includes a wider range of tasks, including regression and sequence generation, and covers speech, music, and environmental audio.",
            "paper-title": "Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks",
            "image-path": "flux_paper_image/2411.05361_1731456075.png"
        },

        {
            "startTime": "26:30",
            "arxivId": "2411.05085",
            "arxivLink": "https://arxiv.org/abs/2411.05085",
            "title": "X-Ray Vision: A Bilingual Dataset for Grounded Radiology Reports",
            "institute": "Microsoft, Medbravo, University of Cambridge...",
            "text": "This research introduces PadChest-GR, a dataset specifically designed for training models that can generate radiology reports with spatial annotations, linking findings to their locations on the image. This differs from previous datasets that either lack spatial annotations or only provide them for single findings or labels.",
            "paper-title": "PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation",
            "image-path": "flux_paper_image/2411.05085_1731452736.png"
        },

        {
            "startTime": "27:08",
            "arxivId": "2411.06181",
            "arxivLink": "https://arxiv.org/abs/2411.06181",
            "title": "CT Scans Get a Neural Makeover: Epi-NAF Fixes Blurry Images!",
            "institute": "Technion \u2013 Israel Institute of Technology, Massachusetts Institute of Technology, NVIDIA",
            "text": "This research introduces a novel loss term, L ECC, based on epipolar consistency conditions in X-ray imaging, to improve the performance of neural attenuation fields (NAF) in limited-angle CT reconstruction. This approach differs from previous work by leveraging the consistency between corresponding epipolar lines in X-ray projections to regularize the optimization of the neural field.",
            "paper-title": "Epi-NAF: Enhancing Neural Attenuation Fields for Limited-Angle CT with Epipolar Consistency Conditions",
            "image-path": "flux_paper_image/2411.06181_1731455673.png"
        },

        {
            "startTime": "27:32",
            "arxivId": "2411.05923",
            "arxivLink": "https://arxiv.org/abs/2411.05923",
            "title": "DNAMite: Survival Analysis Gets a Glass-Box Makeover!",
            "institute": "Stanford University, California Polytechnic State University",
            "text": "This paper introduces DNAMite, a new glass-box machine learning model for survival analysis. Unlike previous models, DNAMite uses feature discretization and kernel smoothing in its embedding module to learn shape functions with a flexible balance of smoothness and jaggedness.",
            "paper-title": "DNAMite: Interpretable Calibrated Survival Analysis with Discretized Additive Models",
            "image-path": "flux_paper_image/2411.05923_1731453953.png"
        },

        {
            "startTime": "27:58",
            "arxivId": "2411.07111",
            "arxivLink": "https://arxiv.org/abs/2411.07111",
            "title": "Taiwanese Mandarin Chatbot: From Text to Talk, It's a Real-Time Thing!",
            "institute": "Academia Sinica, Google",
            "text": "This research focuses on building a spoken large language model (LLM) for Taiwanese Mandarin, specifically designed for real-time, speech-to-speech interaction in multi-turn conversations. Unlike previous work that relies on a cascade framework combining ASR, LLM, and TTS, this paper proposes an end-to-end model that incorporates a decoder-only transformer architecture.",
            "paper-title": "Building a Taiwanese Mandarin Spoken Language Model: A First Attempt",
            "image-path": "flux_paper_image/2411.07111_1731455401.png"
        },

        {
            "startTime": "28:20",
            "arxivId": "2411.05943",
            "arxivLink": "https://arxiv.org/abs/2411.05943",
            "title": "AI's Got Algebra: New Framework Measures Reasoning Power",
            "institute": "IBM",
            "text": "This research introduces a new framework for quantifying symbolic reasoning in AI systems using algebraic circuit complexity. Unlike previous work that focuses on ad hoc benchmarks, this approach provides a theoretically-motivated framework for measuring the complexity of reasoning problems.",
            "paper-title": "Quantifying artificial intelligence through algebraic generalization",
            "image-path": "flux_paper_image/2411.05943_1731457645.png"
        },

        {
            "startTime": "28:38",
            "arxivId": "2411.06184",
            "arxivLink": "https://arxiv.org/abs/2411.06184",
            "title": "Hyperparameter Tuning for Lung Nodules: Multi-Task Bayesian Optimization to the Rescue!",
            "institute": "Tsinghua University, Chinese Academy of Sciences",
            "text": "This research explores the use of multi-task Bayesian optimization (MTBO) to accelerate hyperparameter tuning for multiple SVM classifiers in pulmonary nodule diagnosis. Unlike previous work that focuses on single-task optimization, this study leverages the relationships between tasks to improve efficiency.",
            "paper-title": "Alleviating Hyperparameter-Tuning Burden in SVM Classifiers for Pulmonary Nodules Diagnosis with Multi-Task Bayesian Optimization",
            "image-path": "flux_paper_image/2411.06184_1731453995.png"
        },

        {
            "startTime": "29:01",
            "arxivId": "2411.07154",
            "arxivLink": "https://arxiv.org/abs/2411.07154",
            "title": "Conditional Simulation Gets a Brenier Makeover: Entropic Optimal Transport to the Rescue!",
            "institute": "Caltech, NYU",
            "text": "This research proposes a non-parametric estimator for conditional Brenier maps, leveraging entropic optimal transport. Unlike previous methods, it provides a framework for using any estimator of the transport map and offers a way to quantify the error incurred by finite-sample estimators.",
            "paper-title": "Conditional simulation via entropic optimal transport: Toward non-parametric estimation of conditional Brenier maps",
            "image-path": "flux_paper_image/2411.07154_1731454399.png"
        },

        {
            "startTime": "29:24",
            "arxivId": "2411.05010",
            "arxivLink": "https://arxiv.org/abs/2411.05010",
            "title": "Code Generation: A Forest of Solutions, Not Just One Tree!",
            "institute": "Rensselaer Polytechnic Institute, Princeton University, NEC Laboratories America...",
            "text": "This research proposes a novel approach to code generation by framing it as a black-box optimization problem within the code space. It introduces SCATTERED FOREST SEARCH (SFS), a method that enhances exploration and exploitation of the solution space by dynamically varying input prompts and leveraging feedback from previous searches. This differs from previous methods like best-of-N sampling, line search, and tree search, which often produce similar solutions and struggle to fully explore the search space.",
            "paper-title": "Scattered Forest Search: Smarter Code Space Exploration with LLMs",
            "image-path": "flux_paper_image/2411.05010_1731452476.png"
        },

        {
            "startTime": "29:53",
            "arxivId": "2411.05189",
            "arxivLink": "https://arxiv.org/abs/2411.05189",
            "title": "Transformers: Not So Smart After All? Hijacking Attacks Expose Their Weaknesses!",
            "institute": "University of Cambridge, Google, Montreal Institute for Learning Algorithms...",
            "text": "This research investigates the adversarial robustness of in-context learning in transformers, specifically focusing on linear regression tasks. Unlike previous work that explored the capabilities of transformers in implementing learning algorithms, this study examines their vulnerability to prompt manipulation attacks, known as hijacking attacks.",
            "paper-title": "Adversarial Robustness of In-Context Learning in Transformers for Linear Regression",
            "image-path": "flux_paper_image/2411.05189_1731458684.png"
        },

        {
            "startTime": "30:21",
            "arxivId": "2411.05697",
            "arxivLink": "https://arxiv.org/abs/2411.05697",
            "title": "Pancreas MRI: AI Detects High-Risk Tumors, Keeps Patient Data Safe",
            "institute": "Northwestern University, Istanbul University, University of Catania...",
            "text": "This research uses federated learning to train a model for classifying IPMN risk on pancreas MRI data. This approach allows multiple institutions to collaborate on training a model without sharing raw patient data, ensuring privacy.",
            "paper-title": "IPMN Risk Assessment under Federated Learning Paradigm",
            "image-path": "flux_paper_image/2411.05697_1731453943.png"
        },

        {
            "startTime": "30:55",
            "arxivId": "2411.05783",
            "arxivLink": "https://arxiv.org/abs/2411.05783",
            "title": "Sign Language STEM: A Wiki for Deaf Students to Learn Science!",
            "institute": "UC Berkeley, University of Maryland, Microsoft",
            "text": "This research introduces ASL STEM Wiki, the first continuous sign language dataset focused on STEM topics. Unlike previous datasets that focus on general ASL or other domains, this dataset specifically addresses the lack of STEM resources in ASL.",
            "paper-title": "ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles",
            "image-path": "flux_paper_image/2411.05783_1731458187.png"
        },

        {
            "startTime": "31:22",
            "arxivId": "2411.06191",
            "arxivLink": "https://arxiv.org/abs/2411.06191",
            "title": "Hyper-Relational Knowledge Graphs: A New Way to Connect the Dots!",
            "institute": "Tsinghua University",
            "text": "This research proposes a new method for modeling hyper-relational knowledge graphs (HKGs) by generalizing the hyperedge expansion technique. Unlike previous work that focuses on either semantic or structural information, this approach transforms an HKG into a knowledge graph (KG) and then uses an encoder-decoder framework to capture both aspects simultaneously.",
            "paper-title": "Generalizing Hyperedge Expansion for Hyper-relational Knowledge Graph Modeling",
            "image-path": "flux_paper_image/2411.06191_1731454253.png"
        },

        {
            "startTime": "31:47",
            "arxivId": "2411.05823",
            "arxivLink": "https://arxiv.org/abs/2411.05823",
            "title": "LLMs Get Creative: Building 3D Models with Text and a Pinch of Magic!",
            "institute": "Zhejiang University, Microsoft",
            "text": "This research uses large language models (LLMs) to generate 3D CAD models based on user input. Unlike previous methods that rely on separate models for different types of control, this approach uses a single model to handle various control tasks across all CAD construction hierarchies.",
            "paper-title": "FlexCAD: Unified and Versatile Controllable CAD Generation with Fine-tuned Large Language Models",
            "image-path": "flux_paper_image/2411.05823_1731455084.png"
        },

        {
            "startTime": "32:08",
            "arxivId": "2411.06508",
            "arxivLink": "https://arxiv.org/abs/2411.06508",
            "title": "Equivariant Learning: It's Not Just About the Spin, It's About the Class!",
            "institute": "MIT",
            "text": "This research delves into the theoretical underpinnings of equivariant self-supervised learning (E-SSL), focusing on how it learns useful features for downstream tasks. Unlike previous work that primarily focused on empirical results, this paper uses an information-theoretic perspective to explain the \"explaining-away\" effect, which highlights the synergy between equivariant prediction and class information.",
            "paper-title": "Understanding the Role of Equivariance in Self-supervised Learning",
            "image-path": "flux_paper_image/2411.06508_1731455714.png"
        },

        {
            "startTime": "32:38",
            "arxivId": "2411.07239",
            "arxivLink": "https://arxiv.org/abs/2411.07239",
            "title": "DeepONet Gets a Tune-Up: Physics-Informed Fine-Tuning for Multi-Operator Extrapolation",
            "institute": "Purdue University, Yale University, UC Los Angeles",
            "text": "This research introduces a novel fine-tuning method for DeepONets, a type of neural network used for approximating operators in PDEs. The key innovation lies in using physics-informed losses for zero-shot fine-tuning, which means the model can adapt to new tasks without requiring additional training data. This approach leverages the physical principles embedded in both the pretrained and target operators, enabling models that not only outperform those trained from random initialization but also produce predictions consistent with fundamental physical laws.",
            "paper-title": "DeepONet as a Multi-Operator Extrapolation Model: Distributed Pretraining with Physics-Informed Fine-Tuning",
            "image-path": "flux_paper_image/2411.07239_1731458702.png"
        },

        {
            "startTime": "33:07",
            "arxivId": "2411.06391",
            "arxivLink": "https://arxiv.org/abs/2411.06391",
            "title": "Stock Market's New Sheriff: CausalStock Predicts Price Swings with a Causal Lens",
            "institute": "Renmin University of China, Peking University, King Abdullah University of Science and Technology",
            "text": "This research introduces CausalStock, a novel framework for news-driven multi-stock movement prediction. Unlike previous methods that focused on correlations, CausalStock leverages a lag-dependent temporal causal discovery mechanism to uncover the causal relationships between stocks. This allows for a more accurate and explainable prediction of stock price movements.",
            "paper-title": "CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction",
            "image-path": "flux_paper_image/2411.06391_1731456892.png"
        },

        {
            "startTime": "33:37",
            "arxivId": "2411.06971",
            "arxivLink": "https://arxiv.org/abs/2411.06971",
            "title": "MapSAM: Giving Historical Maps a Vision Makeover!",
            "institute": "ETH Zurich",
            "text": "This research adapts the Segment Anything Model (SAM), a powerful vision foundation model, for historical map segmentation. Unlike previous approaches that rely on extensive training data, MapSAM uses a parameter-efficient fine-tuning strategy to customize SAM for historical maps, requiring only a small amount of training data.",
            "paper-title": "MapSAM: Adapting Segment Anything Model for Automated Feature Detection in Historical Maps",
            "image-path": "flux_paper_image/2411.06971_1731458805.png"
        },

        {
            "startTime": "33:58",
            "arxivId": "2411.05877",
            "arxivLink": "https://arxiv.org/abs/2411.05877",
            "title": "LM's Got a New Trick: Adapting on the Fly with Generative Adapters!",
            "institute": "University of Washington, Microsoft",
            "text": "This paper introduces GenerativeAdapter, a method that directly maps new contexts to low-rank LM adapters, allowing for efficient adaptation without fine-tuning. This differs from previous work that relied on fine-tuning or prompting, which can be computationally expensive.",
            "paper-title": "Generative Adapter: Contextualizing Language Models in Parameters with A Single Forward Pass",
            "image-path": "flux_paper_image/2411.05877_1731453705.png"
        },

        {
            "startTime": "34:21",
            "arxivId": "2411.05335",
            "arxivLink": "https://arxiv.org/abs/2411.05335",
            "title": "Deepfakes: From Easy to Hard, Detectors Learn to Spot the Fakes!",
            "institute": "Shenzhen University, Peking University, Tencent",
            "text": "This research focuses on the varying quality of deepfakes, proposing a training framework that guides detectors to learn from easier, lower-quality fakes to more realistic, higher-quality ones. This approach aims to improve generalization performance by preventing detectors from relying on easily recognizable artifacts in low-quality samples.",
            "paper-title": "A Quality-Centric Framework for Generic Deepfake Detection",
            "image-path": "flux_paper_image/2411.05335_1731453138.png"
        },

        {
            "startTime": "34:44",
            "arxivId": "2411.06908",
            "arxivLink": "https://arxiv.org/abs/2411.06908",
            "title": "Video QA Data: It's Not Just About the Words, It's About the Keywords!",
            "institute": "Peking University, Beijing Institute of Technology",
            "text": "This research introduces EVQAScore, a new method for evaluating video question-answering (QA) data quality. Unlike previous methods that focus on video captions, EVQAScore leverages keyword extraction to assess both video captions and video QA data.",
            "paper-title": "EVQAScore: Efficient Video Question Answering Data Evaluation",
            "image-path": "flux_paper_image/2411.06908_1731455427.png"
        },

        {
            "startTime": "35:11",
            "arxivId": "2411.05026",
            "arxivLink": "https://arxiv.org/abs/2411.05026",
            "title": "Data Cleaning for LLMs: From \"Ugh, Noise!\" to \"Wow, Knowledge!\"",
            "institute": "Google",
            "text": "This research focuses on the specific challenges of cleaning data for training large language models (LLMs). It goes beyond general text preprocessing techniques and delves into issues like removing bias, handling multilingual data, and optimizing tokenization for LLMs.",
            "paper-title": "Deep Learning and Machine Learning -- Natural Language Processing: From Theory to Application",
            "image-path": "flux_paper_image/2411.05026_1731454076.png"
        },

        {
            "startTime": "35:32",
            "arxivId": "2411.06805",
            "arxivLink": "https://arxiv.org/abs/2411.06805",
            "title": "LLMs Get a Brain: Intelligent Assistant Boosts Reasoning Power",
            "institute": "Tsinghua University, Renmin University of China",
            "text": "This paper proposes a new approach called Assistant-based Retrieval-Augmented Generation (ASSISTRAG) that integrates an intelligent information assistant within LLMs. Unlike previous methods that rely on prompt engineering or supervised fine-tuning, ASSISTRAG uses a two-phase training approach to enhance information retrieval and decision-making.",
            "paper-title": "AssistRAG: Boosting the Potential of Large Language Models with an Intelligent Information Assistant",
            "image-path": "flux_paper_image/2411.06805_1731454053.png"
        },

        {
            "startTime": "35:56",
            "arxivId": "2411.05025",
            "arxivLink": "https://arxiv.org/abs/2411.05025",
            "title": "LLMs in Academia: Are Researchers Cheating or Just Getting Smart?",
            "institute": "University of Washington, Pioneer Centre for Artificial Intelligence, University of Copenhagen...",
            "text": "This research stands out by conducting a large-scale survey of 816 verified research article authors, providing a more comprehensive understanding of how researchers use LLMs compared to previous smaller-scale studies.",
            "paper-title": "LLMs as Research Tools: A Large Scale Survey of Researchers' Usage and Perceptions",
            "image-path": "flux_paper_image/2411.05025_1731453846.png"
        },

        {
            "startTime": "36:16",
            "arxivId": "2411.05599",
            "arxivLink": "https://arxiv.org/abs/2411.05599",
            "title": "Game On! Verifying the Psychology of Strategic Decisions",
            "institute": "University of Oxford, University of Glasgow",
            "text": "This research extends the traditional game theory framework by incorporating \"psychological games,\" where players' utilities depend not only on the actions taken but also on their beliefs about those actions. This approach allows for a more nuanced understanding of strategic interactions, particularly in scenarios involving human-computer interaction.",
            "paper-title": "Expectation vs. Reality: Towards Verification of Psychological Games",
            "image-path": "flux_paper_image/2411.05599_1731452485.png"
        },

        {
            "startTime": "36:47",
            "arxivId": "2411.05900",
            "arxivLink": "https://arxiv.org/abs/2411.05900",
            "title": "ECG + CMR + Tabular Data: A Recipe for Better Heart Health Predictions!",
            "institute": "ETH Zurich, Harvard University, University of Zurich",
            "text": "This research combines three different types of medical data - ECG signals, CMR images, and tabular data - to predict cardiovascular disease. Previous studies have focused on using only one or two of these modalities.",
            "paper-title": "Enhancing Cardiovascular Disease Prediction through Multi-Modal Self-Supervised Learning",
            "image-path": "flux_paper_image/2411.05900_1731453876.png"
        },

        {
            "startTime": "37:07",
            "arxivId": "2411.07233",
            "arxivLink": "https://arxiv.org/abs/2411.07233",
            "title": "Diffusion Models Get a Boost from Active Noise!",
            "institute": "University of Chicago",
            "text": "This research introduces \"active\" noise sources into the forward process of generative diffusion models, replacing the traditional Gaussian white noise with exponentially time-correlated noise. This approach introduces a new hyperparameter, the correlation time, which can be tuned to optimize training and sampling efficiency.",
            "paper-title": "Score-based generative diffusion with\"active\"correlated noise sources",
            "image-path": "flux_paper_image/2411.07233_1731452499.png"
        },

        {
            "startTime": "37:32",
            "arxivId": "2411.06917",
            "arxivLink": "https://arxiv.org/abs/2411.06917",
            "title": "Air Pollution Prediction: A Tikhonov-Regularized Twist on Domain Adaptation",
            "institute": "EPFL",
            "text": "This research proposes a novel unsupervised domain adaptation (UDA) method called TikUDA, specifically tailored for regression tasks on graph-structured data. Unlike previous UDA methods for regression, TikUDA leverages Tikhonov regularization to align subspaces between source and target domains, resulting in faster training times and improved scalability.",
            "paper-title": "Efficient Unsupervised Domain Adaptation Regression for Spatial-Temporal Air Quality Sensor Fusion",
            "image-path": "flux_paper_image/2411.06917_1731458768.png"
        },

        {
            "startTime": "37:58",
            "arxivId": "2411.05746",
            "arxivLink": "https://arxiv.org/abs/2411.05746",
            "title": "Adam's Got a Secret: Continuous-Time Reveals the Hidden Power of Normalization",
            "institute": "University of Cambridge, Harvard University",
            "text": "This research uses a continuous-time model to analyze Adam and AdamW, providing a deeper understanding of their training dynamics and the role of normalization layers. Unlike previous work, which focused on asymptotic convergence rates, this study explores the impact of hyperparameter choices and architectural decisions on generalization performance.",
            "paper-title": "Continuous-Time Analysis of Adaptive Optimization and Normalization",
            "image-path": "flux_paper_image/2411.05746_1731454421.png"
        },

        {
            "startTime": "38:16",
            "arxivId": "2411.05540",
            "arxivLink": "https://arxiv.org/abs/2411.05540",
            "title": "CRepair: Fixing Code Bugs with a Little Help from AI's Imagination!",
            "institute": "Nanning Normal University",
            "text": "This research introduces CRepair, a vulnerability repair technique that uses a Conditional Variational Autoencoder (CVAE) to learn diverse vulnerability features and generate repair patches. Unlike previous methods that rely on fixed encoding, CRepair maps vulnerability features to probability distributions, allowing for more flexible and accurate repair.",
            "paper-title": "CRepair: CVAE-based Automatic Vulnerability Repair Technology",
            "image-path": "flux_paper_image/2411.05540_1731455295.png"
        },

        {
            "startTime": "38:35",
            "arxivId": "2411.05197",
            "arxivLink": "https://arxiv.org/abs/2411.05197",
            "title": "Can You Hear That? It's Your LLM Whispering Its Hardware Secrets!",
            "institute": "Imperial College London, University of Cambridge, Google DeepMind",
            "text": "This research introduces a novel method called Hardware and Software Platform Inference (HSPI) that can identify the underlying GPU architecture and software stack of a machine learning model solely based on its input-output behavior. Unlike previous work that focused on identifying model families or specific hardware components, HSPI aims to uncover the entire hardware-software supply chain.",
            "paper-title": "Hardware and Software Platform Inference",
            "image-path": "flux_paper_image/2411.05197_1731453228.png"
        },

        {
            "startTime": "38:57",
            "arxivId": "2411.06659",
            "arxivLink": "https://arxiv.org/abs/2411.06659",
            "title": "Graph Learning's Memory Makeover: A New Trick to Remember Everything!",
            "institute": "Tsinghua University, Shanghai Artificial Intelligence Laboratory, Harbin Institute of Technology",
            "text": "This research introduces Mecoin, a memory module for graph few-shot class-incremental learning (GFSCIL). Unlike previous methods that rely on extensive training samples or parameter fine-tuning, Mecoin efficiently learns and stores class prototypes while minimizing knowledge loss.",
            "paper-title": "An Efficient Memory Module for Graph Few-Shot Class-Incremental Learning",
            "image-path": "flux_paper_image/2411.06659_1731453575.png"
        },

        {
            "startTime": "39:23",
            "arxivId": "2411.06866",
            "arxivLink": "https://arxiv.org/abs/2411.06866",
            "title": "Subgraph Retrieval: A Knowledge Graph's Best Friend for Commonsense QA",
            "institute": "Peking University, Ant Group, Beijing Normal University",
            "text": "This paper proposes a novel framework called SEPTA for commonsense question answering (CSQA) that transforms the knowledge graph into a database of subgraph vectors, shifting the focus from retrieving a relevant subgraph to obtaining relevant subgraph vectors. This approach differs from previous extracting-and-modeling paradigms by bypassing the challenges inherent in subgraph extraction.",
            "paper-title": "Subgraph Retrieval Enhanced by Graph-Text Alignment for Commonsense Question Answering",
            "image-path": "flux_paper_image/2411.06866_1731456719.png"
        },

        {
            "startTime": "39:51",
            "arxivId": "2411.05738",
            "arxivLink": "https://arxiv.org/abs/2411.05738",
            "title": "Single Image, Decomposed 3D Character: StdGEN Makes It Happen!",
            "institute": "Tencent, Tsinghua University",
            "text": "This research introduces StdGEN, a pipeline that generates semantically decomposed 3D characters from single images. Unlike previous methods that focus on generating holistic models, StdGEN leverages a Semantic-aware Large Reconstruction Model (S-LRM) to reconstruct geometry, color, and semantics simultaneously, enabling the generation of distinct semantic components like the body, clothes, and hair.",
            "paper-title": "StdGEN: Semantic-Decomposed 3D Character Generation from Single Images",
            "image-path": "flux_paper_image/2411.05738_1731454017.png"
        },

        {
            "startTime": "40:16",
            "arxivId": "2411.05856",
            "arxivLink": "https://arxiv.org/abs/2411.05856",
            "title": "AI in Psychiatry: Is It Worth the Dough?",
            "institute": "University of Toronto, University of Western Ontario",
            "text": "This research focuses on the economic implications of using machine learning (ML) in clinical psychiatry, a gap in the existing literature.",
            "paper-title": "Evaluating the Economic Implications of Using Machine Learning in Clinical Psychiatry",
            "image-path": "flux_paper_image/2411.05856_1731453731.png"
        },

        {
            "startTime": "40:34",
            "arxivId": "2411.05500",
            "arxivLink": "https://arxiv.org/abs/2411.05500",
            "title": "Pruning Deep Learning Models: A Gradient-First Approach to Sparsity",
            "institute": "NVIDIA Corporation",
            "text": "This research introduces a new method for pruning deep learning models called Fixed-Rate Gradient-First Gradual Pruning (FGGP). Unlike previous methods that prioritize weight magnitudes, FGGP prioritizes gradient magnitudes first, then weight magnitudes, to identify and remove unimportant parameters.",
            "paper-title": "FGGP: Fixed-Rate Gradient-First Gradual Pruning",
            "image-path": "flux_paper_image/2411.05500_1731453418.png"
        },

        {
            "startTime": "41:04",
            "arxivId": "2411.06739",
            "arxivLink": "https://arxiv.org/abs/2411.06739",
            "title": "Low-Rank MDPs: When Bandit Feedback Meets Adversarial Losses",
            "institute": "University of Virginia, Google",
            "text": "This research explores regret minimization in low-rank Markov Decision Processes (MDPs) with unknown transitions and adversarial losses. Unlike previous work that focused on either full-information loss feedback with unknown transitions or bandit loss feedback with known transitions, this paper investigates the challenging scenario where both bandit feedback and unknown transitions are present.",
            "paper-title": "Beating Adversarial Low-Rank MDPs with Unknown Transition and Bandit Feedback",
            "image-path": "flux_paper_image/2411.06739_1731453459.png"
        },

        {
            "startTime": "41:22",
            "arxivId": "2411.06890",
            "arxivLink": "https://arxiv.org/abs/2411.06890",
            "title": "World Models Learn to Think Locally: Sparsity Makes the Difference!",
            "institute": "University of Oxford, Max Planck Society",
            "text": "This research introduces SPARTAN, a Transformer-based world model that learns local causal structures between entities in a scene. Unlike previous work that learns fixed global causal graphs, SPARTAN uses sparsity regularisation to identify sparse local causal models, which are more accurate and interpretable.",
            "paper-title": "SPARTAN: A Sparse Transformer Learning Local Causation",
            "image-path": "flux_paper_image/2411.06890_1731459031.png"
        },

        {
            "startTime": "41:50",
            "arxivId": "2411.05222",
            "arxivLink": "https://arxiv.org/abs/2411.05222",
            "title": "Video Transformers Get a Speed Boost with Run-Length Tokenization!",
            "institute": "CMU",
            "text": "This paper introduces Run-Length Tokenization (RLT), a method that speeds up video transformers by identifying and removing redundant patches in videos. Unlike previous methods that either have significant overhead or require tuning for different datasets, RLT is content-aware and requires no tuning.",
            "paper-title": "Don't Look Twice: Faster Video Transformers with Run-Length Tokenization",
            "image-path": "flux_paper_image/2411.05222_1731453894.png"
        },

        {
            "startTime": "42:11",
            "arxivId": "2411.05679",
            "arxivLink": "https://arxiv.org/abs/2411.05679",
            "title": "\"Tell What You Hear From What You See: AI Learns to Generate Sound From Videos with a Little Help From Text\"",
            "institute": "University of Washington",
            "text": "This research introduces VATT, a framework that generates audio from videos, but unlike previous methods, it can be guided by text prompts. This allows for more control over the generated audio, ensuring it aligns with both the visual content and the desired sound characteristics.",
            "paper-title": "Tell What You Hear From What You See -- Video to Audio Generation Through Text",
            "image-path": "flux_paper_image/2411.05679_1731452878.png"
        },

        {
            "startTime": "42:41",
            "arxivId": "2411.06606",
            "arxivLink": "https://arxiv.org/abs/2411.06606",
            "title": "Gen-AI: The New Sheriff in User Safety Town",
            "institute": "Google",
            "text": "This research focuses on how Generative AI (Gen-AI) techniques can be used to improve user safety across various domains, including online threat protection, misinformation detection, content moderation, and physical safety. It distinguishes itself from previous work by exploring the unique capabilities of Gen-AI in understanding natural language, translating between languages, and adapting to different tasks and domains.",
            "paper-title": "Gen-AI for User Safety: A Survey",
            "image-path": "flux_paper_image/2411.06606_1731455771.png"
        },

        {
            "startTime": "43:00",
            "arxivId": "2411.05348",
            "arxivLink": "https://arxiv.org/abs/2411.05348",
            "title": "StarCraft II Gets a Language Model Makeover: LLMs Take on the Real-Time Strategy Game!",
            "institute": "Nankai University, National University of Defense Technology",
            "text": "This research introduces LLM-PySC2, a new environment for training Large Language Models (LLMs) to make decisions in the complex StarCraft II game. Unlike previous environments, LLM-PySC2 provides a complete action space, multi-modal observations, and a structured game knowledge database, allowing LLMs to interact with the game in a more comprehensive way.",
            "paper-title": "LLM-PySC2: Starcraft II learning environment for Large Language Models",
            "image-path": "flux_paper_image/2411.05348_1731452937.png"
        },

        {
            "startTime": "43:24",
            "arxivId": "2411.05200",
            "arxivLink": "https://arxiv.org/abs/2411.05200",
            "title": "Chatbots Got Feelings? New Research Uncovers AI's Cultural IQ",
            "institute": "Massachusetts Institute of Technology",
            "text": "This paper proposes a new framework called \"cultural interpretability\" (CI) to analyze how large language models (LLMs) learn and represent cultural aspects of language. Unlike previous work that focuses on linguistic competence, CI examines how LLMs understand and use language in a culturally appropriate way, considering factors like politeness and repetition.",
            "paper-title": "Toward Cultural Interpretability: A Linguistic Anthropological Framework for Describing and Evaluating Large Language Models (LLMs)",
            "image-path": "flux_paper_image/2411.05200_1731454794.png"
        },

        {
            "startTime": "43:46",
            "arxivId": "2411.06315",
            "arxivLink": "https://arxiv.org/abs/2411.06315",
            "title": "Brain-bending 3D Registration: NeuReg Makes It Easy!",
            "institute": "Tibbling Technologies",
            "text": "This research introduces NeuReg, a 3D image registration architecture that uses a Swin Transformer encoder and a model-driven decoder to generate domain-agnostic representations of brain volumes. This approach differs from previous methods by minimizing the need for extensive training data and achieving high performance across different imaging modalities and species.",
            "paper-title": "NeuReg: Domain-invariant 3D Image Registration on Human and Mouse Brains",
            "image-path": "flux_paper_image/2411.06315_1731454989.png"
        },

        {
            "startTime": "44:10",
            "arxivId": "2411.07104",
            "arxivLink": "https://arxiv.org/abs/2411.07104",
            "title": "Quadrupedal Robots Learn to Push Like a Boss (and Avoid Obstacles!)",
            "institute": "Carnegie Mellon University, Google DeepMind",
            "text": "This research focuses on long-horizon, obstacle-aware pushing by multiple quadrupedal robots, a task that has been largely unexplored. It proposes a hierarchical multi-agent reinforcement learning framework with three levels of control to achieve this. Unlike previous work, this approach uses a centralized adaptive policy to generate subgoals for the object, enabling more effective coordination and obstacle avoidance.",
            "paper-title": "Learning Multi-Agent Collaborative Manipulation for Long-Horizon Quadrupedal Pushing",
            "image-path": "flux_paper_image/2411.07104_1731453272.png"
        },

        {
            "startTime": "44:34",
            "arxivId": "2411.06655",
            "arxivLink": "https://arxiv.org/abs/2411.06655",
            "title": "Chess Bots Get a Language Lesson: Can Talking Help Them Play Better?",
            "institute": "UCLA, Microsoft Research, MBZUAI...",
            "text": "This research explores the impact of incorporating strategic and tactical explanations into chess datasets for training large language models (LLMs). Unlike previous work that focused on improving chess-playing capabilities through search algorithms or deep neural networks, this study investigates whether language annotations can enhance LLMs' reasoning abilities in the context of chess.",
            "paper-title": "Explore the Reasoning Capability of LLMs in the Chess Testbed",
            "image-path": "flux_paper_image/2411.06655_1731455969.png"
        },

        {
            "startTime": "44:57",
            "arxivId": "2411.05837",
            "arxivLink": "https://arxiv.org/abs/2411.05837",
            "title": "Smoothing Out the Noise: How Gaussian Blur Makes AI Explanations More Reliable",
            "institute": "Tsinghua University, Chinese University of Hong Kong",
            "text": "This research extends the algorithmic stability framework to gradient-based saliency maps, proving bounds on the stability error of standard Simple-Grad, Integrated-Gradients, and Smooth-Grad saliency maps. It analyzes the fidelity of Smooth-Grad maps and their faithfulness to the original Simple-Grad map.",
            "paper-title": "On the Trade-Off between Stability and Fidelity of Gaussian-Smoothed Saliency Maps",
            "image-path": "flux_paper_image/2411.05837_1731457183.png"
        },

        {
            "startTime": "45:21",
            "arxivId": "2411.06481",
            "arxivLink": "https://arxiv.org/abs/2411.06481",
            "title": "Mamba's Memory Makeover: Keyframe Masking for Longer, More Accurate Motion Generation",
            "institute": "Peking University, The Australian National University, Monash University...",
            "text": "This research introduces a novel keyframe masking strategy for extended motion generation. Unlike previous methods that rely on random masking, this approach identifies key frames based on local density and pairwise distance, allowing the model to focus on learning critical actions within long sequences.",
            "paper-title": "KMM: Key Frame Mask Mamba for Extended Motion Generation",
            "image-path": "flux_paper_image/2411.06481_1731458852.png"
        },

        {
            "startTime": "45:47",
            "arxivId": "2411.06782",
            "arxivLink": "https://arxiv.org/abs/2411.06782",
            "title": "Robot Dog Learns to Grasp Like a Pro, Even Transparent Objects!",
            "institute": "Peking University",
            "text": "This research introduces a modular system for quadrupedal whole-body grasping, combining a learned 5D base locomotion policy with a novel Generalized Oriented Reachability Map (GORM) to guide the robot's movements. This approach differs from previous work by integrating accurate manipulation with coordinated whole-body locomotion, resulting in a more robust and generalizable system.",
            "paper-title": "QuadWBG: Generalizable Quadrupedal Whole-Body Grasping",
            "image-path": "flux_paper_image/2411.06782_1731456849.png"
        },

        {
            "startTime": "46:12",
            "arxivId": "2411.06067",
            "arxivLink": "https://arxiv.org/abs/2411.06067",
            "title": "Turning Your Primitive Apartment into a Dream Home: AI-Powered 3D Stylization",
            "institute": "University of California Berkeley",
            "text": "This research introduces a pipeline that combines image stylization techniques with 3D scene generation models to create stylized 3D environments from basic primitives. This approach differs from previous work by integrating text-guided image editing into the 3D scene generation process, allowing for more user-friendly control over the stylization of objects within a scene.",
            "paper-title": "AI-Driven Stylization of 3D Environments",
            "image-path": "flux_paper_image/2411.06067_1731457939.png"
        },

        {
            "startTime": "46:34",
            "arxivId": "2411.06848",
            "arxivLink": "https://arxiv.org/abs/2411.06848",
            "title": "Training Tiny Neural Networks: A Generative Approach to Feature Learning",
            "institute": "University College London, Chemnitz University of Technology",
            "text": "This research proposes a generative modeling approach to train 2-layer neural networks with a small number of hidden weights. Unlike previous methods that rely on fixed features, this approach learns a distribution of features using a deep generative model.",
            "paper-title": "Generative Feature Training of Thin 2-Layer Networks",
            "image-path": "flux_paper_image/2411.06848_1731454528.png"
        },

        {
            "startTime": "46:56",
            "arxivId": "2411.06229",
            "arxivLink": "https://arxiv.org/abs/2411.06229",
            "title": "Urban Space: A New Map for Cities, Made with AI and POIs!",
            "institute": "University College London, University of Surrey",
            "text": "This research proposes a new method for learning urban space representations using a multimodal contrastive learning approach. Unlike previous methods that rely on aggregating POI category embeddings, this model directly embeds continuous urban spaces into vector representations, capturing both spatial and semantic information.",
            "paper-title": "Multimodal Contrastive Learning of Urban Space Representations from POI Data",
            "image-path": "flux_paper_image/2411.06229_1731454773.png"
        },

        {
            "startTime": "47:24",
            "arxivId": "2411.05472",
            "arxivLink": "https://arxiv.org/abs/2411.05472",
            "title": "Molecule Generation: Bridging the Gap Between Learning and Inference with a Pinch of Magic!",
            "institute": "Sichuan University, Tsinghua University",
            "text": "This research proposes a training framework called GapDiff to address the exposure bias issue in diffusion models for 3D molecule generation. It utilizes model-predicted conformations as ground truth probabilistically during training, aiming to mitigate the data distributional disparity between training and inference.",
            "paper-title": "Bridging the Gap between Learning and Inference for Diffusion-Based Molecule Generation",
            "image-path": "flux_paper_image/2411.05472_1731456431.png"
        },

        {
            "startTime": "47:48",
            "arxivId": "2411.05379",
            "arxivLink": "https://arxiv.org/abs/2411.05379",
            "title": "Wordsmiths: How Language Evolves to Be Efficiently Chatty",
            "institute": "University of Toronto, University of Melbourne",
            "text": "This research examines how word reuse and combination, often studied separately, are both shaped by the need for efficient communication. It proposes a unified account of lexicalization grounded in the theory of efficient communication.",
            "paper-title": "Word reuse and combination support efficient communication of emerging concepts.",
            "image-path": "flux_paper_image/2411.05379_1731453561.png"
        },

        {
            "startTime": "48:12",
            "arxivId": "2411.06128",
            "arxivLink": "https://arxiv.org/abs/2411.06128",
            "title": "Warehouse Robots: Dijkstra's Algorithm Gets a PPO Makeover!",
            "institute": "Peking University, NYU, UC Berkeley...",
            "text": "This research combines the Proximal Policy Optimization (PPO) algorithm with Dijkstra's algorithm for warehouse robot navigation. This approach differs from previous work by integrating reinforcement learning for dynamic adaptation with traditional path planning for efficient initial route generation.",
            "paper-title": "Research on reinforcement learning based warehouse robot navigation algorithm in complex warehouse layout",
            "image-path": "flux_paper_image/2411.06128_1731455800.png"
        },

        {
            "startTime": "48:39",
            "arxivId": "2411.06839",
            "arxivLink": "https://arxiv.org/abs/2411.06839",
            "title": "LLM-Neo: Knowledge Distillation Gets a Low-Rank Makeover!",
            "institute": "Tsinghua University, University of Hong Kong, Tencent",
            "text": "This paper proposes LLM-Neo, a method that combines knowledge distillation (KD) with low-rank adaptation (LoRA) to efficiently compress large language models (LLMs). Unlike traditional KD, which updates all model parameters, LLM-Neo leverages LoRA's low-rank branch for parameter-efficient knowledge transfer.",
            "paper-title": "LLM-Neo: Parameter Efficient Knowledge Distillation for Large Language Models",
            "image-path": "flux_paper_image/2411.06839_1731452720.png"
        },

        {
            "startTime": "49:02",
            "arxivId": "2411.07121",
            "arxivLink": "https://arxiv.org/abs/2411.07121",
            "title": "Seeing the Whole Picture: Decoding Visual Experiences with the Entire Brain",
            "institute": "Stanford University",
            "text": "This research uses a pre-trained foundation model to decode visual representations across the entire brain, rather than just the visual cortex, which is a common approach in previous studies.",
            "paper-title": "Decoding Visual Experience and Mapping Semantics through Whole-Brain Analysis Using fMRI Foundation Models",
            "image-path": "flux_paper_image/2411.07121_1731455202.png"
        },

        {
            "startTime": "49:20",
            "arxivId": "2411.06329",
            "arxivLink": "https://arxiv.org/abs/2411.06329",
            "title": "Bandit Algorithms: Balancing Exploration and Exploitation for Smarter Decisions",
            "institute": "Hong Kong University of Science and Technology, University of Pennsylvania",
            "text": "This research focuses on statistical inference for high-dimensional sparse linear contextual bandits, a problem that has been largely unexplored in previous work. The paper introduces a novel debiasing method using inverse propensity weighting (IPW) to address the bias introduced by adaptive data collection and implicit regularization in sparse estimators.",
            "paper-title": "Regret Minimization and Statistical Inference in Online Decision Making with High-dimensional Covariates",
            "image-path": "flux_paper_image/2411.06329_1731452265.png"
        },

        {
            "startTime": "49:40",
            "arxivId": "2411.06590",
            "arxivLink": "https://arxiv.org/abs/2411.06590",
            "title": "AI Gets a Critic: LLMs Learn to Spot Model Flaws",
            "institute": "Stanford University",
            "text": "This research introduces CriticAL, a system that uses LLMs to automatically generate critiques of scientific models by identifying discrepancies between model predictions and data. Unlike previous work, CriticAL goes beyond simply identifying discrepancies and uses hypothesis testing to assess their significance.",
            "paper-title": "CriticAL: Critic Automation with Language Models",
            "image-path": "flux_paper_image/2411.06590_1731453802.png"
        },

        {
            "startTime": "50:00",
            "arxivId": "2411.05813",
            "arxivLink": "https://arxiv.org/abs/2411.05813",
            "title": "AI for ERW Detection: A Minefield of Research!",
            "institute": "University College London",
            "text": "This research provides a comprehensive overview of AI applications for ERW detection, highlighting the two main streams: object detection and risk prediction. It also identifies gaps in current research and suggests opportunities for future work.",
            "paper-title": "AI for ERW Detection in Clearance Operations -- The State of Research",
            "image-path": "flux_paper_image/2411.05813_1731453143.png"
        },

        {
            "startTime": "50:26",
            "arxivId": "2411.07127",
            "arxivLink": "https://arxiv.org/abs/2411.07127",
            "title": "LLMs Get Judged, No Gold Standard Needed!",
            "institute": "University of Michigan, Peking University",
            "text": "This research introduces a new evaluation metric called GEM (Generative Estimator for Mutual Information) that can assess the quality of language models' judgments without relying on a gold standard reference. This is different from previous work that typically uses multiple-choice questions or tasks with objective answers.",
            "paper-title": "Benchmarking LLMs' Judgments with No Gold Standard",
            "image-path": "flux_paper_image/2411.07127_1731456304.png"
        },

        {
            "startTime": "50:48",
            "arxivId": "2411.06465",
            "arxivLink": "https://arxiv.org/abs/2411.06465",
            "title": "LLM Training: Don't Let Your Memory Overflow, Use This Formula!",
            "institute": "Institute of Science Tokyo, Turing. inc, Super Computing Research Center",
            "text": "This research provides precise formulas to estimate memory consumption for 4D parallel training of LLMs in the Llama architecture, considering factors like temporary buffers and memory fragmentation. This differs from previous work by providing a more comprehensive and accurate memory estimation for the Llama architecture, which is widely adopted in recent open-source models.",
            "paper-title": "Accelerating Large Language Model Training with 4D Parallelism and Memory Consumption Estimator",
            "image-path": "flux_paper_image/2411.06465_1731455688.png"
        },

        {
            "startTime": "51:21",
            "arxivId": "2411.06870",
            "arxivLink": "https://arxiv.org/abs/2411.06870",
            "title": "AI-Native 6G: A Layered Architecture for a Seamlessly Connected Future",
            "institute": "DigitalCatapult, Kings College London, Thales Research and Technology...",
            "text": "This research proposes a layered architecture for 6G networks that incorporates AI-native principles, multi-access technologies, and cloud-native solutions. It differs from previous work by emphasizing a holistic approach to AI integration, encompassing ethical considerations and ensuring trustworthiness, resilience, and verifiability across the entire network.",
            "paper-title": "AI-Native Multi-Access Future Networks -- The REASON Architecture",
            "image-path": "flux_paper_image/2411.06870_1731458834.png"
        },

        {
            "startTime": "51:49",
            "arxivId": "2411.06200",
            "arxivLink": "https://arxiv.org/abs/2411.06200",
            "title": "Boosting's Big Bust: Why Learning from Aggregate Labels is a Tough Nut to Crack",
            "institute": "Google",
            "text": "This paper explores the possibility of using boosting techniques to improve the accuracy of classifiers in learning from aggregate labels (LLP and MIL). Unlike previous work that empirically evaluated boosting heuristics, this research proves that boosting is impossible in both LLP and MIL settings under certain conditions.",
            "paper-title": "Weak to Strong Learning from Aggregate Labels",
            "image-path": "flux_paper_image/2411.06200_1731455079.png"
        },

        {
            "startTime": "52:04",
            "arxivId": "2411.05899",
            "arxivLink": "https://arxiv.org/abs/2411.05899",
            "title": "Streaming Bayes: GFlowNets Learn to Forget the Past!",
            "institute": "Funda\u00e7\u00e3o Getulio Vargas, University College London",
            "text": "This research introduces a novel method for training GFlowNets in a streaming setting, allowing them to update their posterior distribution as new data arrives without needing to reprocess all past data. This is achieved by leveraging a streaming balance condition and a tailored procedure that only requires the newly observed data.",
            "paper-title": "Streaming Bayes GFlowNets",
            "image-path": "flux_paper_image/2411.05899_1731453055.png"
        },

        {
            "startTime": "52:28",
            "arxivId": "2411.05054",
            "arxivLink": "https://arxiv.org/abs/2411.05054",
            "title": "AI Makes FMEAs a Breeze: Say Goodbye to Tedious Equipment Maintenance Docs!",
            "institute": "IBM",
            "text": "This research explores using large language models (LLMs) to generate Failure Mode and Effects Analysis (FMEA) documents, a crucial tool in reliability engineering. The novelty lies in the use of dynamic few-shot prompting (DFSP), which involves retrieving relevant examples from a database and incorporating them into the prompts given to the LLM. This approach aims to improve the accuracy and efficiency of FMEA generation.",
            "paper-title": "FMEA Builder: Expert Guided Text Generation for Equipment Maintenance",
            "image-path": "flux_paper_image/2411.05054_1731454540.png"
        },

        {
            "startTime": "52:49",
            "arxivId": "2411.06032",
            "arxivLink": "https://arxiv.org/abs/2411.06032",
            "title": "LLMs: Do They Speak Your Language? A New Benchmark Tests Cultural Values in AI",
            "institute": "Tsinghua University, Microsoft, Chinese Academy of Sciences",
            "text": "This research introduces a novel benchmark, LLM-GLOBE, to evaluate the cultural values embedded in LLM outputs. Unlike previous work that primarily focused on closed-ended questions, this study utilizes both closed-ended and open-ended prompts, including a novel \"LLMs-as-a-Jury\" protocol for scoring open-ended responses.",
            "paper-title": "LLM-GLOBE: A Benchmark Evaluating the Cultural Values Embedded in LLM Output",
            "image-path": "flux_paper_image/2411.06032_1731455782.png"
        },

        {
            "startTime": "53:15",
            "arxivId": "2411.07042",
            "arxivLink": "https://arxiv.org/abs/2411.07042",
            "title": "AI Companions: When Values Clash, Minion Steps In!",
            "institute": "Tsinghua University, CMU, City University of Hong Kong",
            "text": "This research focuses on resolving value conflicts between users and AI companions, specifically those powered by Large Language Models (LLMs). Unlike previous work that primarily addressed technical conflicts, this study explores the unique challenges of value-based disagreements in the context of AI companions.",
            "paper-title": "Minion: A Technology Probe for Resolving Value Conflicts through Expert-Driven and User-Driven Strategies in AI Companion Applications",
            "image-path": "flux_paper_image/2411.07042_1731454093.png"
        },

        {
            "startTime": "53:34",
            "arxivId": "2411.06239",
            "arxivLink": "https://arxiv.org/abs/2411.06239",
            "title": "Cybersecurity's New Weapon: A Graph That Sniffs Out Bad Guys",
            "institute": "Microsoft",
            "text": "This research introduces TITAN, a framework that uses a dynamic graph to track cyber threats in real-time. Unlike traditional approaches that rely on static analysis or manual investigation, TITAN leverages a guilt-by-association framework to propagate reputation scores across millions of entities, incidents, and organizations.",
            "paper-title": "Web Scale Graph Mining for Cyber Threat Intelligence",
            "image-path": "flux_paper_image/2411.06239_1731453699.png"
        },

        {
            "startTime": "53:56",
            "arxivId": "2411.07182",
            "arxivLink": "https://arxiv.org/abs/2411.07182",
            "title": "One-Shot Federated Learning Gets a Boost: Ensembling for Accuracy Without the Communication Blues!",
            "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
            "text": "This research introduces FENS, a novel federated ensembling scheme that combines one-shot federated learning (OFL) with standard federated learning (FL). Unlike previous OFL methods that rely on simple aggregation schemes, FENS trains a lightweight prediction aggregator model using FL, which significantly improves accuracy.",
            "paper-title": "Revisiting Ensembling in One-Shot Federated Learning",
            "image-path": "flux_paper_image/2411.07182_1731452312.png"
        },

        {
            "startTime": "54:21",
            "arxivId": "2411.05359",
            "arxivLink": "https://arxiv.org/abs/2411.05359",
            "title": "India's Farmland Gets a High-Res Makeover: AI Maps Millions of Fields",
            "institute": "Google",
            "text": "This research uses a multi-class panoptic segmentation model to map agricultural landscapes at a national scale, focusing on smallholder farms. This approach goes beyond traditional field boundary delineation by identifying trees and water bodies within the landscape, providing a more nuanced understanding of land-use patterns.",
            "paper-title": "Agricultural Landscape Understanding At Country-Scale",
            "image-path": "flux_paper_image/2411.05359_1731454500.png"
        },

        {
            "startTime": "54:40",
            "arxivId": "2411.06815",
            "arxivLink": "https://arxiv.org/abs/2411.06815",
            "title": "Streetwise Agents: Outsmarting the Unexpected in Real-Time Communication",
            "institute": "Microsoft",
            "text": "This research proposes a novel post-deployment policy shaping framework called \"Streetwise\" to address the challenge of exogenous disturbances in offline reinforcement learning (RL) policies. Unlike previous work that focuses on improving value function estimation or regularizing policy gradients, Streetwise directly tackles the issue of unseen disturbances by shaping the policy's output in real-time based on the characterization of out-of-distribution (OOD) subspaces.",
            "paper-title": "Streetwise Agents: Empowering Offline RL Policies to Outsmart Exogenous Stochastic Disturbances in RTC",
            "image-path": "flux_paper_image/2411.06815_1731455944.png"
        },

        {
            "startTime": "55:06",
            "arxivId": "2411.06347",
            "arxivLink": "https://arxiv.org/abs/2411.06347",
            "title": "Facial Expressions: The Secret Language of Japanese Sign Language",
            "institute": "Waseda University",
            "text": "This research focuses on facial expressions in Japanese Sign Language (JSL), a feature often overlooked in sign language recognition studies. It proposes a method to classify JSL sentences based on facial expressions, using a neural network trained on a dataset of JSL videos.",
            "paper-title": "Classification in Japanese Sign Language Based on Dynamic Facial Expressions",
            "image-path": "flux_paper_image/2411.06347_1731454125.png"
        },

        {
            "startTime": "55:28",
            "arxivId": "2411.06568",
            "arxivLink": "https://arxiv.org/abs/2411.06568",
            "title": "Mirror, Mirror, On the Wall, Who's the Best Policy of Them All?",
            "institute": "University of Oxford",
            "text": "This research introduces a novel framework for preference optimization based on mirror descent, which generalizes existing methods like DPO and ORPO. The authors use evolutionary strategies to discover new loss functions within this framework, leading to improved performance in various scenarios.",
            "paper-title": "Learning Loss Landscapes in Preference Optimization",
            "image-path": "flux_paper_image/2411.06568_1731458890.png"
        },

        {
            "startTime": "55:53",
            "arxivId": "2411.05597",
            "arxivLink": "https://arxiv.org/abs/2411.05597",
            "title": "Stroke Prediction: Seeing Stars, Saving Lives!",
            "institute": "ETH Zurich",
            "text": "This research uses a novel approach to stroke prediction by integrating retinal vessel graphs with clinical data in a contrastive learning framework. This differs from previous work by leveraging the topological and geometric properties of retinal vessels for more efficient representation.",
            "paper-title": "Predicting Stroke through Retinal Graphs and Multimodal Self-supervised Learning",
            "image-path": "flux_paper_image/2411.05597_1731458929.png"
        },

        {
            "startTime": "56:15",
            "arxivId": "2411.05561",
            "arxivLink": "https://arxiv.org/abs/2411.05561",
            "title": "AI's Got a Memory Problem: How Training Objectives Mess with Model Memories",
            "institute": "Technische Universit\u00e4t Berlin, BIFOLD, Hector Fellow Academy...",
            "text": "This research investigates the consistency of representational similarity across different datasets, focusing on how the training objective influences the transferability of model relationships. It goes beyond simply measuring similarity on a single dataset and examines how those relationships hold up when applied to different data.",
            "paper-title": "Training objective drives the consistency of representational similarity across datasets",
            "image-path": "flux_paper_image/2411.05561_1731457513.png"
        },

        {
            "startTime": "56:35",
            "arxivId": "2411.05514",
            "arxivLink": "https://arxiv.org/abs/2411.05514",
            "title": "Skin Deep Learning: Tiny Models, Big Results in Digital Dermatology",
            "institute": "University of Basel, Lucerne University of Applied Sciences and Arts, MIT",
            "text": "This research explores the potential of domain-specific foundation models for dermatology, focusing on smaller models that are more suitable for resource-limited clinical settings. Unlike previous work, it emphasizes the development of models that can be easily adapted to a broad range of use cases.",
            "paper-title": "Towards Scalable Foundation Models for Digital Dermatology",
            "image-path": "flux_paper_image/2411.05514_1731457975.png"
        },

        {
            "startTime": "56:55",
            "arxivId": "2411.06424",
            "arxivLink": "https://arxiv.org/abs/2411.06424",
            "title": "DPO's Secret Weapon: It's Not Just About Silencing Toxic Neurons!",
            "institute": "University of Oxford",
            "text": "This research goes beyond the common assumption that direct preference optimization (DPO) for toxicity reduction works by simply suppressing toxic neurons. It reveals that DPO achieves toxicity reduction through a more nuanced process involving multiple neuron groups, both reducing toxic writing and promoting anti-toxicity.",
            "paper-title": "Ablation is Not Enough to Emulate DPO: How Neuron Dynamics Drive Toxicity Reduction",
            "image-path": "flux_paper_image/2411.06424_1731458102.png"
        },

        {
            "startTime": "57:19",
            "arxivId": "2411.05895",
            "arxivLink": "https://arxiv.org/abs/2411.05895",
            "title": "Small Models, Big Impact: How Tiny AI is Cracking the Code of Document-Level Event Extraction",
            "institute": "Renmin University of China, Xinjiang University, Tsinghua University",
            "text": "This research introduces two novel methods for document-level event argument extraction. The first method, CsEAE, utilizes Small Language Models (SLMs) and incorporates co-occurrences-aware and structure-aware modules to improve event boundary identification and reduce interference from redundant information. The second method leverages Large Language Models (LLMs) with tailored prompts and supervised fine-tuning, addressing the gap in previous work that lacked fine-tuned LLMs for this task.",
            "paper-title": "One Small and One Large for Document-level Event Argument Extraction",
            "image-path": "flux_paper_image/2411.05895_1731455439.png"
        },

        {
            "startTime": "57:41",
            "arxivId": "2411.07098",
            "arxivLink": "https://arxiv.org/abs/2411.07098",
            "title": "REST API Testing: A Multi-Agent Approach to Catch Those Pesky 500 Errors!",
            "institute": "Georgia Institute of Technology, IBM",
            "text": "This research introduces AutoRestTest, a new framework for REST API testing that uses a multi-agent approach, integrating Multi-Agent Reinforcement Learning (MARL) with a Semantic Property Dependency Graph (SPDG) and Large Language Models (LLMs). Unlike previous tools that treat each testing step in isolation, AutoRestTest allows agents to collaborate and learn from each other, leading to more comprehensive and effective testing.",
            "paper-title": "A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs",
            "image-path": "flux_paper_image/2411.07098_1731452850.png"
        },

        {
            "startTime": "58:04",
            "arxivId": "2411.06490",
            "arxivLink": "https://arxiv.org/abs/2411.06490",
            "title": "LLMs Go Network-Crazy: Building a \"Telecommunications Brain\" with Blueprints",
            "institute": "Huawei Technologies, Khalifa University of Science and Technology, The Chinese University of Hong Kong...",
            "text": "This research introduces Hermes, a framework that uses LLMs to create \"blueprints\" for Network Digital Twins (NDTs). Unlike previous work that focused on training LLMs on network data, Hermes leverages LLMs to design and code NDTs, enabling more flexible and adaptable network modeling.",
            "paper-title": "Hermes: A Large Language Model Framework on the Journey to Autonomous Networks",
            "image-path": "flux_paper_image/2411.06490_1731457702.png"
        },

        {
            "startTime": "58:30",
            "arxivId": "2411.05885",
            "arxivLink": "https://arxiv.org/abs/2411.05885",
            "title": "Unsupervised Learning: The Secret Weapon for Sharper Medical Images?",
            "institute": "University College London",
            "text": "This research explores alternative learning paradigms for Image Quality Transfer (IQT), focusing on unsupervised and blended supervised/unsupervised learning approaches. Unlike previous IQT methods that rely solely on supervised learning, these new approaches aim to reduce bias and improve robustness when dealing with data that differs from the training distribution.",
            "paper-title": "Alternative Learning Paradigms for Image Quality Transfer",
            "image-path": "flux_paper_image/2411.05885_1731454353.png"
        },

        {
            "startTime": "58:49",
            "arxivId": "2411.05223",
            "arxivLink": "https://arxiv.org/abs/2411.05223",
            "title": "Medical Image Segmentation: A Causal Revolution with Diffusion Models",
            "institute": "ETH Zurich, Balgrist University Hospital, University of Zurich",
            "text": "This research explores single-source domain generalization (SDG) for cross-modality medical image segmentation. Unlike previous work that relies on basic image-level transformations, this study leverages controlled diffusion models (DMs) to simulate diverse imaging styles while preserving content.",
            "paper-title": "Generalizable Single-Source Cross-modality Medical Image Segmentation via Invariant Causal Mechanisms",
            "image-path": "flux_paper_image/2411.05223_1731452300.png"
        },

        {
            "startTime": "59:09",
            "arxivId": "2411.06306",
            "arxivLink": "https://arxiv.org/abs/2411.06306",
            "title": "Warning! This AI is Driving Smarter Than You!",
            "institute": "UC Berkeley, Honda Research Institute",
            "text": "This research proposes a novel framework for generating driver warnings that considers the driver's reaction to warnings and the interactions between the ego vehicle and other vehicles on a long horizon. This differs from previous work that mainly generates warnings in a one-shot manner without modeling the driver's reactions.",
            "paper-title": "Optimal Driver Warning Generation in Dynamic Driving Environment",
            "image-path": "flux_paper_image/2411.06306_1731454208.png"
        },

        {
            "startTime": "59:35",
            "arxivId": "2411.06802",
            "arxivLink": "https://arxiv.org/abs/2411.06802",
            "title": "Brain's Hidden Code: Chain Motifs Rule the Neural Roost!",
            "institute": "\u00c9cole Normale Sup\u00e9rieure",
            "text": "This research goes beyond the usual assumption that connections in the brain are independent, focusing on how specific patterns of connections, called \"chain motifs,\" impact neural activity.",
            "paper-title": "Identifying the impact of local connectivity patterns on dynamics in excitatory-inhibitory networks",
            "image-path": "flux_paper_image/2411.06802_1731456209.png"
        },

        {
            "startTime": "59:54",
            "arxivId": "2411.05088",
            "arxivLink": "https://arxiv.org/abs/2411.05088",
            "title": "IWSLT 2024: Speech Translation Goes Global, But Can It Handle Your Accent?",
            "institute": "GMU, UMD, FBK...",
            "text": "This research expands the IWSLT evaluation campaign to include new language pairs and domains, such as accented English conversations and physical training videos, pushing the boundaries of speech translation beyond the traditional TED talk format.",
            "paper-title": "FINDINGS OF THE IWSLT 2024 EVALUATION CAMPAIGN",
            "image-path": "flux_paper_image/2411.05088_1731452387.png"
        }
    ],
    "stats": {
        "num_pick": 179,
        "num_total": 782,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202411121801_audio.mp3"
}

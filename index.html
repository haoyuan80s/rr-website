<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ribbit Ribbit</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Quicksand:wght@300;400;700&display=swap">
</head>

<body>
    <div class="container">
        <div class="header">
            <img src="assets/AppLaunchFrog.gif" alt="Descriptive text about the GIF" class="header-gif">
            <div class="header-text">Hop right over soon... We're busy getting everything just right and will be here
                before you can say 'Ribbit'!</div>
            <div style="height: 50px;"></div>
            <div class="header-text">Tue. Jul 09, 2024</div>
        </div>

        <div class="tweet">
            <div class="user-icon">00:44</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04619" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04619</a>
                    <span class="tweet-title">Counting Like a Pro: New Model Counts Objects with Text and
                        Pictures!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Oxford</span>
                </div>
                <div class="tweet-text">
                    This research introduces COUNTGD, a model that can count objects in images using both text
                    descriptions and visual exemplars, unlike previous models that relied on only one or the other.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">01:13</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04699" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04699</a>
                    <span class="tweet-title">LaRa: A Radiance Field Revolution for Large-Baseline 3D
                        Reconstruction!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Tübingen, ETH Zürich</span>
                </div>
                <div class="tweet-text">
                    This paper introduces a novel volume transformer architecture that combines local and global
                    reasoning for efficient feed-forward reconstruction of radiance fields from sparse, large-baseline
                    images. Unlike previous methods that rely on standard global attention mechanisms, LaRa utilizes
                    group attention layers to implicitly match features between groups of voxels, enabling more accurate
                    and faster convergence.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">01:38</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03728" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03728</a>
                    <span class="tweet-title">Disentanglement? Nah, Orthogonality is the New Black!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">ETH Zurich</span>
                </div>
                <div class="tweet-text">
                    This research proposes two new metrics, Importance-Weighted Orthogonality (IWO) and
                    Importance-Weighted Rank (IWR), to evaluate the quality of representations learned by generative
                    models. Unlike traditional disentanglement metrics, which focus on aligning generative factors with
                    the canonical basis of the representation space, IWO and IWR measure the orthogonality of subspaces
                    associated with generative factors, regardless of their alignment.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">02:13</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04694" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04694</a>
                    <span class="tweet-title">AI's Mirror, Mirror: New Dataset Tests If LLMs Know Themselves</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">MIT, Constellation, Apollo Research...</span>
                </div>
                <div class="tweet-text">
                    This research introduces the Situational Awareness Dataset (SAD), a benchmark specifically designed
                    to assess LLMs' knowledge of their own identity, capabilities, and circumstances. Unlike previous
                    benchmarks focusing on general knowledge or reasoning, SAD probes LLMs' self-awareness through a
                    series of tasks that require them to recognize their own generated text, predict their behavior, and
                    even distinguish between evaluation and real-world deployment.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">02:40</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04545" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04545</a>
                    <span class="tweet-title">Eigen-Heads: Avatars That Are Light on the Bytes, Heavy on the
                        Expressions!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Max Planck Institute for Intelligent Systems, Google, TU
                        Darmstadt</span>
                </div>
                <div class="tweet-text">
                    This paper introduces a new method for compressing 3D Gaussian avatars, called Gaussian Eigen Models
                    (GEMs). Unlike previous methods that rely on heavy CNN architectures, GEMs use a linear basis to
                    represent the avatar's appearance, resulting in a more compact and efficient representation.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">03:00</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04528" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04528</a>
                    <span class="tweet-title">GPT vs RETRO: A Fine-Tuning Face-Off!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Nvidia</span>
                </div>
                <div class="tweet-text">
                    This research compares the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) methods when
                    applied to both GPT and RETRO models, which are large language models trained with different
                    approaches. The study focuses on how these methods perform in conjunction with Retrieval-Augmented
                    Generation (RAG), a technique that enhances model performance by incorporating external knowledge.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">03:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04681" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04681</a>
                    <span class="tweet-title">Visual Prompts: Giving LLMs a Pixel-Perfect View of the World!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Microsoft, University of Oxford</span>
                </div>
                <div class="tweet-text">
                    This paper proposes a new visual prompting approach for multimodal large language models (MLLMs)
                    that directly embeds fine-grained external knowledge, such as instance segmentation masks, into a
                    spatial embedding map as a visual prompt. This differs from previous work that transformed external
                    knowledge into additional text prompts, requiring the model to indirectly learn the correspondence
                    between visual content and text coordinates.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">03:54</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04491" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04491</a>
                    <span class="tweet-title">Forget Hyperparameter Tuning: New MLPs and GBDTs Are Better by
                        Default!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Inria, PSL University, University of Stuttgart</span>
                </div>
                <div class="tweet-text">
                    This research focuses on finding better default parameters for both gradient-boosted decision trees
                    (GBDTs) and multilayer perceptrons (MLPs) for tabular data. Unlike previous work that often relies
                    on extensive hyperparameter optimization, this study proposes improved default parameters that are
                    tuned on a large meta-train benchmark and then evaluated on a separate meta-test benchmark.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">04:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04620" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04620</a>
                    <span class="tweet-title">RNNs Learn on the Fly: A New Trick for Long-Term Memory</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Stanford University, UC San Diego, UC Berkeley</span>
                </div>
                <div class="tweet-text">
                    This paper introduces a new class of sequence modeling layers called Test-Time Training (TTT)
                    layers. Unlike traditional RNNs, TTT layers make their hidden state a machine learning model itself,
                    and the update rule a step of self-supervised learning. This allows the hidden state to be updated
                    even on test sequences, effectively training the model at test time.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">05:02</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04036" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04036</a>
                    <span class="tweet-title">Beyond Pixels: Patching Up Segmentation with a Multi-Label
                        Classifier</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Stonybrook University, University of North Carolina at Charlotte,
                        EPFL</span>
                </div>
                <div class="tweet-text">
                    This research introduces a novel plug-in module called Multi-scale Patch-based Multi-label
                    Classifier (MPMC) for semi-supervised segmentation (SSS) frameworks. Unlike previous SSS methods
                    that primarily rely on consistency regularization and pseudo-labeling, MPMC explicitly incorporates
                    contextual information by classifying image patches. This allows the model to better discriminate
                    between different classes within a patch, especially for smaller objects.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">05:41</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04264" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04264</a>
                    <span class="tweet-title">Langevin Dynamics: A Lyapunov Potential for Optimization Fun!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Cornell University, MIT</span>
                </div>
                <div class="tweet-text">
                    This paper introduces a new strategy for analyzing the convergence of Stochastic Gradient Langevin
                    Dynamics (SGLD) to global minima, based on Lyapunov potentials and optimization. This approach
                    differs from previous work that relied on sampling guarantees.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">06:02</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03418" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03418</a>
                    <span class="tweet-title">Multimodal Models: A Holistic Evaluation, Not Just a One-Trick
                        Pony!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Carnegie Mellon University</span>
                </div>
                <div class="tweet-text">
                    This research introduces HEMM, a framework for evaluating multimodal foundation models across three
                    levels: basic skills, information flow, and real-world use cases. This approach goes beyond
                    traditional benchmarking methods that focus on individual datasets or tasks.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">06:25</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03594" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03594</a>
                    <span class="tweet-title">UniPlane: Plane Detection Gets a 3D Makeover!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Southern California, Meta Reality Labs</span>
                </div>
                <div class="tweet-text">
                    UniPlane unifies plane detection and reconstruction into a single network, unlike previous methods
                    that separate these tasks. This allows for direct optimization of the final reconstruction quality
                    and better utilization of temporal information.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">06:49</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03757" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03757</a>
                    <span class="tweet-title">Diffusion Makes Retouching Fun: A New Way to Edit Photos with AI</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Nankai University, SenseTime Research, Tsinghua University...</span>
                </div>
                <div class="tweet-text">
                    This research introduces a diffusion-based method for image retouching, DiffRetouch, which allows
                    users to adjust four image attributes (colorfulness, contrast, color temperature, and brightness) to
                    customize the retouching style. Unlike previous methods that rely on deterministic models and
                    require additional images to indicate the desired style, DiffRetouch can generate various styles
                    within the learned fine-retouched distribution without extra images.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">07:20</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04162" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04162</a>
                    <span class="tweet-title">Schrödinger's Cat Got a Makeover: New Bridge Solves Inverse Problems
                        Faster!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Harvard University</span>
                </div>
                <div class="tweet-text">
                    This paper introduces the Measurement Embedded Schrödinger Bridge (MESB), a new approach to solving
                    inverse problems. Unlike previous methods that rely on iterative denoising from Gaussian noise, MESB
                    directly establishes Schrödinger Bridges between the distribution of corrupted images and the
                    distribution of clean images given observed measurements.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">07:43</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04600" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04600</a>
                    <span class="tweet-title">Self-Distillation: The More You Repeat, The Smarter You Get!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Washington</span>
                </div>
                <div class="tweet-text">
                    This research investigates the performance gains of repeatedly applying self-distillation, a
                    technique where a model learns from its own predictions, in the context of linear regression. Unlike
                    previous work that focused on one-step self-distillation, this paper analyzes the impact of multiple
                    steps.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">08:05</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04368" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04368</a>
                    <span class="tweet-title">Romanizing Speech: A New Way to Talk to Your AI</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Nvidia</span>
                </div>
                <div class="tweet-text">
                    This research proposes using romanization encoding for languages with complex scripts in
                    multilingual Automatic Speech Recognition (ASR) systems. This approach differs from previous work by
                    separating acoustic and language modeling, reducing vocabulary size, and enhancing system
                    flexibility.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">08:34</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03978" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03978</a>
                    <span class="tweet-title">LLMs Get a Reality Check: New Benchmark Tests Their Complex
                        Instruction-Following Skills</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Tsinghua University</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new benchmark called ComplexBench, which focuses on evaluating the
                    ability of LLMs to follow complex instructions that involve multiple constraints and their
                    composition. Unlike previous benchmarks that mainly focus on individual constraints, ComplexBench
                    considers how different constraints are combined within an instruction, making it a more
                    comprehensive and realistic evaluation.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">08:55</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04046" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04046</a>
                    <span class="tweet-title">LLMs: Citation Generation Gets a Prompt Makeover!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Technical University of Darmstadt, IBM Research Europe</span>
                </div>
                <div class="tweet-text">
                    This research explores the impact of different input configurations and instructions on citation
                    text generation using LLMs. Unlike previous work, it systematically investigates the effects of
                    these manipulations on model output using a wide range of measurements.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">09:23</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03495" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03495</a>
                    <span class="tweet-title">Speech Recognition Gets a Makeover: Discrete Codes Take Center
                        Stage!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Nvidia</span>
                </div>
                <div class="tweet-text">
                    This research explores the use of discrete speech representations, specifically acoustic codes, for
                    training automatic speech recognition (ASR) systems. Unlike previous work that primarily relied on
                    continuous representations like mel-spectrograms, this paper investigates the benefits of
                    compressing and quantizing speech signals into discrete codes.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">09:45</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04622" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04622</a>
                    <span class="tweet-title">Can Weak AI Judge Strong AI? Debate Protocol Gets Put to the Test!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Google</span>
                </div>
                <div class="tweet-text">
                    This research expands on previous work by evaluating debate protocols across a wider range of tasks,
                    including mathematics, coding, logic, and multimodal reasoning, instead of focusing solely on
                    extractive question answering with information asymmetry.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">10:09</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03522" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03522</a>
                    <span class="tweet-title">Multi-Modal Learning: When Two Brains Are Better Than One!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">École Polytechnique Fédérale de Lausanne</span>
                </div>
                <div class="tweet-text">
                    This paper analyzes a simplified model of multi-modal learning, focusing on how to optimally combine
                    information from different data sources. It goes beyond previous work by deriving the Bayes-optimal
                    performance and weak recovery threshold for this model, using the Approximate Message Passing (AMP)
                    algorithm and its associated state evolution.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">10:52</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03460" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03460</a>
                    <span class="tweet-title">Minecraft NPCs Get Chatty: GPT-4 Powers Collaborative Quests!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Microsoft</span>
                </div>
                <div class="tweet-text">
                    This research explores how human players collaborate with GPT-4-powered NPCs in a Minecraft
                    minigame, focusing on the emergence of collaborative behaviors and the limitations of language-only
                    models in a 3D environment. This differs from previous work by incorporating a sub-goal generation
                    mechanism to keep the NPCs on track and by addressing the issue of function call failures.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">11:13</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03442" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03442</a>
                    <span class="tweet-title">DETR's Got a New Trick: Quantizing for Critical Categories!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">UC Berkeley, Peking University</span>
                </div>
                <div class="tweet-text">
                    This research focuses on the impact of quantization on the performance of object detection models,
                    specifically for critical categories. Unlike previous work that primarily focused on overall
                    performance, this study analyzes the effects of quantization on specific categories that are crucial
                    for real-world applications.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">11:47</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03718" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03718</a>
                    <span class="tweet-title">Conformer Gets a Multi-Kernel Makeover: Speech Recognition Gets a
                        Boost!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Indian Institute of Technology Bombay, CMU</span>
                </div>
                <div class="tweet-text">
                    This research introduces MULTI-CONVFORMER, a variant of the Conformer architecture that uses
                    multiple convolution kernels instead of a single fixed kernel. This allows for more effective
                    modeling of local context at varying granularities.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">12:08</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04371" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04371</a>
                    <span class="tweet-title">Quantum Neural Networks: Perceptrons in Disguise?</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Oxford</span>
                </div>
                <div class="tweet-text">
                    This research explores the expressivity and inductive bias of quantum neural networks (QNNs) by
                    mapping them to classical perceptrons acting on the tensor product of the input data. This mapping
                    provides a more concrete and intuitive understanding of QNNs compared to previous work that relied
                    on kernel methods.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">12:35</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04683" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04683</a>
                    <span class="tweet-title">Betti Matching: A Topological Twist for 3D Segmentation</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Technical University of Munich, Imperial College London</span>
                </div>
                <div class="tweet-text">
                    This research introduces an efficient algorithm for calculating Betti matching, a topological loss
                    function used to train topology-aware segmentation networks. Unlike previous work, this algorithm is
                    highly optimized for 3D data, enabling faster computation and improved topological accuracy in
                    segmentations.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">13:00</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03994" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03994</a>
                    <span class="tweet-title">LLMs for Low-Resource Languages: Model Merging is the New Black!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Peking University</span>
                </div>
                <div class="tweet-text">
                    This paper explores model merging as a way to adapt large language models (LLMs) to low-resource
                    languages without requiring additional training. This approach differs from previous work that
                    focused on continual pre-training followed by supervised fine-tuning, which often struggles with
                    limited data availability.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">13:29</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04358" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04358</a>
                    <span class="tweet-title">Stop Tuning, Start Learning: A New Adaptive Stepsize for Faster Deep
                        Learning</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Meta</span>
                </div>
                <div class="tweet-text">
                    This research proposes a new adaptive stepsize strategy for stochastic gradient descent (SGD) that
                    leverages the non-negativity of loss functions, a common property in machine learning. The method,
                    called Nonnegative Gauss-Newton (NGN), reformulates the loss function as the composition of a square
                    and its square root, allowing the application of the Gauss-Newton method. This approach results in a
                    stepsize that automatically adapts to the loss landscape, effectively warming up in the beginning
                    and then settling down near the solution.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">13:57</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04689" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04689</a>
                    <span class="tweet-title">Robots Learn to Manipulate Objects Like Humans, Thanks to a Memory of
                        "How-To" Videos!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Southern California, Peking University, Stanford
                        University</span>
                </div>
                <div class="tweet-text">
                    This research proposes a novel framework called RAM (Retrieval-based Affordance Transfer) for
                    zero-shot robotic manipulation. Unlike previous methods that rely on expensive in-domain
                    demonstrations, RAM leverages a retrieval-based paradigm to acquire manipulation skills from diverse
                    out-of-domain data sources, such as robotic datasets, human-object interaction (HOI) data, and even
                    internet images.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">14:30</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03557" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03557</a>
                    <span class="tweet-title">Worst-Case Scenario: When AI's Best Isn't Good Enough for Real-World
                        Decisions</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Carnegie Mellon University</span>
                </div>
                <div class="tweet-text">
                    This research focuses on identifying worst-case distribution shifts in predictive resource
                    allocation settings, unlike previous work that primarily focused on individual-level accuracy. It
                    introduces a hierarchical model structure to capture shifts both within and across instances of the
                    decision problem.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">14:58</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03637" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03637</a>
                    <span class="tweet-title">HERA: Matrix Compression Gets a Heuristic Makeover!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Peking University</span>
                </div>
                <div class="tweet-text">
                    This research introduces HERA, an algorithm that uses heuristic element replacement to compress
                    matrices. Unlike previous methods that uniformly map parameters to compressed spaces, HERA leverages
                    the uneven distribution of parameters for more effective compression.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">15:20</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03779" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03779</a>
                    <span class="tweet-title">Pruning the Fat: A New Way to Understand Language Models</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Toronto</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new algorithm called DiscoGP that combines weight and connection pruning
                    to discover circuits in language models. Unlike previous methods that focused solely on weight
                    pruning or connection patching, DiscoGP offers a more comprehensive approach to understanding the
                    computational mechanisms of these models.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">15:56</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03771" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03771</a>
                    <span class="tweet-title">SpikeGS: Seeing the World in Spikes, One Blur-Free Frame at a Time!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Peking University</span>
                </div>
                <div class="tweet-text">
                    This research introduces SpikeGS, a novel 3D scene reconstruction method that leverages spike
                    cameras, which capture high-temporal resolution data, to overcome the limitations of traditional
                    cameras in fast-moving scenarios. Unlike previous methods that rely on blurry images or event
                    streams lacking texture information, SpikeGS utilizes the unique properties of spike cameras to
                    reconstruct detailed geometry and texture from spike streams.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">16:19</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03834" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03834</a>
                    <span class="tweet-title">Fairness Fairy Tale: Can We Really Remove Bias From AI?</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Johannes Gutenberg-Universität Mainz, ETH Zurich</span>
                </div>
                <div class="tweet-text">
                    This research delves into the theoretical limitations of Fair Representation Learning (FRL) by
                    analyzing the information dynamics of deep neural networks. It challenges the common assumption that
                    deterministic neural networks can effectively remove sensitive information from data
                    representations.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">16:42</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03953" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03953</a>
                    <span class="tweet-title">Graph Transformers Go Big: Pre-training on Industrial-Scale Data for
                        Better Generalization</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Tsinghua University, National University of Singapore, Tencent</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new graph pre-training framework called PGT (Pre-trained Graph
                    Transformer) that utilizes a transformer-based architecture and two distinct pre-training tasks to
                    learn transferable node features and graph structural patterns. Unlike previous work that often
                    focuses on specific tasks on fixed graphs, PGT aims to generalize across diverse graphs and tasks,
                    making it more adaptable to real-world industrial scenarios.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">17:15</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04151" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04151</a>
                    <span class="tweet-title">LLMs on Trial: How to Catch a Chatbot Red-Handed with a Multi-Turn
                        Backdoor</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">UC Davis, Harvard University</span>
                </div>
                <div class="tweet-text">
                    This research focuses on a new type of backdoor attack specifically designed for multi-turn
                    conversational language models (LLMs). Unlike previous work that focused on single-turn attacks,
                    this paper explores how adversaries can implant triggers across multiple user utterances to
                    manipulate the model's responses.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">17:36</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04384" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04384</a>
                    <span class="tweet-title">Teaching Robots to See and Grasp: Unsupervised 3D Pose Estimation from
                        Videos!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Freiburg, Saarland University, Max Planck Institute for
                        Informatics</span>
                </div>
                <div class="tweet-text">
                    This research proposes a novel method for learning category-level 3D pose estimation from
                    object-centric videos without any human supervision. Unlike previous methods that rely on annotated
                    data, CAD models, or RGB-D sensors, this approach leverages self-supervised features and a novel 3D
                    cyclical distance to align objects across videos and learn a 3D representation for pose estimation.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">18:10</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03922" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03922</a>
                    <span class="tweet-title">Deep Learning's New Trick: Polyaffine Registration for Better Brain
                        Scans</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University College London, AINOSTICS ltd.</span>
                </div>
                <div class="tweet-text">
                    This research proposes a novel initialization method for non-linear image registration that
                    leverages recent advancements in deep learning-based segmentation techniques. Unlike traditional
                    affine registration, which relies on global transformations, this approach utilizes local,
                    anatomically grounded feature-based affine matchings to produce a more accurate and robust initial
                    transformation.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">18:35</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04192" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04192</a>
                    <span class="tweet-title">Neural Networks Get a Grid Makeover: KAN-ODEs Learn Dynamics with Fewer
                        Parameters</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">MIT</span>
                </div>
                <div class="tweet-text">
                    This research introduces KAN-ODEs, a novel approach that combines Kolmogorov-Arnold Networks (KANs)
                    with Neural Ordinary Differential Equations (Neural ODEs). Unlike traditional Neural ODEs that rely
                    on Multi-layer Perceptrons (MLPs), KAN-ODEs leverage the faster neural scaling and interpretability
                    of KANs.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">19:06</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03380" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03380</a>
                    <span class="tweet-title">Peptides Get a Multimodal Makeover: Language and Structure Team Up for
                        Property Prediction!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">CMU</span>
                </div>
                <div class="tweet-text">
                    This research introduces Multi-Peptide, a model that combines a transformer-based language model
                    (PeptideBERT) with a Graph Neural Network (GNN) to predict peptide properties. This approach differs
                    from previous work by incorporating both sequence and structural information, allowing for a more
                    comprehensive understanding of peptide behavior.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">19:28</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04191" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04191</a>
                    <span class="tweet-title">Want to Control What People See? This AI Makes Images That Guide Your
                        Gaze!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">NYU, Stanford University</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new method for controlling the visual attention of viewers when
                    generating images using diffusion models. Unlike previous approaches that focus on spatial layout,
                    this method incorporates saliency maps, which represent the areas of an image that are most likely
                    to attract attention, into the generation process.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">19:48</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03925" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03925</a>
                    <span class="tweet-title">Simulating Physics on a Diet: New Model Runs 25x Faster with Sparse
                        Graphs!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Purdue University, University of Toronto, California Institute of
                        Technology...</span>
                </div>
                <div class="tweet-text">
                    This research introduces a neural operator architecture called GIOROM that learns Lagrangian
                    dynamics on highly sparse graphs. Unlike previous graph neural network approaches, GIOROM can
                    generalize to different discretizations and operate on sparse graphs without sacrificing accuracy.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">20:10</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03542" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03542</a>
                    <span class="tweet-title">AI Needs a Doctor: Human-AI Teamwork Perfects Lung Scans</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Imperial College London, Royal Brompton Hospital, King's College
                        London...</span>
                </div>
                <div class="tweet-text">
                    This research introduces a novel Human-Computer Interaction (HCI) based active learning method for
                    pulmonary airway segmentation. Unlike traditional active learning, which focuses on selecting
                    informative samples for annotation, this approach incorporates domain experts into the training
                    process, allowing them to refine the model's predictions and improve its accuracy.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">20:32</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03804" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03804</a>
                    <span class="tweet-title">MEC Systems: Caching, Pricing, and the Game of Offloading!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Sun Yat-sen University, Nanyang Technological University</span>
                </div>
                <div class="tweet-text">
                    This research introduces a two-time scale framework for optimizing service caching, pricing, and
                    task offloading in MEC systems. Unlike previous work, it considers the dynamic nature of program
                    popularity and models the interaction between the BS and users as a Stackelberg game.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">21:00</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03900" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03900</a>
                    <span class="tweet-title">Oracle Bones Get a Digital Makeover: AI Gets a Hand in Deciphering Ancient
                        Chinese Script</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Anyang Normal University, Tencent, Xiamen University...</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new multi-modal dataset for oracle bone inscriptions, offering a
                    comprehensive set of annotations for each inscription, including character categories,
                    transcriptions, and reading sequences. This goes beyond previous datasets that focused on single or
                    limited aspects of the inscriptions.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">21:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03791" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03791</a>
                    <span class="tweet-title">M5: The Multimodal Multilingual Benchmark That's Got LLMs Seeing
                        Stars!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Hamburg, Microsoft</span>
                </div>
                <div class="tweet-text">
                    This research introduces M5, a benchmark specifically designed to evaluate the performance of Large
                    Multimodal Models (LMMs) across diverse languages and cultures. Unlike previous benchmarks, which
                    primarily focused on English or were monolingual, M5 includes eight datasets covering five tasks and
                    41 languages, with a focus on underrepresented languages and culturally diverse images.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">21:53</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04295" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04295</a>
                    <span class="tweet-title">Jailbreaking LLMs: A Guide to the Wild West of AI Security</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Tsinghua University</span>
                </div>
                <div class="tweet-text">
                    This research provides a comprehensive taxonomy of both jailbreak attack and defense methods against
                    LLMs, going beyond previous work by categorizing them into white-box and black-box attacks, and
                    prompt-level and model-level defenses.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">22:27</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04308" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04308</a>
                    <span class="tweet-title">Tracking Targets with a Graph-Based Neural Network: It's Like a Game of
                        Connect the Dots, But for Objects!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Washington</span>
                </div>
                <div class="tweet-text">
                    This research proposes a novel approach to multi-object tracking (MOT) that uses a graph neural
                    network (GNN) to learn edge costs in a tracking graph. Unlike previous methods that rely on linear
                    programming (LP) for inner optimization, this paper utilizes a successive shortest paths (SSP)
                    algorithm, which guarantees an optimal solution while being computationally more efficient.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">22:56</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04579" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04579</a>
                    <span class="tweet-title">Placement Perfection: Learning to Design Chips Like a Pro!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">NVIDIA</span>
                </div>
                <div class="tweet-text">
                    This research proposes a new approach to VLSI placement optimization that leverages cell density
                    control. Unlike traditional incremental methods, it learns from post-route optimized results and
                    uses an empirical Bayes technique to adapt the density targets to a specific placer.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">23:30</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04272" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04272</a>
                    <span class="tweet-title">DLRM Training Gets a Speed Boost: Lossy Compression to the Rescue!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Indiana University, Meta, University of Rochester...</span>
                </div>
                <div class="tweet-text">
                    This research introduces a novel error-bounded lossy compression algorithm specifically designed for
                    embedding lookups in DLRM models. Unlike previous approaches that rely on quantization or lossless
                    compression, this method achieves significantly higher compression ratios while maintaining strict
                    error control.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">23:59</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04557" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04557</a>
                    <span class="tweet-title">Quantum Material Design: Archimedean Lattices Get a Generative
                        Makeover!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">MIT, Oak Ridge National Laboratory</span>
                </div>
                <div class="tweet-text">
                    This research introduces SCIGEN, a method that integrates geometric constraints into generative
                    diffusion models for material discovery. Unlike previous work that focused on crystallographic space
                    groups, SCIGEN specifically targets geometric patterns, like Archimedean lattices, which are crucial
                    for understanding the properties of quantum materials.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">24:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03658" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03658</a>
                    <span class="tweet-title">GPT-4 vs. Human Translators: Who Wins the Translation Game?</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Zhejiang University, Westlake University, University College
                        London...</span>
                </div>
                <div class="tweet-text">
                    This study directly compares GPT-4's translation quality to human translators of varying expertise
                    levels across multiple languages and domains, providing a more nuanced understanding of its
                    strengths and weaknesses.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">24:45</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04020" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04020</a>
                    <span class="tweet-title">LLMs: Not Just Chatbots, Now They're Entity Linking Superheroes!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Tsinghua University</span>
                </div>
                <div class="tweet-text">
                    This research proposes a novel approach to entity linking by using large language models (LLMs) as
                    context augmenters, rather than directly executing the task. This method enhances traditional entity
                    linking models by providing them with richer contextual information generated by LLMs.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">25:16</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04121" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04121</a>
                    <span class="tweet-title">LLMs Gone Wild: New Tool Detects AI Hallucinations</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Fudan University, Microsoft, Singapore Management University...</span>
                </div>
                <div class="tweet-text">
                    This research proposes a new discriminator, RelD, trained on a bilingual question-answering dataset
                    called RelQA. RelD is designed to detect hallucinations in answers generated by LLMs, going beyond
                    traditional metrics like ROUGE and BLEU.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">25:38</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04251" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04251</a>
                    <span class="tweet-title">Knowledge Graph Completion: Smoothing Out the Rough Edges with Triplet
                        Adaptive Negative Sampling</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Nara Institute of Science and Technology, University of Tokyo</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new negative sampling loss function called Triplet Adaptive Negative
                    Sampling (TANS) for knowledge graph embedding. Unlike previous methods like Self-Adversarial
                    Negative Sampling (SANS) that focus on smoothing the frequency of answers, TANS aims to smooth both
                    the frequency of queries and answers, leading to a more balanced and effective training process.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">26:04</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04467" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04467</a>
                    <span class="tweet-title">AI's Got Game: Do Big Language Models Play Fair?</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University College London</span>
                </div>
                <div class="tweet-text">
                    This research investigates the impact of systematic biases on the performance of large language
                    models (LLMs) in two-player non-zero-sum games, a topic not thoroughly explored in previous work.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">26:27</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04521" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04521</a>
                    <span class="tweet-title">Q-Learning Goes Mean-Field: A Unified Approach for Games and
                        Control</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Harbin Institute of Technology, Hong Kong Polytechnic University,
                        University of Michigan</span>
                </div>
                <div class="tweet-text">
                    This paper introduces a unified continuous-time Q-learning algorithm for both mean-field games (MFG)
                    and mean-field control (MFC) problems. Unlike previous work that focused on discrete-time settings
                    or required full population distribution knowledge, this approach utilizes a decoupled integrated
                    Q-function (decoupled Iq-function) from the perspective of a representative agent, allowing for
                    learning in both competitive and cooperative mean-field scenarios.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">26:55</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03333" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03333</a>
                    <span class="tweet-title">Ship Design Goes AI: Diffusion Model Creates Low-Drag Hulls on
                        Demand!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">MIT</span>
                </div>
                <div class="tweet-text">
                    This research introduces a conditional guided diffusion model for ship hull design, which can
                    generate hulls that meet specific design constraints, unlike previous diffusion models.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">27:20</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04495" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04495</a>
                    <span class="tweet-title">Diffusion Models: Speed, Accuracy, and a Dash of Thermodynamics!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Tokyo</span>
                </div>
                <div class="tweet-text">
                    This research connects diffusion models, a popular generative model, to nonequilibrium
                    thermodynamics. It derives a speed-accuracy trade-off for these models, showing how the rate of
                    entropy production in the forward process affects the accuracy of data generation. This is a novel
                    approach compared to previous work that focused on improving diffusion models without explicitly
                    considering thermodynamic principles.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">27:43</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04236" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04236</a>
                    <span class="tweet-title">Graph Pooling Gets a Geometric Makeover: Ricci Flow to the Rescue!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Harvard University</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new graph pooling operator called ORC-Pool that utilizes Ollivier's Ricci
                    curvature and an associated geometric flow to cluster nodes based on both their attributes and the
                    graph's topology. This is a novel approach compared to previous methods that only considered one or
                    the other.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">28:10</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03921" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03921</a>
                    <span class="tweet-title">Concept Discovery: No More Human Annotations Needed!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Freiburg</span>
                </div>
                <div class="tweet-text">
                    This research proposes a novel method for converting black-box models into interpretable
                    concept-based models without relying on human-annotated concepts or predefining a set of concepts.
                    Unlike previous approaches that assumed a predefined set of concepts, this method leverages
                    unsupervised concept discovery to automatically extract concepts from the model's activations.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">28:44</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03966" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03966</a>
                    <span class="tweet-title">Speech Recognition: Who's the Boss? A New Model Learns to Listen to the
                        Loudest Voice!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Tsinghua University, Harbin Institute of Technology</span>
                </div>
                <div class="tweet-text">
                    This research introduces a novel serialization strategy for multi-talker speech recognition, called
                    DOM-SOT. Unlike previous methods that rely on predefined biases like starting time or permutation
                    invariant training (PIT), DOM-SOT trains an auxiliary module to dynamically determine the order of
                    speakers based on their dominance.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">29:10</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03382" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03382</a>
                    <span class="tweet-title">SPD Matrices: A Geometric Mean Machine That Preserves Subspace
                        Structure!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Nanyang Technological University, University of Tübingen, University of
                        Cambridge</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new geometric framework for processing SPD-valued data that preserves
                    subspace structures, unlike previous methods based on the affine-invariant Riemannian metric. This
                    framework utilizes the Thompson geometry of the semidefinite cone and relies on the efficient
                    computation of extreme generalized eigenvalues.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">29:36</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04482" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04482</a>
                    <span class="tweet-title">Whisper's Got a Secret: Hacking Speech Models with a Tiny Audio
                        Trick</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Cambridge</span>
                </div>
                <div class="tweet-text">
                    This research explores a new type of adversarial attack on speech models, focusing on manipulating
                    their task settings rather than disrupting their performance. Unlike previous work that aimed to
                    corrupt transcriptions or force specific phrases, this study demonstrates how a short audio segment
                    can be prepended to any speech signal to force a multi-task model to perform a different task.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">30:01</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03883" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03883</a>
                    <span class="tweet-title">Deep Learning's New Copyright Cop: No Adversarial Examples Needed!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Peking University, University of Oxford, Zhejiang University</span>
                </div>
                <div class="tweet-text">
                    This research proposes a new method for detecting unauthorized reuse of deep learning models that
                    doesn't rely on generating adversarial examples. It analyzes the "neuron functionality" of models,
                    which is the mapping from input to output for each neuron. This approach is more efficient and can
                    handle cases where the model architecture has been changed.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">30:39</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03502" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03502</a>
                    <span class="tweet-title">Teaching AI New Tricks: AgentInstruct Makes Synthetic Data a
                        Superpower</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Microsoft Research</span>
                </div>
                <div class="tweet-text">
                    This research introduces AgentInstruct, a framework for automatically generating large amounts of
                    diverse and high-quality synthetic data for post-training language models. Unlike previous
                    approaches that rely on existing prompts or paraphrasing, AgentInstruct uses raw data sources like
                    text documents and code files as seeds, enabling the creation of more general capabilities.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">31:02</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04230" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04230</a>
                    <span class="tweet-title">Underwater Image Enhancement: A Deep Dive with Physical
                        Constraints!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Beihang University, Chinese Academy of Sciences, Tsinghua
                        University</span>
                </div>
                <div class="tweet-text">
                    This research proposes a framework that jointly trains a deep degradation model (DDM) with any
                    advanced underwater image enhancement (UIE) model. The DDM accurately estimates various imaging
                    parameters, including depth, veiling light, attenuation, and scattering coefficients, which are then
                    used to impose physical constraints on the enhancement process. This approach differs from previous
                    methods that either rely on inaccurate parameter estimation or fail to bridge the gap between the
                    physical imaging model and real underwater conditions.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">31:34</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04547" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04547</a>
                    <span class="tweet-title">Timbre Twister: AI Learns to Remix Your Drum Sounds in Real Time!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Queen Mary University of London, Imperial College London</span>
                </div>
                <div class="tweet-text">
                    This research proposes a novel approach to timbre remapping using differentiable digital signal
                    processing (DDSP). Unlike previous methods that focus on pitch and loudness, this method directly
                    optimizes synthesizer parameters to match relative timbral differences between musical events.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">31:59</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04540" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04540</a>
                    <span class="tweet-title">Quantum Hamiltonian Learning: A Singly Exponential Leap Forward!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Massachusetts Institute of Technology, Google</span>
                </div>
                <div class="tweet-text">
                    This paper improves upon previous work by reducing the runtime and sample complexity dependence on
                    the inverse temperature parameter from doubly exponential to singly exponential. This is achieved by
                    constructing a novel flat polynomial approximation to the exponential function with significantly
                    lower degree.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">32:27</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03760" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03760</a>
                    <span class="tweet-title">Stock Market Predictions: Graphing a Path to Profit</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Caltech</span>
                </div>
                <div class="tweet-text">
                    This research proposes a novel approach to stock market prediction by combining graph neural
                    networks (GNNs) with convolutional neural networks (CNNs). Unlike previous work that relies solely
                    on CNNs or GNNs, this model leverages the strengths of both to extract more comprehensive
                    information from financial data.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">32:53</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03640" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03640</a>
                    <span class="tweet-title">Emotion Recognition: AI Gets a Heartfelt Upgrade with Generative
                        Models!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Chinese Academy of Sciences, Tsinghua University, Xi’an Jiaotong
                        University...</span>
                </div>
                <div class="tweet-text">
                    This research provides a comprehensive overview of generative technology for emotion recognition,
                    analyzing over 320 papers and highlighting its applications in data augmentation, feature
                    extraction, semi-supervised learning, and cross-domain scenarios. Unlike previous reviews, it
                    focuses specifically on the use of generative models for emotion recognition across multiple
                    modalities.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">33:21</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04168" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04168</a>
                    <span class="tweet-title">Logic-Loving Neural Networks: Learning Interpretable Rules with a
                        Twist!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Princeton University</span>
                </div>
                <div class="tweet-text">
                    This research introduces a novel method for training differentiable logic networks (DLNs) that are
                    inherently interpretable. Unlike previous work, this method makes all parts of the network
                    differentiable, allowing for gradient-based optimization and enabling the learning of both network
                    structure and logic functions from scratch.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">33:43</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03340" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03340</a>
                    <span class="tweet-title">Robot's Got a Mouth, Now It's Got an Explanation!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Comenius University in Bratislava, Italian Institute of
                        Technology</span>
                </div>
                <div class="tweet-text">
                    This research goes beyond simply identifying if a robot is being addressed, instead focusing on
                    pinpointing the specific person in a multi-party conversation. It also incorporates explainable AI
                    techniques to make the robot's decision-making process transparent.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">34:12</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04641" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04641</a>
                    <span class="tweet-title">Speech Recognition: Predicting Your Words Before You Even Finish
                        Speaking!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Brno University of Technology, Google</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new method for speculative speech recognition (SSR) that uses an
                    audio-dependent prefix to improve the accuracy of the language model's predictions. Unlike previous
                    work, this approach incorporates information from the audio signal itself, making the model more
                    aware of the acoustic context and potential errors in the transcribed speech.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">34:34</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04444" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04444</a>
                    <span class="tweet-title">TokenVerse: One Model to Rule Them All (Speech & NLP Tasks)</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Idiap Research Institute, University of Zurich, Brno University of
                        Technology...</span>
                </div>
                <div class="tweet-text">
                    This research introduces TokenVerse, a single Transducer-based model that handles multiple speech
                    and NLP tasks. Unlike previous work that uses separate models for each task, TokenVerse integrates
                    task-specific tokens into the reference text during training, streamlining inference and eliminating
                    the need for separate NLP models.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">35:01</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04104" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04104</a>
                    <span class="tweet-title">Gene Networks: The More the Merrier (and More Accurate!)</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Toronto, Carnegie Mellon University</span>
                </div>
                <div class="tweet-text">
                    This paper proposes a network-based neighborhood regression framework that incorporates both global
                    community-level information and local connectivity structures among entities. Unlike previous work,
                    this method directly incorporates neighborhood information and accounts for the heterogeneity of
                    regression coefficients across different communities.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">35:30</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04075" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04075</a>
                    <span class="tweet-title">Pruning's Big Fat Lie: Sparsest Models Are Hiding!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Toronto</span>
                </div>
                <div class="tweet-text">
                    This research investigates the effectiveness of pruning algorithms in finding the sparsest possible
                    neural network, a model with the fewest non-zero parameters that still achieves a desired accuracy.
                    Unlike previous work, this study uses a novel combinatorial search algorithm to identify the ideal
                    sparse model and then compares the performance of various pruning techniques against this benchmark.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">35:52</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03456" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03456</a>
                    <span class="tweet-title">Emergent Language: How Good Is It, Really? A Data-Driven Test</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">CMU</span>
                </div>
                <div class="tweet-text">
                    This paper introduces XferBench, a benchmark for evaluating the overall quality of emergent
                    languages using transfer learning with deep neural models. Unlike previous work that focused on
                    specific properties of emergent languages, XferBench measures the overall quality of the language by
                    assessing its similarity to human language.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">36:19</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04158" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04158</a>
                    <span class="tweet-title">Emergent Language: A Corpus Collection for the Curious</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">CMU</span>
                </div>
                <div class="tweet-text">
                    This research introduces the Emergent Language Corpus Collection (ELCC), a dataset of "languages"
                    generated by various emergent communication systems (ECSs). Unlike previous work, which often
                    focuses on individual ECSs, ELCC provides a collection of corpora from different ECSs, enabling
                    researchers to compare and analyze emergent languages across a wider range of systems.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">36:40</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03665" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03665</a>
                    <span class="tweet-title">Hypergraph Embeddings: The Group Chat for Recommender Systems</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Griffith University, Hanoi University of Science and Technology, Ecole
                        Polytechnique Federale de Lausanne...</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new method for building recommender systems that uses heterogeneous
                    hypergraphs to capture complex relationships between users, items, and knowledge entities. This
                    approach goes beyond traditional graph structures, which only model pairwise connections, to capture
                    group-wise interactions.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">37:10</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04678" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04678</a>
                    <span class="tweet-title">Chinese Chess Engine Learns to Play Like a Human, Not a Machine!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Cambridge</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new deep learning architecture called XQSV (Xiangqi Structurally
                    Variable) that dynamically alters its structure to mimic the behavior of human Xiangqi players at
                    different skill levels. Unlike previous work that focuses on optimizing winning probability, XQSV
                    prioritizes imitating human gameplay patterns.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">37:34</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03653" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03653</a>
                    <span class="tweet-title">BigEarthNet Gets a Makeover: A Refined Dataset for Remote Sensing</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Technical University of Berlin, École Polytechnique Fédérale de
                        Lausanne</span>
                </div>
                <div class="tweet-text">
                    This research refines the BigEarthNet dataset by addressing several issues, including outdated
                    atmospheric correction, label noise, and spatial correlation in the training, validation, and test
                    sets. It also introduces new software tools for efficient deep learning model training.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">37:58</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03824" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03824</a>
                    <span class="tweet-title">Unsupervised Learning: How to Teach AI to See the Forest AND the
                        Trees</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Mohamed bin Zayed University of Artificial Intelligence, New York
                        University Shanghai, Carnegie Mellon University</span>
                </div>
                <div class="tweet-text">
                    This research introduces a novel unsupervised method for disentangling content and style
                    representations in data. Unlike previous methods that rely on domain-specific labels or paired data,
                    this approach leverages the inherent statistical differences between content and style, specifically
                    their variance-versus-invariance patterns.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">38:32</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03387" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03387</a>
                    <span class="tweet-title">LLMs: Code-Savvy or Code-Clueless? New Study Tests Their Constraint
                        Comprehension!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">IBM, Indian Institute of Technology Bombay</span>
                </div>
                <div class="tweet-text">
                    This research focuses on evaluating the ability of Large Language Models (LLMs) to understand and
                    follow code constraints in Domain-Specific Languages (DSLs), a topic not extensively explored in
                    previous work. The study introduces two novel tasks: data-as-code generation and DSL validation,
                    using various code representations like JSON, YAML, XML, and Python.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">38:53</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04516" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04516</a>
                    <span class="tweet-title">Meshing Madness: AI Learns to Optimize Finite Element Methods</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Cambridge, University of Oxford</span>
                </div>
                <div class="tweet-text">
                    This research introduces a novel approach to mesh adaptivity in finite element methods (FEM) by
                    directly minimizing the FEM error using a graph neural network (GNN) and a differentiable FEM
                    solver. Unlike previous work that focused on emulating traditional meshing methods, this approach
                    directly optimizes the mesh point locations to achieve the best possible FEM solution accuracy.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">39:21</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04406" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04406</a>
                    <span class="tweet-title">Quantum Channel Learning: Unitary Mapping Gets a Density Matrix
                        Makeover!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Lomonosov Moscow State University, Peter the Great St. Petersburg
                        Polytechnic University, Ioffe Institute</span>
                </div>
                <div class="tweet-text">
                    This research extends previous work on unitary mapping by incorporating density matrices as input
                    and output states, allowing for a more general representation of quantum channels.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">39:52</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04534" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04534</a>
                    <span class="tweet-title">OOD: It's Not Just About Outliers, It's About the In-Between!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Ariel University, University College London</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new perspective on out-of-distribution (OOD) data by dividing it into
                    "inside" and "outside" categories. This distinction is based on whether the OOD data points are
                    located within the range of the training data or completely outside of it.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">40:25</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03956" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03956</a>
                    <span class="tweet-title">Zebra Puzzles Solved: AI Teams Up with Logic to Crack the Code!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Princeton University, Columbia University</span>
                </div>
                <div class="tweet-text">
                    This research introduces a multi-agent system, ZPS, that combines Large Language Models (LLMs) with
                    a theorem prover to solve Zebra puzzles. Unlike previous approaches that rely solely on LLMs or
                    human intervention, ZPS leverages the strengths of both formal reasoning and natural language
                    processing.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">40:45</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03770" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03770</a>
                    <span class="tweet-title">BERT Gets a VAGO Boost: AI Hybrids for Subjectivity Detection</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">French Institute for Research in Computer Science and Automation,
                        Sorbonne University, CentraleSupélec...</span>
                </div>
                <div class="tweet-text">
                    This research combines a fine-tuned RoBERTa model with a frozen sentence-BERT model and scores from
                    the VAGO expert system to detect subjectivity in text. This hybrid approach differs from previous
                    work by incorporating symbolic AI features into a deep learning framework.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">41:14</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03850" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03850</a>
                    <span class="tweet-title">Fact-Checking with a Side of Structure: Boosting Language Models with
                        Triples!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">CentraleSupélec, French Institute for Research in Computer Science and
                        Automation, Sorbonne University...</span>
                </div>
                <div class="tweet-text">
                    This research explores a novel approach to check-worthiness estimation by incorporating structured
                    information extracted from text in the form of triples (subject; predicate; object) into the
                    language model's representation. This differs from previous work that primarily relied on language
                    models alone.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">41:42</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03585" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03585</a>
                    <span class="tweet-title">Zero-Shot Persuasion: Chatbots That Can Convince You Without Training
                        Data!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">KDDI Corporation, Stanford University</span>
                </div>
                <div class="tweet-text">
                    This research proposes a method for creating persuasive chatbots that don't require task-specific
                    training data. Unlike previous approaches that rely on predefined strategies or annotated
                    conversations, this method leverages the inherent persuasive abilities of large language models
                    (LLMs) and combines them with information retrieval to generate factual and adaptive responses.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">42:10</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04507" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04507</a>
                    <span class="tweet-title">Airway Segmentation Gets a Sparse Makeover: Few-Shot Learning with a
                        Twist!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Telecom Paris Institut Polytechnique de Paris</span>
                </div>
                <div class="tweet-text">
                    This research introduces a novel approach to airway segmentation using convolutional sparse coding
                    (CSC) as a pre-training step for few-shot learning. This differs from previous work by leveraging
                    sparse representations to enhance the visual characteristics of airways, leading to improved
                    performance with limited training data.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">42:31</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04050" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04050</a>
                    <span class="tweet-title">Sentiment Analysis Gets a Triplet Makeover: Unveiling the Nuances of
                        Opinion</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">IBM</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new task called "Entity Aspect Sentiment Triplet Extraction (EASTE)"
                    which goes beyond simply identifying sentiment polarity. It aims to extract triplets of entity,
                    aspect, and sentiment, providing a more nuanced understanding of opinions. This differs from
                    previous work that focused on extracting pairs or quadruplets of information.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">42:55</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04153" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04153</a>
                    <span class="tweet-title">A Million Tiny Experts: Scaling Transformers with Parameter-Efficient
                        Retrieval</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Google</span>
                </div>
                <div class="tweet-text">
                    This paper introduces a novel layer design called PEER (Parameter Efficient Expert Retrieval) that
                    utilizes product key retrieval to efficiently route to a vast pool of tiny experts (over a million).
                    This approach differs from previous MoE models that typically use a small number of large experts.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">43:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03674" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03674</a>
                    <span class="tweet-title">Predicting the Future: How to Evaluate New Policies with Just a
                        Glimpse!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Stanford University</span>
                </div>
                <div class="tweet-text">
                    This research introduces a new setting for policy evaluation where the goal is to estimate the
                    long-term performance of a new decision policy with novel actions using only short-term observations
                    and historical data. This differs from previous work that typically assumes the new policy's actions
                    are already present in the historical data.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">43:53</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03645" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03645</a>
                    <span class="tweet-title">Whisper's New Trick: Teaching AI to Speak Fluent Languages Without
                        Forgetting!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Nanyang Technological University</span>
                </div>
                <div class="tweet-text">
                    This research focuses on improving continual learning (CL) for multilingual automatic speech
                    recognition (MASR) systems by specifically addressing the challenges posed by the auto-regressive
                    decoder architecture. Unlike previous CL methods primarily designed for computer vision and
                    reinforcement learning tasks, this study proposes four optimizations tailored for the decoder,
                    including gradient surgery removal, partial embedding update, language ID token suppression, and
                    rapid learning rate reduction.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">44:19</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03841" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03841</a>
                    <span class="tweet-title">Chatbots are Getting Smarter, But Can We Keep Up?</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">INESC-ID, CMU</span>
                </div>
                <div class="tweet-text">
                    This research focuses on the limitations of current benchmarks used to evaluate Large Language
                    Models (LLMs) for open-domain dialogue. The authors argue that existing benchmarks rely on outdated
                    datasets and quality aspects that fail to accurately reflect the capabilities of modern chatbots.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">44:38</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04605" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04605</a>
                    <span class="tweet-title">Unraveling Causality: How Higher-Order Cumulants Crack the Code of Linear
                        Disentanglement</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">Harvard University, ETH Zurich</span>
                </div>
                <div class="tweet-text">
                    This research extends previous work on linear causal disentanglement by exploring the
                    identifiability of the model using higher-order cumulants. Unlike prior studies that focused on
                    covariance matrices, this paper investigates the use of cumulants of order three and above,
                    demonstrating their effectiveness in recovering model parameters.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">45:00</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03995" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03995</a>
                    <span class="tweet-title">Experience Replay Gets a Makeover: Regularized Optimal Experience Replay
                        (ROER) Optimizes Learning</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">ETH Zurich, MIT, Stanford University...</span>
                </div>
                <div class="tweet-text">
                    This research proposes a new approach to experience replay called Regularized Optimal Experience
                    Replay (ROER). Unlike traditional methods that prioritize experiences based on their temporal
                    difference (TD) error, ROER leverages a regularized RL objective and its dual function to derive a
                    more robust prioritization scheme. This approach aims to mitigate the distribution shift between
                    off-policy data and the current policy, leading to more accurate TD error estimations and improved
                    learning.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">45:28</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.04472" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.04472</a>
                    <span class="tweet-title">ChatGPT for Events: Can AI Make Leisure Planning Profitable?</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">ETH Zurich</span>
                </div>
                <div class="tweet-text">
                    This research goes beyond technical frameworks for LLM-driven conversational recommender systems
                    (CRS) and examines their real-world performance in an SME context, including user evaluations and
                    cost analysis.
                </div>
            </div>
        </div>
        <div class="tweet">
            <div class="user-icon">45:49</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2407.03463" target="_blank"
                        style="text-decoration: none;">@arXiv: 2407.03463</a>
                    <span class="tweet-title">Tired of ImageNet? This AI Makes Domain-Specific Datasets On
                        Demand!</span>
                </div>
                <div class="tweet-institute">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-name">University of Barcelona, Nvidia</span>
                </div>
                <div class="tweet-text">
                    This research proposes a novel method called Precision at Scale (PaS) for automatically generating
                    domain-specific datasets. Unlike previous approaches that rely on human-labeled data or
                    general-purpose datasets, PaS leverages large language models (LLMs) and image generation models to
                    create datasets tailored to specific domains.
                </div>
            </div>
        </div>
    </div>
</body>

</html>
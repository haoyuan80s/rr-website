<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ribbit Ribbit - AI Paper Picks of the Day</title>
    <meta name="description"
        content="Discover top ArXiv papers in AI and machine learning daily with our fresh picks. Browse easily through tweet-sized summaries or listen on-the-go. Make learning engaging and accessible anytime, anywhere.">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Amatic+SC:wght@400;700&family=Dosis:wght@200..800&family=Roboto:wght@300..700&display=swap">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
    <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>
</head>

<body>
    <div id="headerId" class="header"></div>
    <div class="container">
        <div id="topblock">
            <div style="height: 80px;"></div>
            <div class="institute-text" style="padding-top: 3px; line-height: 1.2;">
                Freshest
                Top Picks:
                <span class="highlightNumber" style="font-size: 28px;">51</span> out of <span
                    class="highlightNumber">245</span> arXiv AI
                papers
            </div>
            <div style="display: flex; flex-direction: column; justify-content: flex-start; align-items: flex-start;">
                <div class="institute-text" style="line-height: 1.2;">just released on</div>
                <div id="data-default-date" data-date="2024-09-12"></div>
                <input type="text" id="selectedDate" style="text-decoration: underline;" />
            </div>
            <div style=" height: 10px;">
            </div>
        </div>


        <div class="tweet" id="tweet0">
            <div class="start-time-icon" title="Play from here">01:02</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06765" target="_blank">@arXiv 2409.06765</a>
                    <span class="tweet-title">gsplat: Splatting Gaussians for 3D Reconstruction, Now with a Side of Open
                        Source!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">UC Berkeley, Aalto University, ShanghaiTech University</span>
                </div>
                <div class="primary-text">
                    This paper introduces gsplat, an open-source library specifically designed for training and
                    developing Gaussian Splatting methods. It offers a user-friendly interface and optimized CUDA
                    kernels, making it more efficient than previous implementations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet1">
            <div class="start-time-icon" title="Play from here">01:24</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07025" target="_blank">@arXiv 2409.07025</a>
                    <span class="tweet-title">Diffusion Models Get a Privacy Makeover: Classifier-Protected Sampling to
                        the Rescue!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Stanford University</span>
                </div>
                <div class="primary-text">
                    This paper introduces CPSample, a method that modifies the sampling process in diffusion models to
                    prevent training data replication without sacrificing image quality. Unlike previous approaches that
                    focused on data corruption or differential privacy, CPSample utilizes a classifier trained on random
                    labels to guide the generation process away from the training data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet2">
            <div class="start-time-icon" title="Play from here">01:55</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07431" target="_blank">@arXiv 2409.07431</a>
                    <span class="tweet-title">Teaching LLMs New Tricks: How Synthetic Data Makes Knowledge Acquisition
                        More Efficient</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">UC Berkeley, Stanford University</span>
                </div>
                <div class="primary-text">
                    This research proposes a new method called "synthetic continued pretraining" to teach language
                    models (LLMs) knowledge from small, specialized corpora. Unlike previous work that relies on massive
                    datasets, this approach uses a synthetic data augmentation algorithm called EntiGraph to generate
                    diverse representations of knowledge from the small corpus, making it more amenable to learning.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet3">
            <div class="start-time-icon" title="Play from here">02:31</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07368" target="_blank">@arXiv 2409.07368</a>
                    <span class="tweet-title">Code Security: A Prompt-Optimizing System That's Not Just a Bunch of Hot
                        Air</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Kent State University, New Jersey Institute of Technology, Hamad Bin
                        Khalifa University...</span>
                </div>
                <div class="primary-text">
                    This research introduces SGCode, a system that allows users to easily switch between different
                    prompt-optimization approaches for secure code generation. This flexibility allows for a deeper
                    understanding of the trade-offs between code utility, security analysis, and system performance.
                    Unlike previous work, which focused on specific approaches, SGCode provides a platform for comparing
                    and contrasting various methods.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet4">
            <div class="start-time-icon" title="Play from here">03:02</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07033" target="_blank">@arXiv 2409.07033</a>
                    <span class="tweet-title">E-commerce Recommendations: A Neural Network's Guide to Your Next
                        Click</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Science and Technology of China, Arizona State
                        University, The University of Chicago...</span>
                </div>
                <div class="primary-text">
                    This research combines semantic web mining with a BP neural network to improve e-commerce webpage
                    recommendations. Unlike previous work, it considers not only user search queries but also factors
                    like time spent on pages and explicit/implicit feedback.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet5">
            <div class="start-time-icon" title="Play from here">03:27</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07402" target="_blank">@arXiv 2409.07402</a>
                    <span class="tweet-title">Multimodal Learning: Beyond Redundancy, It's Synergy Time!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">École Polytechnique Fédérale de Lausanne</span>
                </div>
                <div class="primary-text">
                    This research introduces CoMM, a contrastive multimodal learning strategy that goes beyond aligning
                    features based on shared information. It aims to capture unique, redundant, and synergistic
                    information between modalities by maximizing mutual information between augmented versions of
                    multimodal features.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet6">
            <div class="start-time-icon" title="Play from here">03:50</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07409" target="_blank">@arXiv 2409.07409</a>
                    <span class="tweet-title">Blindfolded Robot Walks Through Tiny Traps: Proprioception to the
                        Rescue!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University, Shanghai Qi Zhi Institute, University of
                        Pennsylvania</span>
                </div>
                <div class="primary-text">
                    This research focuses on enabling quadruped robots to navigate tiny obstacles using only
                    proprioceptive sensors, unlike previous methods that rely on unreliable cameras. The paper
                    introduces a two-stage training framework that incorporates a contact encoder and a classification
                    head to learn implicit representations of different traps.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet7">
            <div class="start-time-icon" title="Play from here">04:16</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07094" target="_blank">@arXiv 2409.07094</a>
                    <span class="tweet-title">Deep Learning Saves the Day: AI Calibrates Hyperspectral Cameras for
                        Surgery</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Siemens AG, German Cancer Research Center (DKFZ), Helmholtz Information
                        and Data Science School for Health...</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel learning-based approach to automatically recalibrate hyperspectral
                    images during surgery, eliminating the need for manual white reference measurements. Unlike previous
                    methods, this approach focuses on predicting the white reference image itself, rather than directly
                    recalibrating the image, enabling a more robust and generalizable solution.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet8">
            <div class="start-time-icon" title="Play from here">04:38</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06793" target="_blank">@arXiv 2409.06793</a>
                    <span class="tweet-title">Multi-Modal Models: When Images and Audio Get Hacked!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Duke University, University of Tokyo, Rochester Institute of
                        Technology...</span>
                </div>
                <div class="primary-text">
                    This research introduces CrossFire, a novel adversarial attack on multi-modal models. Unlike
                    previous attacks that directly align the targeted input with the perturbed image/audio, CrossFire
                    first transforms the targeted input into a format matching the modality of the image/audio file.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet9">
            <div class="start-time-icon" title="Play from here">05:04</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07154" target="_blank">@arXiv 2409.07154</a>
                    <span class="tweet-title">Recurrent NAR: When Algorithms Get a Memory Boost!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Cambridge, Google</span>
                </div>
                <div class="primary-text">
                    This research explores the use of recurrent neural networks (RNNs) as aggregators in neural
                    algorithmic reasoning (NAR) models. Unlike previous work that primarily relies on
                    permutation-invariant aggregators, this approach leverages the sequential nature of RNNs to handle
                    tasks with inherent ordering, such as sorting algorithms.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet10">
            <div class="start-time-icon" title="Play from here">05:37</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07032" target="_blank">@arXiv 2409.07032</a>
                    <span class="tweet-title">Score-Based Diffusion Models: Finally, Optimal Sampling!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Yale University, University of Chicago</span>
                </div>
                <div class="primary-text">
                    This paper establishes the sharp minimax rate of score estimation for smooth, compactly supported
                    densities, a key step in training score-based diffusion models. Unlike previous work, it achieves
                    this rate without relying on early stopping or extraneous logarithmic terms.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet11">
            <div class="start-time-icon" title="Play from here">06:00</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07429" target="_blank">@arXiv 2409.07429</a>
                    <span class="tweet-title">Agents Get a Memory Makeover: Learning Reusable Workflows for Web
                        Navigation</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Carnegie Mellon University, Massachusetts Institute of
                        Technology</span>
                </div>
                <div class="primary-text">
                    This research introduces Agent Workflow Memory (AWM), a method that allows agents to learn reusable
                    task workflows from past experiences and apply them to future tasks. Unlike previous methods that
                    rely on fixed sets of examples, AWM enables agents to adapt and improve their performance over time.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet12">
            <div class="start-time-icon" title="Play from here">06:22</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07016" target="_blank">@arXiv 2409.07016</a>
                    <span class="tweet-title">Pre-trained Audio Models: LoRA-ing Their Way to Anomaly Detection!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research explores the use of Low-Rank Adaptation (LoRA) for fine-tuning pre-trained audio
                    models in anomalous sound detection (ASD) tasks. This approach differs from previous work by
                    focusing on adapting the model's weights without altering its architecture, which is particularly
                    beneficial when dealing with limited data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet13">
            <div class="start-time-icon" title="Play from here">06:43</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06762" target="_blank">@arXiv 2409.06762</a>
                    <span class="tweet-title">AI Makes Crystals From Words: A Recipe for New Materials</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Google</span>
                </div>
                <div class="primary-text">
                    This research proposes a hierarchical approach to generating crystal structures from natural
                    language descriptions. Unlike previous work that relies on vast amounts of unconditioned samples or
                    predetermined chemical formulae, this method leverages a language model to generate candidate
                    formulae and a diffusion model to generate structures based on those formulae.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet14">
            <div class="start-time-icon" title="Play from here">07:03</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06997" target="_blank">@arXiv 2409.06997</a>
                    <span class="tweet-title">Predict-then-Optimize: Distance is the New Black!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Harvard University</span>
                </div>
                <div class="primary-text">
                    This research introduces a new dataset distance measure specifically designed for
                    Predict-then-Optimize (PtO) tasks. Unlike traditional measures that focus on features and labels,
                    this new distance incorporates the impact of downstream decisions, making it more relevant for
                    evaluating the adaptability of PtO models across different domains.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet15">
            <div class="start-time-icon" title="Play from here">07:24</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06790" target="_blank">@arXiv 2409.06790</a>
                    <span class="tweet-title">Machine Translation Gets a Makeover: LLMs Learn to Think Like
                        Humans!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Google</span>
                </div>
                <div class="primary-text">
                    This research proposes a step-by-step approach to long-form text translation, breaking down the
                    process into distinct stages like pre-translation research, drafting, refinement, and proofreading.
                    This differs from previous work that often focuses on post-translation refinement or uses complex
                    multi-stage processes.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet16">
            <div class="start-time-icon" title="Play from here">07:47</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07326" target="_blank">@arXiv 2409.07326</a>
                    <span class="tweet-title">EEG Denoising Gets a Transformer Makeover: ART Outperforms the
                        Competition!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">National Tsing Hua University, ELAN Microelectronics Corporation,
                        National Yang Ming Chiao Tung University...</span>
                </div>
                <div class="primary-text">
                    This research introduces ART, a novel EEG denoising model that leverages the transformer
                    architecture to effectively capture both temporal and spatial dependencies in multichannel EEG data.
                    This approach differs from previous work that primarily focused on individual channels or used
                    convolutional neural networks.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet17">
            <div class="start-time-icon" title="Play from here">08:11</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07163" target="_blank">@arXiv 2409.07163</a>
                    <span class="tweet-title">Mamba Policy: Slithering Through 3D Tasks with 80% Less Fat!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Hong Kong University of Science and Technology</span>
                </div>
                <div class="primary-text">
                    This paper introduces the Mamba Policy, a new approach to 3D manipulation that uses a hybrid state
                    space model (SSM) with attention mechanisms. This differs from previous work by significantly
                    reducing the parameter count of the policy network while maintaining or even improving performance.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet18">
            <div class="start-time-icon" title="Play from here">08:37</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07020" target="_blank">@arXiv 2409.07020</a>
                    <span class="tweet-title">Brain Parcellation: A Deep Dive into Uncertainty with EVENet!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Electronic Science and Technology of China, Sun Yat-sen
                        University, Zhejiang University...</span>
                </div>
                <div class="primary-text">
                    This research introduces EVENet, a novel deep learning method for brain parcellation that
                    incorporates evidential deep learning to quantify uncertainty at each voxel during inference. This
                    approach differs from previous work by directly addressing the challenge of handling
                    out-of-distribution data, which is common in brain imaging studies.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet19">
            <div class="start-time-icon" title="Play from here">09:06</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06706" target="_blank">@arXiv 2409.06706</a>
                    <span class="tweet-title">Synapses & Neurons: Fine-Tuning with a Brain-Inspired Twist!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research proposes a new parameter-efficient fine-tuning (PEFT) method called Synapses & Neurons
                    (SAN) that explicitly propagates feature adjustments to subsequent layers, unlike existing methods
                    that implicitly do so.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet20">
            <div class="start-time-icon" title="Play from here">09:27</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07054" target="_blank">@arXiv 2409.07054</a>
                    <span class="tweet-title">Arabic AI: Is English the Key to Unlock Its Potential?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Qatar University, University of Doha for Science and Technology,
                        Liverpool John Moores University...</span>
                </div>
                <div class="primary-text">
                    This research investigates the impact of using native versus non-native language prompts on the
                    performance of large language models (LLMs) for Arabic language tasks. Unlike previous studies that
                    primarily focused on English-dominant tasks, this study explores the effectiveness of prompting in
                    both native and non-native languages for a range of Arabic datasets.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet21">
            <div class="start-time-icon" title="Play from here">09:54</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07146" target="_blank">@arXiv 2409.07146</a>
                    <span class="tweet-title">Gated Slot Attention: Giving Transformers a Memory Makeover!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Soochow University, Massachusetts Institute of Technology, University
                        of California Santa Cruz...</span>
                </div>
                <div class="primary-text">
                    This paper introduces Gated Slot Attention (GSA), a new approach to linear attention that
                    incorporates a gating mechanism inspired by Gated Linear Attention (GLA). GSA enhances the Attention
                    with Bounded-Memory Control (ABC) model by enabling selective forgetting of historical information
                    and introducing a recency inductive bias.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet22">
            <div class="start-time-icon" title="Play from here">10:17</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06985" target="_blank">@arXiv 2409.06985</a>
                    <span class="tweet-title">Pre-trained Transformers: Short-Term Memory Champs or Long-Term Planning
                        Flops?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Renmin University of China, Pennsylvania State University, Queen Mary
                        University of London...</span>
                </div>
                <div class="primary-text">
                    This research investigates the effectiveness of cross-domain pre-trained decision transformers (DT)
                    in reinforcement learning (RL) environments with varying planning abilities. Unlike previous work
                    that focused on short-term planning, this study explores the performance of pre-trained DT in
                    long-term planning environments and identifies a key factor, the "Markov Matrix," that explains the
                    performance disparity.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet23">
            <div class="start-time-icon" title="Play from here">10:44</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06888" target="_blank">@arXiv 2409.06888</a>
                    <span class="tweet-title">MAPF Map Makers: AI Designs Levels That Make Your Bots Go Bonkers!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU, University of Southern California</span>
                </div>
                <div class="primary-text">
                    This research uses a Quality Diversity (QD) algorithm to automatically generate benchmark maps for
                    Multi-Agent Path Finding (MAPF) algorithms. Unlike previous work that relies on fixed,
                    human-designed maps, this approach creates diverse maps that target specific algorithms, allowing
                    for more comprehensive and unbiased comparisons.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet24">
            <div class="start-time-icon" title="Play from here">11:12</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06726" target="_blank">@arXiv 2409.06726</a>
                    <span class="tweet-title">Vision Models: Tricked by a Game of "Who's Who?"</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Huazhong University of Science and Technology, Tsinghua
                        University</span>
                </div>
                <div class="primary-text">
                    This research introduces a new attack paradigm called Feedback-based Modal Mutual Search (FMMS) that
                    leverages target model feedback to refine adversarial examples, improving their effectiveness in
                    attacking vision-language pre-training (VLP) models. Unlike previous methods that rely solely on
                    surrogate models, FMMS incorporates feedback from the target model to guide the search for
                    adversarial examples, bridging the gap in feature representation between surrogate and target
                    models.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet25">
            <div class="start-time-icon" title="Play from here">11:39</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07434" target="_blank">@arXiv 2409.07434</a>
                    <span class="tweet-title">Dropout's Got Rhythm: New Theory Makes SGD Dance to a Stationary
                        Beat</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Chicago</span>
                </div>
                <div class="primary-text">
                    This paper analyzes the asymptotic properties of stochastic gradient descent (SGD) with dropout
                    regularization in linear models. Unlike previous work that focused on fixed designs or marginalized
                    dropout noise, this study establishes the geometric-moment contraction (GMC) property for SGD
                    dropout iterates with random designs and sequential observations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet26">
            <div class="start-time-icon" title="Play from here">12:06</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07253" target="_blank">@arXiv 2409.07253</a>
                    <span class="tweet-title">Diffusion Models: From Dreamy Images to Aligned Art!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Hong Kong University of Science and Technology, Tsinghua University,
                        Mohamed bin Zayed University of Artificial Intelligence</span>
                </div>
                <div class="primary-text">
                    This research focuses on aligning diffusion models with human preferences, a relatively new area
                    compared to aligning large language models. It provides a comprehensive overview of the
                    fundamentals, techniques, benchmarks, and future directions for aligning diffusion models.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet27">
            <div class="start-time-icon" title="Play from here">12:32</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07372" target="_blank">@arXiv 2409.07372</a>
                    <span class="tweet-title">Slides to Life: AI Turns Boring Lectures into Interactive Fun!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel intelligent tutoring system called Slide2Lecture that leverages large
                    language models to convert static lecture slides into interactive learning experiences. Unlike
                    previous systems that focus on specific teaching actions, Slide2Lecture generates a diverse range of
                    actions, including showing files, reading scripts, and asking questions, to create a more dynamic
                    and engaging learning environment.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet28">
            <div class="start-time-icon" title="Play from here">13:01</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06960" target="_blank">@arXiv 2409.06960</a>
                    <span class="tweet-title">Hunting for New Physics: A Data-Driven Approach to Signal Region
                        Selection</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU</span>
                </div>
                <div class="primary-text">
                    This research proposes a model-agnostic method for selecting signal regions in high-energy physics,
                    relying on the localized topology of signal events rather than prior domain knowledge.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet29">
            <div class="start-time-icon" title="Play from here">13:29</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07291" target="_blank">@arXiv 2409.07291</a>
                    <span class="tweet-title">Gradient Snooping: How AI Models Can Spill Your Secrets</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Vanderbilt University, University of Wisconsin-Madison, Mitsubishi
                        Electric Research Laboratories...</span>
                </div>
                <div class="primary-text">
                    This research explores a new type of privacy attack in distributed learning, focusing on recovering
                    user-level information rather than individual data samples. Unlike previous methods that rely on
                    reconstructing entire images, this approach utilizes a diffusion model prior to synthesize a
                    representative image that captures the overall semantics of a user's data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet30">
            <div class="start-time-icon" title="Play from here">13:53</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06754" target="_blank">@arXiv 2409.06754</a>
                    <span class="tweet-title">Scaling Up Multimodal Models: Can More Data Make Them Smaller?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">MIT</span>
                </div>
                <div class="primary-text">
                    This research proposes a scaling law specifically for multimodal models, taking into account the
                    varying compression efficiencies of different data types like text, audio, images, and video. This
                    differs from previous scaling laws that primarily focused on text-based models.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet31">
            <div class="start-time-icon" title="Play from here">14:20</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06851" target="_blank">@arXiv 2409.06851</a>
                    <span class="tweet-title">Tired of Benchmarks That Can't Tell the Difference? LIME-M to the
                        Rescue!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">M-A-P, 201.ai, University of Manchester...</span>
                </div>
                <div class="primary-text">
                    This research proposes a pipeline to curate existing multimodal large language model (MLLM)
                    benchmarks by filtering out overly simple or challenging samples, resulting in a more effective and
                    efficient benchmark called LIME-M. This approach differs from previous work by focusing on the
                    quality of evaluation data rather than simply expanding the number of samples.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet32">
            <div class="start-time-icon" title="Play from here">14:52</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06730" target="_blank">@arXiv 2409.06730</a>
                    <span class="tweet-title">Cargo Bikes vs. Vans: Who Wins the Urban Delivery Race?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Alabama, University of Basel, MIT...</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel framework for modeling delivery performance across diverse urban
                    environments, focusing on service time, a crucial but often overlooked component of delivery time
                    modeling. It leverages geospatial embeddings to represent urban context, enabling more accurate
                    predictions of delivery efficiency.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet33">
            <div class="start-time-icon" title="Play from here">15:18</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07388" target="_blank">@arXiv 2409.07388</a>
                    <span class="tweet-title">Multimodal Affective Computing: Emotions in a Multi-Sensory World!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Copenhagen, Nanjing University, Stony Brook
                        University...</span>
                </div>
                <div class="primary-text">
                    This research focuses on multimodal affective computing, specifically examining how different
                    modalities like text, audio, and visual signals can be combined to understand human emotions. It
                    goes beyond previous work by providing a comprehensive overview of the field, highlighting key
                    tasks, technical approaches, and future directions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet34">
            <div class="start-time-icon" title="Play from here">15:41</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07257" target="_blank">@arXiv 2409.07257</a>
                    <span class="tweet-title">TopoMap++: Mapping High-Dimensional Data with a Touch of Magic!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">NYU, University of São Paulo, Microsoft</span>
                </div>
                <div class="primary-text">
                    This research introduces TopoMap++, an improved version of the TopoMap algorithm for visualizing
                    high-dimensional data. TopoMap++ addresses the limitations of the original TopoMap by incorporating
                    a more space-efficient layout, a faster implementation, and a novel TreeMap-based representation for
                    exploring the topological hierarchy of the data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet35">
            <div class="start-time-icon" title="Play from here">16:04</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06708" target="_blank">@arXiv 2409.06708</a>
                    <span class="tweet-title">AI Fairness Audit: A Recipe for a Less Biased World</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Academia Sinica</span>
                </div>
                <div class="primary-text">
                    This research proposes a framework for auditing AI fairness, focusing on quantifying bias using
                    statistical metrics. It differs from previous work by offering a transparent, open-source tool for
                    third-party auditors to assess AI systems for fairness violations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet36">
            <div class="start-time-icon" title="Play from here">16:31</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07002" target="_blank">@arXiv 2409.07002</a>
                    <span class="tweet-title">Fooling Object Detectors with a Doggy Logo: New Patch Attack Uses
                        Diffusion Models</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Beijing Normal University, Tsinghua University, Northeastern
                        University</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel patch attack framework called AdvLogo that leverages diffusion models
                    to generate adversarial patches with high visual quality and strong attack performance. Unlike
                    previous methods that optimize patches in the pixel space, AdvLogo operates in the frequency domain,
                    reducing distribution shifts and improving image quality.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet37">
            <div class="start-time-icon" title="Play from here">16:57</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06868" target="_blank">@arXiv 2409.06868</a>
                    <span class="tweet-title">Prophet Inequalities: When Rewards Get Correlated, Things Get
                        Complicated!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Harvard University, Tel Aviv University</span>
                </div>
                <div class="primary-text">
                    This research extends the prophet inequality problem to scenarios where rewards are correlated,
                    unlike previous work that focused on independent rewards. It explores the competition complexity,
                    which measures how many additional copies of the original problem are needed to approximate the
                    prophet's performance.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet38">
            <div class="start-time-icon" title="Play from here">17:21</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07331" target="_blank">@arXiv 2409.07331</a>
                    <span class="tweet-title">Knowledge-Based VQA: Cramming Contexts for Faster Answers!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University, Huawei</span>
                </div>
                <div class="primary-text">
                    This research proposes a new framework called RACC (Retrieval-Augmented MLLM with Compressed
                    Contexts) that focuses on improving the inference efficiency of knowledge-based visual question
                    answering (KB-VQA) systems. Unlike previous works that prioritize using as much knowledge as
                    possible, RACC compresses retrieved contexts into compact representations, reducing the number of
                    input tokens and speeding up the inference process.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet39">
            <div class="start-time-icon" title="Play from here">17:44</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06715" target="_blank">@arXiv 2409.06715</a>
                    <span class="tweet-title">Cell-Free Massive MIMO: Fronthaul Compression Gets a Neural Network
                        Makeover!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">King’s College London, Huawei</span>
                </div>
                <div class="primary-text">
                    This research introduces two new multivariate quantization (MQ) techniques for precode-and-compress
                    (PC) based transmission in cell-free massive MIMO systems. The paper proposes α-parallel MQ (α-PMQ)
                    for low-fronthaul capacity regimes and neural-MQ for high-fronthaul capacity regimes. These
                    techniques aim to improve the scalability of PC methods by reducing computational complexity.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet40">
            <div class="start-time-icon" title="Play from here">18:06</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06817" target="_blank">@arXiv 2409.06817</a>
                    <span class="tweet-title">Robot Surgeon Finds the Perfect Vein: AI Helps Navigate
                        Bifurcations!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU, University of Pittsburgh Medical Center</span>
                </div>
                <div class="primary-text">
                    This research introduces BIFURC, an algorithm that uses deep learning and expert knowledge to
                    identify vessel bifurcations in ultrasound images. Unlike previous work, BIFURC is trained on a
                    limited amount of in-vivo data and can be used for autonomous robotic cannulation.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet41">
            <div class="start-time-icon" title="Play from here">18:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07323" target="_blank">@arXiv 2409.07323</a>
                    <span class="tweet-title">Boltzmann Sampling Gets a Speed Boost: Consistency Models to the
                        Rescue!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Cambridge</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel sampling method that combines Consistency Models (CMs) with
                    importance sampling to accelerate the process of generating samples from Boltzmann distributions.
                    Unlike previous approaches that address bias and speed separately, this method integrates both
                    aspects, leading to more efficient and unbiased sampling.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet42">
            <div class="start-time-icon" title="Play from here">18:48</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06729" target="_blank">@arXiv 2409.06729</a>
                    <span class="tweet-title">AI: Democracy's New BFF or Worst Nightmare?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Oxford, Brigham Young University, Collective Intelligence
                        Project...</span>
                </div>
                <div class="primary-text">
                    This research goes beyond the usual "AI is bad for democracy" narrative by exploring both the
                    potential threats and opportunities that advanced AI systems, like LLMs, present for democratic
                    processes. It focuses on three key impact categories: epistemic, material, and foundational.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet43">
            <div class="start-time-icon" title="Play from here">19:10</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07190" target="_blank">@arXiv 2409.07190</a>
                    <span class="tweet-title">Multi-Fidelity Bayesian Optimization: A Chemical Discovery Speed
                        Demon?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Imperial College London, École Polytechnique Fédérale de
                        Lausanne</span>
                </div>
                <div class="primary-text">
                    This research investigates the application of multi-fidelity Bayesian optimization (MFBO) to
                    accelerate chemical discovery. The paper specifically analyzes the conditions under which
                    lower-fidelity data can enhance performance compared to single-fidelity problem formulations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet44">
            <div class="start-time-icon" title="Play from here">19:38</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06716" target="_blank">@arXiv 2409.06716</a>
                    <span class="tweet-title">Fetal Brain Mapping: Deep Learning Takes the Wheel!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Boston Children’s Hospital, Harvard Medical School, Elmhurst Hospital
                        Center...</span>
                </div>
                <div class="primary-text">
                    This research focuses on segmenting fetal brain structures directly from diffusion-weighted MRI
                    (dMRI) data, a novel approach compared to previous work that primarily used structural MRI.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet45">
            <div class="start-time-icon" title="Play from here">19:56</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07307" target="_blank">@arXiv 2409.07307</a>
                    <span class="tweet-title">Saliency Supercharged: How AI Learned to Make Images More
                        Eye-Catching</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">École Polytechnique Fédérale de Lausanne</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel data augmentation method for saliency prediction models. Unlike
                    traditional techniques that alter scene composition, this approach leverages a latent diffusion
                    model to edit images while preserving the integrity of the scene. It focuses on manipulating
                    photometric properties like color, contrast, and brightness to control the saliency of specific
                    regions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet46">
            <div class="start-time-icon" title="Play from here">20:20</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07215" target="_blank">@arXiv 2409.07215</a>
                    <span class="tweet-title">Data Merging: Is It Worth the Headache? A Secure Way to Know!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Oxford</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel approach for evaluating the value of merging datasets in the
                    context of causal inference. Unlike previous work that focuses on general information gain, this
                    method specifically targets the reduction of uncertainty in parameters directly related to the
                    causal effect.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet47">
            <div class="start-time-icon" title="Play from here">20:58</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07265" target="_blank">@arXiv 2409.07265</a>
                    <span class="tweet-title">TTS with a Twist: Teaching AI to Speak Different Dialects</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">The University of Tokyo</span>
                </div>
                <div class="primary-text">
                    This research focuses on cross-dialect text-to-speech (CD-TTS), specifically for languages with
                    pitch-accent systems. Unlike previous work that relied on accent dictionaries, this paper proposes a
                    novel TTS model that automatically predicts accent latent variables (ALVs) tailored to each dialect
                    using a multi-dialect phoneme-level BERT (MD-PL-BERT).
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet48">
            <div class="start-time-icon" title="Play from here">21:25</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06953" target="_blank">@arXiv 2409.06953</a>
                    <span class="tweet-title">Neural Networks Learn to Think Like Algorithms, But Now They Can Find
                        Multiple Solutions!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Northeastern University, University of Cambridge</span>
                </div>
                <div class="primary-text">
                    This research introduces a new method for Neural Algorithmic Reasoning (NAR) that allows neural
                    networks to find multiple correct solutions to a problem, unlike previous methods that only returned
                    a single solution.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet49">
            <div class="start-time-icon" title="Play from here">22:00</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.06791" target="_blank">@arXiv 2409.06791</a>
                    <span class="tweet-title">Motion Stitching: Diffusion Models Make Human Movement Look Real!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Stanford University</span>
                </div>
                <div class="primary-text">
                    This research proposes a diffusion model with a transformer-based denoiser to generate realistic
                    human motion, specifically addressing the challenge of motion stitching and in-betweening. Unlike
                    previous methods that require manual efforts or struggle with longer sequences, this approach can
                    handle variable input poses and generate smooth, realistic motion sequences.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet50">
            <div class="start-time-icon" title="Play from here">22:25</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.07337" target="_blank">@arXiv 2409.07337</a>
                    <span class="tweet-title">Hand Pose Datasets: A Deep Dive into the 2D Egocentric World</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Toronto</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel protocol for evaluating egocentric datasets specifically for 2D hand
                    pose estimation, going beyond just analyzing stated characteristics. It also assesses data quality
                    by evaluating the performance of state-of-the-art hand pose estimation models on these datasets.
                </div>
            </div>
        </div>

        <div
            style="padding: 50px 0; text-align: center; margin: 5px 0; font-weight: 300; font-size: 10px; color: #000000;">
            Opening music
            from <a href="https://ikson.com" target="_blank" style="color: black; text-decoration: none;">TELL
                YOUR STORY by ikson</a></div>
        <div style="height: 50px;"></div>
    </div>

    <footer class="player-footer">
        <div class="player-detail-hidden-on-small-screen">
            <div id="audio-title" class="tweet-title-small">Hit play and learn on the go!</div>
            <div style="height: 2px;"></div>
            <div id="audio-institutes" class="institute-text-small"></div>
        </div>
        <div class="control-panel">
            <div class="control-horizontal">
                <div id="playSpeedButton" title="Adjust speed">
                    <div id="selectedSpeed">1&times;</div>
                    <div class="speedMenuItems">
                        <div data-value="0.6">Speed 0.6&times;</div>
                        <div data-value="0.8">Speed 0.8&times;</div>
                        <div data-value="1" class="selected">Speed 1&times;</div>
                        <div data-value="1.2">Speed 1.2&times;</div>
                        <div data-value="1.4">Speed 1.4&times;</div>
                        <div data-value="1.6">Speed 1.6&times;</div>
                    </div>
                    <select id="speedOptionsHidden">
                        <option value="0.6">0.6&times;</option>
                        <option value="0.8">0.8&times;</option>
                        <option value="1" selected>1&times;</option>
                        <option value="1.2">1.2&times;</option>
                        <option value="1.4">1.4&times;</option>
                        <option value="1.6">1.6&times;</option>
                    </select>
                </div>
                <div id="playLastButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(false)" title="Play last" disabled>
                        <img src="assets/buttonLastEpisode.svg" alt="Last" style="width: 12px;">
                    </button>
                </div>
                <button class="controllerButton" onclick="scrollToCurrentTweet()" title="Scoll to the current episode">
                    <img id="locateImage" src="assets/buttonTarget.svg" alt="Locate">
                </button>
                <button class="controllerButton" onclick="togglePlayPause()" title="Play/Pause">
                    <img id="playPauseImage" src="assets/buttonPlay.svg" alt="Play">
                </button>
                <div id="playNextButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(true)" title="Play next" disabled>
                        <img src="assets/buttonNextEpisode.svg" alt="Next" style="width: 12px;">
                    </button>
                </div>
            </div>
            <div class="control-horizontal">
                <div id="progressTime">0:00</div>
                <div id="progressContainer" onclick="seek(event)">
                    <div id="progressBar"></div>
                    <div id="progressCircle" draggable="true"></div>
                </div>
                <audio id="audioPlayer"
                    src="https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202409122125_audio.mp3"></audio>
                <div id="progressTime"><span id="audioDuration">Loading...</span></div>
            </div>
        </div>
    </footer>
    <div id="privacyModal" class="modal"></div>
    <script src="script.js"></script>
    <script src="calendar.js"></script>
    <script>
        fetch('https://ribbitribbit.co/header.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('headerId').innerHTML = data;
            })
            .catch(error => console.error('Error loading header.html:', error));
        fetch('file:///Users/yandeng/Projects/website/rr-website/privacy.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('privacyModal').innerHTML = data;
            })
            .catch(error => console.error('Error loading privacy.html:', error));
    </script>
</body>

</html>
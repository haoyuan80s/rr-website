
daily_data = {
    "date": "2024-07-26",
    "tweets": [
            {
                "startTime": "00:50",
                "arxivId": "2407.17852",
                "arxivLink": "https://arxiv.org/abs/2407.17852",
                "title": "Zero-Shot Speech Recognition: Romanization Rules!",
                "institute": "Monash University, Meta",
                "text": "This research proposes a novel zero-shot speech recognition approach that utilizes romanization instead of phonemes, eliminating the need for language-specific phonemizers.",
                "paper-title": "Scaling A Simple Approach to Zero-Shot Speech Recognition",
                "image-path": ""
            },

            {
                "startTime": "01:13",
                "arxivId": "2407.17773",
                "arxivLink": "https://arxiv.org/abs/2407.17773",
                "title": "Kids Can Do It, Can AI? New Benchmark Tests Visual Reasoning in Large Models",
                "institute": "University of California Berkeley, Boston University, Google DeepMind",
                "text": "This research introduces a new benchmark called KiVA, which uses real-world objects and simple visual transformations to test analogical reasoning in large multimodal models. Unlike previous benchmarks that rely on abstract shapes and complex patterns, KiVA focuses on basic visual changes that even young children can understand.",
                "paper-title": "KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models",
                "image-path": ""
            },

            {
                "startTime": "01:39",
                "arxivId": "2407.17678",
                "arxivLink": "https://arxiv.org/abs/2407.17678",
                "title": "LLMs Get a Diet: Sharding Attention for Faster Training and Serving",
                "institute": "Microsoft",
                "text": "This research proposes Sparsely-Sharded (S2) Attention, a new approach to training and serving LLMs. Unlike previous methods that focus on homogeneous sparsity patterns, S2-Attention assigns heterogeneous context partitions to different attention heads, allowing for greater sparsity and efficiency.",
                "paper-title": "Efficient LLM Training and Serving with Heterogeneous Context Sharding among Attention Heads",
                "image-path": ""
            },

            {
                "startTime": "02:03",
                "arxivId": "2407.18112",
                "arxivLink": "https://arxiv.org/abs/2407.18112",
                "title": "Re-IDing the Occluded: Keypoint Prompts for Person Recognition",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Universit\u00e9 Catholique de Louvain, Sportradar",
                "text": "This research introduces a novel approach to person re-identification (ReID) by incorporating keypoint prompts. Unlike previous methods that rely solely on bounding boxes, this method explicitly addresses the ambiguity caused by multiple individuals within a single bounding box.",
                "paper-title": "Keypoint Promptable Re-Identification",
                "image-path": ""
            },

            {
                "startTime": "02:30",
                "arxivId": "2407.18245",
                "arxivLink": "https://arxiv.org/abs/2407.18245",
                "title": "Synthetic Heads: A Million Fake Faces for Real-World AI",
                "institute": "University of Oxford, Ukrainian Catholic University, Pi\u00f1ataFarms AI",
                "text": "This research introduces a large-scale synthetic dataset of human heads, generated using diffusion models, and a novel model trained on this data that can simultaneously detect and reconstruct 3D head meshes from a single image. This approach differs from previous work by directly predicting 3D head models from images, rather than relying on separate detection and reconstruction steps.",
                "paper-title": "VGGHeads: A Large-Scale Synthetic Dataset for 3D Human Heads",
                "image-path": ""
            },

            {
                "startTime": "02:59",
                "arxivId": "2407.18219",
                "arxivLink": "https://arxiv.org/abs/2407.18219",
                "title": "LLMs Learn to Self-Improve: A Recursive Introspection Approach",
                "institute": "CMU",
                "text": "This research introduces RISE, a novel approach for fine-tuning LLMs to enable them to improve their responses over multiple turns. Unlike previous work that focuses on prompting techniques or external feedback, RISE trains models to learn from their own mistakes and iteratively refine their answers.",
                "paper-title": "Recursive Introspection: Teaching Language Model Agents How to Self-Improve",
                "image-path": ""
            },

            {
                "startTime": "03:31",
                "arxivId": "2407.18141",
                "arxivLink": "https://arxiv.org/abs/2407.18141",
                "title": "Tired of Yelling at Alexa? This Smart Ring Sees Your Home and Does Your Bidding!",
                "institute": "University of Washington",
                "text": "This research introduces IRIS, a wireless smart ring equipped with a camera that enables vision-based smart home interaction. Unlike previous work that relies on voice commands or requires modifications to existing devices, IRIS uses image recognition to identify and control smart home devices.",
                "paper-title": "IRIS: Wireless Ring for Vision-based Smart Home Interaction",
                "image-path": ""
            },

            {
                "startTime": "03:55",
                "arxivId": "2407.17817",
                "arxivLink": "https://arxiv.org/abs/2407.17817",
                "title": "LLMs: Memorizing More Than Just Words, They're Remembering the Vibe!",
                "institute": "Stanford University",
                "text": "This research introduces a novel framework for studying verbatim memorization in LLMs by injecting specific sequences into the training data. This allows for a controlled setting to study the effects of language modeling quality on memorization, unlike previous observational studies.",
                "paper-title": "Demystifying Verbatim Memorization in Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "04:16",
                "arxivId": "2407.17605",
                "arxivLink": "https://arxiv.org/abs/2407.17605",
                "title": "Speech to Text: A Match Made in L2-Loss Heaven!",
                "institute": "Google",
                "text": "This research introduces an \"exporter\" layer trained under L2-loss to align speech encoder embeddings with text model token embeddings. This approach differs from previous work by ensuring that the resulting cascade speech translation model performs no worse than the 1-best cascade baseline while allowing back-propagation gradient to flow from the text model into the speech recognition components.",
                "paper-title": "Coupling Speech Encoders with Downstream Text Models",
                "image-path": ""
            },

            {
                "startTime": "04:44",
                "arxivId": "2407.18121",
                "arxivLink": "https://arxiv.org/abs/2407.18121",
                "title": "KV Cache: Don't Throw It Away, Merge It!",
                "institute": "Tsinghua University, University of Washington, Carnegie Mellon University...",
                "text": "This paper introduces ElasticCache, a novel approach to managing key-value (KV) caches in instruction-following vision-language models (LVLMs). Unlike previous methods that focus on cache eviction, ElasticCache employs a cache merging strategy, where less important vectors are merged with anchor points to preserve contextual information.",
                "paper-title": "Efficient Inference of Vision Instruction-Following Models with Elastic Cache",
                "image-path": ""
            },

            {
                "startTime": "05:09",
                "arxivId": "2407.17792",
                "arxivLink": "https://arxiv.org/abs/2407.17792",
                "title": "Time Travel for Action Detection: New AI Sees the Future (and Past) of Videos!",
                "institute": "KAUST, 4Paradigm Inc., Moonshot AI...",
                "text": "This research introduces a novel approach to temporal action detection by incorporating temporal causality. Unlike previous methods that treat past and future information equally, this study proposes a hybrid causal block that leverages causal attention and causal Mamba to model the inherent causal relationships in action transitions.",
                "paper-title": "Harnessing Temporal Causality for Advanced Temporal Action Detection",
                "image-path": ""
            },

            {
                "startTime": "05:40",
                "arxivId": "2407.18249",
                "arxivLink": "https://arxiv.org/abs/2407.18249",
                "title": "Action Recognition with a Pointy Twist: Trajectory-Aligned Tokens for Few-Shot Learning",
                "institute": "University of Maryland, Meta",
                "text": "This research proposes a novel approach for few-shot action recognition by disentangling motion and appearance representations. It leverages point trajectories from tracking algorithms and self-supervised representation learning to create trajectory-aligned tokens (TATs), which capture both motion and appearance information. This approach significantly reduces the data requirements while retaining essential information.",
                "paper-title": "Trajectory-aligned Space-time Tokens for Few-shot Action Recognition",
                "image-path": ""
            },

            {
                "startTime": "06:03",
                "arxivId": "2407.17952",
                "arxivLink": "https://arxiv.org/abs/2407.17952",
                "title": "Depth Estimation: Diffusion Models Get a Boost from Pre-Trained Experts!",
                "institute": "ETH Z\u00fcrich, DisneyResearch|Studios",
                "text": "This paper proposes BetterDepth, a method that combines pre-trained zero-shot monocular depth estimation (MDE) models with diffusion-based refiners. This approach aims to leverage the strengths of both types of models, achieving robust performance with fine-grained details. Unlike previous diffusion-based MDE methods, BetterDepth does not require extensive training on real-world datasets, which often have noisy and incomplete depth labels.",
                "paper-title": "BetterDepth: Plug-and-Play Diffusion Refiner for Zero-Shot Monocular Depth Estimation",
                "image-path": ""
            },

            {
                "startTime": "06:27",
                "arxivId": "2407.17712",
                "arxivLink": "https://arxiv.org/abs/2407.17712",
                "title": "Predicting the Future: How Machine Learning Can Make Online Algorithms Smarter",
                "institute": "Google",
                "text": "This research explores using machine-learned predictions to improve the performance of online algorithms. Unlike previous work that focused on worst-case scenarios, this paper introduces the concepts of robustness and consistency, allowing algorithms to adapt to varying prediction accuracy.",
                "paper-title": "Improving Online Algorithms via ML Predictions",
                "image-path": ""
            },

            {
                "startTime": "06:54",
                "arxivId": "2407.18178",
                "arxivLink": "https://arxiv.org/abs/2407.18178",
                "title": "Piano-Playing Robot Learns From YouTube, Plays (Almost) Like a Pro!",
                "institute": "TU Munich, TU Darmstadt, UC Berkeley",
                "text": "This research differs from previous work by training a piano-playing robot using internet demonstrations, specifically YouTube videos, rather than relying solely on traditional reinforcement learning methods.",
                "paper-title": "PianoMime: Learning a Generalist, Dexterous Piano Player from Internet Demonstrations",
                "image-path": ""
            },

            {
                "startTime": "07:14",
                "arxivId": "2407.18184",
                "arxivLink": "https://arxiv.org/abs/2407.18184",
                "title": "Antibody Epitope Prediction: A New Dataset and Model That's Not Just a Bunch of Hot Air!",
                "institute": "University College London",
                "text": "This research introduces a new dataset, AsEP, for antibody-specific epitope prediction, which is larger and more diverse than previous datasets. It also proposes a new model, WALLE, that combines protein language models and graph neural networks to improve epitope prediction accuracy.",
                "paper-title": "AsEP: Benchmarking Deep Learning Methods for Antibody-specific Epitope Prediction",
                "image-path": ""
            },

            {
                "startTime": "07:37",
                "arxivId": "2407.17770",
                "arxivLink": "https://arxiv.org/abs/2407.17770",
                "title": "BOTEVAL: Chatbots Get a Human Touch for Better Evaluation",
                "institute": "University of Southern California, Microsoft",
                "text": "This research introduces BOTEVAL, a toolkit designed for evaluating NLP models in interactive tasks, where human evaluators directly interact with the models. This differs from previous approaches that focused on evaluating static outputs or completed conversations.",
                "paper-title": "BotEval: Facilitating Interactive Human Evaluation",
                "image-path": ""
            },

            {
                "startTime": "08:00",
                "arxivId": "2407.18247",
                "arxivLink": "https://arxiv.org/abs/2407.18247",
                "title": "Drag It, Don't Drag It Out: Region-Based Image Editing Speeds Up Diffusion Models",
                "institute": "University of Hong Kong, University of Oxford",
                "text": "This paper proposes a region-based approach to image editing using diffusion models, unlike previous point-based methods. Instead of dragging individual points, users define handle and target regions, providing richer context for the model.",
                "paper-title": "RegionDrag: Fast Region-Based Image Editing with Diffusion Models",
                "image-path": ""
            },

            {
                "startTime": "08:19",
                "arxivId": "2407.17956",
                "arxivLink": "https://arxiv.org/abs/2407.17956",
                "title": "Gigapixel Images? No Problem! SaccadeDet Sees It All, Fast!",
                "institute": "Shanghai Jiao Tong University, Tsinghua University",
                "text": "This research introduces SaccadeDet, a novel dual-stage architecture for object detection in gigapixel images. Unlike previous methods that process the entire image, SaccadeDet strategically selects and processes only regions of interest, significantly reducing computational load and improving speed.",
                "paper-title": "SaccadeDet: A Novel Dual-Stage Architecture for Rapid and Accurate Detection in Gigapixel Images",
                "image-path": ""
            },

            {
                "startTime": "08:43",
                "arxivId": "2407.18145",
                "arxivLink": "https://arxiv.org/abs/2407.18145",
                "title": "Semantic Segmentation Goes Hyperbolic: A Taxonomy-Aware Approach to Open-World Perception",
                "institute": "University of Freiburg",
                "text": "This research proposes a new approach to class-incremental semantic segmentation that leverages hyperbolic space to represent class relationships. Unlike previous methods that focus on incremental learning from the background, this approach allows for new classes to originate from both the background and known classes, making it more realistic for real-world applications.",
                "paper-title": "Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception",
                "image-path": ""
            },

            {
                "startTime": "09:16",
                "arxivId": "2407.18046",
                "arxivLink": "https://arxiv.org/abs/2407.18046",
                "title": "Pixels Are So 2023: GaussianSR Blurs the Lines for Super-Resolution!",
                "institute": "Tsinghua University",
                "text": "This paper introduces GaussianSR, a new method for arbitrary-scale super-resolution (ASSR) that uses 2D Gaussian Splatting to represent pixels as continuous fields instead of discrete points. This differs from previous INR-based ASSR methods that rely on discrete latent codes.",
                "paper-title": "GaussianSR: High Fidelity 2D Gaussian Splatting for Arbitrary-Scale Image Super-Resolution",
                "image-path": ""
            },

            {
                "startTime": "09:38",
                "arxivId": "2407.17933",
                "arxivLink": "https://arxiv.org/abs/2407.17933",
                "title": "Five Images, One Click: New AI Tool Makes Medical Segmentation a Breeze!",
                "institute": "University College London, Wellcome/EPSRC Centre for Interventional and Surgical Sciences, Royal National Orthopaedic Hospital",
                "text": "This research proposes a novel approach to medical image segmentation using the Segment Anything Model (SAM). Unlike previous methods that require extensive training data or full segmentation labels, this technique leverages image registration to align a new image with a small set of reference images, each with only a few point prompts. This allows for accurate segmentation without the need for extensive manual annotation.",
                "paper-title": "Segmentation by registration-enabled SAM prompt engineering using five reference images",
                "image-path": ""
            },

            {
                "startTime": "10:06",
                "arxivId": "2407.17854",
                "arxivLink": "https://arxiv.org/abs/2407.17854",
                "title": "Shapley Value: The Fair Way to Align Images and Text for Information Extraction",
                "institute": "Peking University",
                "text": "This research introduces a new paradigm for multimodal information extraction (MIE) called Image-Context-Text interaction. Instead of directly aligning images and text, it uses a large multimodal model (LMM) to generate a descriptive textual context that bridges the semantic and modality gaps between the two.",
                "paper-title": "Shapley Value-based Contrastive Alignment for Multimodal Information Extraction",
                "image-path": ""
            },

            {
                "startTime": "10:28",
                "arxivId": "2407.18207",
                "arxivLink": "https://arxiv.org/abs/2407.18207",
                "title": "Spherical Images: FID's Got No View, OmniFID's the New Crew!",
                "institute": "Technical University of Denmark, Google",
                "text": "This research introduces two new metrics, OmniFID and Discontinuity Score (DS), to evaluate the geometric fidelity of spherical images generated by AI models. Unlike the widely used Fr\u00e9chet Inception Distance (FID), these metrics specifically account for the unique geometric constraints of spherical images, such as field-of-view and seam alignment.",
                "paper-title": "Geometry Fidelity for Spherical Images",
                "image-path": ""
            },

            {
                "startTime": "10:56",
                "arxivId": "2407.17954",
                "arxivLink": "https://arxiv.org/abs/2407.17954",
                "title": "Stop Wasting Storage! New Research Shows How to Train AI Models on Compressed Images",
                "institute": "Granica",
                "text": "This research introduces a \"bits-samples scaling law\" that describes how the error rate of a machine learning model changes with both the number of training samples and the number of bits used to represent each sample. This differs from previous scaling laws that only considered the number of samples.",
                "paper-title": "Scaling Training Data with Lossy Image Compression",
                "image-path": ""
            },

            {
                "startTime": "11:19",
                "arxivId": "2407.17616",
                "arxivLink": "https://arxiv.org/abs/2407.17616",
                "title": "Pre-trained in 1D, Ready to Rule in 2D: A Neural Operator's Low-Dimensional Trick",
                "institute": "Carnegie Mellon University",
                "text": "This research proposes a novel pretraining strategy for neural PDE solvers. Instead of relying on expensive high-dimensional PDE data, the authors pretrain the model on lower-dimensional (1D) PDEs, then transfer the learned weights to higher dimensions. This approach aims to reduce the cost of data collection and improve the accuracy of the model.",
                "paper-title": "Pretraining a Neural Operator in Lower Dimensions",
                "image-path": ""
            },

            {
                "startTime": "11:43",
                "arxivId": "2407.17477",
                "arxivLink": "https://arxiv.org/abs/2407.17477",
                "title": "AI Detects Bias in Doctor Talk: Is Your Doc a Warm Fuzzy or a Cold Shoulder?",
                "institute": "University of Washington, University of California San Diego",
                "text": "This research uses automated speech recognition (ASR) and natural language processing (NLP) to analyze the content of clinical conversations, going beyond just nonverbal cues to identify social signals that may indicate bias.",
                "paper-title": "Toward Automated Detection of Biased Social Signals from the Content of Clinical Conversations",
                "image-path": ""
            },

            {
                "startTime": "12:08",
                "arxivId": "2407.17624",
                "arxivLink": "https://arxiv.org/abs/2407.17624",
                "title": "LLMs Get Schooled: Traditional Methods Ace Credit Rating Forecasting",
                "institute": "University of Oxford",
                "text": "This research investigates the performance of LLMs in forecasting corporate credit ratings, a task that has not been extensively explored before. It compares LLMs to traditional methods, specifically XGBoost, and finds that traditional methods are more effective when incorporating both textual and numerical data.",
                "paper-title": "Traditional Methods Outperform Generative LLMs at Forecasting Credit Ratings",
                "image-path": ""
            },

            {
                "startTime": "12:29",
                "arxivId": "2407.17879",
                "arxivLink": "https://arxiv.org/abs/2407.17879",
                "title": "FPGA-Accelerated Vision Transformers: Hybrid-Grained Pipeline for Speed Demons!",
                "institute": "Peking University",
                "text": "This research introduces a hybrid-grained pipeline architecture for accelerating Vision Transformers (ViTs) on FPGAs. Unlike previous approaches that rely on either coarse-grained or fine-grained pipelines, this method combines the benefits of both, resulting in a more efficient and balanced design.",
                "paper-title": "HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline",
                "image-path": ""
            },

            {
                "startTime": "12:56",
                "arxivId": "2407.17703",
                "arxivLink": "https://arxiv.org/abs/2407.17703",
                "title": "Traffic Forecasting Gets a Knowledge Graph Makeover: Predicting Speed with Contextual Clues!",
                "institute": "ETH Zurich, University of Canterbury, University of Wisconsin-Madison",
                "text": "This research proposes a context-aware knowledge graph (CKG) framework for traffic speed forecasting, which integrates spatial and temporal context information into a graph neural network (GNN) model. This approach differs from previous work by explicitly modeling the relationships between traffic data and surrounding environmental factors.",
                "paper-title": "Context-aware knowledge graph framework for traffic speed forecasting using graph neural network",
                "image-path": ""
            },

            {
                "startTime": "13:34",
                "arxivId": "2407.17622",
                "arxivLink": "https://arxiv.org/abs/2407.17622",
                "title": "AI Minds: Can Neural Networks Mimic Human Decision-Making?",
                "institute": "Singapore Management University, CMU, Rutgers University",
                "text": "This research proposes two new attention-based neural network models that personalize decision-making by incorporating individual memory, unlike previous work that often assumes a single model for all humans.",
                "paper-title": "Towards Neural Network based Cognitive Models of Dynamic Decision-Making by Humans",
                "image-path": ""
            },

            {
                "startTime": "13:56",
                "arxivId": "2407.17492",
                "arxivLink": "https://arxiv.org/abs/2407.17492",
                "title": "Spectra-licious! New Dataset Makes Molecular Structure Elucidation a Breeze",
                "institute": "IBM",
                "text": "This research introduces a multimodal spectroscopic dataset containing simulated spectra from various techniques for 790,000 molecules, enabling the development of AI models that can integrate information from multiple modalities, mimicking the approach used by human experts. This differs from previous work that primarily focused on single-modality tasks.",
                "paper-title": "Unraveling Molecular Structure: A Multimodal Spectroscopic Dataset for Chemistry",
                "image-path": ""
            },

            {
                "startTime": "14:18",
                "arxivId": "2407.17695",
                "arxivLink": "https://arxiv.org/abs/2407.17695",
                "title": "LLMs Learn the Game: How a Framework Makes AI Agents Smarter Than Humans in Crafter",
                "institute": "Universit\u00e9 de Montr\u00e9al, Mila, Microsoft Research",
                "text": "This research introduces DiVE, a framework that helps large language models (LLMs) learn the dynamics of a game environment from a small number of demonstrations. Unlike previous methods that rely on extensive training data, DiVE focuses on discovering, verifying, and evolving knowledge about the game world, enabling LLMs to make better decisions.",
                "paper-title": "Enhancing Agent Learning through World Dynamics Modeling",
                "image-path": ""
            },

            {
                "startTime": "14:39",
                "arxivId": "2407.17686",
                "arxivLink": "https://arxiv.org/abs/2407.17686",
                "title": "Transformers: Deep Learning Doesn't Need to Be Deep!",
                "institute": "UC Berkeley",
                "text": "This research challenges the common belief that transformers need a large number of layers to learn complex patterns in data. It shows that a transformer with just three layers can effectively learn kth-order Markov processes, which are models that capture dependencies between consecutive elements in a sequence. This finding contrasts with previous studies that suggested a linear scaling of the number of layers with the order of the Markov process.",
                "paper-title": "Transformers on Markov Data: Constant Depth Suffices",
                "image-path": ""
            },

            {
                "startTime": "15:02",
                "arxivId": "2407.17998",
                "arxivLink": "https://arxiv.org/abs/2407.17998",
                "title": "Deep Learning Debugging: A Visual Guide to Untangling the Knots",
                "institute": "ETH Zurich, University of Konstanz",
                "text": "This research proposes a structured framework for debugging deep learning models, going beyond traditional metrics like accuracy and loss. It emphasizes the importance of analyzing data across multiple levels of abstraction, from the model's architecture to individual neurons, and provides a system called iNNspector to facilitate this process.",
                "paper-title": "iNNspector: Visual, Interactive Deep Model Debugging",
                "image-path": ""
            },

            {
                "startTime": "15:30",
                "arxivId": "2407.18110",
                "arxivLink": "https://arxiv.org/abs/2407.18110",
                "title": "Mapping Madness: AI Tunes Up ASIC Design with a Library of Tricks",
                "institute": "University of Maryland, MIT",
                "text": "This research proposes MapTune, a framework that uses reinforcement learning to optimize the selection of cells from a technology library during ASIC technology mapping. Unlike previous work that focuses on end-to-end tool parameter space exploration, MapTune specifically targets the cell selection process, aiming to reduce the search space and improve mapping quality.",
                "paper-title": "MapTune: Advancing ASIC Technology Mapping via Reinforcement Learning Guided Library Tuning",
                "image-path": ""
            },

            {
                "startTime": "15:56",
                "arxivId": "2407.18074",
                "arxivLink": "https://arxiv.org/abs/2407.18074",
                "title": "AI Agents Get Paid: Contracts for Smarter Bots",
                "institute": "Google, Technion \u2013 Israel Institute of Technology, Harvard University",
                "text": "This research explores the use of contracts in reinforcement learning settings where the agent's goals are misaligned with the principal's. It differs from previous work by focusing on sequential contracting problems and developing a meta-algorithm that provably converges to a subgame-perfect equilibrium.",
                "paper-title": "Principal-Agent Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "16:30",
                "arxivId": "2407.18058",
                "arxivLink": "https://arxiv.org/abs/2407.18058",
                "title": "Music AI Can Hear, But Can It Read?",
                "institute": "Queen Mary University of London, Spotify",
                "text": "This research delves into the limitations of two-tower multimodal systems for instrument recognition, specifically focusing on the text encoder's ability to accurately interpret musical descriptions. It evaluates the systems' performance using different prompts and analyzes the semantic meaningfulness of the text embeddings.",
                "paper-title": "I can listen but cannot read: An evaluation of two-tower multimodal systems for instrument recognition",
                "image-path": ""
            },

            {
                "startTime": "16:54",
                "arxivId": "2407.17642",
                "arxivLink": "https://arxiv.org/abs/2407.17642",
                "title": "Traffic Accidents? Let's Hypergraph Our Way to Safety!",
                "institute": "University College London",
                "text": "This research introduces a new model called SMA-Hyper, which uses adaptive hypergraphs and graphs to capture complex relationships between urban regions, unlike previous models that rely on predefined structures.",
                "paper-title": "SMA-Hyper: Spatiotemporal Multi-View Fusion Hypergraph Learning for Traffic Accident Prediction",
                "image-path": ""
            },

            {
                "startTime": "17:21",
                "arxivId": "2407.18251",
                "arxivLink": "https://arxiv.org/abs/2407.18251",
                "title": "Tiny Tweaks, Big Trouble: How a Few Pixels Can Break Multimodal Models",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, armasuisse",
                "text": "This research focuses on the impact of sparse and contiguous pixel perturbations on the robustness of multimodal models. Unlike previous work that focused on whole-image perturbations, this study investigates the vulnerability of these models to attacks targeting a limited number of pixels, exploring different spatial distributions of those pixels.",
                "paper-title": "Sparse vs Contiguous Adversarial Pixel Perturbations in Multimodal Models: An Empirical Analysis",
                "image-path": ""
            },

            {
                "startTime": "17:50",
                "arxivId": "2407.17491",
                "arxivLink": "https://arxiv.org/abs/2407.17491",
                "title": "Black-Box Vision: How to Teach a Model Without Peeking!",
                "institute": "University of Wisconsin-Madison, CMU",
                "text": "This research introduces a new method called \"Black-Box Visual Prompting\" (BlackVIP) that allows users to adapt pre-trained vision models without needing access to the model's internal parameters or a large memory capacity. This differs from previous methods that require full parameter access and significant memory for gradient calculations.",
                "paper-title": "Robust Adaptation of Foundation Models with Black-Box Visual Prompting",
                "image-path": ""
            },

            {
                "startTime": "18:19",
                "arxivId": "2407.18227",
                "arxivLink": "https://arxiv.org/abs/2407.18227",
                "title": "AI Doctor's New Trick: Mixing Images and Records for Better Diagnoses!",
                "institute": "University of Oxford",
                "text": "This research introduces AutoPrognosis-M, an automated machine learning framework that combines structured clinical data (like patient records) with medical images to create more accurate diagnostic and prognostic models. Unlike previous approaches that typically rely on a single data type, AutoPrognosis-M leverages the power of multiple modalities, mirroring how clinicians make decisions in real-world settings.",
                "paper-title": "Automated Ensemble Multimodal Machine Learning for Healthcare",
                "image-path": ""
            },

            {
                "startTime": "18:52",
                "arxivId": "2407.17777",
                "arxivLink": "https://arxiv.org/abs/2407.17777",
                "title": "Babel: Six-Sensing Superpower for Your Devices!",
                "institute": "Microsoft, University of Wisconsin-Madison, Hong Kong University of Science and Technology",
                "text": "This research introduces Babel, a framework that aligns multiple sensing modalities using partially paired data. Unlike previous work that requires fully paired data, Babel leverages existing single-modal networks and a novel expandable architecture to achieve multi-modal alignment.",
                "paper-title": "Advancing Multi-Modal Sensing Through Expandable Modality Alignment",
                "image-path": ""
            },

            {
                "startTime": "19:23",
                "arxivId": "2407.17716",
                "arxivLink": "https://arxiv.org/abs/2407.17716",
                "title": "Speech Recognition: When Noise Gets in the Way, Text to the Rescue!",
                "institute": "University of Texas at Dallas, Boston University, Harvard University...",
                "text": "This research explores using text descriptions of the environment to improve speech emotion recognition (SER) systems' performance in noisy conditions. Unlike previous work that focused on data augmentation or feature enhancement, this study leverages the semantic information from text prompts to guide the SER model's adaptation to different noisy environments.",
                "paper-title": "Describe Where You Are: Improving Noise-Robustness for Speech Emotion Recognition with Text Description of the Environment",
                "image-path": ""
            },

            {
                "startTime": "19:48",
                "arxivId": "2407.17505",
                "arxivLink": "https://arxiv.org/abs/2407.17505",
                "title": "Voice of Health: Can Your Speech Reveal Your Secrets?",
                "institute": "University of Freiburg",
                "text": "This research paper provides a comprehensive overview of vocal biomarkers, focusing on their potential for detecting various health conditions and estimating measurements from other sensory modalities. It distinguishes itself from previous work by offering a broader definition of vocal biomarkers, encompassing systems that utilize human vocalizations to detect a condition or estimate measurements from other sensors.",
                "paper-title": "Survey on biomarkers in human vocalizations",
                "image-path": ""
            },

            {
                "startTime": "20:14",
                "arxivId": "2407.18243",
                "arxivLink": "https://arxiv.org/abs/2407.18243",
                "title": "Blind Photographers, Private Pics: A Dataset for Privacy-Aware AI",
                "institute": "University of Colorado, University of Illinois, University of Washington",
                "text": "This research introduces BIV-Priv-Seg, the first localization dataset specifically designed for images taken by people with visual impairments that shows private content. This dataset is unique because it includes images lacking target objects, objects with greater variability in size, and a higher prevalence of objects with text.",
                "paper-title": "BIV-Priv-Seg: Locating Private Content in Images Taken by People With Visual Impairments",
                "image-path": ""
            },

            {
                "startTime": "20:49",
                "arxivId": "2407.18044",
                "arxivLink": "https://arxiv.org/abs/2407.18044",
                "title": "Query-Based RAG: A New Way to Ask Questions and Get Answers Right!",
                "institute": "Verily",
                "text": "This research introduces a novel approach called Query-Based Retrieval Augmented Generation (QB-RAG) that pre-computes a database of potential queries from a content base using LLMs. This differs from previous methods that rely on generating hypothetical documents or candidate answers.",
                "paper-title": "The Geometry of Queries: Query-Based Innovations in Retrieval-Augmented Generation",
                "image-path": ""
            },

            {
                "startTime": "21:17",
                "arxivId": "2407.17688",
                "arxivLink": "https://arxiv.org/abs/2407.17688",
                "title": "LLMs: Politically Biased or Just Bad at Stance?",
                "institute": "Carnegie Mellon University, Army Cyber Institute, Singapore University of Technology and Design",
                "text": "This research investigates the influence of political biases on Large Language Models (LLMs) performance in stance classification tasks. Unlike previous work that focused on political biases in general responses, this study specifically examines how these biases affect the accuracy of stance detection.",
                "paper-title": "Examining the Influence of Political Bias on Large Language Model Performance in Stance Classification",
                "image-path": ""
            },

            {
                "startTime": "21:44",
                "arxivId": "2407.17654",
                "arxivLink": "https://arxiv.org/abs/2407.17654",
                "title": "Predicting Vehicle Faults: A Deep Dive into the Army's Data-Driven Maintenance Revolution",
                "institute": "Duke University, Stanford University",
                "text": "This research proposes a hybrid generative model that combines DeepAR and STAM to predict vehicle faults, incorporating real-world factors like vehicle age and location. This approach differs from previous work by generating future sensor data using STAM, addressing the need for future covariates in DeepAR.",
                "paper-title": "Generative Learning for Simulation of US Army Vehicle Faults",
                "image-path": ""
            },

            {
                "startTime": "22:08",
                "arxivId": "2407.17835",
                "arxivLink": "https://arxiv.org/abs/2407.17835",
                "title": "IsUMap: Unfolding Data Like a Swiss Roll, One Metric at a Time!",
                "institute": "Max Planck Society",
                "text": "This paper introduces IsUMap, a manifold learning technique that combines aspects of UMAP and Isomap with Vietoris-Rips filtrations. Unlike previous methods, IsUMap addresses limitations in existing methods by accommodating non-uniform data distributions and intricate local geometries.",
                "paper-title": "IsUMap: Manifold Learning and Data Visualization leveraging Vietoris-Rips filtrations",
                "image-path": ""
            },

            {
                "startTime": "22:28",
                "arxivId": "2407.18213",
                "arxivLink": "https://arxiv.org/abs/2407.18213",
                "title": "Big Models, Big Problems? Scaling Up Language Models Doesn't Always Mean Scaling Up Robustness!",
                "institute": "FAR AI, Mila, Universit\u00b4e de Montr\u00b4eal",
                "text": "This research investigates the relationship between model size and adversarial robustness in language models. Unlike previous work that focused on computer vision, this study examines how scaling affects the ability of language models to withstand attacks specifically designed to exploit their vulnerabilities.",
                "paper-title": "Exploring Scaling Trends in LLM Robustness",
                "image-path": ""
            },

            {
                "startTime": "23:01",
                "arxivId": "2407.18147",
                "arxivLink": "https://arxiv.org/abs/2407.18147",
                "title": "Multilingual News Bias: A Shared Task to Unmask Propaganda in Five Languages!",
                "institute": "Northwestern University, Birzeit University, NYU...",
                "text": "This research focuses on developing annotation guidelines for identifying bias and propaganda in news articles related to the Israel War on Gaza, using a multilingual corpus of Facebook posts. This approach differs from previous work by emphasizing the collaborative development of guidelines and the inclusion of multiple languages.",
                "paper-title": "The FIGNEWS Shared Task on News Media Narratives",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 52,
        "num_total": 264,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202407261714_audio.mp3"
}
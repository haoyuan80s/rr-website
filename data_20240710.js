
daily_data = {
    "date": "2024-07-10",
    "tweets": [
            {
                "startTime": "00:51",
                "arxivId": "2407.07018",
                "arxivLink": "https://arxiv.org/abs/2407.07018",
                "title": "Can AI Read Your Diary to Predict Treatment Effects?",
                "institute": "University of Toronto, Vector Institute, Meta",
                "text": "This research proposes a novel method called NATURAL, which uses large language models (LLMs) to estimate causal effects from unstructured text data. Unlike previous approaches that rely on structured data, NATURAL leverages the ability of LLMs to extract conditional distributions from text, enabling the estimation of treatment effects without manual data structuring.",
                "paper-title": "End-To-End Causal Effect Estimation from Unstructured Natural Language Data",
                "image-path": ""
            },

            {
                "startTime": "01:12",
                "arxivId": "2407.06380",
                "arxivLink": "https://arxiv.org/abs/2407.06380",
                "title": "Data Diet: How to Build the Perfect Language Model Menu",
                "institute": "Nvidia",
                "text": "This research systematically analyzes the entire pipeline of constructing pretraining datasets for language models, going beyond just data curation and exploring a wider range of data sources and languages.",
                "paper-title": "Data, Data Everywhere: A Guide for Pretraining Dataset Construction",
                "image-path": ""
            },

            {
                "startTime": "01:31",
                "arxivId": "2407.06460",
                "arxivLink": "https://arxiv.org/abs/2407.06460",
                "title": "Making AI Forget: A Six-Way Test for Machine Unlearning",
                "institute": "University of Washington, Princeton University, University of Southern California...",
                "text": "This research proposes a new benchmark called MUSE to evaluate machine unlearning algorithms for language models. MUSE considers six key properties, including verbatim memorization, knowledge memorization, privacy leakage, utility preservation, scalability, and sustainability. This comprehensive approach goes beyond previous benchmarks that focused on specific tasks like question answering.",
                "paper-title": "MUSE: Machine Unlearning Six-Way Evaluation for Language Models",
                "image-path": ""
            },

            {
                "startTime": "02:02",
                "arxivId": "2407.06842",
                "arxivLink": "https://arxiv.org/abs/2407.06842",
                "title": "Chatting Your Way to a 3D Makeover: New AI Edits Scenes with Text Prompts",
                "institute": "Beihang University, Google, Megvii...",
                "text": "This research proposes a novel approach to 3D scene editing by decoupling the 2D editing process from the 3D reconstruction process. This allows for flexible integration of various visual models, unlike previous methods that relied on intricate pipelines combining specific 2D and 3D models.",
                "paper-title": "Chat-Edit-3D: Interactive 3D Scene Editing via Text Prompts",
                "image-path": ""
            },

            {
                "startTime": "02:30",
                "arxivId": "2407.06946",
                "arxivLink": "https://arxiv.org/abs/2407.06946",
                "title": "Can AI Recognize Itself? A New Test for Language Model Self-Awareness",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research proposes a novel approach to assess self-recognition in language models (LMs) using model-generated \"security questions.\" Unlike previous work that relies on internal model parameters or output probabilities, this method only requires model outputs, making it externally administrable and scalable.",
                "paper-title": "Self-Recognition in Language Models",
                "image-path": ""
            },

            {
                "startTime": "02:53",
                "arxivId": "2407.07082",
                "arxivLink": "https://arxiv.org/abs/2407.07082",
                "title": "Can AI Learn to Be a Better Teacher for AI?",
                "institute": "University of Oxford",
                "text": "This research explores the use of learned optimization in reinforcement learning (RL). Unlike previous work that focuses on improving specific aspects of RL, this paper proposes a meta-learning approach to train an optimizer that can handle multiple challenges in RL simultaneously, including non-stationarity, plasticity loss, and exploration.",
                "paper-title": "Can Learned Optimization Make Reinforcement Learning Less Difficult?",
                "image-path": ""
            },

            {
                "startTime": "03:21",
                "arxivId": "2407.07038",
                "arxivLink": "https://arxiv.org/abs/2407.07038",
                "title": "Climate Change Chat: A New Model Decodes Disagreements on Reddit",
                "institute": "University of Oxford",
                "text": "This research uses Graph Attention Networks (GATs) to analyze comment-reply pairs on Reddit, focusing on climate change discussions. Unlike previous work that primarily relies on textual features, this model incorporates both textual embeddings and sentiment scores, capturing the intricate interactions and sentiment dynamics within these conversations.",
                "paper-title": "Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics",
                "image-path": ""
            },

            {
                "startTime": "03:49",
                "arxivId": "2407.06723",
                "arxivLink": "https://arxiv.org/abs/2407.06723",
                "title": "Captions Get a Graph Makeover: Images Described with Links and Relationships!",
                "institute": "Apple Inc., University of Washington, National Tsing Hua University",
                "text": "This research proposes a new way to annotate images using a graph-based captioning (GBC) format. Unlike traditional scene graphs, GBC uses plain text descriptions for each node, allowing for more flexibility and intuitiveness.",
                "paper-title": "Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions",
                "image-path": ""
            },

            {
                "startTime": "04:17",
                "arxivId": "2407.07074",
                "arxivLink": "https://arxiv.org/abs/2407.07074",
                "title": "SLAM Goes Decentralized: Hyperion's Continuous-Time GBP Framework",
                "institute": "ETH Zurich, Imperial College London, University of Cyprus",
                "text": "This research introduces a novel continuous-time Gaussian Belief Propagation (GBP) framework, called Hyperion, for decentralized probabilistic inference in Continuous-Time SLAM (CTSLAM). Unlike traditional centralized NLLS optimization approaches, Hyperion enables distributed and asynchronous state estimation across multiple agents.",
                "paper-title": "Hyperion - A fast, versatile symbolic Gaussian Belief Propagation framework for Continuous-Time SLAM",
                "image-path": ""
            },

            {
                "startTime": "04:48",
                "arxivId": "2407.06334",
                "arxivLink": "https://arxiv.org/abs/2407.06334",
                "title": "Double-Ended Synthesis Planning: A Chemical Search Party!",
                "institute": "MIT, Georgia Institute of Technology",
                "text": "This research introduces a new approach to computer-aided synthesis planning (CASP) that incorporates starting material constraints. Unlike previous methods that assume any building block can be used, this method specifically targets desired starting materials, making it more relevant to real-world scenarios.",
                "paper-title": "Double-Ended Synthesis Planning with Goal-Constrained Bidirectional Search",
                "image-path": ""
            },

            {
                "startTime": "05:11",
                "arxivId": "2407.07061",
                "arxivLink": "https://arxiv.org/abs/2407.07061",
                "title": "Internet of Agents: LLMs Team Up to Solve Problems Like a Boss!",
                "institute": "Tsinghua University, Peking University",
                "text": "This paper proposes the Internet of Agents (IoA), a framework that allows diverse, third-party agents to collaborate on tasks. Unlike previous multi-agent systems, IoA supports distributed agents and dynamic communication, enabling agents to form teams and manage conversations autonomously.",
                "paper-title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence",
                "image-path": ""
            },

            {
                "startTime": "05:43",
                "arxivId": "2407.06325",
                "arxivLink": "https://arxiv.org/abs/2407.06325",
                "title": "Sparsity Saves the Day: How Compressive Sensing Makes Microservices Management a Breeze",
                "institute": "Texas A&M University, University of Texas at Austin",
                "text": "This research introduces CONGO, an algorithm that leverages sparsity in gradient information to optimize resource allocation in microservices. Unlike previous methods that rely on full gradient information, CONGO uses compressive sensing to estimate gradients with fewer samples, leading to faster convergence and reduced computational cost.",
                "paper-title": "CONGO: Compressive Online Gradient Optimization with Application to Microservices Management",
                "image-path": ""
            },

            {
                "startTime": "06:12",
                "arxivId": "2407.07090",
                "arxivLink": "https://arxiv.org/abs/2407.07090",
                "title": "Ray Tracing Radiance Fields: Faster Than a Speeding Splat!",
                "institute": "NVIDIA, University of Toronto, Vector Institute",
                "text": "This paper proposes a new method for ray tracing particle-based scene representations, specifically focusing on 3D Gaussian Splatting. Unlike previous work that relied on rasterization, this approach leverages specialized GPU ray tracing hardware for more efficient rendering.",
                "paper-title": "3D Gaussian Ray Tracing: Fast Tracing of Particle Scenes",
                "image-path": ""
            },

            {
                "startTime": "06:33",
                "arxivId": "2407.06863",
                "arxivLink": "https://arxiv.org/abs/2407.06863",
                "title": "AI's Got Culture: New Benchmark Tests If Text-to-Image Models Can Tell a Samosa from a Sushi",
                "institute": "Google",
                "text": "This research introduces a new benchmark called CUBE to evaluate the cultural competence of text-to-image models. Unlike previous benchmarks that focus on realism and faithfulness, CUBE assesses the models' ability to accurately represent cultural artifacts and avoid stereotypical depictions.",
                "paper-title": "Beyond Aesthetics: Cultural Competence in Text-to-Image Models",
                "image-path": ""
            },

            {
                "startTime": "06:53",
                "arxivId": "2407.07087",
                "arxivLink": "https://arxiv.org/abs/2407.07087",
                "title": "AI's Got a Copycat Problem: New Benchmark Catches Literal and Non-Literal Copying",
                "institute": "University of Washington, Cornell University, Allen Institute for AI",
                "text": "This research introduces COPYBENCH, a benchmark that evaluates both literal and non-literal copying of copyrighted text by language models. Previous work primarily focused on literal copying, neglecting the more nuanced forms of plagiarism that can occur.",
                "paper-title": "CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation",
                "image-path": ""
            },

            {
                "startTime": "07:28",
                "arxivId": "2407.06464",
                "arxivLink": "https://arxiv.org/abs/2407.06464",
                "title": "Sidewalk Sleuths: New Dataset Helps Us See the City Through Pedestrian Eyes",
                "institute": "University of S\u00e3o Paulo, University of Illinois Chicago, Massachusetts Institute of Technology",
                "text": "This research introduces a new multimodal dataset called SideSeeing, which combines video footage, sensor data, and GPS information to provide a comprehensive understanding of sidewalk accessibility. Unlike previous datasets that focus on specific aspects of sidewalks, SideSeeing offers a more holistic view by integrating multiple data sources.",
                "paper-title": "SideSeeing: A multimodal dataset and collection of tools for sidewalk assessment",
                "image-path": ""
            },

            {
                "startTime": "07:56",
                "arxivId": "2407.06518",
                "arxivLink": "https://arxiv.org/abs/2407.06518",
                "title": "V2X Communication: Graph Neural Networks to the Rescue!",
                "institute": "Jiangnan University, Tsinghua University, Shanghai Jiao Tong University...",
                "text": "This research proposes a novel method for resource allocation in V2X communication by integrating Graph Neural Networks (GNN) with Deep Reinforcement Learning (DRL). Unlike previous work that primarily focuses on centralized resource allocation, this approach enables distributed decision-making, allowing vehicles to make independent resource allocation decisions based on local observations.",
                "paper-title": "Graph Neural Networks and Deep Reinforcement Learning Based Resource Allocation for V2X Communications",
                "image-path": ""
            },

            {
                "startTime": "08:27",
                "arxivId": "2407.07088",
                "arxivLink": "https://arxiv.org/abs/2407.07088",
                "title": "Spacecraft Dating: How to Make Sure Your Satellite Doesn't Get Lost in Space!",
                "institute": "Stanford University, Hebrew University of Jerusalem, IT University of Copenhagen...",
                "text": "This research introduces a novel design-for-verification approach that modifies the training loop of deep reinforcement learning (DRL) controllers to make them more verification-friendly. It also utilizes formal verification techniques, specifically k-induction, to ensure the correctness of the training process.",
                "paper-title": "Safe and Reliable Training of Learning-Based Aerospace Controllers",
                "image-path": ""
            },

            {
                "startTime": "08:58",
                "arxivId": "2407.07059",
                "arxivLink": "https://arxiv.org/abs/2407.07059",
                "title": "Brain-Like Models: Are We Measuring the Right Things?",
                "institute": "MIT, NYU, University of T\u00fcbingen",
                "text": "This research directly optimizes synthetic datasets to become more similar to real neural recordings, allowing for a deeper understanding of how different similarity measures prioritize various aspects of the data.",
                "paper-title": "Differentiable Optimization of Similarity Scores Between Models and Brains",
                "image-path": ""
            },

            {
                "startTime": "09:23",
                "arxivId": "2407.06683",
                "arxivLink": "https://arxiv.org/abs/2407.06683",
                "title": "Mapping the Future: How BEV Features Speed Up Self-Driving Cars",
                "institute": "University of Toronto, Nvidia, Stanford University",
                "text": "This research proposes directly using internal features from online map estimation models for behavior prediction, rather than relying solely on decoded map elements. This approach allows for tighter integration between mapping and prediction, potentially leading to faster inference times and more accurate predictions.",
                "paper-title": "Accelerating Online Mapping and Behavior Prediction via Direct BEV Feature Attention",
                "image-path": ""
            },

            {
                "startTime": "09:53",
                "arxivId": "2407.06249",
                "arxivLink": "https://arxiv.org/abs/2407.06249",
                "title": "LLMs Learn New Tricks: A Benchmark for Teaching Code Models API Updates",
                "institute": "University of Texas at Austin",
                "text": "This research introduces CodeUpdateArena, a benchmark specifically designed to evaluate how well large language models (LLMs) can incorporate new API function updates into their knowledge. Unlike previous benchmarks that focus on general code generation, CodeUpdateArena focuses on the ability of LLMs to adapt to evolving APIs, a crucial aspect for real-world code generation.",
                "paper-title": "CodeUpdateArena: Benchmarking Knowledge Editing on API Updates",
                "image-path": ""
            },

            {
                "startTime": "10:20",
                "arxivId": "2407.07093",
                "arxivLink": "https://arxiv.org/abs/2407.07093",
                "title": "Binary Brains: LLMs Go Full 1-Bit, No Pretraining Needed!",
                "institute": "Mohamed bin Zayed University of Artificial Intelligence, CMU",
                "text": "This research presents a novel method for training fully binarized large language models (LLMs) from scratch, without relying on pre-trained models. It utilizes an autoregressive distillation loss function to guide the training process, achieving comparable performance to full-precision LLMs.",
                "paper-title": "FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation",
                "image-path": ""
            },

            {
                "startTime": "10:42",
                "arxivId": "2407.06800",
                "arxivLink": "https://arxiv.org/abs/2407.06800",
                "title": "Whisper's New Language Trick: Teaching an Old Dog New Sounds!",
                "institute": "University of Cambridge",
                "text": "This research focuses on adding new languages to pre-trained Automatic Speech Recognition (ASR) models without sacrificing performance on existing languages. It compares different fine-tuning methods, including a novel approach called Soft Language Code Tuning (SLCT), and explores the use of Elastic Weight Consolidation (EWC) to mitigate catastrophic forgetting.",
                "paper-title": "Learn and Don't Forget: Adding a New Language to ASR Foundation Models",
                "image-path": ""
            },

            {
                "startTime": "11:07",
                "arxivId": "2407.06756",
                "arxivLink": "https://arxiv.org/abs/2407.06756",
                "title": "Fourier Features: Fast Learners, Slow Thinkers?",
                "institute": "University College London, DeepMind",
                "text": "This research investigates the frequency of representations learned by periodic activation functions in deep reinforcement learning (RL) algorithms. Unlike previous work that focused on either low or high frequency representations, this study empirically shows that periodic activations consistently converge to high frequencies regardless of their initialisation.",
                "paper-title": "Frequency and Generalisation of Periodic Activation Functions in Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "11:28",
                "arxivId": "2407.07086",
                "arxivLink": "https://arxiv.org/abs/2407.07086",
                "title": "LLMs Get Minds of Their Own: AI Agents Learn to Read Opponents' Minds",
                "institute": "Stanford University",
                "text": "This research introduces a novel approach to multi-agent reinforcement learning (MARL) by leveraging large language models (LLMs) to create agents that can infer the strategies of other agents. This differs from previous work by incorporating a \"Theory of Mind\" module that generates, evaluates, and refines hypotheses about other agents' goals and actions.",
                "paper-title": "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "11:55",
                "arxivId": "2407.06323",
                "arxivLink": "https://arxiv.org/abs/2407.06323",
                "title": "LLMs Gone Wild? New Guardrails Tame Toxic Text with Synthetic Data!",
                "institute": "IBM",
                "text": "This research tackles the \"use-mention\" distinction problem in social bias detection for LLMs. Unlike previous work, it focuses on generating synthetic data to train guardrail models specifically to differentiate between harmful use and harmless mention of biased language.",
                "paper-title": "When in Doubt, Cascade: Towards Building Efficient and Capable Guardrails",
                "image-path": ""
            },

            {
                "startTime": "12:18",
                "arxivId": "2407.07055",
                "arxivLink": "https://arxiv.org/abs/2407.07055",
                "title": "Folding Embryos: AI Predicts Cell Rearrangements Before They Happen!",
                "institute": "Massachusetts Institute of Technology, Northeastern University",
                "text": "This research introduces a dual-graph data structure to represent multicellular systems, enabling a geometric deep learning model to predict cell rearrangements during embryogenesis. This approach differs from previous work by unifying granular and foam-like physical pictures within a single framework.",
                "paper-title": "Multicell-Fold: geometric learning in folding multicellular life",
                "image-path": ""
            },

            {
                "startTime": "12:44",
                "arxivId": "2407.06628",
                "arxivLink": "https://arxiv.org/abs/2407.06628",
                "title": "IMU-Powered Action Recognition: When Your Phone Knows You're Doing the Macarena",
                "institute": "University of Tokyo",
                "text": "This research proposes a novel method for action recognition that integrates motion data from body-worn IMUs with egocentric video. The key innovation lies in the use of a multimodal masked autoencoder (MAE) for self-supervised pretraining, which leverages the natural correlation between visual and motion signals. This approach addresses the scarcity of labeled multimodal data and allows the model to learn strong representations from unlabeled data. Additionally, the paper introduces a graph-based IMU modeling technique to capture the collaborative dynamics of multiple IMU devices placed across the body.",
                "paper-title": "Masked Video and Body-worn IMU Autoencoder for Egocentric Action Recognition",
                "image-path": ""
            },

            {
                "startTime": "13:16",
                "arxivId": "2407.06939",
                "arxivLink": "https://arxiv.org/abs/2407.06939",
                "title": "Robots in Homes: A New Challenge for Open-Vocabulary Manipulation!",
                "institute": "FAIR Georgia Tech Hello Robot Inc Carnegie Mellon Bielefeld University Ukrainian Catholic University Bosch Center for AI IIITA IIT ISM Dhanbad IIITM CNAEIT",
                "text": "This research introduces a new benchmark task for robotics called Open-Vocabulary Mobile Manipulation (OVMM), which focuses on robots finding and manipulating objects in previously unseen environments. This differs from previous work that typically assumes a closed world with known object categories.",
                "paper-title": "Towards Open-World Mobile Manipulation in Homes: Lessons from the Neurips 2023 HomeRobot Open Vocabulary Mobile Manipulation Challenge",
                "image-path": ""
            },

            {
                "startTime": "13:47",
                "arxivId": "2407.06866",
                "arxivLink": "https://arxiv.org/abs/2407.06866",
                "title": "ChatGPT's Got a Bias: How Your Fandom Affects Its Answers",
                "institute": "Harvard University",
                "text": "This paper examines the biases in the guardrails of large language models (LLMs), specifically focusing on how contextual information about the user influences the model's likelihood to refuse a request. This is distinct from previous work that primarily focused on biases in the model's output rather than its refusal mechanisms.",
                "paper-title": "ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context",
                "image-path": ""
            },

            {
                "startTime": "14:12",
                "arxivId": "2407.06813",
                "arxivLink": "https://arxiv.org/abs/2407.06813",
                "title": "AI Diplomat Richelieu: Self-Evolving Agent Masters Diplomacy Without Human Help!",
                "institute": "Peking University, Beijing Information Science and Technology University",
                "text": "This research introduces Richelieu, an AI agent that learns to play Diplomacy through self-play, unlike previous methods that relied heavily on human data.",
                "paper-title": "Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy",
                "image-path": ""
            },

            {
                "startTime": "14:38",
                "arxivId": "2407.07071",
                "arxivLink": "https://arxiv.org/abs/2407.07071",
                "title": "LLMs Hallucinating? LookbackLens to the Rescue!",
                "institute": "MIT",
                "text": "This research focuses on detecting and mitigating contextual hallucinations in LLMs, a type of error where the model generates content inconsistent with the provided context. Unlike previous work that primarily focuses on hallucinations arising from the model's internal knowledge, this paper leverages attention maps to identify and address these contextual errors.",
                "paper-title": "Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps",
                "image-path": ""
            },

            {
                "startTime": "14:58",
                "arxivId": "2407.06233",
                "arxivLink": "https://arxiv.org/abs/2407.06233",
                "title": "AI: The New Social Theorist?",
                "institute": "University of Oxford",
                "text": "This paper proposes a framework for AI-driven social theory, where AI models are used to test and generate new social theories based on their predictive power. This approach differs from previous work by emphasizing the need for AI systems to possess specific capabilities like semanticization, transferability, and generativity.",
                "paper-title": "AI and social theory",
                "image-path": ""
            },

            {
                "startTime": "15:24",
                "arxivId": "2407.06304",
                "arxivLink": "https://arxiv.org/abs/2407.06304",
                "title": "Video Generation Gets a Visual Makeover: New Model Learns from Images!",
                "institute": "Snap Inc., UC Merced, Carnegie Mellon University",
                "text": "This research introduces a new approach to video generation that incorporates visual information during the training process. Unlike previous models that rely solely on text-based prompts, this model leverages a retrieval method to pair multimodal in-context examples with text prompts, enabling it to generate videos grounded in both text and images.",
                "paper-title": "VIMI: Grounding Video Generation through Multi-modal Instruction",
                "image-path": ""
            },

            {
                "startTime": "15:47",
                "arxivId": "2407.06529",
                "arxivLink": "https://arxiv.org/abs/2407.06529",
                "title": "Financial Fraud Fighters: GNN-CL's Got Your Back!",
                "institute": "Columbia University, Rutgers University, College of William & Mary...",
                "text": "This research introduces a new model called GNN-CL for financial fraud detection. It combines graph neural networks (GNN), convolutional neural networks (CNN), and long short-term memory (LSTM) networks. The key innovation is the use of reinforcement learning to dynamically adjust the weights assigned to central nodes in the GNN, which helps to mitigate the problem of feature weakening that can occur when aggregating information from neighboring nodes.",
                "paper-title": "Advanced Financial Fraud Detection Using GNN-CL Model",
                "image-path": ""
            },

            {
                "startTime": "16:25",
                "arxivId": "2407.06886",
                "arxivLink": "https://arxiv.org/abs/2407.06886",
                "title": "Embodied AI: From Couch Potato to Kitchen King!",
                "institute": "University of Hong Kong, Peking University",
                "text": "This research provides a comprehensive survey of Embodied AI, focusing on the advancements made possible by Multi-modal Large Models (MLMs) and World Models (WMs), which were not fully explored in previous surveys.",
                "paper-title": "Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI",
                "image-path": ""
            },

            {
                "startTime": "16:54",
                "arxivId": "2407.06235",
                "arxivLink": "https://arxiv.org/abs/2407.06235",
                "title": "AI Auditing: From Balance Sheets to Bots, It's Time to Get Real!",
                "institute": "University of Oxford",
                "text": "This research goes beyond just looking at the technical aspects of AI systems and also examines the governance structures of the organizations that design and deploy them.",
                "paper-title": "Auditing of AI: Legal, Ethical and Technical Approaches",
                "image-path": ""
            },

            {
                "startTime": "17:14",
                "arxivId": "2407.06677",
                "arxivLink": "https://arxiv.org/abs/2407.06677",
                "title": "Transformers Get a Makeover: Dynamic Modules for Better Language Models",
                "institute": "Peking University, Renmin University of China, Tsinghua University...",
                "text": "This research proposes a new architecture called Mixture-of-Modules (MoM) that breaks the traditional depth-ordered structure of Transformers. Instead of processing tokens sequentially from shallow to deep layers, MoM allows for dynamic selection and assembly of modules, creating a more flexible and efficient computation graph.",
                "paper-title": "Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules",
                "image-path": ""
            },

            {
                "startTime": "17:43",
                "arxivId": "2407.06833",
                "arxivLink": "https://arxiv.org/abs/2407.06833",
                "title": "CryoET Segmentation Gets a Prompt-Based Makeover: No Training Required!",
                "institute": "Carnegie Mellon University, University of Alabama at Birmingham",
                "text": "This research introduces a training-free approach for segmenting CryoET tomograms using prompt-based methods. Unlike previous work that relied on supervised training or template matching, this method leverages existing 2D foundation models and a novel prompt-based 3D segmentation pipeline.",
                "paper-title": "Training-free CryoET Tomogram Segmentation",
                "image-path": ""
            },

            {
                "startTime": "18:11",
                "arxivId": "2407.06512",
                "arxivLink": "https://arxiv.org/abs/2407.06512",
                "title": "Moon-derful Data: A New Dataset for Lunar Rover Adventures!",
                "institute": "University of Chinese Academy of Sciences, Chinese Academy of Sciences",
                "text": "This research introduces LuSNAR, a multi-task, multi-scene, and multi-label lunar dataset. Unlike previous datasets focused on single tasks, LuSNAR provides comprehensive data for evaluating autonomous perception and navigation systems.",
                "paper-title": "LuSNAR:A Lunar Segmentation, Navigation and Reconstruction Dataset based on Muti-sensor for Autonomous Exploration",
                "image-path": ""
            },

            {
                "startTime": "18:31",
                "arxivId": "2407.06935",
                "arxivLink": "https://arxiv.org/abs/2407.06935",
                "title": "Federated Learning Gets a Speed Boost with Hamiltonian Monte Carlo",
                "institute": "ByteDance Inc, Purdue University, Morgan Stanley",
                "text": "This paper introduces a new Bayesian federated learning algorithm called FA-HMC, which uses Hamiltonian Monte Carlo (HMC) for parameter estimation and uncertainty quantification. Unlike previous work that relied on stochastic gradient Langevin dynamics (SGLD), FA-HMC leverages the second-order nature of HMC, which has been shown to be more computationally efficient in various settings.",
                "paper-title": "Bayesian Federated Learning with Hamiltonian Monte Carlo: Algorithm and Theory",
                "image-path": ""
            },

            {
                "startTime": "19:02",
                "arxivId": "2407.06536",
                "arxivLink": "https://arxiv.org/abs/2407.06536",
                "title": "Two-Stage Evolution: A Multi-Objective Optimization Algorithm That's Twice as Nice!",
                "institute": "Xi'an Jiaotong University, Nanyang Technological University, University of Science and Technology of China",
                "text": "This research proposes a novel two-stage evolutionary framework for multi-objective optimization (TEMOF). Unlike traditional approaches, TEMOF divides the optimization process into two distinct stages, enhancing the search capability of the population by selectively choosing parents from both the primary population and an external archive.",
                "paper-title": "A Two-stage Evolutionary Framework For Multi-objective Optimization",
                "image-path": ""
            },

            {
                "startTime": "19:52",
                "arxivId": "2407.06549",
                "arxivLink": "https://arxiv.org/abs/2407.06549",
                "title": "Ads Relevance: One Model to Rule Them All!",
                "institute": "Microsoft",
                "text": "This research introduces a novel multi-faceted attention model that uses task ID encoding to improve the generalization capability of a single model for multi-task ads relevance. This approach differs from previous work by treating the multi-task problem as a language task, enabling the model to learn from all tasks while only needing to see one task at a time during inference.",
                "paper-title": "AutoTask: Task Aware Multi-Faceted Single Model for Multi-Task Ads Relevance",
                "image-path": ""
            },

            {
                "startTime": "20:14",
                "arxivId": "2407.06938",
                "arxivLink": "https://arxiv.org/abs/2407.06938",
                "title": "RodinHD: Avatar Generation Gets a Hair-Raising Upgrade!",
                "institute": "University of Science and Technology of China, Tsinghua University, Microsoft Research Asia",
                "text": "This paper tackles the issue of \"catastrophic forgetting\" in 3D avatar generation, which occurs when the model forgets details from previously trained avatars. To address this, the authors introduce a novel data scheduling strategy called \"task replay\" and a weight consolidation regularization term.",
                "paper-title": "RodinHD: High-Fidelity 3D Avatar Generation with Diffusion Models",
                "image-path": ""
            },

            {
                "startTime": "20:50",
                "arxivId": "2407.06984",
                "arxivLink": "https://arxiv.org/abs/2407.06984",
                "title": "Stereo Vision: Seeing Objects in 3D, Even Through Glass!",
                "institute": "Tsinghua University, Tencent",
                "text": "This research introduces CODERS, a one-stage approach for object detection, pose estimation, and reconstruction from stereo images. Unlike previous methods that rely on two-stage frameworks or point cloud data, CODERS leverages stereo information to directly estimate object properties, including shape, in an end-to-end manner.",
                "paper-title": "Category-level Object Detection, Pose Estimation and Reconstruction from Stereo Images",
                "image-path": ""
            },

            {
                "startTime": "21:16",
                "arxivId": "2407.06312",
                "arxivLink": "https://arxiv.org/abs/2407.06312",
                "title": "Koopman Learning: When Data Can't Save You",
                "institute": "University of Cambridge",
                "text": "This paper establishes fundamental limits on Koopman learning, proving that certain spectral properties of Koopman operators cannot be learned from trajectory data, even with unlimited data and perfect measurements. This is achieved by embedding abrupt spectral changes into the system dynamics, effectively creating adversarial systems that prevent algorithmic convergence.",
                "paper-title": "Limits and Powers of Koopman Learning",
                "image-path": ""
            },

            {
                "startTime": "21:41",
                "arxivId": "2407.06703",
                "arxivLink": "https://arxiv.org/abs/2407.06703",
                "title": "HERMES: A Neural Network That Predicts Protein Mutations Like a Boss!",
                "institute": "University of Washington",
                "text": "This research introduces HERMES, a 3D rotationally equivariant neural network model for mutational effect and stability prediction. Unlike previous work, HERMES is pre-trained to predict amino acid propensity from its surrounding 3D structure, making it more versatile and adaptable for various predictive objectives.",
                "paper-title": "HERMES: Holographic Equivariant neuRal network model for Mutational Effect and Stability prediction",
                "image-path": ""
            },

            {
                "startTime": "22:05",
                "arxivId": "2407.06823",
                "arxivLink": "https://arxiv.org/abs/2407.06823",
                "title": "DJs, Meet Your New Sidekick: AI Learns to Drop the Beat (and Cue Points)",
                "institute": "ETH Zurich",
                "text": "This research proposes a novel method for cue point estimation in electronic dance music (EDM) tracks using a pre-trained object detection transformer, fine-tuned on a new dataset of manually annotated cue points. Unlike previous methods, this approach does not rely on low-level musical information analysis.",
                "paper-title": "Cue Point Estimation using Object Detection",
                "image-path": ""
            },

            {
                "startTime": "22:25",
                "arxivId": "2407.06234",
                "arxivLink": "https://arxiv.org/abs/2407.06234",
                "title": "US vs. EU AI Laws: A Tale of Two Acts (and What They Can Learn From Each Other)",
                "institute": "University of Oxford, University College London, University of Bologna",
                "text": "This research compares the US Algorithmic Accountability Act of 2022 (US AAA) with the EU Artificial Intelligence Act (EU AIA), highlighting their similarities and differences in scope, approach, and enforcement mechanisms. It goes beyond simply describing the acts, offering insights into how each can learn from the other to improve their effectiveness.",
                "paper-title": "The US Algorithmic Accountability Act of 2022 vs. The EU Artificial Intelligence Act: what can they learn from each other?",
                "image-path": ""
            },

            {
                "startTime": "22:53",
                "arxivId": "2407.06483",
                "arxivLink": "https://arxiv.org/abs/2407.06483",
                "title": "Language Models: Can They Handle a Multi-Task Makeover?",
                "institute": "University of Virginia, Microsoft",
                "text": "This research introduces the concept of \"composable interventions\" for language models. Unlike previous work that focuses on individual interventions, this study examines how multiple interventions interact when applied sequentially to the same model.",
                "paper-title": "Composable Interventions for Language Models",
                "image-path": ""
            },

            {
                "startTime": "23:14",
                "arxivId": "2407.06250",
                "arxivLink": "https://arxiv.org/abs/2407.06250",
                "title": "Fairness in Eye Scans: A Pointy-Headed Approach to Better Diagnosis",
                "institute": "Chinese Academy of Sciences, Tsinghua University",
                "text": "This research introduces a novel Point-Image Diffusion method for medical image synthesis. Unlike previous methods that directly generate images, this approach first generates segmentation masks using 3D point clouds, which allows for more precise control over the boundaries of the synthesized images.",
                "paper-title": "FairDiff: Fair Segmentation with Point-Image Diffusion",
                "image-path": ""
            },

            {
                "startTime": "23:42",
                "arxivId": "2407.06541",
                "arxivLink": "https://arxiv.org/abs/2407.06541",
                "title": "Malicious Bots Can't Stop This New Optimization Algorithm!",
                "institute": "Harvard University, Bar-Ilan University, Arizona State University",
                "text": "This research introduces a new distributed optimization algorithm called Resilient Projected Push-Pull (RP3) that achieves geometric convergence rates in expectation even in the presence of malicious agents. Unlike previous work, RP3 leverages stochastic inter-agent trust values and gradient tracking to achieve this resilience.",
                "paper-title": "Fast Distributed Optimization over Directed Graphs under Malicious Attacks using Trust",
                "image-path": ""
            },

            {
                "startTime": "24:10",
                "arxivId": "2407.06567",
                "arxivLink": "https://arxiv.org/abs/2407.06567",
                "title": "AI Stock Whisperer: FINCON's Multi-Agent System Makes Market Moves",
                "institute": "Yale University",
                "text": "This research introduces FINCON, a multi-agent system that uses a manager-analyst hierarchy to process financial information and make trading decisions. Unlike previous systems, FINCON incorporates a risk control component that updates investment beliefs based on performance, enhancing decision-making.",
                "paper-title": "FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making",
                "image-path": ""
            },

            {
                "startTime": "24:37",
                "arxivId": "2407.06783",
                "arxivLink": "https://arxiv.org/abs/2407.06783",
                "title": "Poisson Learning: From Spikes to Smoothness with Measure Data",
                "institute": "University of W\u00fcrzburg, University of Minnesota, University of Bonn",
                "text": "This research proves convergence rates for Poisson Learning, a semi-supervised learning algorithm, to its continuum limit, which is a Poisson equation with measure data. This is a novel contribution as previous work focused on proving convergence for smoother data.",
                "paper-title": "Convergence rates for Poisson learning to a Poisson equation with measure data",
                "image-path": ""
            },

            {
                "startTime": "25:17",
                "arxivId": "2407.06516",
                "arxivLink": "https://arxiv.org/abs/2407.06516",
                "title": "VQA-Diff: Turning Car Pics into 3D Assets with a Chatty AI!",
                "institute": "University of Toronto, Huawei, York University",
                "text": "This research proposes VQA-Diff, a framework that leverages the zero-shot prediction ability of Visual Question Answering (VQA) models and the structure and appearance generation capabilities of Diffusion Models to generate 3D vehicle assets from single images. Unlike previous methods that rely solely on image RGB information, VQA-Diff incorporates real-world knowledge from a Large Language Model (LLM) to understand the characteristics of vehicles, enabling robust zero-shot prediction for novel view rendering.",
                "paper-title": "VQA-Diff: Exploiting VQA and Diffusion for Zero-Shot Image-to-3D Vehicle Asset Generation in Autonomous Driving",
                "image-path": ""
            },

            {
                "startTime": "25:43",
                "arxivId": "2407.06798",
                "arxivLink": "https://arxiv.org/abs/2407.06798",
                "title": "AI-Generated Legal Docs: Can Lawyers Tell the Difference?",
                "institute": "Masaryk University, CMU",
                "text": "This research focuses on how lawyers perceive legal documents when they believe those documents were generated by AI, specifically ChatGPT. Previous research has explored the use of LLMs in legal tasks, but this study uniquely examines the impact of perceived AI authorship on document evaluation.",
                "paper-title": "It Cannot Be Right If It Was Written by AI: On Lawyers' Preferences of Documents Perceived as Authored by an LLM vs a Human",
                "image-path": ""
            },

            {
                "startTime": "26:04",
                "arxivId": "2407.06910",
                "arxivLink": "https://arxiv.org/abs/2407.06910",
                "title": "Microsoft Sellers Get Smart: AI Recommends the Perfect Content for Every Deal!",
                "institute": "Microsoft",
                "text": "This research focuses on recommending content at the opportunity level, the lowest granularity in a CRM system, which is more relevant for sellers than previous approaches that focused on broader recommendations.",
                "paper-title": "Fine-grained large-scale content recommendations for MSX sellers",
                "image-path": ""
            },

            {
                "startTime": "26:23",
                "arxivId": "2407.06888",
                "arxivLink": "https://arxiv.org/abs/2407.06888",
                "title": "ReLU's Quadratic Constraints: A Complete Set, Finally!",
                "institute": "University of Michigan, University of Illinois",
                "text": "This paper presents a complete set of quadratic constraints (QCs) for the repeated ReLU function, which is commonly used in neural networks. This is different from previous work that only provided partial sets of QCs.",
                "paper-title": "A Complete Set of Quadratic Constraints For Repeated ReLU",
                "image-path": ""
            },

            {
                "startTime": "26:48",
                "arxivId": "2407.06576",
                "arxivLink": "https://arxiv.org/abs/2407.06576",
                "title": "Virtual Personas Get Backstories: LLMs Now Have Lives!",
                "institute": "UC Berkeley",
                "text": "This research introduces \"Anthology,\" a method for conditioning LLMs to specific virtual personas by using open-ended life narratives, or \"backstories,\" as a prompt prefix. This differs from previous work that relied on explicit demographic information or question-answer pairs.",
                "paper-title": "Virtual Personas for Language Models via an Anthology of Backstories",
                "image-path": ""
            },

            {
                "startTime": "27:13",
                "arxivId": "2407.06496",
                "arxivLink": "https://arxiv.org/abs/2407.06496",
                "title": "Privacy Amplification: It's Our Loss, Not Yours!",
                "institute": "University College London",
                "text": "This research investigates whether privacy guarantees in a popular machine learning algorithm, DP-SGD, can be improved when only the final trained model is released, unlike the current analysis that assumes all intermediate steps are revealed. Unlike previous work that focused on constrained loss functions, this study explores the possibility of privacy amplification for general loss functions.",
                "paper-title": "It's Our Loss: No Privacy Amplification for Hidden State DP-SGD With Non-Convex Loss",
                "image-path": ""
            },

            {
                "startTime": "27:38",
                "arxivId": "2407.06964",
                "arxivLink": "https://arxiv.org/abs/2407.06964",
                "title": "Vision Transformers Get a Memory Makeover: A Disentangled Approach to Efficient Tuning",
                "institute": "Tsinghua University, ShanghaiTech University, National University of Singapore",
                "text": "This research proposes a new method called Synthesized Query Tuning (SynQT) for adapting pre-trained Vision Transformers to downstream tasks. Unlike previous methods that insert new structures into the pre-trained model, SynQT separates task-specific learning from pre-trained knowledge utilization, resulting in a more memory-efficient training process.",
                "paper-title": "Parameter-Efficient and Memory-Efficient Tuning for Vision Transformer: A Disentangled Approach",
                "image-path": ""
            },

            {
                "startTime": "28:06",
                "arxivId": "2407.06608",
                "arxivLink": "https://arxiv.org/abs/2407.06608",
                "title": "Deep Learning Gets a Makeover: Image Reconstruction with Learned Attentive Regularizers",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Chemnitz University of Technology",
                "text": "This research proposes a new regularization scheme for image reconstruction that leverages deep learning while maintaining interpretability. Unlike previous deep learning-based models, this scheme is based on a series of convex problems, making it easier to analyze theoretically. The key innovation lies in the use of learned masks to refine the regularization strength spatially, making the model progressively attentive to image structure.",
                "paper-title": "Iteratively Refined Image Reconstruction with Learned Attentive Regularizers",
                "image-path": ""
            },

            {
                "startTime": "28:31",
                "arxivId": "2407.06765",
                "arxivLink": "https://arxiv.org/abs/2407.06765",
                "title": "Linearity's Little Helper: A Generalization Bound for Nearly-Linear Networks",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This paper proposes a novel generalization bound for neural networks that are close to being linear. Unlike previous work, this bound can be evaluated before training, making it a-priori.",
                "paper-title": "A Generalization Bound for Nearly-Linear Networks",
                "image-path": ""
            },

            {
                "startTime": "29:01",
                "arxivId": "2407.06226",
                "arxivLink": "https://arxiv.org/abs/2407.06226",
                "title": "Quantum Computing: Brain-Boosting PSP Diagnosis",
                "institute": "Derozio Memorial College",
                "text": "This research explores the use of quantum machine learning (QML) for classifying brain networks affected by Progressive Supranuclear Palsy (PSP), a neurological disorder. Unlike previous studies that primarily relied on classical machine learning techniques, this paper investigates the potential of QML to improve classification accuracy and efficiency.",
                "paper-title": "Quantum Machine Learning with Application to Progressive Supranuclear Palsy Network Classification",
                "image-path": ""
            },

            {
                "startTime": "29:25",
                "arxivId": "2407.06295",
                "arxivLink": "https://arxiv.org/abs/2407.06295",
                "title": "Teaching Cells to Build: A New Way to Engineer Morphogenesis",
                "institute": "Harvard University, University of Lausanne",
                "text": "This research uses automatic differentiation to learn the rules governing cell interactions and genetic networks that lead to complex developmental outcomes. This approach differs from previous work by directly optimizing over the parameters of the physical model, rather than relying on manually crafted rules.",
                "paper-title": "Engineering morphogenesis of cell clusters with differentiable programming",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 65,
        "num_total": 290,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202407102335_audio.mp3"
}
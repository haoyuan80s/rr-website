
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ribbit Ribbit - Fresh AI Paper Top Picks</title>
    <meta name="description"
        content="Discover top ArXiv papers in AI and machine learning daily with our fresh picks. Browse easily through tweet-sized summaries or listen on-the-go. Make learning engaging and accessible anytime, anywhere.">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Amatic+SC:wght@400;700&family=Dosis:wght@200..800&family=Roboto:wght@300..700&display=swap">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
    <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>
</head>

<body>
    <div class="header">
        <a style="display: flex; align-items: flex-end;  margin-top: 3px; margin-bottom: 3px;"
            href="https://ribbitribbit.co">
            <img src="assets/AppLaunchFrog.gif" alt="icon"
                style="width: 45px; height: auto; margin-left: 20px; margin-right: 5px;">
            <div style="display: flex; flex-direction: column;">
                <img src="assets/AppLaunchText1.gif" alt="icon text"
                    style="width: 55px; height: auto; margin-left: 0px;">
                <img src="assets/AppLaunchText2.gif" alt="icon text"
                    style="width: 55px; height: auto; margin-left: 8px;">
            </div>
        </a>
        <div class="header-title"></div>
        <div id="externalLinkButtons" style="padding: 0 0; margin: 0;">
            <a title="Join us on Discord" class="externalLinkButton"
                href="https://podcasts.apple.com/us/podcast/ribbit-ribbit/id1756448619" target="_blank"
                style="text-decoration: none;">
                <img src="assets/iconDiscord.svg" style="width: 24px;">
            </a>
            <a title="Install app" class="externalLinkButton"
                href="https://podcasts.apple.com/us/podcast/ribbit-ribbit/id1756448619" target="_blank"
                style="text-decoration: none;">
                <img src="assets/iconAppStore.svg" style="width: 24px;">
            </a>
            <a title="Listen on Spotify" class="externalLinkButton"
                href="https://open.spotify.com/show/0YhT3crdRlM0s7bUskVPBK" target="_blank"
                style="text-decoration: none;">
                <img src="assets/iconSpotify.svg" style="width: 25px;">
            </a>
            <a title="Listen on Apple Podcasts" class="externalLinkButton"
                href="https://podcasts.apple.com/us/podcast/ribbit-ribbit/id1756448619" target="_blank"
                style="text-decoration: none;">
                <img src="assets/iconApplePodcast.svg" style="width: 24px;">
            </a>
        </div>
        <div class="dropdown">
            <button onclick="ToggleDropDown()" class="dropbtn" title="Menu"
                style="padding-right: 20px; padding-left: 6px;">
                <img src="assets/buttonSetting.svg" id="menuButtonId" style="height: 20px;">
            </button>
            <div id="myDropdown" class="dropdown-content">
                <div class="externalLinkMenuItemMandatory">
                    <img src="assets/iconPrivacy.svg" style="width: 15px; padding-left: 10px;">
                    <a href="#" onclick="openPopup('privacyModal')">Privacy</a>
                </div>
                <div class="externalLinkMenuItem">
                    <img src="assets/iconDiscord.svg" style="width: 15px; padding-left: 10px;">
                    <a href="https://podcasts.apple.com/us/podcast/ribbit-ribbit/id1756448619" target="_blank"
                        style="text-decoration: none;">Join us on Discord</a>
                </div>
                <div class="externalLinkMenuItem">
                    <img src="assets/iconAppStore.svg" style="width: 15px; padding-left: 10px;">
                    <a href="https://podcasts.apple.com/us/podcast/ribbit-ribbit/id1756448619" target="_blank"
                        style="text-decoration: none;">Install app</a>
                </div>
                <div class="externalLinkMenuItem">
                    <img src="assets/iconSpotify.svg" style="width: 15px; padding-left: 10px;">
                    <a href="https://open.spotify.com/show/0YhT3crdRlM0s7bUskVPBK" target="_blank"
                        style="text-decoration: none;">Listen on Spotify</a>
                </div>
                <div class="externalLinkMenuItem">
                    <img src="assets/iconApplePodcast.svg" style="width: 15px; padding-left: 10px;">
                    <a href="https://podcasts.apple.com/us/podcast/ribbit-ribbit/id1756448619" target="_blank"
                        style="text-decoration: none;">Listen on Apple Podcasts</a>
                </div>
            </div>
        </div>
    </div>
    <div class="container">
        <div id="topblock">
            <div style="height: 80px;"></div>
            <div class="institute-text" style="padding-top: 3px; line-height: 1.2;">
                Freshest
                Top Picks:
                <span class="highlightNumber" style="font-size: 28px;">44</span> out of <span
                    class="highlightNumber">220</span> arXiv AI
                papers
            </div>
            <div style="display: flex; flex-direction: column; justify-content: flex-start; align-items: flex-start;">
                <div class="institute-text" style="line-height: 1.2;">just released on</div>
                <div id="data-default-date" data-date="2024-08-05"></div>
                <input type="text" id="selectedDate" style="text-decoration: underline;" />
            </div>
            <div style=" height: 10px;">
            </div>
        </div>

<div class="tweet" id="tweet0">
 <div class="start-time-icon" title="Play from here">
  00:48
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00872" target="_blank">
    @arXiv 2408.00872
   </a>
   <span class="tweet-title">
    TKGs:  Anomaly Detection with a Side of Interpretability
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Electronic Science and Technology of China, Yale University
   </span>
  </div>
  <div class="primary-text">
   This research introduces AnoT, a method for online anomaly detection in temporal knowledge graphs (TKGs) that leverages a novel rule graph summarization technique. Unlike previous approaches, AnoT captures complex patterns arising from entity and relation semantics and temporal relevance, while also providing interpretable evidence for its anomaly detection results.
  </div>
 </div>
</div>
<div class="tweet" id="tweet1">
 <div class="start-time-icon" title="Play from here">
  01:20
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01416" target="_blank">
    @arXiv 2408.01416
   </a>
   <span class="tweet-title">
    Neural Network Interpretability:  The Quest for the Right Mediator
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Northeastern University, University of Mannheim, Anthropic...
   </span>
  </div>
  <div class="primary-text">
   This paper proposes a new framework for understanding neural network interpretability grounded in causal mediation analysis. It categorizes existing interpretability methods based on the types of causal units (mediators) they employ and the methods used to search for them.
  </div>
 </div>
</div>
<div class="tweet" id="tweet2">
 <div class="start-time-icon" title="Play from here">
  01:50
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01262" target="_blank">
    @arXiv 2408.01262
   </a>
   <span class="tweet-title">
    RAG Evaluation Gets a Makeover:  New Dataset Makes LLMs Sweat!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research introduces RAGEval, a framework for automatically generating scenario-specific evaluation datasets for Retrieval-Augmented Generation (RAG) systems. Unlike existing benchmarks that focus on general knowledge, RAGEval targets specific domains like finance, healthcare, and law, allowing for a more nuanced assessment of RAG models' ability to handle domain-specific knowledge.
  </div>
 </div>
</div>
<div class="tweet" id="tweet3">
 <div class="start-time-icon" title="Play from here">
  02:20
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01166" target="_blank">
    @arXiv 2408.01166
   </a>
   <span class="tweet-title">
    Spiking Neural Networks:  They Can Remember Random Spike Trains, Seriously!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    ETH Zurich
   </span>
  </div>
  <div class="primary-text">
   This paper explores the ability of continuous-time recurrent neural networks to store and recall precisely timed spike patterns. Unlike previous work that focused on chaotic behavior in networks with randomly assigned weights, this study demonstrates that with carefully computed weights, these networks can stably memorize and reproduce arbitrary spike trains with high temporal precision.
  </div>
 </div>
</div>
<div class="tweet" id="tweet4">
 <div class="start-time-icon" title="Play from here">
  02:48
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00989" target="_blank">
    @arXiv 2408.00989
   </a>
   <span class="tweet-title">
    Malicious Bots Gone Wild: How to Build AI Teams That Can't Be Hacked
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    The Chinese University of Hong Kong, Tsinghua University, Carnegie Mellon University...
   </span>
  </div>
  <div class="primary-text">
   This research focuses on the resilience of multi-agent systems against malicious agents, specifically how different system structures affect their ability to recover from errors. Unlike previous work that mainly investigates attacks on agents to induce toxicity or misinformation spread, this paper examines the disruption of collaboration in solving general tasks.
  </div>
 </div>
</div>
<div class="tweet" id="tweet5">
 <div class="start-time-icon" title="Play from here">
  03:28
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00802" target="_blank">
    @arXiv 2408.00802
   </a>
   <span class="tweet-title">
    LLMs Get Smart About Recommendations:  Reasoning Makes Them More Human-Like
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    UC Berkeley, Google
   </span>
  </div>
  <div class="primary-text">
   This research explores how Large Language Models (LLMs) can be used to improve personalized recommender systems by incorporating reasoning into their decision-making process. Unlike previous work that focused on LLMs for objective tasks like arithmetic reasoning, this study investigates how LLMs can reason about subjective user preferences.
  </div>
 </div>
</div>
<div class="tweet" id="tweet6">
 <div class="start-time-icon" title="Play from here">
  03:49
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01366" target="_blank">
    @arXiv 2408.01366
   </a>
   <span class="tweet-title">
    Robots Learn to Multitask Like Chefs: Stage-Guided Sensory Fusion for Smarter Machines
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Renmin University of China, Shenzhen Taobotics Co.  Ltd., China Telecom
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new approach to multi-sensory fusion in robots, incorporating task stages divided by sub-goals into the imitation learning process. Unlike previous methods that rely solely on current observations, this method dynamically adjusts the priority of different senses based on the predicted stage and its internal state.
  </div>
 </div>
</div>
<div class="tweet" id="tweet7">
 <div class="start-time-icon" title="Play from here">
  04:16
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00863" target="_blank">
    @arXiv 2408.00863
   </a>
   <span class="tweet-title">
    Molecules Speak a New Language: UniMoT Makes LLMs Bilingual!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Chinese University of Hong Kong, Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research introduces UniMoT, a language model that uses a tokenizer-based architecture to represent both molecules and text as discrete tokens. This differs from previous molecular LLMs that relied on adapter-based architectures, which didn't treat molecules and text equally.
  </div>
 </div>
</div>
<div class="tweet" id="tweet8">
 <div class="start-time-icon" title="Play from here">
  04:40
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01380" target="_blank">
    @arXiv 2408.01380
   </a>
   <span class="tweet-title">
    AI Agents: Teamwork Makes the Dream Work (and Saves Money!)
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    IBM
   </span>
  </div>
  <div class="primary-text">
   This research explores the use of coalitions of pretrained LLMs, each specialized for specific sub-tasks, to build AI agents, instead of relying on single, fine-tuned models.
  </div>
 </div>
</div>
<div class="tweet" id="tweet9">
 <div class="start-time-icon" title="Play from here">
  05:06
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01046" target="_blank">
    @arXiv 2408.01046
   </a>
   <span class="tweet-title">
    QUDSELECT:  Parsing Discourse with a Question-Answering Twist!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    UC Los Angeles, Peking University
   </span>
  </div>
  <div class="primary-text">
   This research introduces QUDSELECT, a joint-training framework for Question Under Discussion (QUD) parsing that selectively decodes QUD structures by incorporating criteria like answer compatibility, givenness, and anchor relevance. Unlike previous work that uses separate models for anchor prediction and question generation, QUDSELECT trains a single model to perform both tasks simultaneously, providing a more holistic view of the task.
  </div>
 </div>
</div>
<div class="tweet" id="tweet10">
 <div class="start-time-icon" title="Play from here">
  05:39
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01332" target="_blank">
    @arXiv 2408.01332
   </a>
   <span class="tweet-title">
    Click-Through Rate Prediction:  A Hierarchical Multi-Distribution Network for Smarter Recommendations
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    OPPO, Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new modeling paradigm called Hierarchical Multi-Distribution Network (HMDN) that captures hierarchical relationships within mixed multi-distributions. Unlike previous work that focuses on single multi-distribution modeling, HMDN considers the coexistence and hierarchical relationships of multiple multi-distributions.
  </div>
 </div>
</div>
<div class="tweet" id="tweet11">
 <div class="start-time-icon" title="Play from here">
  06:04
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01379" target="_blank">
    @arXiv 2408.01379
   </a>
   <span class="tweet-title">
    Averaging Embeddings: A New Way to Unroll the Swiss Roll of Data
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Pennsylvania, Columbia University, University of California  Berkeley
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel method for robustly computing intrinsic coordinates on point clouds by generating multiple candidate coordinates through subsampling and varying hyperparameters. It then aligns these embeddings using generalized Procrustes analysis and identifies representative embeddings through clustering and topological data analysis.
  </div>
 </div>
</div>
<div class="tweet" id="tweet12">
 <div class="start-time-icon" title="Play from here">
  06:31
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00771" target="_blank">
    @arXiv 2408.00771
   </a>
   <span class="tweet-title">
    Neural Fields Learn to See the Lines, Not Just the Colors!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    NYU, Adobe
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new type of neural field that can learn the locations of discontinuities in images, unlike previous methods that require these locations to be provided beforehand. This is achieved by treating all edges in a triangle mesh as potential discontinuities and optimizing continuous variables that represent the magnitude of the discontinuity across each edge.
  </div>
 </div>
</div>
<div class="tweet" id="tweet13">
 <div class="start-time-icon" title="Play from here">
  07:00
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01419" target="_blank">
    @arXiv 2408.01419
   </a>
   <span class="tweet-title">
    Debatable Questions, Diverse Answers: A New Dataset for Evaluating Chatbots on Controversial Topics
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research introduces DEBATEQA, a dataset of 2,941 debatable questions, each with multiple human-annotated partial answers representing different perspectives. This differs from previous work by focusing on evaluating models' ability to handle questions with no single fixed answer, rather than just identifying controversy.
  </div>
 </div>
</div>
<div class="tweet" id="tweet14">
 <div class="start-time-icon" title="Play from here">
  07:21
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01294" target="_blank">
    @arXiv 2408.01294
   </a>
   <span class="tweet-title">
    Feature Clock:  Unwinding the Secrets of High-Dimensional Data
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    ETH Zurich
   </span>
  </div>
  <div class="primary-text">
   This research introduces Feature Clock, a novel visualization technique that helps understand the impact of individual features in low-dimensional representations of high-dimensional data. Unlike previous methods that require multiple plots for each feature, Feature Clock provides a single, compact visualization that captures the contributions of all features.
  </div>
 </div>
</div>
<div class="tweet" id="tweet15">
 <div class="start-time-icon" title="Play from here">
  07:41
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01122" target="_blank">
    @arXiv 2408.01122
   </a>
   <span class="tweet-title">
    LLMs on Trial: New Benchmark Tests Their Ability to Follow Instructions
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Peking University
   </span>
  </div>
  <div class="primary-text">
   This research introduces CFBench, a benchmark that evaluates LLMs' ability to follow instructions by focusing on the comprehensiveness and authenticity of constraints from a user's perspective. Unlike previous benchmarks, CFBench systematically categorizes constraint types and incorporates a multi-dimensional evaluation framework that prioritizes user needs.
  </div>
 </div>
</div>
<div class="tweet" id="tweet16">
 <div class="start-time-icon" title="Play from here">
  08:06
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00891" target="_blank">
    @arXiv 2408.00891
   </a>
   <span class="tweet-title">
    Knee X-Ray Time Machine: Morphing Your Way to KOA Diagnosis!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Orléans, Harvard University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel Diffusion-based Morphing Model (DMM) for synthesizing intermediate knee X-ray images, which differs from previous work by integrating diffusion and morphing modules to capture spatial morphing details between source and target images.
  </div>
 </div>
</div>
<div class="tweet" id="tweet17">
 <div class="start-time-icon" title="Play from here">
  08:35
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00911" target="_blank">
    @arXiv 2408.00911
   </a>
   <span class="tweet-title">
    Spatial Transcriptomics Gets a Geometry Lesson: New Model Preserves Distance, Improves Accuracy
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    CMU
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new class of generative models for spatial transcriptomics that incorporates spatial information by enforcing a distance-preserving property in the learned latent representation space. This differs from previous work by providing a formal definition of distance-preserving generative models and deriving a tractable loss function to enforce this property.
  </div>
 </div>
</div>
<div class="tweet" id="tweet18">
 <div class="start-time-icon" title="Play from here">
  09:03
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00859" target="_blank">
    @arXiv 2408.00859
   </a>
   <span class="tweet-title">
    News Recommendation:  Long-Chain Interest Makes the Clicks Go Round!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Beijing University of Posts and Telecommunications, Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research proposes a new method for news recommendation called LICM (Long Interest Chain Modeling). Unlike previous methods that focus on local user information, LICM leverages a global news click graph to capture long-chain interests of similar users. This allows the model to better understand and predict user preferences based on their broader reading history.
  </div>
 </div>
</div>
<div class="tweet" id="tweet19">
 <div class="start-time-icon" title="Play from here">
  09:29
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01067" target="_blank">
    @arXiv 2408.01067
   </a>
   <span class="tweet-title">
    Seeing Through Walls: Amodal Segmentation for Laparoscopic Surgery
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Peking University
   </span>
  </div>
  <div class="primary-text">
   This research introduces amodal segmentation, a technique that predicts the complete shape of an object, including its occluded parts, to the field of laparoscopic surgery. This is different from previous work that focused primarily on segmenting only the visible parts of surgical instruments.
  </div>
 </div>
</div>
<div class="tweet" id="tweet20">
 <div class="start-time-icon" title="Play from here">
  10:00
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00932" target="_blank">
    @arXiv 2408.00932
   </a>
   <span class="tweet-title">
    Zero-Shot Annotation: Teaching AI to See the City's Hidden Details
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Washington
   </span>
  </div>
  <div class="primary-text">
   This research explores using vision-language models (VLMs) to annotate urban features from satellite images, reducing the need for extensive human-annotated training data. Unlike previous work that focuses on common objects, this study investigates the annotation of less frequently encountered features like stop lines and raised tables, crucial for accessibility and safety.
  </div>
 </div>
</div>
<div class="tweet" id="tweet21">
 <div class="start-time-icon" title="Play from here">
  10:23
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01040" target="_blank">
    @arXiv 2408.01040
   </a>
   <span class="tweet-title">
    Vision Transformers Get a Privacy Makeover: Patch-Wise CutMix to the Rescue!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Yonsei University, Duke University, Singapore University of Technology and Design...
   </span>
  </div>
  <div class="primary-text">
   This research proposes a novel privacy-preserving split learning framework for Vision Transformers (ViT) called DP-CutMixSL. It utilizes a patch-wise random and noisy CutMix technique to enhance privacy protection against various attacks, including membership inference, reconstruction, and label inference attacks. This approach differs from previous work by focusing on the specific characteristics of ViT, such as its large receptive field and absence of pooling layers, to design a more effective privacy-preserving mechanism.
  </div>
 </div>
</div>
<div class="tweet" id="tweet22">
 <div class="start-time-icon" title="Play from here">
  10:53
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00998" target="_blank">
    @arXiv 2408.00998
   </a>
   <span class="tweet-title">
    Image Editing with a Frequency Twist: Plug-and-Play Diffusion for Text-Driven Control
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Peking University
   </span>
  </div>
  <div class="primary-text">
   This research proposes a novel approach for text-driven image-to-image translation using pre-trained diffusion models. Instead of fine-tuning the model or relying on online optimization, it introduces a "frequency band substitution" layer that dynamically transplants specific frequency bands from a reference image into the diffusion process, enabling flexible control over image appearance, layout, and contours.
  </div>
 </div>
</div>
<div class="tweet" id="tweet23">
 <div class="start-time-icon" title="Play from here">
  11:22
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00793" target="_blank">
    @arXiv 2408.00793
   </a>
   <span class="tweet-title">
    Machine Learning: The New Alchemist for Natural Products
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Boston University, Northeastern University, Zhejiang University...
   </span>
  </div>
  <div class="primary-text">
   This research proposes a standardized approach for integrating machine learning into natural product analysis, focusing on a structured methodology rather than just model deployment.
  </div>
 </div>
</div>
<div class="tweet" id="tweet24">
 <div class="start-time-icon" title="Play from here">
  11:48
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00960" target="_blank">
    @arXiv 2408.00960
   </a>
   <span class="tweet-title">
    Personalized Language Models:  A Soft Prompt for Your Inner Voice
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Waterloo, Google
   </span>
  </div>
  <div class="primary-text">
   This research introduces PERSOMA, a novel approach to personalized language prompting that utilizes soft prompt adapters to efficiently capture user history. Unlike previous methods that rely on lengthy text prompts, PERSOMA compresses user interactions into expressive embeddings, making it more efficient for handling large and complex user histories.
  </div>
 </div>
</div>
<div class="tweet" id="tweet25">
 <div class="start-time-icon" title="Play from here">
  12:13
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01072" target="_blank">
    @arXiv 2408.01072
   </a>
   <span class="tweet-title">
    Self-Play in RL: A Guide Map to Mastering Games
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University, Tencent, Peking University...
   </span>
  </div>
  <div class="primary-text">
   This research provides a unified framework for classifying self-play algorithms in reinforcement learning, bridging the gap between algorithms and their practical implications. It also highlights open challenges and future research directions in self-play.
  </div>
 </div>
</div>
<div class="tweet" id="tweet26">
 <div class="start-time-icon" title="Play from here">
  12:42
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01323" target="_blank">
    @arXiv 2408.01323
   </a>
   <span class="tweet-title">
    LLMs Go Wild: Building Instruction Datasets Without Human Help!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Southern University of Science and Technology, Peking University, Jilin University
   </span>
  </div>
  <div class="primary-text">
   This research introduces FANNO, a framework that automatically generates high-quality instruction datasets for training LLMs. Unlike previous methods that rely on expensive APIs or manual annotation, FANNO leverages open-sourced LLMs and a structured process to create diverse and complex datasets.
  </div>
 </div>
</div>
<div class="tweet" id="tweet27">
 <div class="start-time-icon" title="Play from here">
  13:10
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01384" target="_blank">
    @arXiv 2408.01384
   </a>
   <span class="tweet-title">
    Robots Learn to Navigate by Watching YouTube!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Peking University
   </span>
  </div>
  <div class="primary-text">
   This research proposes a new setting for visual navigation called "Video Navigation" where an agent learns to navigate a new environment by only watching a video of it, without any physical interaction. This differs from previous methods that require the agent to physically explore the environment or rely on additional sensor data like depth images or robot poses.
  </div>
 </div>
</div>
<div class="tweet" id="tweet28">
 <div class="start-time-icon" title="Play from here">
  13:33
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01044" target="_blank">
    @arXiv 2408.01044
   </a>
   <span class="tweet-title">
    Gaze Object Segmentation:  Seeing What You See, Pixel by Pixel!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Northwestern Polytechnical University, Peking University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new task called gaze object segmentation (GOS), which aims to predict the pixel-level mask of the object a person is looking at. Unlike previous methods that relied on box-level supervision, this approach leverages pixel-level supervision from a vision foundation model (VFM) to mitigate semantic ambiguity.
  </div>
 </div>
</div>
<div class="tweet" id="tweet29">
 <div class="start-time-icon" title="Play from here">
  14:02
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01283" target="_blank">
    @arXiv 2408.01283
   </a>
   <span class="tweet-title">
    Tiny Brains, Big Savings: How Data Pruning Makes On-Device Learning More Efficient
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Texas at Austin
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new approach to supervised on-device learning (ODL) that uses automatic data pruning to reduce the number of queries needed to acquire predicted labels from a teacher device, thereby saving power consumption during model retraining. This differs from previous work that relied on manual threshold tuning or simply mentioned the use of online post-training without specifying the labeling mechanism.
  </div>
 </div>
</div>
<div class="tweet" id="tweet30">
 <div class="start-time-icon" title="Play from here">
  14:28
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00874" target="_blank">
    @arXiv 2408.00874
   </a>
   <span class="tweet-title">
    Medical Images as Videos: One Prompt to Rule Them All!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Oxford
   </span>
  </div>
  <div class="primary-text">
   This research adapts the SAM2 framework for medical image segmentation, treating medical images as videos. This approach unlocks a unique "One-prompt Segmentation" capability, where a single prompt can segment the same object across multiple images, even if they lack a temporal relationship.
  </div>
 </div>
</div>
<div class="tweet" id="tweet31">
 <div class="start-time-icon" title="Play from here">
  14:55
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01051" target="_blank">
    @arXiv 2408.01051
   </a>
   <span class="tweet-title">
    AI's Got a Supply Chain Problem: Can We Contest It?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Delft University of Technology, University of Warwick, Harvard University...
   </span>
  </div>
  <div class="primary-text">
   This research expands the concept of "contestable AI" by considering the entire AI value chain, including the extraction of materials, construction of infrastructure, and the impact on society and the environment. Previous work primarily focused on contesting AI design or outputs within specific domains.
  </div>
 </div>
</div>
<div class="tweet" id="tweet32">
 <div class="start-time-icon" title="Play from here">
  15:28
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01291" target="_blank">
    @arXiv 2408.01291
   </a>
   <span class="tweet-title">
    TexGen: Texturing 3D Objects with a Multi-View Magic Trick!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Alberta, University of Toronto, Huawei
   </span>
  </div>
  <div class="primary-text">
   This paper introduces TexGen, a novel multi-view sampling and resampling framework for text-driven 3D texture generation. Unlike previous methods that rely on score distillation or autoregressive image inpainting, TexGen directly generates view-consistent RGB images with rich appearance details from pre-trained 2D text-to-image models.
  </div>
 </div>
</div>
<div class="tweet" id="tweet33">
 <div class="start-time-icon" title="Play from here">
  16:01
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01173" target="_blank">
    @arXiv 2408.01173
   </a>
   <span class="tweet-title">
    AI-Powered Digital Twins:  A Contract for Data Sharing in Smart Factories
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Nanjing University of Aeronautics and Astronautics, Guangdong University of Technology, Nanyang Technological University
   </span>
  </div>
  <div class="primary-text">
   This research proposes a novel approach to incentivize IIoT devices to share data for constructing digital twins in industrial cyber-physical systems. It utilizes a sustainable diffusion-based soft actor-critic algorithm, incorporating dynamic structured pruning techniques to optimize contract design and reduce computational overhead. This distinguishes it from previous work that primarily focused on iterative contract design or multi-agent reinforcement learning.
  </div>
 </div>
</div>
<div class="tweet" id="tweet34">
 <div class="start-time-icon" title="Play from here">
  16:36
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01337" target="_blank">
    @arXiv 2408.01337
   </a>
   <span class="tweet-title">
    Music for Brains: New Test Makes AI Sing (or Not)
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Pompeu Fabra University, Queen Mary University of London
   </span>
  </div>
  <div class="primary-text">
   This research introduces MuChoMusic, a benchmark for evaluating music understanding in multimodal audio-language models (Audio LLMs). Unlike previous work that relies on text-based metrics or ad-hoc datasets, MuChoMusic uses multiple-choice questions validated by human annotators to assess a model's ability to understand music across various dimensions.
  </div>
 </div>
</div>
<div class="tweet" id="tweet35">
 <div class="start-time-icon" title="Play from here">
  17:01
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01367" target="_blank">
    @arXiv 2408.01367
   </a>
   <span class="tweet-title">
    Transformers: Universal In-Context Learners - They Can Handle Any Number of Tokens!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Rice University, École Normale Supérieure
   </span>
  </div>
  <div class="primary-text">
   This research explores the ability of transformers to handle an arbitrarily large number of context tokens. Unlike previous work that focused on simplified architectures or required embedding dimensions to grow with the number of tokens, this paper demonstrates that deep transformers with a fixed embedding dimension can operate on an arbitrary number of tokens.
  </div>
 </div>
</div>
<div class="tweet" id="tweet36">
 <div class="start-time-icon" title="Play from here">
  17:26
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00781" target="_blank">
    @arXiv 2408.00781
   </a>
   <span class="tweet-title">
    From 3D Printing to Cosmic Rays: FabLabs Bring STEM to Life!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    International Centre for Theoretical Physics
   </span>
  </div>
  <div class="primary-text">
   This research focuses on the use of FabLabs to create hands-on STEM learning experiences, particularly for students with disabilities. It differs from previous work by emphasizing the accessibility and inclusivity of these experiences, showcasing how FabLabs can be used to create tangible and visual learning tools for a wide range of students.
  </div>
 </div>
</div>
<div class="tweet" id="tweet37">
 <div class="start-time-icon" title="Play from here">
  17:50
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01090" target="_blank">
    @arXiv 2408.01090
   </a>
   <span class="tweet-title">
    Neuromorphic Dataflow:  A Brain-Inspired Way to Run Programs
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University
   </span>
  </div>
  <div class="primary-text">
   This research proposes a new dataflow model specifically tailored for neuromorphic hardware. It introduces "where" and "when" primitives to represent control logic in a more compact and efficient way compared to traditional dataflow models.
  </div>
 </div>
</div>
<div class="tweet" id="tweet38">
 <div class="start-time-icon" title="Play from here">
  18:15
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01370" target="_blank">
    @arXiv 2408.01370
   </a>
   <span class="tweet-title">
    Event Cameras Get a Boost from IMUs: Tracking Gets Smoother, Faster!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    ShanghaiTech University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new event-based visual-inertial tracking (EVIT) framework that combines event camera data with inertial measurements from an IMU. Unlike previous work that relies solely on event cameras, EVIT leverages the IMU to improve pose initialization and regularization during windowed multi-frame tracking.
  </div>
 </div>
</div>
<div class="tweet" id="tweet39">
 <div class="start-time-icon" title="Play from here">
  18:36
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01362" target="_blank">
    @arXiv 2408.01362
   </a>
   <span class="tweet-title">
    Autoencoders Go Functional:  Learning From Data That's More Than Just Numbers!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Cambridge, The Alan Turing Institute, University of Warwick...
   </span>
  </div>
  <div class="primary-text">
   This paper extends variational autoencoders (VAEs) to function spaces, which are infinite-dimensional spaces that represent data as functions. This is different from traditional VAEs, which operate on finite-dimensional data.
  </div>
 </div>
</div>
<div class="tweet" id="tweet40">
 <div class="start-time-icon" title="Play from here">
  19:07
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01112" target="_blank">
    @arXiv 2408.01112
   </a>
   <span class="tweet-title">
    LLMs Get a Reality Check: AI-Powered Patient Reports That Actually Make Sense
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    UC Berkeley, Brown University, NYU
   </span>
  </div>
  <div class="primary-text">
   This research introduces an agentic workflow for generating patient-friendly medical reports using LLMs. Unlike previous work that relies on zero-shot prompting, this approach incorporates iterative self-reflection to improve the accuracy and readability of the generated reports.
  </div>
 </div>
</div>
<div class="tweet" id="tweet41">
 <div class="start-time-icon" title="Play from here">
  19:43
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01301" target="_blank">
    @arXiv 2408.01301
   </a>
   <span class="tweet-title">
    AI's Got a Confidence Problem: New Research Helps Machines Self-Assess
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Johns Hopkins University Applied Physics Laboratory, CMU
   </span>
  </div>
  <div class="primary-text">
   This research focuses on designing AI self-assessment techniques that explicitly consider the impact of those assessments on downstream decisions and their associated costs. This is a departure from previous work that often focuses on generic metrics for self-assessment without considering their real-world implications.
  </div>
 </div>
</div>
<div class="tweet" id="tweet42">
 <div class="start-time-icon" title="Play from here">
  20:09
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.00986" target="_blank">
    @arXiv 2408.00986
   </a>
   <span class="tweet-title">
    Bayesian Networks Get a Logic Check:  SAT-Based Verification for Safety-Critical AI
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    CMU
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel verification framework for Bayesian networks, specifically focusing on encoding them into Boolean logic using Multi-valued Decision Diagrams (MDDs) and Conjunctive Normal Form (CNF). This approach allows for the development of formal verification queries, enabling the precise assessment of model properties.
  </div>
 </div>
</div>
<div class="tweet" id="tweet43">
 <div class="start-time-icon" title="Play from here">
  20:31
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2408.01159" target="_blank">
    @arXiv 2408.01159
   </a>
   <span class="tweet-title">
    Curve Detection in Medical Images:  A New Attraction Field for Precision!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    IRA-Labs Ltd, Information Transmission Problems, Lomonosov Moscow State University...
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel approach to curve detection in medical images that uses a two-headed CNN architecture to predict an attraction field and a closeness map. This method does not require prior knowledge of the object's orientation, shape, or position, making it more versatile than previous methods.
  </div>
 </div>
</div>


        <div
            style="padding: 50px 0; text-align: center; margin: 5px 0; font-weight: 300; font-size: 10px; color: #000000;">
            Opening music
            from <a href="https://ikson.com" target="_blank" style="color: black; text-decoration: none;">TELL
                YOUR STORY by ikson</a></div>
        <div style="height: 50px;"></div>
    </div>

    <footer class="player-footer">
        <div class="player-detail-hidden-on-small-screen">
            <div id="audio-title" class="tweet-title-small">Listen and learn ^.^</div>
            <div style="height: 2px;"></div>
            <div id="audio-institutes" class="institute-text-small"></div>
        </div>
        <div class="control-panel">
            <div class="control-horizontal">
                <div id="playSpeedButton" title="Adjust speed">
                    <div id="selectedSpeed">1&times;</div>
                    <div class="speedMenuItems">
                        <div data-value="0.6">Speed 0.6&times;</div>
                        <div data-value="0.8">Speed 0.8&times;</div>
                        <div data-value="1" class="selected">Speed 1&times;</div>
                        <div data-value="1.2">Speed 1.2&times;</div>
                        <div data-value="1.4">Speed 1.4&times;</div>
                        <div data-value="1.6">Speed 1.6&times;</div>
                    </div>
                    <select id="speedOptionsHidden">
                        <option value="0.6">0.6&times;</option>
                        <option value="0.8">0.8&times;</option>
                        <option value="1" selected>1&times;</option>
                        <option value="1.2">1.2&times;</option>
                        <option value="1.4">1.4&times;</option>
                        <option value="1.6">1.6&times;</option>
                    </select>
                </div>
                <div id="playLastButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(false)" title="Play last" disabled>
                        <img src="assets/buttonLastEpisode.svg" alt="Last" style="width: 12px;">
                    </button>
                </div>
                <button class="controllerButton" onclick="scrollToCurrentTweet()" title="Scoll to the current episode">
                    <img id="locateImage" src="assets/buttonTarget.svg" alt="Locate">
                </button>
                <button class="controllerButton" onclick="togglePlayPause()" title="Play/Pause">
                    <img id="playPauseImage" src="assets/buttonPlay.svg" alt="Play">
                </button>
                <div id="playNextButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(true)" title="Play next" disabled>
                        <img src="assets/buttonNextEpisode.svg" alt="Next" style="width: 12px;">
                    </button>
                </div>
            </div>
            <div class="control-horizontal">
                <div id="progressTime">0:00</div>
                <div id="progressContainer" onclick="seek(event)">
                    <div id="progressBar"></div>
                    <div id="progressCircle" draggable="true"></div>
                </div>
                <audio id="audioPlayer"
                    src="https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202408050810_audio.mp3"></audio>
                <div id="progressTime"><span id="audioDuration">Loading...</span></div>
            </div>
        </div>
    </footer>
    <div id="privacyModal" class="modal"></div>
    <script src="script.js"></script>
    <script src="calendar.js"></script>    
    <script>
        fetch('https://ribbitribbit.co/privacy.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('privacyModal').innerHTML = data;
            })
            .catch(error => console.error('Error loading privacy:', error));
    </script>
</body>
</html>
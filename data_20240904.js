
daily_data = {
    "date": "2024-09-04",
    "tweets": [
            {
                "startTime": "00:51",
                "arxivId": "2409.00610",
                "arxivLink": "https://arxiv.org/abs/2409.00610",
                "title": "Protein Function Prediction Gets a Graph-Based Makeover: Region Proposals to the Rescue!",
                "institute": "MIT, City University of Hong Kong",
                "text": "This research introduces ProteinRPN, a novel model for protein function prediction that utilizes a graph-based region proposal network to identify and refine functional regions within protein residue graphs. This approach differs from previous methods by incorporating domain-specific knowledge and multi-stage refinement, leading to more accurate and structurally coherent predictions.",
                "paper-title": "ProteinRPN: Towards Accurate Protein Function Prediction with Graph-Based Region Proposals",
                "image-path": ""
            },

            {
                "startTime": "01:14",
                "arxivId": "2409.00342",
                "arxivLink": "https://arxiv.org/abs/2409.00342",
                "title": "AI Image Generation Gets a Policy Makeover: AdaNAT Learns to Adapt!",
                "institute": "Tsinghua University, National University of Singapore",
                "text": "This research introduces AdaNAT, a method that uses a learnable policy network to automatically configure the generation policy for token-based image generation, unlike previous methods that rely on manually designed rules.",
                "paper-title": "AdaNAT: Exploring Adaptive Policy for Token-Based Image Generation",
                "image-path": ""
            },

            {
                "startTime": "01:39",
                "arxivId": "2409.00252",
                "arxivLink": "https://arxiv.org/abs/2409.00252",
                "title": "Dataset Creators Spill the Tea: 7 Tips for Building Better Data",
                "institute": "University of Southern California, Microsoft Research",
                "text": "This research focuses on the perspectives of dataset creators, a group often overlooked in discussions about responsible machine learning. It presents seven recommendations for improving dataset creation practices based on interviews with 18 leading dataset creators.",
                "paper-title": "Building Better Datasets: Seven Recommendations for Responsible Design from Dataset Creators",
                "image-path": ""
            },

            {
                "startTime": "02:01",
                "arxivId": "2409.02060",
                "arxivLink": "https://arxiv.org/abs/2409.02060",
                "title": "Open-Source Language Model: It's Not Just About the Weights, It's About the Whole Shebang!",
                "institute": "Allen Institute for AI, Contextual AI, University of Washington...",
                "text": "This research introduces OLMOE, a fully open-source Mixture-of-Experts (MoE) language model. Unlike previous MoE models, which often only release model weights, OLMOE provides access to training data, code, and logs, making it a more transparent and accessible resource for researchers.",
                "paper-title": "OLMoE: Open Mixture-of-Experts Language Models",
                "image-path": ""
            },

            {
                "startTime": "02:32",
                "arxivId": "2409.01704",
                "arxivLink": "https://arxiv.org/abs/2409.01704",
                "title": "OCR 2.0: A Unified Model for All Your Optical Character Needs!",
                "institute": "StepFun, Megvii Technology, University of Chinese Academy of Sciences...",
                "text": "This research proposes a \"General OCR Theory\" and a model called GOT, which aims to unify various OCR tasks into a single end-to-end model. Unlike traditional OCR systems that rely on multiple modules, GOT uses a single encoder-decoder architecture, reducing complexity and maintenance costs. It also differs from large vision-language models (LVLMs) by focusing on pure OCR tasks, using a smaller number of parameters, and prioritizing high compression rates for optical characters.",
                "paper-title": "General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model",
                "image-path": ""
            },

            {
                "startTime": "03:04",
                "arxivId": "2409.00276",
                "arxivLink": "https://arxiv.org/abs/2409.00276",
                "title": "Hacking the System: New Research Cracks the Code on Adversarial Attacks in Non-linear Systems",
                "institute": "UC Berkeley",
                "text": "This research focuses on the exact recovery guarantees for a non-smooth estimator in the context of parameterized non-linear system identification under adversarial attacks. It differs from previous work by providing a more general and stronger analysis of the necessary and sufficient conditions for optimality and uniqueness of solutions, leading to improved sample complexity bounds.",
                "paper-title": "Exact Recovery Guarantees for Parameterized Non-linear System Identification Problem under Adversarial Attacks",
                "image-path": ""
            },

            {
                "startTime": "03:28",
                "arxivId": "2409.01247",
                "arxivLink": "https://arxiv.org/abs/2409.01247",
                "title": "AI's Chatty Side: How Much Talk Does It Take to Get a Bot to Go Bad?",
                "institute": "University of Cambridge, Spanish National Research Council, Universitat Polit`ecnica de Val`encia",
                "text": "This research introduces two new metrics, Conversational Length and Conversational Complexity, to assess the risk of eliciting harmful outputs from LLMs. Unlike previous work that focuses on individual prompts, this study examines the dynamics of extended conversations and the effort required to steer LLMs towards harmful content.",
                "paper-title": "Conversational Complexity for Assessing Risk in Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "03:50",
                "arxivId": "2409.01890",
                "arxivLink": "https://arxiv.org/abs/2409.01890",
                "title": "Stale Embeddings? No Problem! Corrector Networks to the Rescue!",
                "institute": "Google",
                "text": "This paper introduces a novel approach to training dense retrieval models by using a small parametric \"corrector network\" to adjust stale cached target embeddings. This method avoids the computationally expensive process of re-embedding targets during training, which is a common practice in previous work.",
                "paper-title": "A Fresh Take on Stale Embeddings: Improving Dense Retriever Training with Corrector Networks",
                "image-path": ""
            },

            {
                "startTime": "04:13",
                "arxivId": "2409.00358",
                "arxivLink": "https://arxiv.org/abs/2409.00358",
                "title": "Decoding Dialects: How a Low-Rank Adapter Makes AI Understand Your Accent",
                "institute": "University of New South Wales, Google",
                "text": "This research extends dialect adaptation techniques, previously applied to encoder models, to decoder models. It introduces a novel architecture called LORDD, which utilizes task-specific and dialect-specific adapters to improve the performance of decoder models on target word prediction tasks in Indian English.",
                "paper-title": "Predicting the Target Word of Game-playing Conversations using a Low-Rank Dialect Adapter for Decoder Models",
                "image-path": ""
            },

            {
                "startTime": "04:38",
                "arxivId": "2409.01011",
                "arxivLink": "https://arxiv.org/abs/2409.01011",
                "title": "Ancient Chinese Scripts Get a Multi-Modal Makeover!",
                "institute": "Tsinghua University",
                "text": "This research introduces a multi-modal multi-granularity tokenizer specifically designed for analyzing ancient Chinese scripts, particularly the Chu bamboo slip (CBS) script. Unlike previous work that focuses on character-level tokenization, this tokenizer breaks down characters into sub-character components, potentially revealing more information about the semantics and phonetics of the text.",
                "paper-title": "Multi-Modal Multi-Granularity Tokenizer for Chu Bamboo Slip Scripts",
                "image-path": ""
            },

            {
                "startTime": "04:57",
                "arxivId": "2409.00138",
                "arxivLink": "https://arxiv.org/abs/2409.00138",
                "title": "AI Chatbots: Spilling Secrets Without a Whisper?",
                "institute": "Stanford University, Northeastern University, Harvard University",
                "text": "This research focuses on evaluating the privacy awareness of language models (LMs) in action, specifically when they are used as agents to assist with communication tasks. Unlike previous work that primarily used probing questions, this study constructs a framework called PrivacyLens to evaluate LMs in a more realistic scenario where they interact with tools like email and calendars.",
                "paper-title": "PrivacyLens: Evaluating Privacy Norm Awareness of Language Models in Action",
                "image-path": ""
            },

            {
                "startTime": "05:19",
                "arxivId": "2409.01156",
                "arxivLink": "https://arxiv.org/abs/2409.01156",
                "title": "Video's Got Talent: New Technique Merges Redundant Frames for Faster Text-Video Retrieval",
                "institute": "JD.com, Tsinghua University",
                "text": "This research tackles the issue of temporal redundancy in video data, which is often overlooked in efficient text-video retrieval methods. The authors propose a novel Temporal Token Merging (TempMe) framework that progressively merges similar tokens across frames, reducing computational overhead while improving performance.",
                "paper-title": "TempMe: Video Temporal Token Merging for Efficient Text-Video Retrieval",
                "image-path": ""
            },

            {
                "startTime": "05:42",
                "arxivId": "2409.00800",
                "arxivLink": "https://arxiv.org/abs/2409.00800",
                "title": "Speech Recognition: Discrete vs. Continuous - Who Wins the Token Race?",
                "institute": "Tsinghua University, Tencent AI Lab, The Chinese University of Hong Kong",
                "text": "This research systematically compares discrete and continuous speech representations within Large Language Model (LLM)-based Automatic Speech Recognition (ASR), a topic not extensively explored before.",
                "paper-title": "Comparing Discrete and Continuous Space LLMs for Speech Recognition",
                "image-path": ""
            },

            {
                "startTime": "06:07",
                "arxivId": "2409.02108",
                "arxivLink": "https://arxiv.org/abs/2409.02108",
                "title": "Deep Shadows: A Deep Dive into Shadow Detection, Removal, and Generation",
                "institute": "Shanghai Artificial Intelligence Laboratory, Chinese University of Hong Kong, Adobe Research",
                "text": "This research provides a comprehensive survey of shadow analysis in the deep learning era, covering tasks, deep models, datasets, evaluation metrics, and result comparisons. It also includes a cross-dataset generalization study and explores the relationship between model size/speed and performance.",
                "paper-title": "Unveiling Deep Shadows: A Survey on Image and Video Shadow Detection, Removal, and Generation in the Era of Deep Learning",
                "image-path": ""
            },

            {
                "startTime": "06:28",
                "arxivId": "2409.00588",
                "arxivLink": "https://arxiv.org/abs/2409.00588",
                "title": "Diffusion Policy Gets a Fine-Tuning Boost: RL Meets Diffusion for Robot Superpowers!",
                "institute": "Princeton University, Massachusetts Institute of Technology, Toyota Research Institute...",
                "text": "This paper introduces Diffusion Policy Policy Optimization (DPPO), a new framework for fine-tuning diffusion-based policies using policy gradient methods from reinforcement learning. Unlike previous work that focused on off-policy Q-learning or weighted regression, DPPO leverages the unique properties of diffusion models to achieve more efficient and stable training.",
                "paper-title": "Diffusion Policy Policy Optimization",
                "image-path": ""
            },

            {
                "startTime": "06:56",
                "arxivId": "2409.01141",
                "arxivLink": "https://arxiv.org/abs/2409.01141",
                "title": "LLMs Get a Speed Boost: Duplex Makes Big Language Models Run Faster and Cooler",
                "institute": "Seoul National University, Samsung",
                "text": "This research proposes Duplex, a device that integrates two types of processing units to accelerate large language models (LLMs). Unlike previous heterogeneous systems that duplicate MoE layers, Duplex uses a combination of high-Op/B and low-Op/B processors to efficiently handle the varying computational demands of different layers within LLMs.",
                "paper-title": "Duplex: A Device for Large Language Models with Mixture of Experts, Grouped Query Attention, and Continuous Batching",
                "image-path": ""
            },

            {
                "startTime": "07:25",
                "arxivId": "2409.01071",
                "arxivLink": "https://arxiv.org/abs/2409.01071",
                "title": "VideoLLaMB: Remembering the Whole Movie, One Scene at a Time!",
                "institute": "Beijing Academy of Artificial Intelligence, UC Santa Cruz, Peking University",
                "text": "This paper introduces VideoLLaMB, a framework that uses recurrent memory tokens within bridge layers to encode entire video sequences, preserving semantic continuity and enhancing model performance across various tasks. This approach differs from previous work that often relies on video compression strategies, which can lead to the loss of critical visual cues.",
                "paper-title": "VideoLLaMB: Long-context Video Understanding with Recurrent Memory Bridges",
                "image-path": ""
            },

            {
                "startTime": "07:55",
                "arxivId": "2409.00250",
                "arxivLink": "https://arxiv.org/abs/2409.00250",
                "title": "Medical Report Generation: From Text to Tags, It's a Multi-Label Thing!",
                "institute": "NYU, University of Technology Sydney, Stanford University",
                "text": "This research proposes a new approach to medical report generation by framing it as a multi-label classification problem. Instead of generating text directly, the model focuses on identifying and classifying key medical concepts from images, simplifying the process and potentially improving accuracy. This differs from previous methods that relied heavily on complex sequence generation models.",
                "paper-title": "Medical Report Generation Is A Multi-label Classification Problem",
                "image-path": ""
            },

            {
                "startTime": "08:20",
                "arxivId": "2409.01007",
                "arxivLink": "https://arxiv.org/abs/2409.01007",
                "title": "AI Debate Club: Unlocking Wisdom Through Contentious Conversations",
                "institute": "Stanford University",
                "text": "This research introduces EVINCE, a framework that uses conditional statistics and information theory to quantify and moderate adversarial dialogues between LLMs. This approach aims to improve prediction accuracy, robustness, and stability in LLMs by balancing diverse perspective exploration with strong prior exploitation.",
                "paper-title": "Unlocking the Wisdom of Large Language Models: An Introduction to The Path to Artificial General Intelligence",
                "image-path": ""
            },

            {
                "startTime": "08:41",
                "arxivId": "2409.01927",
                "arxivLink": "https://arxiv.org/abs/2409.01927",
                "title": "Web Agents: Planning is the Real Bottleneck, Not Grounding!",
                "institute": "IBM",
                "text": "This research breaks down web agents into two components: planning and grounding. It then isolates these components in experiments to determine which one is the main bottleneck in web agent performance. This approach differs from previous work that often treats web agents as black boxes and focuses on end-to-end evaluations.",
                "paper-title": "From Grounding to Planning: Benchmarking Bottlenecks in Web Agents",
                "image-path": ""
            },

            {
                "startTime": "09:04",
                "arxivId": "2409.00951",
                "arxivLink": "https://arxiv.org/abs/2409.00951",
                "title": "Robots Learn New Tricks with AI-Powered Image Makeovers!",
                "institute": "University of Washington, CMU",
                "text": "This research proposes a novel framework for semantically controllable data augmentation in robot learning. Unlike traditional data augmentation techniques that focus on minor variations like color adjustments, this approach leverages pre-trained image-text generative models to introduce diverse, realistic, and semantically meaningful alterations to robot data. This allows robots to learn from a wider range of experiences, improving their ability to generalize to unseen real-world scenarios.",
                "paper-title": "Semantically Controllable Augmentations for Generalizable Robot Learning",
                "image-path": ""
            },

            {
                "startTime": "09:37",
                "arxivId": "2409.01652",
                "arxivLink": "https://arxiv.org/abs/2409.01652",
                "title": "Robot Choreographer: New AI Makes Robots Dance to Your Commands!",
                "institute": "Stanford University",
                "text": "This research introduces Relational Keypoint Constraints (ReKep), a new way to represent robotic manipulation tasks. Unlike previous methods that rely on rigid-body transformations or require extensive training data, ReKep uses semantically meaningful 3D keypoints and Python functions to define constraints, enabling more flexible and adaptable robot behaviors.",
                "paper-title": "ReKep: Spatio-Temporal Reasoning of Relational Keypoint Constraints for Robotic Manipulation",
                "image-path": ""
            },

            {
                "startTime": "10:02",
                "arxivId": "2409.01420",
                "arxivLink": "https://arxiv.org/abs/2409.01420",
                "title": "Neural Networks Get a Coding Makeover: Erasure Codes for Faster Inference!",
                "institute": "IBM, CMU",
                "text": "This research proposes a method to apply erasure coding to neural networks, a technique previously used for linear computations. The key difference is that the authors leverage the diagonal Fisher information matrix to create a coded model that approximates a linear combination of the outputs of multiple neural networks.",
                "paper-title": "Erasure Coded Neural Network Inference via Fisher Averaging",
                "image-path": ""
            },

            {
                "startTime": "10:27",
                "arxivId": "2409.01369",
                "arxivLink": "https://arxiv.org/abs/2409.01369",
                "title": "Imitation Game: Teaching Language Models to Think Like Humans with Inverse Reinforcement Learning",
                "institute": "Google DeepMind, Cohere",
                "text": "This research explores the use of inverse reinforcement learning (IRL) for fine-tuning large language models (LLMs). Unlike traditional maximum likelihood estimation (MLE), which focuses on predicting the next token, IRL aims to optimize the entire sequence generation process by extracting rewards and directly optimizing actions.",
                "paper-title": "Imitating Language via Scalable Inverse Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "10:47",
                "arxivId": "2409.00133",
                "arxivLink": "https://arxiv.org/abs/2409.00133",
                "title": "LLMs in Medicine: From Zero to Hero (With a Little Fine-Tuning)",
                "institute": "Xinxiang Medical University, Henan Province, Shanghai AI Laboratory...",
                "text": "This research stands out by providing a comprehensive analysis of LLMs across various biomedical fields, including genomics, clinical practice, and drug discovery. It goes beyond specific applications or model architectures, offering a broader perspective on the current landscape, challenges, and future prospects of LLMs in biomedicine.",
                "paper-title": "A Survey for Large Language Models in Biomedicine",
                "image-path": ""
            },

            {
                "startTime": "11:09",
                "arxivId": "2409.01199",
                "arxivLink": "https://arxiv.org/abs/2409.01199",
                "title": "Video Compression Gets a 3D Makeover: How Omni-dimensional VAEs Are Revolutionizing Video Generation",
                "institute": "Peking University",
                "text": "This research introduces OD-VAE, a variational autoencoder (VAE) that compresses videos in both the spatial and temporal dimensions. Unlike previous VAEs used in latent video diffusion models (LVDMs), which only compress spatially, OD-VAE leverages the temporal redundancy in video frames to achieve more concise latent representations.",
                "paper-title": "OD-VAE: An Omni-dimensional Video Compressor for Improving Latent Video Diffusion Model",
                "image-path": ""
            },

            {
                "startTime": "11:37",
                "arxivId": "2409.01072",
                "arxivLink": "https://arxiv.org/abs/2409.01072",
                "title": "Rainy Day Blues? This AI Can Still See the Road!",
                "institute": "Wuhan University, Nanyang Technological University, National Tsing Hua University",
                "text": "This research introduces a new online domain adaptation framework called RODASS, which dynamically detects domain shifts and adjusts hyperparameters to minimize training costs and error propagation. Unlike previous methods, RODASS incorporates a Dynamic Ambiguous Patch Mask (DAP Mask) strategy to mitigate error accumulation in ambiguous classes, enhancing the model's robustness against external noise.",
                "paper-title": "Towards Robust Online Domain Adaptive Semantic Segmentation under Adverse Weather Conditions",
                "image-path": ""
            },

            {
                "startTime": "12:05",
                "arxivId": "2409.02048",
                "arxivLink": "https://arxiv.org/abs/2409.02048",
                "title": "Single Image, Endless Views: Taming Diffusion Models for 3D Scene Magic",
                "institute": "Peking University, Tencent AI Lab, The Chinese University of Hong Kong...",
                "text": "This research proposes ViewCrafter, a novel view synthesis method that combines the power of video diffusion models with point cloud representations. Unlike previous methods that rely on dense multi-view captures, ViewCrafter can generate high-fidelity novel views from single or sparse images, enabling precise camera pose control and consistent view generation.",
                "paper-title": "ViewCrafter: Taming Video Diffusion Models for High-fidelity Novel View Synthesis",
                "image-path": ""
            },

            {
                "startTime": "12:25",
                "arxivId": "2409.01055",
                "arxivLink": "https://arxiv.org/abs/2409.01055",
                "title": "Outpainting Videos: From Tiny to Titanic, No Memory Limits!",
                "institute": "Tencent, HKUST, USTC...",
                "text": "This research proposes a new method for video outpainting that uses spatial windows to overcome GPU memory limitations, allowing for higher-resolution outpainting with extensive content generation. Unlike previous methods that rely on single-shot outpainting, this approach breaks down the task into smaller, manageable sub-tasks, enabling the generation of larger, more detailed videos.",
                "paper-title": "Follow-Your-Canvas: Higher-Resolution Video Outpainting with Extensive Content Generation",
                "image-path": ""
            },

            {
                "startTime": "12:57",
                "arxivId": "2409.00141",
                "arxivLink": "https://arxiv.org/abs/2409.00141",
                "title": "Battery Health Check: Graphing the Way to Longer Life",
                "institute": "Singapore University of Technology and Design, Chongqing University, Nanyang Technological University",
                "text": "This research uses a graph convolutional network (GCN) to estimate the state of health (SOH) of lithium-ion batteries, incorporating inter-cycle degradation information through a graph structure. Unlike previous methods that focus on individual cycles, this approach captures the temporal dynamics of battery degradation across multiple cycles.",
                "paper-title": "Graph neural network-based lithium-ion battery state of health estimation using partial discharging curve",
                "image-path": ""
            },

            {
                "startTime": "13:22",
                "arxivId": "2409.01524",
                "arxivLink": "https://arxiv.org/abs/2409.01524",
                "title": "LLMs Learn to Catch Their Own Math Mistakes: A Step-by-Step Self-Correction Revolution!",
                "institute": "Zhejiang University, Peking University, Meituan...",
                "text": "This research introduces a novel approach to self-correction in LLMs, focusing on spontaneous step-level correction during mathematical reasoning. Unlike previous methods that rely on post-hoc generation or external tools, this study equips LLMs with the ability to identify and correct errors as they occur during the inference process.",
                "paper-title": "S$^3$c-Math: Spontaneous Step-level Self-correction Makes Large Language Models Better Mathematical Reasoners",
                "image-path": ""
            },

            {
                "startTime": "13:39",
                "arxivId": "2409.00839",
                "arxivLink": "https://arxiv.org/abs/2409.00839",
                "title": "Unlocking the Black Box: How Entropy Loss Makes 3D Object Detection Smarter",
                "institute": "Mohamed bin Zayed University of Artificial Intelligence, Beijing University of Posts and Telecommunications, Tianjin University...",
                "text": "This research introduces a novel loss function called \"Entropy Loss\" that aims to improve the interpretability of 3D object detection networks. Unlike previous methods that focus on architectural design, this approach leverages principles from communication theory to quantify and control information flow within the network.",
                "paper-title": "Entropy Loss: An Interpretability Amplifier of 3D Object Detection Network for Intelligent Driving",
                "image-path": ""
            },

            {
                "startTime": "14:10",
                "arxivId": "2409.01086",
                "arxivLink": "https://arxiv.org/abs/2409.01086",
                "title": "Fashion AI Gets a Texture Makeover: New Model Makes Clothes Look Real!",
                "institute": "Shenzhen Technology University, Shenzhen University, Carnegie Mellon University...",
                "text": "This research introduces a new method for fashion image editing called DPDEdit, which uses multiple types of information, including text, human poses, and garment textures, to create more realistic and detailed clothing edits. Unlike previous methods that rely solely on text descriptions, DPDEdit incorporates actual texture images to guide the generation process, resulting in more accurate and visually appealing results.",
                "paper-title": "DPDEdit: Detail-Preserved Diffusion Models for Multimodal Fashion Image Editing",
                "image-path": ""
            },

            {
                "startTime": "14:44",
                "arxivId": "2409.01661",
                "arxivLink": "https://arxiv.org/abs/2409.01661",
                "title": "NeRFs Get a Privacy Makeover: How to Share 3D Scenes Without Sharing Your Home!",
                "institute": "Zhejiang University, Chinese University of Hong Kong, Nanyang Technological University",
                "text": "This research introduces SplitNeRF, a framework for training NeRF models collaboratively without sharing private scene data. It differs from previous work by focusing on privacy concerns specific to NeRF training, where the model itself can reveal sensitive information about the scene.",
                "paper-title": "$S^2$NeRF: Privacy-preserving Training Framework for NeRF",
                "image-path": ""
            },

            {
                "startTime": "15:04",
                "arxivId": "2409.01151",
                "arxivLink": "https://arxiv.org/abs/2409.01151",
                "title": "Hallucination Busting: New Metric Unmasks Image Understanding Woes in AI",
                "institute": "Peking University, Beijing Academy of Artificial Intelligence",
                "text": "This research introduces a parameter-free representation alignment metric (Pfram) to assess the quality of image representations in multimodal large language models (MLLMs). Unlike previous work that evaluates MLLMs as a whole, Pfram isolates the impact of image understanding on object hallucination.",
                "paper-title": "Understanding Multimodal Hallucination with Parameter-Free Representation Alignment",
                "image-path": ""
            },

            {
                "startTime": "15:34",
                "arxivId": "2409.00879",
                "arxivLink": "https://arxiv.org/abs/2409.00879",
                "title": "Soft MoE: More Experts, Less Confusion, More Power!",
                "institute": "Carnegie Mellon University",
                "text": "This research investigates the implicit biases of Soft Mixture of Experts (MoE) models, specifically focusing on the impact of the number of experts on representation power and expert specialization. Unlike previous work that primarily focused on computational aspects of MoE, this paper delves into the architectural implications of Soft MoE.",
                "paper-title": "Beyond Parameter Count: Implicit Bias in Soft Mixture of Experts",
                "image-path": ""
            },

            {
                "startTime": "15:57",
                "arxivId": "2409.00618",
                "arxivLink": "https://arxiv.org/abs/2409.00618",
                "title": "YOLOO: Multi-Modal Tracking Without the Multi-Modal Fuss!",
                "institute": "Nanjing University of Aeronautics and Astronautics, Tsinghua University",
                "text": "This paper proposes a new approach to multi-modal 3D object tracking called YOLOO. Unlike previous methods that require processing data from multiple sources (like images and point clouds) during inference, YOLOO learns a unified representation from all modalities during training, allowing it to track objects efficiently using only point cloud data during inference.",
                "paper-title": "YOLOO: You Only Learn from Others Once",
                "image-path": ""
            },

            {
                "startTime": "16:32",
                "arxivId": "2409.01989",
                "arxivLink": "https://arxiv.org/abs/2409.01989",
                "title": "Electrolyte Design: A Data-Driven Recipe for Better Batteries",
                "institute": "IBM",
                "text": "This research uses a data-driven approach to optimize electrolyte formulations for a novel interhalogen battery, considering not only electrolyte composition but also cathode loading and separator type. This differs from previous work that focused on optimizing electrolyte composition alone.",
                "paper-title": "Improving Electrolyte Performance for Target Cathode Loading Using Interpretable Data-Driven Approach",
                "image-path": ""
            },

            {
                "startTime": "16:47",
                "arxivId": "2409.00088",
                "arxivLink": "https://arxiv.org/abs/2409.00088",
                "title": "LLMs on Your Phone? It's Happening!",
                "institute": "Meta, University of North Texas",
                "text": "This research provides a comprehensive review of the challenges and solutions for deploying large language models (LLMs) on edge devices, focusing on efficient architectures, model compression techniques, and hardware acceleration strategies. It differs from previous work by offering a detailed analysis of the evolution of on-device LLMs, including a timeline of key model releases and a discussion of the advantages and limitations of on-device inference compared to cloud-based approaches.",
                "paper-title": "On-Device Language Models: A Comprehensive Review",
                "image-path": ""
            },

            {
                "startTime": "17:08",
                "arxivId": "2409.00162",
                "arxivLink": "https://arxiv.org/abs/2409.00162",
                "title": "Rewarding LLMs with Language: A New Recipe for Alignment",
                "institute": "Peking University",
                "text": "This paper proposes a novel sequence-to-sequence (seq2seq) reward modeling method for RLHF. Unlike traditional methods that rely on scalar feedback, this approach leverages language feedback, providing richer and more fine-grained information to the reward model.",
                "paper-title": "Sequence to Sequence Reward Modeling: Improving RLHF by Language Feedback",
                "image-path": ""
            },

            {
                "startTime": "17:28",
                "arxivId": "2409.00331",
                "arxivLink": "https://arxiv.org/abs/2409.00331",
                "title": "WikiCausal: Building a Knowledge Graph of Causes and Effects, One Wikipedia Article at a Time!",
                "institute": "IBM",
                "text": "This research introduces a new corpus and evaluation framework specifically designed for building causal knowledge graphs from text. Unlike previous work that focused on smaller, manually curated datasets or low-level tasks, this framework allows for evaluating the quality of end-to-end causal extraction solutions.",
                "paper-title": "WikiCausal: Corpus and Evaluation Framework for Causal Knowledge Graph Construction",
                "image-path": ""
            },

            {
                "startTime": "17:49",
                "arxivId": "2409.01421",
                "arxivLink": "https://arxiv.org/abs/2409.01421",
                "title": "CSG Shapes Get a Differentiable Makeover: Rasterization Makes CAD Editing a Breeze!",
                "institute": "University of Edinburgh, University College London",
                "text": "This research introduces a new method for rendering CSG models in a differentiable manner, which allows for the optimization of shape parameters. Unlike previous approaches that rely on complex mesh processing or analytical SDF expressions, this method leverages CSG rasterization and anti-aliasing to achieve differentiability.",
                "paper-title": "DiffCSG: Differentiable CSG via Rasterization",
                "image-path": ""
            },

            {
                "startTime": "18:20",
                "arxivId": "2409.00028",
                "arxivLink": "https://arxiv.org/abs/2409.00028",
                "title": "Pupil Power: Holograms That See Like You Do!",
                "institute": "Peking University, University of North Carolina at Chapel Hill",
                "text": "This research introduces a new framework for generating 3D holograms that dynamically adjust their depth-of-field based on the viewer's pupil size. Unlike previous methods that either assume a fixed pupil size or struggle with speckle noise, this approach uses an adjustable deformable convolutional layer to create realistic defocus effects.",
                "paper-title": "Pupil-Adaptive 3D Holography Beyond Coherent Depth-of-Field",
                "image-path": ""
            },

            {
                "startTime": "18:42",
                "arxivId": "2409.00851",
                "arxivLink": "https://arxiv.org/abs/2409.00851",
                "title": "Time's Up! Text-to-Audio Models Can't Tell Time (But We Can Help)",
                "institute": "University of Oxford, University of T\u00fcbingen",
                "text": "This research delves into the temporal understanding capabilities of text-to-audio retrieval models, focusing on how they handle the order of events in audio descriptions. Unlike previous work that primarily used CNN-based audio encoders, this study investigates the performance of transformer-based encoders, which are known for their ability to handle temporal data.",
                "paper-title": "Dissecting Temporal Understanding in Text-to-Audio Retrieval",
                "image-path": ""
            },

            {
                "startTime": "19:01",
                "arxivId": "2409.00558",
                "arxivLink": "https://arxiv.org/abs/2409.00558",
                "title": "LLM Director: Composing 3D Videos with a Textual Script",
                "institute": "University of Science and Technology of China, Microsoft, Shanghai Jiao Tong University",
                "text": "This research proposes a novel approach to text-to-video generation by composing individual concepts in 3D space. Unlike previous methods that implicitly learn concepts in 2D, this approach explicitly represents each concept in 3D, allowing for more flexible control and interaction.",
                "paper-title": "Compositional 3D-aware Video Generation with LLM Director",
                "image-path": ""
            },

            {
                "startTime": "19:25",
                "arxivId": "2409.01588",
                "arxivLink": "https://arxiv.org/abs/2409.01588",
                "title": "Reinforcement Learning: City Planners' New Best Friend for Facility Placement",
                "institute": "Tsinghua University",
                "text": "This research proposes a knowledge-informed reinforcement learning (RL) method for solving the large-scale urban facility location problem (FLP). Unlike previous approaches that rely heavily on local search, this method leverages a graph neural network (GNN) to guide the selection of edges on a swap graph, significantly accelerating the solution generation process.",
                "paper-title": "Large-scale Urban Facility Location Selection with Knowledge-informed Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "19:44",
                "arxivId": "2409.01931",
                "arxivLink": "https://arxiv.org/abs/2409.01931",
                "title": "Force Fields: From Slow and Steady to Fast and Furious",
                "institute": "New York University, Asahi Kasei Pharma Corporation, Open Molecular Software Foundation...",
                "text": "This research focuses on the design space between molecular mechanics (MM) and machine learning (ML) force fields, exploring the speed-accuracy tradeoff. It argues that the accuracy of MLFFs is no longer a limiting factor, but their speed is, and proposes a new generation of MLFFs that are faster, more stable, and more generalizable than current models.",
                "paper-title": "On the design space between molecular mechanics and machine learning force fields",
                "image-path": ""
            },

            {
                "startTime": "20:04",
                "arxivId": "2409.01990",
                "arxivLink": "https://arxiv.org/abs/2409.01990",
                "title": "Shrinking LLMs: How to Make Big Language Models Tiny and Speedy",
                "institute": "University of Wisconsin-Madison",
                "text": "This research explores systematic design in model compression, focusing on optimizing memory usage and improving KV cache eviction techniques for LLMs. Unlike previous work that primarily focused on quantization, knowledge distillation, and pruning, this paper delves into the architectural level of LLM deployment, aiming to make them more efficient and scalable.",
                "paper-title": "Contemporary Model Compression on Large Language Models Inference",
                "image-path": ""
            },

            {
                "startTime": "20:26",
                "arxivId": "2409.01306",
                "arxivLink": "https://arxiv.org/abs/2409.01306",
                "title": "Neural Networks: The New Electron Density Detectives!",
                "institute": "Microsoft",
                "text": "This research introduces a novel method called NERD (Neural Electron Real-space Density) to extract accurate electron densities from real-space many-electron wave functions. Unlike previous methods that rely on basis sets or struggle with multi-modal densities, NERD uses a neural network trained with score matching and noise-contrastive estimation to capture both local and global features of the density.",
                "paper-title": "Highly Accurate Real-space Electron Densities with Neural Networks",
                "image-path": ""
            },

            {
                "startTime": "20:59",
                "arxivId": "2409.02038",
                "arxivLink": "https://arxiv.org/abs/2409.02038",
                "title": "LLMs Go to Work: Enterprise Data Makes Them Sweat!",
                "institute": "MIT, Amazon, University of Washington",
                "text": "This research introduces a new benchmark dataset called BEAVER, specifically designed for evaluating text-to-SQL models on real-world enterprise data warehouses. Unlike existing benchmarks that rely on publicly available data, BEAVER uses anonymized data from actual enterprise systems, capturing the complexity and unique characteristics of enterprise data.",
                "paper-title": "BEAVER: An Enterprise Benchmark for Text-to-SQL",
                "image-path": ""
            },

            {
                "startTime": "21:26",
                "arxivId": "2409.01992",
                "arxivLink": "https://arxiv.org/abs/2409.01992",
                "title": "QueryCheetah: Hunting Privacy Vulnerabilities with Speed and Finesse",
                "institute": "Imperial College London, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research introduces QueryCheetah, a method for automated discovery of privacy attacks against query-based systems (QBSs). Unlike previous methods, QueryCheetah uses a fast local-search technique to explore a wider range of query syntaxes, resulting in a significant speed-up.",
                "paper-title": "QueryCheetah: Fast Automated Discovery of Attribute Inference Attacks Against Query-Based Systems",
                "image-path": ""
            },

            {
                "startTime": "21:43",
                "arxivId": "2409.01666",
                "arxivLink": "https://arxiv.org/abs/2409.01666",
                "title": "RAG's Back, Baby! Long-Context LLMs Get a Retrieval Boost",
                "institute": "Nvidia",
                "text": "This paper challenges the notion that long-context LLMs have rendered RAG obsolete. It proposes an order-preserving RAG mechanism that outperforms long-context LLMs by focusing on relevant information within a long document.",
                "paper-title": "In Defense of RAG in the Era of Long-Context Language Models",
                "image-path": ""
            },

            {
                "startTime": "22:24",
                "arxivId": "2409.00844",
                "arxivLink": "https://arxiv.org/abs/2409.00844",
                "title": "LLMs Get Report Cards: Grading AI with Human-Readable Summaries",
                "institute": "University of Toronto",
                "text": "This research proposes a new method for evaluating large language models (LLMs) called \"Report Cards.\" Unlike traditional quantitative benchmarks, Report Cards are human-interpretable natural language summaries of model behavior for specific skills or topics.",
                "paper-title": "Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries",
                "image-path": ""
            },

            {
                "startTime": "22:46",
                "arxivId": "2409.00316",
                "arxivLink": "https://arxiv.org/abs/2409.00316",
                "title": "OMR: From Perfect to Imperfect \u2013 A New Way to Read Music!",
                "institute": "University of Washington",
                "text": "This research tackles the challenge of imperfect object detection in optical music recognition (OMR) by introducing a training pipeline that directly trains the notation assembly model on the output of an object detector. This approach differs from previous work that assumed perfect detection output.",
                "paper-title": "Toward a More Complete OMR Solution",
                "image-path": ""
            },

            {
                "startTime": "23:10",
                "arxivId": "2409.01502",
                "arxivLink": "https://arxiv.org/abs/2409.01502",
                "title": "Avatar-Powered Video Magic: Turning Text Prompts into Realistic Human Videos!",
                "institute": "Arizona State University, University of Washington",
                "text": "This research proposes a novel method for generating human videos by conditioning video diffusion models on controlled 3D avatar rendering. This approach combines the photorealism of 2D methods with the controllability of 3D avatar-based approaches, addressing limitations of both.",
                "paper-title": "AMG: Avatar Motion Guided Video Generation",
                "image-path": ""
            },

            {
                "startTime": "23:35",
                "arxivId": "2409.00486",
                "arxivLink": "https://arxiv.org/abs/2409.00486",
                "title": "Sounding Objects: A Multi-Scale, Multi-Instance Approach to Visual Sound Localization",
                "institute": "Carnegie Mellon University, MBZUAI, Xiaohongshu",
                "text": "This research introduces a novel framework called M2VSL that utilizes multi-scale visual features to align audio-visual representations at multiple levels. This differs from previous methods that primarily focused on global audio and single-scale visual features.",
                "paper-title": "Multi-scale Multi-instance Visual Sound Localization and Segmentation",
                "image-path": ""
            },

            {
                "startTime": "23:57",
                "arxivId": "2409.00845",
                "arxivLink": "https://arxiv.org/abs/2409.00845",
                "title": "2D to 3D: Bridging the Gap with Relational Distillation",
                "institute": "University of Toronto, Mila-Quebec AI Institute",
                "text": "This research focuses on the structural mismatch between 2D and 3D representations in autonomous driving data distillation. It proposes a relational distillation framework that enforces intra-modal and cross-modal constraints to bridge this gap, leading to improved performance in zero-shot and few-shot 3D semantic segmentation tasks.",
                "paper-title": "Image-to-Lidar Relational Distillation for Autonomous Driving Data",
                "image-path": ""
            },

            {
                "startTime": "24:24",
                "arxivId": "2409.01367",
                "arxivLink": "https://arxiv.org/abs/2409.01367",
                "title": "Fairness on Graphs: A New Framework That's Not Afraid to Be Bottlenecked!",
                "institute": "South China University of Technology, Hong Kong Polytechnic University, Tsinghua University",
                "text": "This research proposes a new framework called GRAFair, which uses a variational graph auto-encoder to learn fair representations on graphs. Unlike previous adversarial learning methods, GRAFair achieves fairness in a stable manner without relying on adversarial training.",
                "paper-title": "Debiasing Graph Representation Learning based on Information Bottleneck",
                "image-path": ""
            },

            {
                "startTime": "24:52",
                "arxivId": "2409.00124",
                "arxivLink": "https://arxiv.org/abs/2409.00124",
                "title": "AI for Wireless: Can ChatGPT Decode Your Phone Calls?",
                "institute": "Rensselaer Polytechnic Institute",
                "text": "This research explores using large language models (LLMs) for wireless symbol detection, specifically focusing on in-context learning (ICL) without any training or fine-tuning. This differs from previous work that primarily relied on traditional deep neural networks (DNNs) which require extensive training data.",
                "paper-title": "Leveraging Large Language Models for Wireless Symbol Detection via In-Context Learning",
                "image-path": ""
            },

            {
                "startTime": "25:14",
                "arxivId": "2409.01411",
                "arxivLink": "https://arxiv.org/abs/2409.01411",
                "title": "Multi-Agent Networks: Learning to Talk, Learning to Listen, Learning to Win!",
                "institute": "University of Michigan",
                "text": "This research introduces a novel algorithm, Anaconda, that allows multi-agent networks to dynamically adjust their communication topology to optimize performance during collaborative tasks. Unlike previous methods that rely on fixed network structures, Anaconda enables agents to choose their communication partners based on the task at hand, balancing the trade-off between decision speed and accuracy.",
                "paper-title": "Performance-Aware Self-Configurable Multi-Agent Networks: A Distributed Submodular Approach for Simultaneous Coordination and Network Design",
                "image-path": ""
            },

            {
                "startTime": "25:34",
                "arxivId": "2409.01676",
                "arxivLink": "https://arxiv.org/abs/2409.01676",
                "title": "Diffusion Models: The New Way to Spot Faulty Machines",
                "institute": "Tsinghua University, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research proposes a classifier-free diffusion model for health indicator derivation in rotating machines. Unlike previous methods that model the entire data distribution, this approach focuses on generating healthy samples and comparing them to real-time data to identify anomalies.",
                "paper-title": "Classifier-Free Diffusion-Based Weakly-Supervised Approach for Health Indicator Derivation in Rotating Machines: Advancing Early Fault Detection and Condition Monitoring",
                "image-path": ""
            },

            {
                "startTime": "25:59",
                "arxivId": "2409.00597",
                "arxivLink": "https://arxiv.org/abs/2409.00597",
                "title": "Stance Wars: New Dataset Makes Multimodal Conversation Analysis a Real Fight!",
                "institute": "Shenzhen Technology University, Peking University",
                "text": "This research introduces a new dataset, MmMtCSD, specifically designed for multimodal multi-turn conversation stance detection. Unlike previous datasets, MmMtCSD focuses on capturing the nuances of stance within conversational threads, including both text and images.",
                "paper-title": "Multimodal Multi-turn Conversation Stance Detection: A Challenge Dataset and Effective Model",
                "image-path": ""
            },

            {
                "startTime": "26:31",
                "arxivId": "2409.01595",
                "arxivLink": "https://arxiv.org/abs/2409.01595",
                "title": "DiT-tastic Videos: AI Makes Driving Scenes Look Real!",
                "institute": "Harbin Institute of Technology, Li Auto Inc., Tsinghua University...",
                "text": "This research proposes a novel DiT-based framework for generating temporally and multi-view consistent videos, specifically designed for autonomous driving scenarios. Unlike previous methods, it incorporates bird's-eye view layouts and scene text for precise control, addressing limitations in resolution, aspect ratios, and object inconsistencies.",
                "paper-title": "DiVE: DiT-based Video Generation with Enhanced Control",
                "image-path": ""
            },

            {
                "startTime": "27:04",
                "arxivId": "2409.00101",
                "arxivLink": "https://arxiv.org/abs/2409.00101",
                "title": "EEG Signals: The New Language LLMs Can Speak!",
                "institute": "Shanghai Jiao Tong University, Microsoft",
                "text": "This research proposes NeuroLM, a multi-task foundation model for EEG signal processing that leverages the capabilities of Large Language Models (LLMs) by treating EEG signals as a foreign language. Unlike previous work that requires individual fine-tuning for each downstream task, NeuroLM can perform multiple tasks within a single model through instruction tuning.",
                "paper-title": "NeuroLM: A Universal Multi-task Foundation Model for Bridging the Gap between Language and EEG Signals",
                "image-path": ""
            },

            {
                "startTime": "27:32",
                "arxivId": "2409.00894",
                "arxivLink": "https://arxiv.org/abs/2409.00894",
                "title": "Over-parameterized Models: Learning to Adapt Like a Chameleon!",
                "institute": "Tsinghua University",
                "text": "This research explores how over-parameterization in sequence models can dynamically adjust the eigenvalues of a kernel, leading to improved adaptivity and generalization compared to traditional fixed-kernel methods.",
                "paper-title": "Improving Adaptivity via Over-Parameterization in Sequence Models",
                "image-path": ""
            },

            {
                "startTime": "27:59",
                "arxivId": "2409.01315",
                "arxivLink": "https://arxiv.org/abs/2409.01315",
                "title": "NeuralBIM Gets a Multi-Frequency Makeover: Solving Inverse Scattering Problems with a Deep Learning Twist!",
                "institute": "Tsinghua University",
                "text": "This research introduces a multi-frequency Neural Born Iterative Method (NeuralBIM) for solving inverse scattering problems. Unlike previous single-frequency approaches, this method leverages information from multiple frequencies to improve accuracy and efficiency.",
                "paper-title": "Multi-frequency Neural Born Iterative Method for Solving 2-D Inverse Scattering Problems",
                "image-path": ""
            },

            {
                "startTime": "28:23",
                "arxivId": "2409.00083",
                "arxivLink": "https://arxiv.org/abs/2409.00083",
                "title": "Brain-Computer Interface Gets a Brain: On-Device Learning for Wearable EEG!",
                "institute": "ETH Zurich, Tsinghua University, Slovak Academy of Sciences...",
                "text": "This research focuses on on-device learning for EEG-based motor imagery brain-computer interfaces (BCIs), which allows for real-time adaptation to individual users' brain signals without needing to send data to a cloud or server. This is different from previous work that relied on offline training and transfer learning, which can be time-consuming and require significant computational resources.",
                "paper-title": "On-device Learning of EEGNet-based Network For Wearable Motor Imagery Brain-Computer Interface",
                "image-path": ""
            },

            {
                "startTime": "28:50",
                "arxivId": "2409.00997",
                "arxivLink": "https://arxiv.org/abs/2409.00997",
                "title": "DataSculpt: LLMs Get a Long-Context Makeover!",
                "institute": "Peking University",
                "text": "This research introduces DataSculpt, a framework that tackles the challenge of constructing long-context training data for LLMs by framing it as a multi-objective combinatorial optimization problem. Unlike previous approaches that focus on single objectives or heuristic methods, DataSculpt considers multiple objectives like relevance, homogeneity, integrity, and computational efficiency, leading to a more balanced and effective data organization strategy.",
                "paper-title": "DataSculpt: Crafting Data Landscapes for LLM Post-Training through Multi-objective Partitioning",
                "image-path": ""
            },

            {
                "startTime": "29:24",
                "arxivId": "2409.00744",
                "arxivLink": "https://arxiv.org/abs/2409.00744",
                "title": "LiDAR Odometry Gets a Memory Boost: Deep Learning Learns from the Past!",
                "institute": "Shanghai Jiao Tong University, University of Cambridge, UC Berkeley",
                "text": "This research introduces a novel deep sequence LiDAR odometry method called DSLO, which leverages inconsistent spatio-temporal propagation. Unlike previous methods that focus on two adjacent frames, DSLO incorporates historical motion information to improve accuracy and robustness.",
                "paper-title": "DSLO: Deep Sequence LiDAR Odometry Based on Inconsistent Spatio-temporal Propagation",
                "image-path": ""
            },

            {
                "startTime": "29:49",
                "arxivId": "2409.00349",
                "arxivLink": "https://arxiv.org/abs/2409.00349",
                "title": "Toddler Tantrums: New Dataset Helps AI Understand Tiny Tykes!",
                "institute": "University of Washington",
                "text": "This research introduces ToddlerAct, a new dataset specifically designed for action recognition in toddlers, addressing the lack of toddler-specific data in existing datasets.",
                "paper-title": "ToddlerAct: A Toddler Action Recognition Dataset for Gross Motor Development Assessment",
                "image-path": ""
            },

            {
                "startTime": "30:10",
                "arxivId": "2409.01082",
                "arxivLink": "https://arxiv.org/abs/2409.01082",
                "title": "Image Retrieval Gets a Confidence Boost: Evidential Transformers Take the Lead!",
                "institute": "ETH Zurich, Texas A&M University",
                "text": "This paper introduces the Evidential Transformer, a new approach to image retrieval that incorporates uncertainty quantification. Unlike previous methods that rely on deterministic neural networks, this model explicitly models uncertainty, providing a more robust and informative framework for retrieval tasks.",
                "paper-title": "Evidential Transformers for Improved Image Retrieval",
                "image-path": ""
            },

            {
                "startTime": "30:34",
                "arxivId": "2409.00244",
                "arxivLink": "https://arxiv.org/abs/2409.00244",
                "title": "Deep Learning Gets a Data Assimilation Makeover: TorchDA Makes It Easy!",
                "institute": "\u00c9cole des Ponts ParisTech",
                "text": "This research introduces TorchDA, a Python package that integrates deep learning models into data assimilation workflows. Unlike existing tools, TorchDA allows users to seamlessly incorporate custom neural networks for state transition and observation functions.",
                "paper-title": "TorchDA: A Python package for performing data assimilation with deep learning forward and transformation functions",
                "image-path": ""
            },

            {
                "startTime": "30:59",
                "arxivId": "2409.00237",
                "arxivLink": "https://arxiv.org/abs/2409.00237",
                "title": "Wildfire Forecasting Gets a Speed Boost: Deep Learning to the Rescue!",
                "institute": "\u00c9cole des Ponts ParisTech",
                "text": "This research proposes two deep learning models, CAE-LSTM and ConvLSTM, to act as surrogates for the JULES-INFERNO wildfire model, significantly reducing the computational time required for global wildfire prediction. This approach differs from previous work by focusing on global-scale prediction and utilizing a combination of convolutional and recurrent neural networks.",
                "paper-title": "Deep Learning Surrogate Models of JULES-INFERNO for Wildfire Prediction on a Global Scale",
                "image-path": ""
            },

            {
                "startTime": "31:26",
                "arxivId": "2409.00147",
                "arxivLink": "https://arxiv.org/abs/2409.00147",
                "title": "Math-tastic Vision: A Language Model That Can See and Solve Problems!",
                "institute": "Peking University, ByteDance, University of Electronic Science and Technology of China",
                "text": "This research introduces MultiMath-7B, a multimodal large language model (MLLM) that combines visual and mathematical reasoning. Unlike previous work that focused solely on text-based math problems or geometric problem solving, MultiMath-7B can handle a wider range of mathematical tasks involving images, such as function plots and scientific charts.",
                "paper-title": "MultiMath: Bridging Visual and Mathematical Reasoning for Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "31:47",
                "arxivId": "2409.01821",
                "arxivLink": "https://arxiv.org/abs/2409.01821",
                "title": "Visual Prompting vs. Linear Probing: A Likelihood-Based Showdown!",
                "institute": "National Tsing Hua University, Dartmouth College, IBM Research...",
                "text": "This research introduces a log-likelihood ratio (LLR) method to assess the effectiveness of visual prompting (VP) versus linear probing (LP) for adapting pre-trained models to new tasks. Unlike previous work that focused on model selection, this paper focuses on method selection, providing a way to predict which approach will perform better on a given dataset.",
                "paper-title": "When Does Visual Prompting Outperform Linear Probing for Vision-Language Models? A Likelihood Perspective",
                "image-path": ""
            },

            {
                "startTime": "32:19",
                "arxivId": "2409.00315",
                "arxivLink": "https://arxiv.org/abs/2409.00315",
                "title": "Chatbots Need a Memory Makeover: How Long is Too Long for a Chat History?",
                "institute": "Peking University",
                "text": "This research investigates the impact of context length on the performance of Transformer-based open-domain dialog models. Unlike previous work that focused on the absolute performance of models, this study examines how varying the length of the dialog history during training and testing affects the model's ability to generate coherent responses.",
                "paper-title": "An Empirical Study on Context Length for Open-Domain Dialog Generation",
                "image-path": ""
            },

            {
                "startTime": "32:42",
                "arxivId": "2409.00099",
                "arxivLink": "https://arxiv.org/abs/2409.00099",
                "title": "LiCoNet's Got Your Back: Custom Keyword Spotting with a Twist!",
                "institute": "META AI",
                "text": "This research introduces a hardware-efficient framework for customized keyword spotting (KWS) using LiCoNet, a streaming convolution network. The novelty lies in the use of spectral-temporal graph attentive pooling (GAP) and a hybrid loss function to improve word embedding learning.",
                "paper-title": "Query-by-Example Keyword Spotting Using Spectral-Temporal Graph Attentive Pooling and Multi-Task Learning",
                "image-path": ""
            },

            {
                "startTime": "33:01",
                "arxivId": "2409.00286",
                "arxivLink": "https://arxiv.org/abs/2409.00286",
                "title": "Sports-Obsessed AI: Tiny Model, Big Sports Knowledge!",
                "institute": "NYU, CMU, Cornell University...",
                "text": "This research focuses on developing a small, domain-specific language model trained exclusively on sports data. Unlike previous work that relies on large, general-purpose models, this study explores the potential of optimizing model structure for specific domains.",
                "paper-title": "OnlySportsLM: Optimizing Sports-Domain Language Models with SOTA Performance under Billion Parameters",
                "image-path": ""
            },

            {
                "startTime": "33:24",
                "arxivId": "2409.00815",
                "arxivLink": "https://arxiv.org/abs/2409.00815",
                "title": "Speech Separation: A New Way to Untangle the Cocktail Party Problem",
                "institute": "Kyoto University, Meta",
                "text": "This research introduces a new method called \"overlapped encoding separation\" (EncSep) to improve the performance of serialized output training (SOT) in multi-speaker automatic speech recognition (ASR). EncSep utilizes the CTC-Attention hybrid loss, which is typically difficult to apply in SOT-based ASR due to the serialized nature of the training labels.",
                "paper-title": "Serialized Speech Information Guidance with Overlapped Encoding Separation for Multi-Speaker Automatic Speech Recognition",
                "image-path": ""
            },

            {
                "startTime": "33:48",
                "arxivId": "2409.00297",
                "arxivLink": "https://arxiv.org/abs/2409.00297",
                "title": "Quantized Networks: Universal Approximators, Even With Rounding Errors!",
                "institute": "Korea Institute for Advanced Study, Korea University",
                "text": "This research investigates the expressive power of quantized neural networks under fixed-point arithmetic, considering rounding errors during calculations. Unlike previous work that focused on exact operations, this study analyzes the impact of rounding on the networks' ability to approximate functions.",
                "paper-title": "On Expressive Power of Quantized Neural Networks under Fixed-Point Arithmetic",
                "image-path": ""
            },

            {
                "startTime": "34:09",
                "arxivId": "2409.00753",
                "arxivLink": "https://arxiv.org/abs/2409.00753",
                "title": "Traffic Pressure: A Multi-Hop Approach to Smarter Perimeter Control",
                "institute": "University of Toronto",
                "text": "This research introduces a new metric called \"multi-hop pressure\" to improve perimeter control in traffic networks. Unlike previous methods that only consider immediate downstream traffic, multi-hop pressure accounts for congestion further down the road, providing a more comprehensive view of traffic conditions.",
                "paper-title": "Generalized Multi-hop Traffic Pressure for Heterogeneous Traffic Perimeter Control",
                "image-path": ""
            },

            {
                "startTime": "34:29",
                "arxivId": "2409.01216",
                "arxivLink": "https://arxiv.org/abs/2409.01216",
                "title": "VR Point Clouds: Less Data, More Action!",
                "institute": "City University of Hong Kong, Southeast University, ETH Zurich...",
                "text": "This research introduces ESP-PCT, a new framework that focuses on identifying the most important parts of point cloud data generated by millimeter-wave sensors in VR applications. This approach differs from previous methods that process the entire point cloud, leading to improved accuracy and efficiency.",
                "paper-title": "ESP-PCT: Enhanced VR Semantic Performance through Efficient Compression of Temporal and Spatial Redundancies in Point Cloud Transformers",
                "image-path": ""
            },

            {
                "startTime": "34:55",
                "arxivId": "2409.01584",
                "arxivLink": "https://arxiv.org/abs/2409.01584",
                "title": "Artful Explanations: Can AI Understand Art in Different Languages?",
                "institute": "University of Tokyo, Nara Institute of Science and Technology",
                "text": "This research focuses on evaluating the ability of large-scale vision language models (LVLMs) to generate explanations for artworks in multiple languages. Unlike previous work that primarily relied on machine translation, this study created a dataset without translation, ensuring cultural nuances are considered.",
                "paper-title": "Towards Cross-Lingual Explanation of Artwork in Large-scale Vision Language Models",
                "image-path": ""
            },

            {
                "startTime": "35:20",
                "arxivId": "2409.00458",
                "arxivLink": "https://arxiv.org/abs/2409.00458",
                "title": "Predicting the Future with Sparse Data: A Voronoi Tessellation Tale",
                "institute": "\u00c9cole des Ponts ParisTech",
                "text": "This research introduces a new framework called DSOVT, which uses Voronoi tessellation to interpolate sparse and time-varying data in dynamical systems. This approach differs from previous work by directly integrating physics constraints into the training process of the deep learning models, enhancing the accuracy and robustness of predictions.",
                "paper-title": "Dynamical system prediction from sparse observations using deep neural networks with Voronoi tessellation and physics constraint",
                "image-path": ""
            },

            {
                "startTime": "35:48",
                "arxivId": "2409.01690",
                "arxivLink": "https://arxiv.org/abs/2409.01690",
                "title": "CLIP Goes to the Museum: Taming AI for Fine-Grained Art Understanding",
                "institute": "ETH Zurich",
                "text": "This research adapts CLIP, a powerful vision-language model, to understand museum exhibits in a structured, tabular format. Unlike previous work that focuses on general image-text understanding, this study specifically targets the nuanced details and relationships within museum data.",
                "paper-title": "Taming CLIP for Fine-grained and Structured Visual Understanding of Museum Exhibits",
                "image-path": ""
            },

            {
                "startTime": "36:11",
                "arxivId": "2409.00966",
                "arxivLink": "https://arxiv.org/abs/2409.00966",
                "title": "Graph Matching: When Correlation Meets Community Detection, It Gets Tricky!",
                "institute": "Peking University",
                "text": "This paper investigates the detection problem for correlated stochastic block models, focusing on the power and limitations of low-degree polynomial tests. It establishes a sharp computational transition for these tests, showing that they can distinguish correlated block models from independent Erd\u02ddos-R\u00b4enyi graphs if and only if the subsampling probability exceeds a certain threshold. This threshold is determined by the minimum of two thresholds: the correlation detection threshold for Erd\u02ddos-R\u00b4enyi graphs and the Kesten-Stigum threshold for community detection in block models.",
                "paper-title": "A computational transition for detecting correlated stochastic block models by low-degree polynomials",
                "image-path": ""
            },

            {
                "startTime": "36:32",
                "arxivId": "2409.01154",
                "arxivLink": "https://arxiv.org/abs/2409.01154",
                "title": "Flu Forecasting: Neural Networks Get a Grip on Uncertainty",
                "institute": "University College London",
                "text": "This research introduces two new frameworks for forecasting infectious disease prevalence using neural networks. The first framework incorporates Bayesian layers to produce uncertainty estimates, while the second framework uses neural ordinary differential equations to bridge the gap between mechanistic compartmental models and neural networks.",
                "paper-title": "Forecasting infectious disease prevalence with associated uncertainty using neural networks",
                "image-path": ""
            },

            {
                "startTime": "36:55",
                "arxivId": "2409.01362",
                "arxivLink": "https://arxiv.org/abs/2409.01362",
                "title": "Time Series Detective: Unmasking Temporal Patterns with Sparse Kernels",
                "institute": "MIT, University of Central Florida, McGill University",
                "text": "This research proposes a novel approach to learning convolutional kernels from time series data by formulating the problem as a sparse regression with non-negativity constraints. This differs from previous work by automatically learning kernels, reducing human bias, and enhancing interpretability through sparsity.",
                "paper-title": "Correlating Time Series with Interpretable Convolutional Kernels",
                "image-path": ""
            },

            {
                "startTime": "37:18",
                "arxivId": "2409.01184",
                "arxivLink": "https://arxiv.org/abs/2409.01184",
                "title": "Brain Surgery, But Make It AI: A Challenge to Automate Pituitary Tumor Removal",
                "institute": "University College London",
                "text": "This research focuses on workflow recognition in endoscopic pituitary surgery, a unique task compared to other minimally invasive surgeries due to the smaller working space and higher frequency of instrument and step switching.",
                "paper-title": "PitVis-2023 Challenge: Workflow Recognition in videos of Endoscopic Pituitary Surgery",
                "image-path": ""
            },

            {
                "startTime": "37:43",
                "arxivId": "2409.01175",
                "arxivLink": "https://arxiv.org/abs/2409.01175",
                "title": "Logit Scaling: A Simple Trick to Spot Fake News in AI!",
                "institute": "University of Belgrade, ML Collective, Google DeepMind",
                "text": "This research proposes a new method called Logit Scaling (LTS) for out-of-distribution (OOD) detection. Unlike previous methods, LTS doesn't require access to the model's training data or any additional training steps.",
                "paper-title": "Logit Scaling for Out-of-Distribution Detection",
                "image-path": ""
            },

            {
                "startTime": "38:05",
                "arxivId": "2409.01545",
                "arxivLink": "https://arxiv.org/abs/2409.01545",
                "title": "Speech Enhancement Gets a Noise Makeover: GANs Learn to Mimic Real-World Sounds",
                "institute": "National Taiwan Normal University, Academia Sinica, United-Link Co. Ltd.",
                "text": "This research introduces a novel data simulation method for speech enhancement that leverages noise embeddings extracted from target-domain data. Unlike previous approaches that focus on replicating overall spectral characteristics, this method explicitly models and incorporates the intricate, fine-grained features of the noise.",
                "paper-title": "Effective Noise-aware Data Simulation for Domain-adaptive Speech Enhancement Leveraging Dynamic Stochastic Perturbation",
                "image-path": ""
            },

            {
                "startTime": "38:38",
                "arxivId": "2409.00041",
                "arxivLink": "https://arxiv.org/abs/2409.00041",
                "title": "Waveform Noise: The Secret Code of Line Access",
                "institute": "University of Toronto, University of Sydney, University of Oxford...",
                "text": "This research focuses on detecting line-access events in critical care by analyzing the noise artifacts in high-frequency blood pressure waveform data, rather than removing them as is typically done.",
                "paper-title": "Needles in Needle Stacks: Meaningful Clinical Information Buried in Noisy Waveform Data",
                "image-path": ""
            },

            {
                "startTime": "39:00",
                "arxivId": "2409.01037",
                "arxivLink": "https://arxiv.org/abs/2409.01037",
                "title": "Cartoon Capers: New Dataset Unmasks Metaphor and Sarcasm in Memes!",
                "institute": "Peking University",
                "text": "This research introduces a new benchmark dataset called NYK-MS, which focuses on understanding metaphor and sarcasm in cartoon-caption pairs. Unlike previous datasets that primarily rely on text or memes, NYK-MS leverages the rich visual and textual information present in cartoons.",
                "paper-title": "NYK-MS: A Well-annotated Multi-modal Metaphor and Sarcasm Understanding Benchmark on Cartoon-Caption Dataset",
                "image-path": ""
            },

            {
                "startTime": "39:19",
                "arxivId": "2409.01281",
                "arxivLink": "https://arxiv.org/abs/2409.01281",
                "title": "LLMs Get a Speed Boost: Prefixing Their Way to Faster Reasoning!",
                "institute": "Shanghai Jiao Tong University, Microsoft",
                "text": "This paper introduces \"path-consistency,\" a method that leverages the confidence of answers generated in earlier branches to identify the prefix of the most promising path. This approach dynamically guides the generation of subsequent branches, reducing both errors and redundancies from random or less useful sampling in self-consistency.",
                "paper-title": "Path-Consistency: Prefix Enhancement for Efficient Inference in LLM",
                "image-path": ""
            },

            {
                "startTime": "39:49",
                "arxivId": "2409.01089",
                "arxivLink": "https://arxiv.org/abs/2409.01089",
                "title": "Deep Learning on Mobile Devices: A Framework That's Always Ready to Adapt!",
                "institute": "National Technical University of Athens, Samsung",
                "text": "This research introduces CARIn, a framework that optimizes deep learning (DL) applications on mobile devices by generating a set of execution configurations that anticipate and adapt to runtime fluctuations. This differs from previous work that typically focuses on finding a single optimal configuration.",
                "paper-title": "CARIn: Constraint-Aware and Responsive Inference on Heterogeneous Devices for Single- and Multi-DNN Workloads",
                "image-path": ""
            },

            {
                "startTime": "40:16",
                "arxivId": "2409.00137",
                "arxivLink": "https://arxiv.org/abs/2409.00137",
                "title": "AI Jailbreak: Multi-Turn Attacks Are the New Escape Route!",
                "institute": "University of California Berkeley, Stanford University, Georgia Institute of Technology...",
                "text": "This research introduces a new dataset and framework for studying multi-turn jailbreak attacks on large language models (LLMs). Unlike previous work that focused on single-turn attacks, this study explores how malicious instructions can be spread across multiple prompts, potentially bypassing safety measures.",
                "paper-title": "Emerging Vulnerabilities in Frontier Models: Multi-Turn Jailbreak Attacks",
                "image-path": ""
            },

            {
                "startTime": "40:43",
                "arxivId": "2409.01447",
                "arxivLink": "https://arxiv.org/abs/2409.01447",
                "title": "Zero-Sum Games: When AI Learns to Play Nice (and Win!)",
                "institute": "Purdue University, University of Maryland, Caltech...",
                "text": "This research focuses on developing independent learning dynamics for two-player zero-sum games, both matrix and stochastic, with provable last-iterate finite-sample guarantees. Unlike previous work, this study achieves polynomial sample complexity for finding a Nash equilibrium in both settings.",
                "paper-title": "Last-Iterate Convergence of Payoff-Based Independent Learning in Zero-Sum Stochastic Games",
                "image-path": ""
            },

            {
                "startTime": "41:10",
                "arxivId": "2409.00853",
                "arxivLink": "https://arxiv.org/abs/2409.00853",
                "title": "Robots Learn to Farm, Code, and Communicate: A New AI Simulation Evolves Culture",
                "institute": "University of Oxford",
                "text": "This research differs from previous work by focusing on the evolution of higher-level cognitive abilities, such as cultural accumulation, in an open-ended simulation. Instead of modeling low-level processes like physics or chemistry, the researchers created an environment where agents can interact with programmable robots, allowing them to develop complex behaviors like tool use and communication.",
                "paper-title": "JaxLife: An Open-Ended Agentic Simulator",
                "image-path": ""
            },

            {
                "startTime": "41:34",
                "arxivId": "2409.02026",
                "arxivLink": "https://arxiv.org/abs/2409.02026",
                "title": "LLMs on a Diet: How to Slim Down Your Language Model Without Losing Its Smarts",
                "institute": "MIT",
                "text": "This paper proposes a new method for compressing large language models (LLMs) by quantizing their weights using a convex optimization framework. Unlike previous methods that rely on heuristics or approximations, this approach aims to find the optimal bit depth for each weight matrix to minimize prediction accuracy loss.",
                "paper-title": "Foundations of Large Language Model Compression -- Part 1: Weight Quantization",
                "image-path": ""
            },

            {
                "startTime": "42:02",
                "arxivId": "2409.00015",
                "arxivLink": "https://arxiv.org/abs/2409.00015",
                "title": "AI's Got a License to Learn: Dynamic Certification for Responsible Robots",
                "institute": "Universitat Polit\u00e8cnica de Catalunya, University of California San Diego, The University of Texas at Austin",
                "text": "This paper proposes a dynamic certification framework for embodied AI systems, which differs from traditional static certification by allowing for continuous evaluation and adjustment of the system's operational envelope based on real-world performance.",
                "paper-title": "Navigating the sociotechnical labyrinth: Dynamic certification for responsible embodied AI",
                "image-path": ""
            },

            {
                "startTime": "42:30",
                "arxivId": "2409.00084",
                "arxivLink": "https://arxiv.org/abs/2409.00084",
                "title": "LLMs: Gastroenterology's New BFFs? (But They Can't See!)",
                "institute": "Icahn School of Medicine at Mount Sinai, University of Texas Health, Virginia Hospital Center...",
                "text": "This study evaluates the performance of large language models (LLMs) and vision-language models (VLMs) on gastroenterology board exams, focusing on the impact of model configurations, prompt engineering, and the integration of visual data. It differs from previous work by specifically examining the performance of VLMs on image-containing questions, a previously unexplored area in medical reasoning.",
                "paper-title": "Vision-Language and Large Language Model Performance in Gastroenterology: GPT, Claude, Llama, Phi, Mistral, Gemma, and Quantized Models",
                "image-path": ""
            },

            {
                "startTime": "42:57",
                "arxivId": "2409.00112",
                "arxivLink": "https://arxiv.org/abs/2409.00112",
                "title": "GPT-4 as Therapist: Can AI Really Help You Solve Your Problems?",
                "institute": "University of Washington, Dartmouth College",
                "text": "This study explores the use of prompt engineering to improve the performance of Large Language Models (LLMs) in delivering Problem-Solving Therapy (PST), focusing on the symptom identification and goal-setting phases. Unlike previous work that focused on fine-tuning LLMs for specific tasks, this research investigates the potential of prompt engineering as a more efficient and resource-friendly approach.",
                "paper-title": "Toward Large Language Models as a Therapeutic Tool: Comparing Prompting Techniques to Improve GPT-Delivered Problem-Solving Therapy",
                "image-path": ""
            },

            {
                "startTime": "43:18",
                "arxivId": "2409.00103",
                "arxivLink": "https://arxiv.org/abs/2409.00103",
                "title": "LLMs: Causal Reasoning's New Consistency Crisis?",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, University of Waterloo",
                "text": "This research introduces the concept of \"causal epistemic consistency\" to evaluate how well LLMs can differentiate between subtle variations in causal reasoning. It goes beyond simply identifying the existence of a causal relationship and focuses on the nuanced impact of intermediate factors.",
                "paper-title": "Nuance Matters: Probing Epistemic Consistency in Causal Reasoning",
                "image-path": ""
            },

            {
                "startTime": "43:40",
                "arxivId": "2409.01293",
                "arxivLink": "https://arxiv.org/abs/2409.01293",
                "title": "Chaos to Clarity: A New Method for Taming Dynamical Systems",
                "institute": "Harvard University",
                "text": "This research builds upon the MAGI method for analyzing dynamical systems, introducing a novel approach called PilotMAGI (pMAGI) that significantly improves numerical stability and accuracy in parameter inference and trajectory reconstruction.",
                "paper-title": "Extracting Signal out of Chaos: Advancements on MAGI for Bayesian Analysis of Dynamical Systems",
                "image-path": ""
            },

            {
                "startTime": "44:06",
                "arxivId": "2409.02069",
                "arxivLink": "https://arxiv.org/abs/2409.02069",
                "title": "Brushing Up on AI: How a Smart Toothbrush Learned to Motivate Patients",
                "institute": "Harvard University, Imperial College London, University of Michigan...",
                "text": "This research focuses on deploying an online reinforcement learning algorithm as part of a mHealth intervention in a registered clinical trial, addressing the unique challenges of this setting.",
                "paper-title": "A Deployed Online Reinforcement Learning Algorithm In An Oral Health Clinical Trial",
                "image-path": ""
            },

            {
                "startTime": "44:35",
                "arxivId": "2409.00438",
                "arxivLink": "https://arxiv.org/abs/2409.00438",
                "title": "Financial News: Not Just Chatter, It's a Hypergraph!",
                "institute": "University of Cambridge, Durham University",
                "text": "This research uses a geometric hypergraph attention network (GHAN) to analyze the impact of financial news on stock prices. Unlike traditional graph-based models, hypergraphs can capture complex, multi-entity interactions, such as the simultaneous impact of a single news event on multiple stocks.",
                "paper-title": "Breaking Down Financial News Impact: A Novel AI Approach with Geometric Hypergraphs",
                "image-path": ""
            },

            {
                "startTime": "45:00",
                "arxivId": "2409.00696",
                "arxivLink": "https://arxiv.org/abs/2409.00696",
                "title": "Rating LLMs: A Fairer, Cheaper, and More Nuanced Approach",
                "institute": "ETH Zurich",
                "text": "This paper introduces POLYRATING, a new rating system for LLMs that accounts for biases in human and LLM-based evaluations. Unlike previous systems, POLYRATING models shared features and biases, allowing for more accurate and nuanced comparisons of model performance across different tasks.",
                "paper-title": "Polyrating: A Cost-Effective and Bias-Aware Rating System for LLM Evaluation",
                "image-path": ""
            },

            {
                "startTime": "45:23",
                "arxivId": "2409.00717",
                "arxivLink": "https://arxiv.org/abs/2409.00717",
                "title": "Teaching AI to Play Nice: How Human Feedback Can Tame Multi-Agent Chaos",
                "institute": "University of Washington, Harvard University",
                "text": "This research focuses on multi-agent reinforcement learning from human feedback (MARLHF), a new area that explores how to train multiple AI agents to cooperate or compete effectively based on human preferences. Unlike previous work that focused on single-agent RLHF, this paper investigates the unique challenges and requirements for training multiple agents simultaneously.",
                "paper-title": "Multi-Agent Reinforcement Learning from Human Feedback: Data Coverage and Algorithmic Techniques",
                "image-path": ""
            },

            {
                "startTime": "45:48",
                "arxivId": "2409.00129",
                "arxivLink": "https://arxiv.org/abs/2409.00129",
                "title": "Minishogi's State-Space: A 2.38 x 10^18 Position Puzzle!",
                "institute": "The University of Tokyo",
                "text": "This research estimates the number of reachable positions in Minishogi using a statistical sampling method, unlike previous studies that focused on precise calculations or strict bounds.",
                "paper-title": "Estimating the number of reachable positions in Minishogi",
                "image-path": ""
            },

            {
                "startTime": "46:13",
                "arxivId": "2409.00391",
                "arxivLink": "https://arxiv.org/abs/2409.00391",
                "title": "Depressed? Don't Worry, Your Voice Can Tell Us!",
                "institute": "CMU, San Diego State University",
                "text": "This research introduces two new models, DAAMAudioCNNLSTM and DAAMAudioTransformer, which use a Density Adaptive Attention Mechanism (DAAM) to focus on the most informative parts of speech signals for depression detection. This approach differs from previous work by dynamically weighting features based on their importance, leading to more accurate and explainable results.",
                "paper-title": "Density Adaptive Attention-based Speech Network: Enhancing Feature Understanding for Mental Health Disorders",
                "image-path": ""
            },

            {
                "startTime": "46:39",
                "arxivId": "2409.00729",
                "arxivLink": "https://arxiv.org/abs/2409.00729",
                "title": "Can We Pinpoint What Makes LLMs Say What They Say?",
                "institute": "MIT",
                "text": "This paper introduces the concept of \"context attribution,\" which aims to identify the specific parts of the context that cause a language model to generate a particular statement. Unlike previous work that focuses on teaching models to generate citations, this method directly identifies the sources the model actually uses.",
                "paper-title": "ContextCite: Attributing Model Generation to Context",
                "image-path": ""
            },

            {
                "startTime": "47:05",
                "arxivId": "2409.01712",
                "arxivLink": "https://arxiv.org/abs/2409.01712",
                "title": "GWAS Gets a Speed Boost: Mixed Precision Makes Epistasis Analysis a Breeze!",
                "institute": "King Abdullah University of Science and Technology, MIT, Saint Louis University...",
                "text": "This research introduces a novel mixed-precision approach for Kernel Ridge Regression (KRR) in Genome-Wide Association Studies (GWAS). Unlike previous methods that rely on single precision, this approach leverages multiple precisions, including INT8 and FP8, to accelerate computations while maintaining accuracy.",
                "paper-title": "Toward Capturing Genetic Epistasis From Multivariate Genome-Wide Association Studies Using Mixed-Precision Kernel Ridge Regression",
                "image-path": ""
            },

            {
                "startTime": "47:31",
                "arxivId": "2409.00163",
                "arxivLink": "https://arxiv.org/abs/2409.00163",
                "title": "Deep Learning Predicts Esophageal Cancer Recurrence: A New Recipe for Personalized Treatment",
                "institute": "University of Oxford",
                "text": "This research uses deep neural networks to predict disease-free survival and overall survival in patients with esophageal cancer after surgery. Unlike previous studies that relied on single-center data, this study utilizes a large, multicenter dataset, making the findings more generalizable.",
                "paper-title": "Deep Neural Networks for Predicting Recurrence and Survival in Patients with Esophageal Cancer After Surgery",
                "image-path": ""
            },

            {
                "startTime": "47:51",
                "arxivId": "2409.01477",
                "arxivLink": "https://arxiv.org/abs/2409.01477",
                "title": "Reinforcement Learning's New Trick: Zeroth-Order Gradient Magic",
                "institute": "Yale University",
                "text": "This paper introduces a new actor-critic algorithm called Compatible Policy Gradient (CPG) that uses a zeroth-order approximation of the action-value gradient. This approach avoids the need for precise gradient computations, which is a common challenge in deterministic policy gradient (DPG) methods.",
                "paper-title": "Compatible Gradient Approximations for Actor-Critic Algorithms",
                "image-path": ""
            },

            {
                "startTime": "48:25",
                "arxivId": "2409.01564",
                "arxivLink": "https://arxiv.org/abs/2409.01564",
                "title": "Spiking Neural Networks Get a Temporal Boost: Key-Residual Frames for Action Recognition!",
                "institute": "Yale University",
                "text": "This research proposes ReSpike, a hybrid neural network architecture that combines the strengths of Artificial Neural Networks (ANNs) and Spiking Neural Networks (SNNs) for action recognition. Unlike previous work that primarily focused on static image tasks, ReSpike leverages the temporal information in video clips by decomposing them into key frames (for spatial information) and residual frames (for temporal information).",
                "paper-title": "ReSpike: Residual Frames-based Hybrid Spiking Neural Networks for Efficient Action Recognition",
                "image-path": ""
            },

            {
                "startTime": "48:49",
                "arxivId": "2409.02078",
                "arxivLink": "https://arxiv.org/abs/2409.02078",
                "title": "Political Text Analysis: Tiny Models, Big Results!",
                "institute": "Princeton University, The Pennsylvania State University, Louisiana State University",
                "text": "This research introduces two open-source language models, Political DEBATE Large and Base, specifically trained for zero-shot and few-shot classification of political text. Unlike previous work that relies on large, proprietary models, these models are significantly smaller and more efficient, yet achieve comparable or even better performance.",
                "paper-title": "Political DEBATE: Efficient Zero-shot and Few-shot Classifiers for Political Text",
                "image-path": ""
            },

            {
                "startTime": "49:13",
                "arxivId": "2409.01668",
                "arxivLink": "https://arxiv.org/abs/2409.01668",
                "title": "One-Shot Voice Conversion: A Pure Transformer Trick for Mimicking Voices",
                "institute": "Xiangtan University, Peking University",
                "text": "This research proposes Pureformer-VC, a voice conversion framework that uses Conformer and Zipformer blocks for disentangled encoding and style transfer. Unlike previous methods, it relies on a pure transformer architecture and incorporates a triplet loss for discriminative training.",
                "paper-title": "Pureformer-VC: Non-parallel One-Shot Voice Conversion with Pure Transformer Blocks and Triplet Discriminative Training",
                "image-path": ""
            },

            {
                "startTime": "49:36",
                "arxivId": "2409.00993",
                "arxivLink": "https://arxiv.org/abs/2409.00993",
                "title": "LLMs Learn to Gossip: How AI Agents Develop Social Norms Through Chat",
                "institute": "University of Tokyo",
                "text": "This research explores the emergence of social norms in LLMs through natural language interactions, going beyond simple choices like \"cooperate\" or \"defect\" and allowing for more complex strategies and discussions.",
                "paper-title": "Evolution of Social Norms in LLM Agents using Natural Language",
                "image-path": ""
            },

            {
                "startTime": "50:01",
                "arxivId": "2409.00313",
                "arxivLink": "https://arxiv.org/abs/2409.00313",
                "title": "Sketchy Business: Training-Free Diffusion Model Makes Images Look Like You Drew Them!",
                "institute": "University of Tokyo",
                "text": "This paper proposes a training-free method for incorporating sketches as guidance in image generation using pre-trained diffusion models. Unlike previous methods that rely on additional training or fine-tuning, this approach leverages the cross-attention maps of diffusion models to track the layout and structure features of sketches, enabling the generation of images that closely resemble the input sketch.",
                "paper-title": "Training-Free Sketch-Guided Diffusion with Latent Optimization",
                "image-path": ""
            },

            {
                "startTime": "50:22",
                "arxivId": "2409.01138",
                "arxivLink": "https://arxiv.org/abs/2409.01138",
                "title": "Fake Satellite Images: Can You Tell the Real Deal From the Deep Fake?",
                "institute": "Berlin University of Applied Sciences, Einstein Center Digital Future, Princeton University",
                "text": "This research focuses on generating synthetic satellite imagery of rare objects, specifically nuclear power plants. Unlike previous work, it investigates the effectiveness of using both textual and image input to guide the generation process, and it compares the results of different models with human perception.",
                "paper-title": "Generating Synthetic Satellite Imagery for Rare Objects: An Empirical Comparison of Models and Metrics",
                "image-path": ""
            },

            {
                "startTime": "50:46",
                "arxivId": "2409.00301",
                "arxivLink": "https://arxiv.org/abs/2409.00301",
                "title": "Driving in the Dark? No Problem! New AI Can See Through Rain, Snow, and Even Tunnels!",
                "institute": "CMU",
                "text": "This research proposes a new framework called ContextVLM that uses vision-language models (VLMs) to detect driving contexts, such as weather, lighting, and traffic conditions, in autonomous vehicles. Unlike traditional supervised learning approaches, ContextVLM leverages zero-shot and few-shot learning, reducing the need for large, class-balanced, and context-annotated datasets.",
                "paper-title": "ContextVLM: Zero-Shot and Few-Shot Context Understanding for Autonomous Driving using Vision Language Models",
                "image-path": ""
            },

            {
                "startTime": "51:16",
                "arxivId": "2409.01574",
                "arxivLink": "https://arxiv.org/abs/2409.01574",
                "title": "Parallel Tempering Gets a Brain: Policy Gradients for Optimal MCMC",
                "institute": "Harvard University",
                "text": "This paper introduces a novel reinforcement learning approach to optimize parallel tempering MCMC. Unlike previous adaptive methods that focus on achieving uniform acceptance rates, this work explores alternative reward formulations and proposes a new metric based on the distance between swapped states.",
                "paper-title": "Policy Gradients for Optimal Parallel Tempering MCMC",
                "image-path": ""
            },

            {
                "startTime": "51:42",
                "arxivId": "2409.00768",
                "arxivLink": "https://arxiv.org/abs/2409.00768",
                "title": "Super-Resolution: Low-Res Images, High-Res Results?",
                "institute": "National Institute of Advanced Industrial Science and Technology, Keio University, University of Tsukuba...",
                "text": "This research challenges the common assumption that high-resolution images are essential for training image super-resolution (SR) models. The authors propose a new dataset, DiverSeg, constructed from low-resolution images, demonstrating that SR models can achieve comparable or even better performance than those trained on high-resolution datasets.",
                "paper-title": "Rethinking Image Super-Resolution from Training Data Perspectives",
                "image-path": ""
            },

            {
                "startTime": "52:03",
                "arxivId": "2409.00393",
                "arxivLink": "https://arxiv.org/abs/2409.00393",
                "title": "Neural Networks Learn to Control, But Can They Stay Stable?",
                "institute": "UC Berkeley",
                "text": "This research introduces a new approach called Lyapunov-NODE Control (L-NODEC) for learning control policies in continuous-time optimal control problems. Unlike previous methods, L-NODEC incorporates a Lyapunov condition into the learning process, ensuring the stability of the controlled system.",
                "paper-title": "Lyapunov Neural ODE Feedback Control Policies",
                "image-path": ""
            },

            {
                "startTime": "52:23",
                "arxivId": "2409.01985",
                "arxivLink": "https://arxiv.org/abs/2409.01985",
                "title": "Denoising Without a Clue: How to Clean Up Noisy Images When You Don't Know the Noise Level",
                "institute": "CNRS, ENS de Lyon, University of Edinburgh...",
                "text": "This research introduces a new self-supervised learning method called UNSURE, which can denoise images without requiring knowledge of the noise level. Unlike previous methods that either assume full knowledge of the noise distribution or rely on cross-validation techniques, UNSURE leverages the concept of divergence-free estimators, which are less constrained and more expressive.",
                "paper-title": "UNSURE: Unknown Noise level Stein's Unbiased Risk Estimator",
                "image-path": ""
            },

            {
                "startTime": "52:53",
                "arxivId": "2409.00269",
                "arxivLink": "https://arxiv.org/abs/2409.00269",
                "title": "Your Brain, My Brain: How AI Can Tell If We Think Alike",
                "institute": "CMU",
                "text": "This research introduces a new method for measuring subjective similarity between human-written and AI-generated content. Unlike previous approaches that rely on large datasets and machine learning, this method uses a cognitive model to predict individual preferences and biases.",
                "paper-title": "Leveraging a Cognitive Model to Measure Subjective Similarity of Human and GPT-4 Written Content",
                "image-path": ""
            },

            {
                "startTime": "53:15",
                "arxivId": "2409.00025",
                "arxivLink": "https://arxiv.org/abs/2409.00025",
                "title": "Power Quality Problems? Vision Transformers to the Rescue!",
                "institute": "University of Connecticut, Concordia University, University of Toronto...",
                "text": "This research uses a Vision Transformer (ViT) model to classify power quality disturbances (PQDs), a novel approach compared to previous methods that relied on hand-crafted features or convolutional neural networks (CNNs).",
                "paper-title": "A Novel Approach to Classify Power Quality Signals Using Vision Transformers",
                "image-path": ""
            },

            {
                "startTime": "53:40",
                "arxivId": "2409.01217",
                "arxivLink": "https://arxiv.org/abs/2409.01217",
                "title": "Low-Resource Languages Get a Voice: Multilingual TTS Makes a Splash!",
                "institute": "Mohammed V University in Rabat, International University of Rabat, University of Leeds...",
                "text": "This research explores the use of multilingual pre-training for Text-to-Speech (TTS) systems in low-resource languages. Unlike previous work that primarily focused on monolingual transfer learning, this study investigates the benefits of leveraging data from multiple languages, including those from different language families.",
                "paper-title": "A multilingual training strategy for low resource Text to Speech",
                "image-path": ""
            },

            {
                "startTime": "54:11",
                "arxivId": "2409.01245",
                "arxivLink": "https://arxiv.org/abs/2409.01245",
                "title": "Safe Exploration in RL: Consecutive Cost Steps Tell the Tale!",
                "institute": "University of Freiburg",
                "text": "This research introduces a new metric called Expected Maximum Consecutive Cost steps (EMCC) to evaluate safe exploration in reinforcement learning (RL) algorithms. Unlike previous metrics that focus on overall cost, EMCC considers the severity of unsafe actions based on their consecutive occurrences during training.",
                "paper-title": "Revisiting Safe Exploration in Safe Reinforcement learning",
                "image-path": ""
            },

            {
                "startTime": "54:35",
                "arxivId": "2409.00606",
                "arxivLink": "https://arxiv.org/abs/2409.00606",
                "title": "Style Transfer Showdown: Neural Networks vs. Patchwork Art",
                "institute": "University of Illinois, Washington University in St. Louis, Georgia Institute of Technology...",
                "text": "This research compares traditional style transfer methods, which rely on stitching together image patches, with a modern deep-learning approach that uses segmentation to isolate foreground objects and apply style transfer only to the background.",
                "paper-title": "Style Transfer: From Stitching to Neural Networks",
                "image-path": ""
            },

            {
                "startTime": "55:03",
                "arxivId": "2409.00721",
                "arxivLink": "https://arxiv.org/abs/2409.00721",
                "title": "Chatbots Go to the Polls: Who Would ChatGPT Vote For?",
                "institute": "Czech University of Life Sciences Prague",
                "text": "This study distinguishes itself by focusing on the political bias of ChatGPT and Gemini in the context of the 2024 European Parliament elections, using a standardized prompt across all 27 EU member states.",
                "paper-title": "Who Would Chatbots Vote For? Political Preferences of ChatGPT and Gemini in the 2024 European Union Elections",
                "image-path": ""
            },

            {
                "startTime": "55:20",
                "arxivId": "2409.00869",
                "arxivLink": "https://arxiv.org/abs/2409.00869",
                "title": "Robot Butler: Deep Learning Makes Tabletop Tidying a Breeze!",
                "institute": "University of California Berkeley, University of Michigan, Massachusetts Institute of Technology...",
                "text": "This research focuses on using deep learning to estimate the orientation of objects on a tabletop, which is a unique application compared to previous work that primarily focused on object recognition and 3D pose estimation.",
                "paper-title": "Detection, Recognition and Pose Estimation of Tabletop Objects",
                "image-path": ""
            },

            {
                "startTime": "55:44",
                "arxivId": "2409.01407",
                "arxivLink": "https://arxiv.org/abs/2409.01407",
                "title": "Cosmological Data Fusion: Flowing Through the Nuisance Parameters",
                "institute": "University of Oxford",
                "text": "This research proposes using normalising flows to emulate marginal posterior distributions of cosmological parameters, allowing for efficient combination of constraints from independent datasets without increasing the dimensionality of the parameter space. This differs from previous work that often relies on sampling over the full joint parameter space, which can be computationally expensive.",
                "paper-title": "$\mathtt{emuflow}$: Normalising Flows for Joint Cosmological Analysis",
                "image-path": ""
            },

            {
                "startTime": "56:03",
                "arxivId": "2409.00128",
                "arxivLink": "https://arxiv.org/abs/2409.00128",
                "title": "Can AI Pass the Psych 101 Test? LLMs Put to the Test in a Big Way!",
                "institute": "Tsinghua University",
                "text": "This research stands out by replicating a large number of psychological experiments using GPT-4, a powerful language model, as a simulated participant. It goes beyond previous studies that focused on specific experiments or assessments, providing a broader understanding of LLMs' capabilities in replicating human responses across diverse psychological contexts.",
                "paper-title": "Can AI Replace Human Subjects? A Large-Scale Replication of Psychological Experiments with LLMs",
                "image-path": ""
            },

            {
                "startTime": "56:25",
                "arxivId": "2409.00608",
                "arxivLink": "https://arxiv.org/abs/2409.00608",
                "title": "TinyAgent: Siri on Steroids, But It Lives on Your Mac!",
                "institute": "UC Berkeley, ICSI",
                "text": "This research focuses on training smaller language models (SLMs) for function calling, a key component of agentic systems, and deploying them locally on devices like Macbooks. This differs from previous work that primarily focused on large models requiring cloud infrastructure.",
                "paper-title": "TinyAgent: Function Calling at the Edge",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 135,
        "num_total": 734,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202409042340_audio.mp3"
}
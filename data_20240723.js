
daily_data = {
    "date": "2024-07-23",
    "tweets": [
            {
                "startTime": "00:46",
                "arxivId": "2407.15850",
                "arxivLink": "https://arxiv.org/abs/2407.15850",
                "title": "Zero-Shot Audio Description: Training-Free, But Still Awesome!",
                "institute": "University of Oxford, \u00c9cole des Ponts ParisTech, Shanghai Jiao Tong University",
                "text": "This research proposes a training-free method for generating audio descriptions (ADs) for movies and TV series. Unlike previous approaches that rely on fine-tuning large models on AD datasets, this method leverages pre-trained visual-language models (VLMs) and large language models (LLMs) with novel visual and text prompting strategies.",
                "paper-title": "AutoAD-Zero: A Training-Free Framework for Zero-Shot Audio Description",
                "image-path": ""
            },

            {
                "startTime": "01:17",
                "arxivId": "2407.15838",
                "arxivLink": "https://arxiv.org/abs/2407.15838",
                "title": "Tired of Vision-Language Models Hallucinating? MMInstruct to the Rescue!",
                "institute": "Tsinghua University",
                "text": "This research introduces MMInstruct, a visual instruction tuning dataset that addresses limitations in existing datasets by focusing on instruction annotation quality, instruction and image diversity, and cost-effectiveness. Unlike previous datasets that rely heavily on automatic generation, MMInstruct leverages a semi-automatic data engine that combines GPT-4V, GPT-3.5, and manual correction to ensure high-quality and diverse instructions.",
                "paper-title": "MMInstruct: A High-Quality Multi-Modal Instruction Tuning Dataset with Extensive Diversity",
                "image-path": ""
            },

            {
                "startTime": "01:45",
                "arxivId": "2407.15208",
                "arxivLink": "https://arxiv.org/abs/2407.15208",
                "title": "Robots Learn New Tricks with Flow-Based Manipulation!",
                "institute": "Stanford University, Columbia University, J.P. Morgan AI Research...",
                "text": "This research introduces Im2Flow2Act, a framework that uses object flow as a unifying interface to bridge the gap between human demonstrations and simulated robot data. Unlike previous work that relies on either real-world robot data or task-specific simulations, Im2Flow2Act leverages both cross-embodiment videos and simulated robot play data, enabling robots to learn new manipulation skills more efficiently.",
                "paper-title": "Flow as the Cross-Domain Manipulation Interface",
                "image-path": ""
            },

            {
                "startTime": "02:16",
                "arxivId": "2407.15680",
                "arxivLink": "https://arxiv.org/abs/2407.15680",
                "title": "Visual Hallucinations: When AI Sees Things That Aren't There!",
                "institute": "Google",
                "text": "This research introduces HaloQuest, a new dataset for evaluating and mitigating visual hallucinations in vision-language models (VLMs). Unlike previous datasets, HaloQuest leverages both real and synthetic images, allowing for a more comprehensive and scalable evaluation of VLM performance.",
                "paper-title": "HaloQuest: A Visual Hallucination Dataset for Advancing Multimodal Reasoning",
                "image-path": ""
            },

            {
                "startTime": "02:38",
                "arxivId": "2407.15211",
                "arxivLink": "https://arxiv.org/abs/2407.15211",
                "title": "Image Jailbreaks: Can You Trick a Vision-Language Model?",
                "institute": "Stanford University, Anthropic",
                "text": "This research investigates the transferability of image-based \"jailbreaks\" against vision-language models (VLMs), a type of AI that processes both text and images. Unlike previous work that focused on text-based attacks, this study explores the effectiveness of adversarial images in manipulating VLMs.",
                "paper-title": "When Do Universal Image Jailbreaks Transfer Between Vision-Language Models?",
                "image-path": ""
            },

            {
                "startTime": "03:09",
                "arxivId": "2407.15229",
                "arxivLink": "https://arxiv.org/abs/2407.15229",
                "title": "Stop the Presses! New AI Alignment Method Makes LLMs More Concise and Less Prone to Overfitting!",
                "institute": "University of Southern California, Microsoft, Information Sciences Institute",
                "text": "This research focuses on the robustness of preference optimization (*PO) methods for aligning large language models (LLMs) with human preferences. Unlike previous work that primarily focused on finding the best-performing *PO* method through extensive hyperparameter searches, this paper investigates the stability of different *PO* methods across a range of hyperparameters.",
                "paper-title": "The Hitchhiker's Guide to Human Alignment with *PO",
                "image-path": ""
            },

            {
                "startTime": "03:35",
                "arxivId": "2407.14717",
                "arxivLink": "https://arxiv.org/abs/2407.14717",
                "title": "Cross-Attention Gets a Privacy Makeover: New Algorithm Keeps Your Secrets Safe!",
                "institute": "Adobe, University of Hong Kong, University of Wisconsin-Madison...",
                "text": "This research introduces a novel data structure, DPTreeSoftmaxAdaptive, that provides a provable guarantee for differential privacy in cross-attention computations. Unlike previous work that focused on empirical methods, this paper offers a theoretical framework for privacy protection in large generative models.",
                "paper-title": "Differential Privacy of Cross-Attention with Provable Guarantee",
                "image-path": ""
            },

            {
                "startTime": "04:03",
                "arxivId": "2407.15754",
                "arxivLink": "https://arxiv.org/abs/2407.15754",
                "title": "Hour-Long Videos? No Problem! New Benchmark Tests AI's Long-Term Memory",
                "institute": "Google, Stanford University, University of California Berkeley...",
                "text": "This research introduces LONGVIDEOBENCH, a new benchmark for evaluating large multimodal models (LMMs) on their ability to understand long-duration videos. Unlike previous benchmarks that focus on short videos or summary-level tasks, LONGVIDEOBENCH specifically targets the challenge of understanding detailed multimodal information from videos that can be up to an hour long.",
                "paper-title": "LongVideoBench: A Benchmark for Long-context Interleaved Video-Language Understanding",
                "image-path": ""
            },

            {
                "startTime": "04:29",
                "arxivId": "2407.14679",
                "arxivLink": "https://arxiv.org/abs/2407.14679",
                "title": "Shrinking Super Brains: How to Make Tiny Language Models That Still Know Everything!",
                "institute": "Nvidia",
                "text": "This research explores a new approach to creating smaller language models by pruning an existing large model and retraining it with a fraction of the original data. Unlike previous work that focuses on either depth or width pruning, this study investigates the effectiveness of combining both techniques.",
                "paper-title": "Compact Language Models via Pruning and Knowledge Distillation",
                "image-path": ""
            },

            {
                "startTime": "04:57",
                "arxivId": "2407.14916",
                "arxivLink": "https://arxiv.org/abs/2407.14916",
                "title": "Stop Saying \"Pineapple on Pizza is Bad!\" New Research Shows Context is King!",
                "institute": "University of Toronto, Microsoft Research, Johns Hopkins University...",
                "text": "This research proposes a two-step approach to preference modeling for language models, first identifying the context and then evaluating preference within that context. This differs from previous work that directly models preference without explicitly considering context.",
                "paper-title": "Improving Context-Aware Preference Modeling for Language Models",
                "image-path": ""
            },

            {
                "startTime": "05:27",
                "arxivId": "2407.15078",
                "arxivLink": "https://arxiv.org/abs/2407.15078",
                "title": "Neural Network Compilers: Turning Code into AI!",
                "institute": "MIT",
                "text": "This research introduces a new technique called \"neural surrogate compilation\" which directly compiles program text into neural networks, bypassing the traditional approach of training on input-output pairs.",
                "paper-title": "Learning to Compile Programs to Neural Networks",
                "image-path": ""
            },

            {
                "startTime": "05:53",
                "arxivId": "2407.14681",
                "arxivLink": "https://arxiv.org/abs/2407.14681",
                "title": "Learning to Want What They Want: How AI Internalizes Social Values",
                "institute": "Stanford University, University of Washington",
                "text": "This paper introduces a novel model of value internalization in reinforcement learning agents, where an agent learns to generate internal rewards based on social feedback from a caregiver, enabling it to persist in goal-directed behavior even when the caregiver is absent. This differs from previous work by explicitly modeling the process of internalizing social rewards and its impact on generalization and continual learning.",
                "paper-title": "Value Internalization: Learning and Generalizing from Social Reward",
                "image-path": ""
            },

            {
                "startTime": "06:19",
                "arxivId": "2407.15806",
                "arxivLink": "https://arxiv.org/abs/2407.15806",
                "title": "Fingerspelling for Smartphones: A 3 Million Character Dataset for Sign Language Recognition",
                "institute": "Google",
                "text": "This research presents FSboard, a dataset of over 3 million characters of American Sign Language (ASL) fingerspelling collected from 147 Deaf signers using smartphone cameras. This dataset is significantly larger than previous fingerspelling datasets and is specifically designed for a mobile text entry use case.",
                "paper-title": "FSboard: Over 3 million characters of ASL fingerspelling collected via smartphones",
                "image-path": ""
            },

            {
                "startTime": "06:49",
                "arxivId": "2407.14622",
                "arxivLink": "https://arxiv.org/abs/2407.14622",
                "title": "BOND: Making LLMs Smarter, One Sample at a Time!",
                "institute": "Google",
                "text": "This paper proposes BOND, a new RLHF algorithm that aims to achieve the quality of Best-of-N sampling without the computational overhead. It does this by distilling the Best-of-N strategy into the policy through online distribution matching.",
                "paper-title": "BOND: Aligning LLMs with Best-of-N Distillation",
                "image-path": ""
            },

            {
                "startTime": "07:09",
                "arxivId": "2407.15018",
                "arxivLink": "https://arxiv.org/abs/2407.15018",
                "title": "Transformers: They're Not Just for Language Models Anymore!",
                "institute": "Allen Institute for AI, University of Washington, Technion",
                "text": "This research investigates how transformer language models answer formatted multiple-choice questions, focusing on the specific mechanisms responsible for selecting the correct answer symbol. Unlike previous work, this study uses vocabulary projection and activation patching to pinpoint the causal role of individual layers and attention heads in the prediction process.",
                "paper-title": "Answer, Assemble, Ace: Understanding How Transformers Answer Multiple Choice Questions",
                "image-path": ""
            },

            {
                "startTime": "07:40",
                "arxivId": "2407.14957",
                "arxivLink": "https://arxiv.org/abs/2407.14957",
                "title": "Neural Networks Learn to Warp Space: A New Way to Match Data in Different Dimensions",
                "institute": "ETH Zurich",
                "text": "This paper introduces a novel neural framework for learning optimal transport maps between distributions supported on spaces of different dimensionality. Unlike previous methods that rely on comparable spaces, this approach leverages the concept of strong isomorphism to decompose the transport map into two components: an isomorphism and a Gromov-Monge optimal map.",
                "paper-title": "Strongly Isomorphic Neural Optimal Transport Across Incomparable Spaces",
                "image-path": ""
            },

            {
                "startTime": "08:10",
                "arxivId": "2407.14779",
                "arxivLink": "https://arxiv.org/abs/2407.14779",
                "title": "AI's Indian Fashion Faux Pas: When Sarees Become Stereotypes",
                "institute": "University of Washington, Pennsylvania State University",
                "text": "This research investigates the impact of text-to-image generators on the representation of non-Western cultures, specifically focusing on Indian contexts. Unlike previous work, it uses a community-centered approach to identify novel forms of representational harm, such as exoticism and cultural misappropriation.",
                "paper-title": "Do Generative AI Models Output Harm while Representing Non-Western Cultures: Evidence from A Community-Centered Approach",
                "image-path": ""
            },

            {
                "startTime": "08:37",
                "arxivId": "2407.15703",
                "arxivLink": "https://arxiv.org/abs/2407.15703",
                "title": "Astronomers Teach AI to See Stars, Not Just Their Shadows!",
                "institute": "University of Toronto",
                "text": "This research combines a Transformer model, commonly used for language processing, with a Denoising Diffusion Probabilistic Model (DDPM) to estimate probability density distributions for astronomical data. This approach differs from previous work that primarily focused on predicting scalar values with Gaussian uncertainty.",
                "paper-title": "Estimating Probability Densities with Transformer and Denoising Diffusion",
                "image-path": ""
            },

            {
                "startTime": "09:04",
                "arxivId": "2407.15645",
                "arxivLink": "https://arxiv.org/abs/2407.15645",
                "title": "Can AI Really Think Like Us? New Test Measures How Well Language Models Mimic Human Knowledge",
                "institute": "Stanford University",
                "text": "This research introduces a new metric called \"psychometric alignment\" to assess how closely the knowledge distribution of language models (LLMs) aligns with that of humans. Unlike previous work that focused on overall accuracy, this metric analyzes the differences in item functioning between LLMs and humans using Item Response Theory (IRT).",
                "paper-title": "Psychometric Alignment: Capturing Human Knowledge Distributions via Language Models",
                "image-path": ""
            },

            {
                "startTime": "09:32",
                "arxivId": "2407.15337",
                "arxivLink": "https://arxiv.org/abs/2407.15337",
                "title": "ThermalNeRF: Seeing the Heat, Literally!",
                "institute": "Stanford University",
                "text": "This research extends radiance field models to include thermal (LWIR) data, allowing for 3D reconstruction of scenes using both visible and infrared light. Unlike previous work, it models material interactions with different wavelengths separately, improving reconstruction quality.",
                "paper-title": "ThermalNeRF: Thermal Radiance Fields",
                "image-path": ""
            },

            {
                "startTime": "09:57",
                "arxivId": "2407.15007",
                "arxivLink": "https://arxiv.org/abs/2407.15007",
                "title": "Behavior Cloning: Not All You Need, But Maybe All You Want?",
                "institute": "Microsoft Research, MIT",
                "text": "This paper revisits the sample complexity of imitation learning, focusing on general policy classes, including deep neural networks. It shows that behavior cloning with the logarithmic loss can achieve horizon-independent sample complexity under certain conditions, challenging the conventional wisdom that online methods are more efficient.",
                "paper-title": "Is Behavior Cloning All You Need? Understanding Horizon in Imitation Learning",
                "image-path": ""
            },

            {
                "startTime": "10:19",
                "arxivId": "2407.15771",
                "arxivLink": "https://arxiv.org/abs/2407.15771",
                "title": "Grasping the Unseen: How AI Completes Objects for Robot Hands",
                "institute": "Peking University",
                "text": "This research focuses on improving robotic grasping by predicting the occupancy of objects in a scene, even when parts are hidden from view. Unlike previous methods that rely on complete object information, this approach uses a multi-group tri-plane scheme to infer the shape of objects locally around the grasp point.",
                "paper-title": "Local Occupancy-Enhanced Object Grasping with Multiple Triplanar Projection",
                "image-path": ""
            },

            {
                "startTime": "10:46",
                "arxivId": "2407.15041",
                "arxivLink": "https://arxiv.org/abs/2407.15041",
                "title": "Room Layout Estimation: Ray-Casting Away the Occlusion Blues!",
                "institute": "National Tsing Hua University, Industrial Technology Research Institute, Google",
                "text": "This research introduces a novel geometry-aware self-training framework for room layout estimation that utilizes a ray-casting formulation to aggregate multiple estimates from different viewing positions. This approach differs from previous work by explicitly incorporating geometry reasoning into the pseudo-labeling process, enabling the model to handle complex room geometries and occluded walls without relying on assumptions like Manhattan World or planar room walls.",
                "paper-title": "Self-training Room Layout Estimation via Geometry-aware Ray-casting",
                "image-path": ""
            },

            {
                "startTime": "11:16",
                "arxivId": "2407.15268",
                "arxivLink": "https://arxiv.org/abs/2407.15268",
                "title": "Radiology Reports: Fact-Checking AI for Accurate Diagnoses",
                "institute": "CMU",
                "text": "This research introduces a fact-aware multimodal retriever that leverages RadGraph to mine factual report pairs, enhancing the accuracy of radiology report generation by multimodal foundation models. This approach differs from previous work by explicitly incorporating factual knowledge into the retrieval process, addressing the issue of factual inaccuracies in generated reports.",
                "paper-title": "Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation",
                "image-path": ""
            },

            {
                "startTime": "11:36",
                "arxivId": "2407.15431",
                "arxivLink": "https://arxiv.org/abs/2407.15431",
                "title": "Pre-Training and Prompting: A New Recipe for Few-Shot Node Classification on Text-Attributed Graphs",
                "institute": "Tsinghua University, University of Edinburgh, Anhui University...",
                "text": "This research proposes a novel framework called P2TAG that integrates language models (LMs) and graph neural networks (GNNs) for few-shot node classification on text-attributed graphs (TAGs). Unlike previous methods that train LMs and GNNs separately, P2TAG jointly trains them using a masked language modeling objective, enabling a more efficient and effective approach.",
                "paper-title": "Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs",
                "image-path": ""
            },

            {
                "startTime": "12:10",
                "arxivId": "2407.15320",
                "arxivLink": "https://arxiv.org/abs/2407.15320",
                "title": "Edge AI Gets Graph-tastic: A Love Story of Networks and Intelligence",
                "institute": "Sun Yat-sen University, The Hong Kong University of Science and Technology, Tsinghua University...",
                "text": "This research introduces the concept of \"Edge Graph Intelligence\" (EGI), which explores the reciprocal interplay between graph intelligence (GI) and edge networks. Unlike previous work that either focused on GI models or edge networks in isolation, EGI emphasizes their mutual empowerment and proposes a rating system to measure the degree of their integration.",
                "paper-title": "Edge Graph Intelligence: Reciprocally Empowering Edge Networks with Graph Intelligence",
                "image-path": ""
            },

            {
                "startTime": "12:40",
                "arxivId": "2407.15595",
                "arxivLink": "https://arxiv.org/abs/2407.15595",
                "title": "Discrete Flow Matching: A New Way to Generate Text and Code, Without the Autoregressive Blues!",
                "institute": "Meta AI, Weizmann Institute",
                "text": "This paper introduces Discrete Flow Matching (Discrete FM), a new framework for discrete flow models that generates discrete data like text and code in a non-autoregressive fashion. Unlike previous approaches, Discrete FM leverages a general family of probability paths and provides a unified formulation for the generating probability velocity, directly expressed in terms of learned posteriors and schedulers.",
                "paper-title": "Discrete Flow Matching",
                "image-path": ""
            },

            {
                "startTime": "13:13",
                "arxivId": "2407.15160",
                "arxivLink": "https://arxiv.org/abs/2407.15160",
                "title": "Can Transformers Count? A New Study Reveals the Limits of LLMs!",
                "institute": "New York University, Google Research, Tel Aviv University...",
                "text": "This research explores the limitations of transformer architectures in performing simple counting tasks. Unlike previous work that focused on complex tasks, this study investigates the ability of transformers to count the occurrences of specific tokens within a sequence.",
                "paper-title": "When Can Transformers Count to n?",
                "image-path": ""
            },

            {
                "startTime": "13:52",
                "arxivId": "2407.15070",
                "arxivLink": "https://arxiv.org/abs/2407.15070",
                "title": "Gaussian Gurus: New Head Model Makes Avatars Look Real!",
                "institute": "Tsinghua University, NNKosmos",
                "text": "This paper introduces a novel 3D Gaussian Parametric Head Model, which uses 3D Gaussians to represent the complexities of the human head. This approach differs from previous methods that relied on mesh-based or NeRF-based representations.",
                "paper-title": "3D Gaussian Parametric Head Model",
                "image-path": ""
            },

            {
                "startTime": "14:11",
                "arxivId": "2407.14774",
                "arxivLink": "https://arxiv.org/abs/2407.14774",
                "title": "Turning Text into Art: A Deep Dive into Intelligent Typography",
                "institute": "Peking University",
                "text": "This research provides a comprehensive overview of artistic text generation, focusing on two main categories: artistic text stylization and semantic typography. It also explores the incorporation of motion for dynamic artistic text generation. The paper highlights the unique challenges of artistic text generation, such as maintaining legibility while incorporating visual effects and semantic meaning.",
                "paper-title": "Intelligent Artistic Typography: A Comprehensive Review of Artistic Text Design and Generation",
                "image-path": ""
            },

            {
                "startTime": "14:37",
                "arxivId": "2407.15354",
                "arxivLink": "https://arxiv.org/abs/2407.15354",
                "title": "BEV-erly Hills Cop: New 3D Object Detection with Vector Queries",
                "institute": "Hong Kong University of Science and Technology",
                "text": "This research introduces a novel approach to 3D object detection using a high-resolution vector representation. Unlike traditional BEV (Bird's-Eye-View) methods that rely on dense grids, VectorFormer factorizes the BEV representation into two low-rank vector queries, enabling efficient modeling of crucial regions at a finer granularity.",
                "paper-title": "Learning High-resolution Vector Representation from Multi-Camera Images for 3D Object Detection",
                "image-path": ""
            },

            {
                "startTime": "15:01",
                "arxivId": "2407.15021",
                "arxivLink": "https://arxiv.org/abs/2407.15021",
                "title": "Stop the Information Overload! LLMs Get a Memory Makeover with JSON",
                "institute": "University of British Columbia, Google",
                "text": "This research introduces a novel approach to incremental summarization using structured knowledge representations, specifically JSON, to address the information overload issue faced by LLMs when processing extensive input contexts. Unlike previous methods that rely on unstructured memory, this approach leverages JSON's ability to organize information into distinct, easily accessible segments, facilitating efficient updates and retrievals.",
                "paper-title": "Enhancing Incremental Summarization with Structured Representations",
                "image-path": ""
            },

            {
                "startTime": "15:23",
                "arxivId": "2407.15837",
                "arxivLink": "https://arxiv.org/abs/2407.15837",
                "title": "Masked Image Modeling Goes Latent: Unlocking High-Level Semantics Without Fine-Tuning!",
                "institute": "University of Wisconsin-Madison, Carnegie Mellon University",
                "text": "This research explores Latent Masked Image Modeling (Latent MIM), a new approach to self-supervised visual representation learning. Unlike traditional MIM methods that reconstruct pixels, Latent MIM reconstructs latent representations, aiming to capture higher-level semantics without relying on supervised fine-tuning.",
                "paper-title": "Towards Latent Masked Image Modeling for Self-Supervised Visual Representation Learning",
                "image-path": ""
            },

            {
                "startTime": "15:53",
                "arxivId": "2407.14532",
                "arxivLink": "https://arxiv.org/abs/2407.14532",
                "title": "AIOps Algorithms Get a Real-Time Workout: New Benchmark Puts Them Through Their Paces!",
                "institute": "Nankai University, CNIC CAS, Microsoft...",
                "text": "This research introduces a new benchmark called MicroServo that evaluates AIOps algorithms using real-time datasets generated from a live microservice system. Unlike previous benchmarks that rely on offline datasets, MicroServo simulates various operation scenarios, making the evaluation more realistic and relevant to real-world applications.",
                "paper-title": "A Scenario-Oriented Benchmark for Assessing AIOps Algorithms in Microservice Management",
                "image-path": ""
            },

            {
                "startTime": "16:28",
                "arxivId": "2407.15516",
                "arxivLink": "https://arxiv.org/abs/2407.15516",
                "title": "LLMs: Attention is All You Need... But Not All of It!",
                "institute": "University College London, University of Edinburgh",
                "text": "This research explores the impact of dropping attention and MLP layers during inference of Llama-v2 models, focusing on the performance trade-off when removing deeper layers. This approach differs from previous work that primarily focused on dropping layers from the end of the model.",
                "paper-title": "Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "16:51",
                "arxivId": "2407.15815",
                "arxivLink": "https://arxiv.org/abs/2407.15815",
                "title": "Robots Learn to See the World, No Matter What!",
                "institute": "Tsinghua University",
                "text": "This research introduces Maniwhere, a framework that enables robots to learn visual tasks and generalize to different camera viewpoints, visual appearances, and even different robot embodiments. Unlike previous methods that focus on a single type of visual change, Maniwhere tackles multiple visual generalization types simultaneously.",
                "paper-title": "Learning to Manipulate Anywhere: A Visual Generalizable Framework For Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "17:16",
                "arxivId": "2407.15187",
                "arxivLink": "https://arxiv.org/abs/2407.15187",
                "title": "HoloDreamer: Turning Text into 3D Panoramas, One Splat at a Time!",
                "institute": "Peking University, National University of Singapore",
                "text": "HoloDreamer differs from previous methods by directly generating a high-resolution panorama from text prompts, then using 3D Gaussian Splatting for fast and robust 3D reconstruction. This approach avoids the limitations of progressive outpainting, which can lead to visual inconsistencies and chaotic objects.",
                "paper-title": "HoloDreamer: Holistic 3D Panoramic World Generation from Text Descriptions",
                "image-path": ""
            },

            {
                "startTime": "17:47",
                "arxivId": "2407.15839",
                "arxivLink": "https://arxiv.org/abs/2407.15839",
                "title": "Driving Like a Boss: New AI Learns to Navigate Intersections Without Crashing",
                "institute": "Stanford University, UC Riverside, Honda Research Institute",
                "text": "This research introduces a novel training framework that integrates guided meta reinforcement learning with importance sampling (IS) to optimize training distributions for navigating highly interactive driving scenarios. Unlike traditional methods that may underrepresent critical interactions or overemphasize extreme cases during training, this approach strategically adjusts the training distribution towards more challenging driving behaviors.",
                "paper-title": "Importance Sampling-Guided Meta-Training for Intelligent Agents in Highly Interactive Environments",
                "image-path": ""
            },

            {
                "startTime": "18:13",
                "arxivId": "2407.14563",
                "arxivLink": "https://arxiv.org/abs/2407.14563",
                "title": "Generative VLMs: Turning Detection Datasets into Grounding Goldmines!",
                "institute": "Brown University, Google DeepMind, Google Cloud",
                "text": "This research explores using generative vision-language models (VLMs) to automatically generate annotations for visual grounding datasets, bypassing the need for expensive human labeling.",
                "paper-title": "Learning Visual Grounding from Generative Vision and Language Model",
                "image-path": ""
            },

            {
                "startTime": "18:35",
                "arxivId": "2407.15317",
                "arxivLink": "https://arxiv.org/abs/2407.15317",
                "title": "Open-CD: Change Detection's New Playground!",
                "institute": "Sun Yat-sen University, Ateneo Pontificio Regina Apostolorum, Wuhan University...",
                "text": "This research introduces Open-CD, a comprehensive toolbox for change detection, which differs from previous work by offering a unified platform for training, inference, and data analysis, encompassing a wide range of change detection methods.",
                "paper-title": "Open-CD: A Comprehensive Toolbox for Change Detection",
                "image-path": ""
            },

            {
                "startTime": "19:06",
                "arxivId": "2407.15797",
                "arxivLink": "https://arxiv.org/abs/2407.15797",
                "title": "Lidar Labeling: One Click, One Thousandth the Work!",
                "institute": "Valeo.ai, LIGM, Ecole des Ponts...",
                "text": "This research proposes a novel method for annotating lidar point clouds, dubbed MILAN, which leverages self-supervised representations to significantly reduce the annotation effort. Unlike previous methods that rely on iterative selection of data points or regions, MILAN directly selects a small subset of scans and clusters points within those scans based on their features. Annotators only need to label the cluster centers, and the labels are then propagated to all points within the cluster. This approach achieves a three-order-of-magnitude reduction in the number of manually labeled points while maintaining performance close to fully annotated training sets.",
                "paper-title": "MILAN: Milli-Annotations for Lidar Semantic Segmentation",
                "image-path": ""
            },

            {
                "startTime": "19:36",
                "arxivId": "2407.15620",
                "arxivLink": "https://arxiv.org/abs/2407.15620",
                "title": "Out-of-Distribution Recommendations: When Your Algorithm Needs a Tune-Up!",
                "institute": "IEEE",
                "text": "This research introduces a novel Dual Test-Time Training framework (DT3OR) for out-of-distribution (OOD) recommendation systems. Unlike previous methods that rely on retraining or interventions during the training phase, DT3OR adapts the model during the test phase using self-supervised learning tasks.",
                "paper-title": "Dual Test-time Training for Out-of-distribution Recommender System",
                "image-path": ""
            },

            {
                "startTime": "20:04",
                "arxivId": "2407.15047",
                "arxivLink": "https://arxiv.org/abs/2407.15047",
                "title": "Video QA: Don't Just Watch, Ask the Right Questions!",
                "institute": "Peking University, Huawei",
                "text": "This research introduces a novel frame selection strategy for VideoQA, using three scoring mechanisms to evaluate the importance of each frame for a given question. This differs from previous work by incorporating a differentiable adaptive frame sampling mechanism, enabling end-to-end training for the frame selector and answer generator.",
                "paper-title": "End-to-End Video Question Answering with Frame Scoring Mechanisms and Adaptive Sampling",
                "image-path": ""
            },

            {
                "startTime": "20:26",
                "arxivId": "2407.15167",
                "arxivLink": "https://arxiv.org/abs/2407.15167",
                "title": "Brain-Hacking Images: AI Makes Your Brain See Better!",
                "institute": "Fudan University, Microsoft Research",
                "text": "This research proposes a closed-loop AI system called the VEP Booster that generates visual stimuli tailored to individual brain responses, improving the reliability and stability of EEG biomarkers compared to traditional methods.",
                "paper-title": "The VEP Booster: A Closed-Loop AI System for Visual EEG Biomarker Auto-generation",
                "image-path": ""
            },

            {
                "startTime": "20:45",
                "arxivId": "2407.14933",
                "arxivLink": "https://arxiv.org/abs/2407.14933",
                "title": "AI's Data Diet: The Web is Going on a Consent-Only Plan",
                "institute": "Google, Meta, OpenAI...",
                "text": "This research goes beyond analyzing AI training datasets and instead examines the web domains those datasets are derived from, tracking how consent preferences for data use are changing over time.",
                "paper-title": "Consent in Crisis: The Rapid Decline of the AI Data Commons",
                "image-path": ""
            },

            {
                "startTime": "21:06",
                "arxivId": "2407.15441",
                "arxivLink": "https://arxiv.org/abs/2407.15441",
                "title": "LLMs Gone Wild? Microsoft's New Service Tames Hallucinating AI",
                "institute": "Microsoft",
                "text": "This research introduces a federated hallucination detection and mitigation framework that combines multiple AI techniques, including named entity recognition (NER), natural language inference (NLI), and span-based detection (SBD), to identify and correct errors in LLM outputs. This approach differs from previous work by focusing on a multi-source ensemble for more comprehensive detection and leveraging GPT4 for both data labeling and rewriting.",
                "paper-title": "Developing a Reliable, General-Purpose Hallucination Detection and Mitigation Service: Insights and Lessons Learned",
                "image-path": ""
            },

            {
                "startTime": "21:28",
                "arxivId": "2407.14982",
                "arxivLink": "https://arxiv.org/abs/2407.14982",
                "title": "GreenStableYolo: Making AI Art Faster and Better (Without Breaking the Bank)",
                "institute": "Loughborough University, Beijing University of Posts and Telecommunications, University of L\u2019Aquila...",
                "text": "This research introduces GreenStableYolo, a system that optimizes Stable Diffusion for both image quality and inference time, unlike previous work that focused solely on image quality.",
                "paper-title": "GreenStableYolo: Optimizing Inference Time and Image Quality of Text-to-Image Generation",
                "image-path": ""
            },

            {
                "startTime": "21:57",
                "arxivId": "2407.15186",
                "arxivLink": "https://arxiv.org/abs/2407.15186",
                "title": "LLMs for Text-to-SQL: From Zero to Hero (and Back Again)?",
                "institute": "Peking University",
                "text": "This research focuses on the use of Large Language Models (LLMs) for Text-to-SQL tasks, specifically exploring the effectiveness of prompt engineering and fine-tuning methods. It distinguishes itself from previous work by examining the application of LLMs in this domain, highlighting the challenges and opportunities presented by these powerful models.",
                "paper-title": "A Survey on Employing Large Language Models for Text-to-SQL Tasks",
                "image-path": ""
            },

            {
                "startTime": "22:18",
                "arxivId": "2407.15792",
                "arxivLink": "https://arxiv.org/abs/2407.15792",
                "title": "Outlier Outmaneuvered: New Algorithm Finds Tiny Groups in Noisy Data",
                "institute": "ETH Zurich, TU Munich, Lucerne School of Computer Science and Information Technology...",
                "text": "This paper tackles the problem of estimating the means of well-separated mixtures when outliers overwhelm small groups. Unlike previous work that assumes outliers are less than the smallest group, this research focuses on the scenario where outliers can outnumber smaller groups. The paper proposes a new algorithm that leverages the mixture structure to partially cluster samples before iterating a base learner for list-decodable mean estimation at different scales.",
                "paper-title": "Robust Mixture Learning when Outliers Overwhelm Small Groups",
                "image-path": ""
            },

            {
                "startTime": "22:44",
                "arxivId": "2407.15202",
                "arxivLink": "https://arxiv.org/abs/2407.15202",
                "title": "Pre-trained Models Get a Boost: Drug Discovery with Nearest Neighbors!",
                "institute": "Renmin University of China, Peking University, Microsoft...",
                "text": "This research proposes a novel approach called kNN-DTA, which uses nearest neighbor retrieval to enhance the performance of pre-trained drug-target affinity (DTA) prediction models. Unlike traditional methods that rely on chemical similarity, kNN-DTA leverages embeddings extracted from the pre-trained model to find similar drug-target pairs.",
                "paper-title": "Exploiting Pre-trained Models for Drug Target Affinity Prediction with Nearest Neighbors",
                "image-path": ""
            },

            {
                "startTime": "23:14",
                "arxivId": "2407.15527",
                "arxivLink": "https://arxiv.org/abs/2407.15527",
                "title": "Deep Learning Gets a Logic Lesson: New Model Makes AI Decisions Transparent",
                "institute": "KU Leuven, Universit\u00e0 della Svizzera Italiana, University of Cambridge...",
                "text": "This research introduces a new type of Concept Bottleneck Model (CBM) called Concept-based Memory Reasoner (CMR). Unlike previous CBMs, CMR's task predictor uses a memory of learnable logic rules, allowing for inspection, intervention, and verification of the decision-making process before deployment.",
                "paper-title": "Interpretable Concept-Based Memory Reasoning",
                "image-path": ""
            },

            {
                "startTime": "23:41",
                "arxivId": "2407.15233",
                "arxivLink": "https://arxiv.org/abs/2407.15233",
                "title": "Layout Generation: Diffusion Models Get a Grip on Graphic Design!",
                "institute": "Tsinghua University",
                "text": "This research introduces a transformer-based diffusion model for content-aware layout generation, addressing the imbalance between content and graphic features in previous methods. It introduces a content and graphic balance weight to adjust the interaction process between layout representations and image embeddings, optimizing the layout generation space.",
                "paper-title": "CGB-DM: Content and Graphic Balance Layout Generation with Transformer-based Diffusion Model",
                "image-path": ""
            },

            {
                "startTime": "24:02",
                "arxivId": "2407.14911",
                "arxivLink": "https://arxiv.org/abs/2407.14911",
                "title": "Plant Pests? No Problem! New AI Model Uses \"Masked\" Images to Spot Trouble",
                "institute": "China Agricultural University",
                "text": "This research introduces a new pre-training method for plant pest and disease classification models. It combines Masked Image Modeling (MIM) with contrastive learning, which is different from previous approaches that primarily relied on convolutional neural networks (CNNs).",
                "paper-title": "Self-supervised transformer-based pre-training method with General Plant Infection dataset",
                "image-path": ""
            },

            {
                "startTime": "24:21",
                "arxivId": "2407.15739",
                "arxivLink": "https://arxiv.org/abs/2407.15739",
                "title": "Beyond Road Scenes: Detecting Anomalies with Diffusion Models",
                "institute": "University of Freiburg",
                "text": "This research extends out-of-distribution (OoD) detection for semantic segmentation beyond the typical road scene domain. It introduces a new benchmark, ADE-OoD, which features a wider range of semantic categories and diverse indoor and outdoor scenes. The paper also proposes a novel approach, DOoD, that utilizes diffusion models for OoD detection, specifically designed to handle the increased semantic diversity.",
                "paper-title": "Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond",
                "image-path": ""
            },

            {
                "startTime": "24:43",
                "arxivId": "2407.15762",
                "arxivLink": "https://arxiv.org/abs/2407.15762",
                "title": "Multi-Objective Language Models: Steering the Chatbot with a Twist of the Knob",
                "institute": "Google",
                "text": "This paper introduces Conditional Language Policies (CLP), a framework for fine-tuning language models on multiple objectives. Unlike previous approaches that rely on prompt engineering or training separate models for each objective, CLP uses parameter-efficient multi-task training to learn a single model that can be steered to generate outputs that trade off different objectives at inference time.",
                "paper-title": "Conditioned Language Policy: A General Framework for Steerable Multi-Objective Finetuning",
                "image-path": ""
            },

            {
                "startTime": "25:23",
                "arxivId": "2407.15464",
                "arxivLink": "https://arxiv.org/abs/2407.15464",
                "title": "Federated Learning: Don't Be a Copycat, Embrace the Diversity Bonus!",
                "institute": "Beihang University, University of Chicago, Hong Kong Polytechnic University",
                "text": "This research challenges the common assumption in personalized federated learning (PFL) that clients benefit most from collaborating with those having similar data distributions. It proposes a new method, DiversiFed, that encourages clients to learn from dissimilar clients by pushing their models apart in the parameter space.",
                "paper-title": "The Diversity Bonus: Learning from Dissimilar Distributed Clients in Personalized Federated Learning",
                "image-path": ""
            },

            {
                "startTime": "25:57",
                "arxivId": "2407.15403",
                "arxivLink": "https://arxiv.org/abs/2407.15403",
                "title": "Suboptimal Robot? No Problem! Graph Search and Retrieval to the Rescue!",
                "institute": "UC Berkeley",
                "text": "This research proposes a novel algorithm called GSR (Graph Search and Retrieval) that learns from suboptimal demonstrations by directly identifying and stitching good behaviors through graph representation and retrieval, without relying on deep reinforcement learning (RL) updates. This approach sidesteps the instability and fragility issues often encountered in offline deep RL methods, particularly in complex environments with high-dimensional visual inputs.",
                "paper-title": "Offline Imitation Learning Through Graph Search and Retrieval",
                "image-path": ""
            },

            {
                "startTime": "26:28",
                "arxivId": "2407.15366",
                "arxivLink": "https://arxiv.org/abs/2407.15366",
                "title": "LLMs Learn Empathy: Perspective-Taking Prompts Make AI Less Toxic!",
                "institute": "Tsinghua University, Nanyang Technological University",
                "text": "This research proposes a novel prompting strategy called \"perspective-taking prompting\" (PET) that encourages LLMs to consider diverse human perspectives and self-regulate their responses. Unlike previous methods that rely on white-box access or extensive training, PET operates in a black-box scenario and requires no additional training data.",
                "paper-title": "Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias",
                "image-path": ""
            },

            {
                "startTime": "26:51",
                "arxivId": "2407.15504",
                "arxivLink": "https://arxiv.org/abs/2407.15504",
                "title": "Prompt Compression: How Much Can We Squeeze Before It Pops?",
                "institute": "EPFL, UT Austin",
                "text": "This research formalizes the problem of prompt compression for large language models (LLMs) and presents a rate-distortion framework to unify existing methods. It derives the distortion-rate function as a linear program and provides an efficient algorithm to compute this fundamental limit.",
                "paper-title": "Fundamental Limits of Prompt Compression: A Rate-Distortion Framework for Black-Box Language Models",
                "image-path": ""
            },

            {
                "startTime": "27:13",
                "arxivId": "2407.15831",
                "arxivLink": "https://arxiv.org/abs/2407.15831",
                "title": "Stop the Negative Nancy! New Text Embedding Model Mines Hard Negatives Like a Pro",
                "institute": "Nvidia",
                "text": "This research focuses on improving text embedding models by exploring different methods for mining hard-negative passages during training. Unlike previous work that often overlooks or inadequately describes this process, the authors introduce a novel family of positive-aware mining methods that leverage the positive relevance score for more effective false negative removal.",
                "paper-title": "NV-Retriever: Improving text embedding models with effective hard-negative mining",
                "image-path": ""
            },

            {
                "startTime": "27:47",
                "arxivId": "2407.15567",
                "arxivLink": "https://arxiv.org/abs/2407.15567",
                "title": "FedAvg's Secret Weapon: Data Heterogeneity Doesn't Have to Be a Downer!",
                "institute": "University of Utah, IBM",
                "text": "This research introduces a new metric called the \"heterogeneity-driven pseudo-Lipschitz constant\" (Lh) to better understand the impact of data heterogeneity in federated learning. Unlike previous work that relied on the local Lipschitz constant, this new metric focuses on the difference between the averaged model and the centralized model, providing a more accurate picture of the error caused by local updates.",
                "paper-title": "A New Theoretical Perspective on Data Heterogeneity in Federated Optimization",
                "image-path": ""
            },

            {
                "startTime": "28:20",
                "arxivId": "2407.14958",
                "arxivLink": "https://arxiv.org/abs/2407.14958",
                "title": "Motion Transfer Without the Rigmarole: New Method Makes Animation a Breeze!",
                "institute": "University College London, Adobe Research, University Of Montreal",
                "text": "This research introduces Temporal Residual Jacobians, a novel representation for data-driven motion transfer. Unlike previous methods that rely on rigging or intermediate shape keyframes, this approach directly predicts local geometric and temporal changes, integrating them spatially and temporally to produce the final animated meshes.",
                "paper-title": "Temporal Residual Jacobians For Rig-free Motion Transfer",
                "image-path": ""
            },

            {
                "startTime": "28:42",
                "arxivId": "2407.15124",
                "arxivLink": "https://arxiv.org/abs/2407.15124",
                "title": "Patent Reactions: Unmasking the Chemistry Behind Innovation",
                "institute": "CMU",
                "text": "This research focuses on extracting reaction spans from chemical patents, a task that has received limited attention in previous work. The authors propose several novel approaches, including the use of BERT embeddings and a special [CHEM] token to improve generalization across different domains of chemical patents.",
                "paper-title": "Chemical Reaction Extraction for Chemical Knowledge Base",
                "image-path": ""
            },

            {
                "startTime": "29:06",
                "arxivId": "2407.15786",
                "arxivLink": "https://arxiv.org/abs/2407.15786",
                "title": "Reinforcement Learning Gets a Brain: Learning Concepts with Fewer Labels!",
                "institute": "CMU",
                "text": "This research introduces a new training scheme for reinforcement learning (RL) algorithms that can learn concept-based policies with limited or no human labels. Unlike previous work that relies on continuous human annotation, this approach interleaves concept learning and RL training, actively selects informative data points for labeling, and decorrelates the concept data.",
                "paper-title": "Concept-Based Interpretable Reinforcement Learning with Limited to No Human Labels",
                "image-path": ""
            },

            {
                "startTime": "29:36",
                "arxivId": "2407.14653",
                "arxivLink": "https://arxiv.org/abs/2407.14653",
                "title": "Offline Safe RL Gets a Data Makeover: OASIS Shapes Up for Success!",
                "institute": "CMU",
                "text": "This paper introduces OASIS, a new approach to offline safe reinforcement learning that uses a conditional diffusion model to reshape the data distribution. Unlike previous methods that rely on regularization, OASIS generates new data points that are more aligned with the desired safe and rewarding behavior.",
                "paper-title": "OASIS: Conditional Distribution Shaping for Offline Safe Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "30:02",
                "arxivId": "2407.15488",
                "arxivLink": "https://arxiv.org/abs/2407.15488",
                "title": "DiffX: Laying Down the Law for Cross-Modal Image Generation",
                "institute": "Zhejiang University, Monash University, University of Nottingham...",
                "text": "This paper introduces DiffX, a novel diffusion model for generating cross-modal \"RGB+X\" images, where X represents additional data like thermal or depth information. Unlike previous work that focuses on generating RGB images alone, DiffX simultaneously generates both RGB and X images, guided by layout conditions and text descriptions.",
                "paper-title": "DiffX: Guide Your Layout to Cross-Modal Generative Modeling",
                "image-path": ""
            },

            {
                "startTime": "30:37",
                "arxivId": "2407.15549",
                "arxivLink": "https://arxiv.org/abs/2407.15549",
                "title": "LLMs Gone Rogue? Targeted Latent Training to the Rescue!",
                "institute": "Georgia Institute of Technology, University of Maryland, MIT",
                "text": "This research introduces targeted latent adversarial training (LAT), a technique that perturbs the hidden representations of LLMs to elicit specific undesirable behaviors. Unlike previous work, which focused on untargeted attacks, this approach aims to remove specific harmful capabilities by directly targeting them.",
                "paper-title": "Targeted Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs",
                "image-path": ""
            },

            {
                "startTime": "31:08",
                "arxivId": "2407.14516",
                "arxivLink": "https://arxiv.org/abs/2407.14516",
                "title": "RobocupGym: Kicking Goals in RL with a Simulated Soccer League!",
                "institute": "University of Oxford",
                "text": "This research introduces RobocupGym, a new reinforcement learning (RL) environment based on the 3D simulation league of Robocup, a robotic football competition. Unlike previous RL environments that focus on video games or lack real-world applicability, RobocupGym provides a challenging continuous control domain for training RL agents in a robotics context.",
                "paper-title": "RobocupGym: A challenging continuous control benchmark in Robocup",
                "image-path": ""
            },

            {
                "startTime": "31:36",
                "arxivId": "2407.15352",
                "arxivLink": "https://arxiv.org/abs/2407.15352",
                "title": "Fact-Checking the News: A Giant Dataset for Event Factuality Detection",
                "institute": "Tsinghua University",
                "text": "This research introduces MAVEN-FACT, a large-scale dataset for event factuality detection, which is significantly larger than previous datasets and includes annotations for supporting evidence.",
                "paper-title": "MAVEN-Fact: A Large-scale Event Factuality Detection Dataset",
                "image-path": ""
            },

            {
                "startTime": "32:02",
                "arxivId": "2407.15131",
                "arxivLink": "https://arxiv.org/abs/2407.15131",
                "title": "Token-Picker: Pruning Unimportant Words in Text Generation for a Speedier Chatbot!",
                "institute": "Korea Advanced Institute of Science and Technology, Samsung",
                "text": "This research proposes a new method for pruning unimportant tokens in text generation by estimating their probability before all calculations are complete. This differs from previous methods that relied on fixed pruning ratios or required retraining.",
                "paper-title": "Token-Picker: Accelerating Attention in Text Generation with Minimized Memory Transfer via Probability Estimation",
                "image-path": ""
            },

            {
                "startTime": "32:26",
                "arxivId": "2407.15462",
                "arxivLink": "https://arxiv.org/abs/2407.15462",
                "title": "Retrieval Revolution: MoL Makes Learned Similarities Speedy!",
                "institute": "Microsoft, Meta",
                "text": "This research proposes using Mixture-of-Logits (MoL) to approximate learned similarity functions, enabling efficient retrieval in recommendation systems. Unlike previous work that focused on dot products or specific neural network architectures, MoL offers a universal approach for handling diverse learned similarity functions.",
                "paper-title": "Efficient Retrieval with Learned Similarities",
                "image-path": ""
            },

            {
                "startTime": "32:51",
                "arxivId": "2407.14859",
                "arxivLink": "https://arxiv.org/abs/2407.14859",
                "title": "Particle Physics Gets a Data Diet: Graph Neural Networks Go on a Slim-Down",
                "institute": "Sapienza University of Rome, European Organization for Nuclear Research",
                "text": "This research integrates data attribution techniques, specifically TracIn, into the graph classification pipeline for high-energy particle physics. This approach aims to improve the accuracy and efficiency of collision event prediction by identifying and removing non-contributory training samples.",
                "paper-title": "Enhancing High-Energy Particle Physics Collision Analysis through Graph Data Attribution Techniques",
                "image-path": ""
            },

            {
                "startTime": "33:22",
                "arxivId": "2407.15073",
                "arxivLink": "https://arxiv.org/abs/2407.15073",
                "title": "LLMs Go Multi-Agent: Debating Their Way to Causal Discovery!",
                "institute": "Tsinghua University",
                "text": "This research explores the use of multiple LLM agents, each with its own reasoning and knowledge, to tackle causal discovery problems. Unlike previous work that focuses on single LLMs or traditional statistical methods, this approach leverages the collaborative and debating capabilities of multiple agents.",
                "paper-title": "Multi-Agent Causal Discovery Using Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "33:50",
                "arxivId": "2407.14880",
                "arxivLink": "https://arxiv.org/abs/2407.14880",
                "title": "Blurred Vision? No Problem! New AI Sharpens Images with a Twist",
                "institute": "Tsinghua University, Kuaishou Technology",
                "text": "This research introduces a new dataset specifically for blurred images, called ReBlurSR, and a framework called PBaSR that can handle both blurred and general images without extra processing. This is different from previous work that often struggled with blurred images or required separate models for each type of image.",
                "paper-title": "A New Dataset and Framework for Real-World Blurred Images Super-Resolution",
                "image-path": ""
            },

            {
                "startTime": "34:16",
                "arxivId": "2407.15731",
                "arxivLink": "https://arxiv.org/abs/2407.15731",
                "title": "Fine-Tuning Vision-Language Models: A New Measure to Predict Learning and Forgetting",
                "institute": "MIT",
                "text": "This research introduces the Inter-Intra Modal Measure (IIMM), a new metric that predicts how much a vision-language model will improve or worsen after fine-tuning. Unlike previous methods, IIMM considers both the image and text embedding spaces, providing a more comprehensive assessment of model performance changes.",
                "paper-title": "Zero-Shot Embeddings Inform Learning and Forgetting with Vision-Language Encoders",
                "image-path": ""
            },

            {
                "startTime": "34:41",
                "arxivId": "2407.14616",
                "arxivLink": "https://arxiv.org/abs/2407.14616",
                "title": "Deep Learning Makes 3D Heart Maps From 2D X-Rays: No More Guesswork!",
                "institute": "University of Oxford",
                "text": "This research uses deep learning to reconstruct 3D coronary trees from just two 2D X-ray projections, unlike previous methods that required more projections or manual intervention.",
                "paper-title": "Deep Learning-based 3D Coronary Tree Reconstruction from Two 2D Non-simultaneous X-ray Angiography Projections",
                "image-path": ""
            },

            {
                "startTime": "35:06",
                "arxivId": "2407.15282",
                "arxivLink": "https://arxiv.org/abs/2407.15282",
                "title": "Point Transformer Goes Extreme: Multi-Frame Training Wins Waymo Challenge!",
                "institute": "HKU, SH AI Lab, NUS...",
                "text": "This research introduces a new approach to semantic segmentation in 3D point clouds by incorporating multi-frame training and a non-clipping point policy. This differs from previous work by leveraging information from past LiDAR frames to improve the perception of distant objects, which are often poorly sampled in single-frame data.",
                "paper-title": "Point Transformer V3 Extreme: 1st Place Solution for 2024 Waymo Open Dataset Challenge in Semantic Segmentation",
                "image-path": ""
            },

            {
                "startTime": "35:39",
                "arxivId": "2407.15171",
                "arxivLink": "https://arxiv.org/abs/2407.15171",
                "title": "Don't Judge a Generated Image by Its Cover: New Method Assesses Quality from the Inside Out",
                "institute": "Stony Brook University, EPFL",
                "text": "This research proposes a novel method for assessing the quality of generated samples by directly examining the latent space of the generative model itself, rather than relying on pre-trained feature extractors.",
                "paper-title": "Assessing Sample Quality via the Latent Space of Generative Models",
                "image-path": ""
            },

            {
                "startTime": "36:06",
                "arxivId": "2407.15339",
                "arxivLink": "https://arxiv.org/abs/2407.15339",
                "title": "Deep Learning: Economists Get a Leg Up on Big Data",
                "institute": "Harvard University",
                "text": "This research focuses on using deep learning to extract structured information from unstructured text and image datasets, particularly in contexts where the ground truth is uncontroversial but extraction needs to be automated due to the massive scale of the problem. This differs from previous work by emphasizing the use of deep learning for data exploration and imputation of low-dimensional structured data, rather than solely focusing on prediction tasks.",
                "paper-title": "Deep Learning for Economists",
                "image-path": ""
            },

            {
                "startTime": "36:30",
                "arxivId": "2407.15498",
                "arxivLink": "https://arxiv.org/abs/2407.15498",
                "title": "Chinese Spelling Correction: Cleaning Up the Mess with Confidence!",
                "institute": "Peking University, Microsoft",
                "text": "This research focuses on refining Chinese spelling correction (CSC) corpora by leveraging model calibration. Unlike previous work that primarily focused on model design, this paper proposes a data-centric approach to improve CSC performance by filtering noisy samples from OCR/ASR-based datasets using a well-calibrated CSC model trained on random replacement data.",
                "paper-title": "Refining Corpora from a Model Calibration Perspective for Chinese Spelling Correction",
                "image-path": ""
            },

            {
                "startTime": "36:50",
                "arxivId": "2407.15569",
                "arxivLink": "https://arxiv.org/abs/2407.15569",
                "title": "ChatGPT's New Trick: Thinking Out Loud with Retrieved Knowledge!",
                "institute": "Tsinghua University",
                "text": "This research introduces RAFT, a method that combines retrieval augmented generation (RAG) with chain-of-thought (CoT) for fine-tuning smaller language models. This approach aims to improve the reasoning abilities of these models by integrating external knowledge and prompting them to think through their reasoning steps.",
                "paper-title": "An Empirical Study of Retrieval Augmented Generation with Chain-of-Thought",
                "image-path": ""
            },

            {
                "startTime": "37:15",
                "arxivId": "2407.15083",
                "arxivLink": "https://arxiv.org/abs/2407.15083",
                "title": "Rocket Landing: From 8% to 97% Success with a Jump Start!",
                "institute": "Tsinghua University, LandSpace Technology Corporation",
                "text": "This research introduces a novel approach called Random Annealing Jump Start (RAJS) for reinforcement learning (RL) in goal-oriented tasks. RAJS leverages prior feedback controllers as guide policies to facilitate exploration and learning, unlike previous methods that rely on extensive exploration or manually designed rewards.",
                "paper-title": "Rocket Landing Control with Random Annealing Jump Start Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "37:38",
                "arxivId": "2407.15350",
                "arxivLink": "https://arxiv.org/abs/2407.15350",
                "title": "Pedestrians Take the Wheel: New Dataset Captures Fine-Grained Traffic Behavior",
                "institute": "Woven by Toyota, The University of Tokyo, Santa Clara University",
                "text": "This research introduces a new dataset, WTS, that focuses on pedestrian behavior in traffic scenarios, unlike previous datasets that primarily focused on vehicle and driver behavior.",
                "paper-title": "WTS: A Pedestrian-Centric Traffic Video Dataset for Fine-grained Spatial-Temporal Understanding",
                "image-path": ""
            },

            {
                "startTime": "38:05",
                "arxivId": "2407.14541",
                "arxivLink": "https://arxiv.org/abs/2407.14541",
                "title": "Big Data, Big Problems? How to Fix Bias in Mobility Data",
                "institute": "Southwest Jiaotong University, University of Washington, University of South Florida...",
                "text": "This research goes beyond simply acknowledging bias in big mobility data (BMD) and proposes a new mitigation method using data standardization. Previous studies often relied on linear scaling, which this paper shows is ineffective due to varying relationships across regions and over time.",
                "paper-title": "Mitigating biases in big mobility data: a case study of monitoring large-scale transit systems",
                "image-path": ""
            },

            {
                "startTime": "38:31",
                "arxivId": "2407.14662",
                "arxivLink": "https://arxiv.org/abs/2407.14662",
                "title": "Neural Networks: More Than Just a Bag of Features?",
                "institute": "Harvard University",
                "text": "This paper explores the concept of relational composition in neural networks, focusing on how feature vectors are combined to represent complex relationships. It goes beyond the traditional \"bag of features\" model, which assumes that information is simply a sum of individual features.",
                "paper-title": "Relational Composition in Neural Networks: A Survey and Call to Action",
                "image-path": ""
            },

            {
                "startTime": "38:54",
                "arxivId": "2407.14876",
                "arxivLink": "https://arxiv.org/abs/2407.14876",
                "title": "Seizure Prediction: Not Just When, But How Long?",
                "institute": "GROW Research Institute for Oncology and Reproduction, Maastricht University Medical Centre+, MuirMaxwell Epilepsy Centre...",
                "text": "This research introduces a new metric, the Continuous Input-Output Performance Ratio (CIOPR), to evaluate seizure prediction models. Unlike traditional metrics that focus on accuracy at specific time points, CIOPR considers the model's behavior over continuous EEG data, taking into account prediction time, output stability, and transition time between states.",
                "paper-title": "Preictal Period Optimization for Deep Learning-Based Epileptic Seizure Prediction",
                "image-path": ""
            },

            {
                "startTime": "39:32",
                "arxivId": "2407.15199",
                "arxivLink": "https://arxiv.org/abs/2407.15199",
                "title": "360\u00b0 Vision for Safer Cycling: How AI Tracks Overtakes in Panoramic Videos",
                "institute": "University College London",
                "text": "This research focuses on adapting existing object detection and tracking models to panoramic videos, specifically addressing the challenges of distorted objects and boundary continuity in equirectangular projections.",
                "paper-title": "Multiple Object Detection and Tracking in Panoramic Videos for Cycling Safety Analysis",
                "image-path": ""
            },

            {
                "startTime": "40:03",
                "arxivId": "2407.15730",
                "arxivLink": "https://arxiv.org/abs/2407.15730",
                "title": "Sun's Got a New Compression Suit: Transformers Take on Solar Data!",
                "institute": "West Virginia University, NASA Goddard Space Flight Center",
                "text": "This research introduces a Transformer-based video compression approach for the Solar Dynamics Observatory (SDO) mission, leveraging both spatial and temporal redundancies in the data. Unlike previous work, this approach utilizes a Hybrid CNN-MLP Window (HCMWin) Transformer block to capture both local and global information, leading to a more efficient compression.",
                "paper-title": "Neural-based Video Compression on Solar Dynamics Observatory Images",
                "image-path": ""
            },

            {
                "startTime": "40:26",
                "arxivId": "2407.15828",
                "arxivLink": "https://arxiv.org/abs/2407.15828",
                "title": "J-CHAT: A Dialogue Corpus So Big, It's Got More Words Than Your Last Argument!",
                "institute": "University of Tokyo",
                "text": "This research constructs a large-scale, open-source spoken dialogue corpus in Japanese, J-CHAT, addressing the lack of such resources for non-English languages. It also introduces a fully automated method for corpus construction, making it scalable and language-independent.",
                "paper-title": "J-CHAT: Japanese Large-scale Spoken Dialogue Corpus for Spoken Dialogue Language Modeling",
                "image-path": ""
            },

            {
                "startTime": "40:45",
                "arxivId": "2407.15593",
                "arxivLink": "https://arxiv.org/abs/2407.15593",
                "title": "Robots with Eyesight: Learning Where to Look for Better Localization!",
                "institute": "Sapienza University of Rome, ETH Zurich, Microsoft...",
                "text": "This research proposes a self-supervised learning approach for viewpoint selection in active localization. Unlike previous methods that rely on hand-crafted techniques or require manual labeling, this approach learns from the distribution of 3D landmarks and their contribution to visual localization.",
                "paper-title": "Learning Where to Look: Self-supervised Viewpoint Selection for Active Localization using Geometrical Information",
                "image-path": ""
            },

            {
                "startTime": "41:11",
                "arxivId": "2407.15816",
                "arxivLink": "https://arxiv.org/abs/2407.15816",
                "title": "H&E Images: A New Way to Predict Cancer Mutations?",
                "institute": "Tempus AI Inc.",
                "text": "This research explores a multi-task learning approach to predict multiple DNA alterations from H&E whole slide images, unlike previous studies that focused on single biomarker prediction.",
                "paper-title": "Efficient and generalizable prediction of molecular alterations in multiple cancer cohorts using H&E whole slide images",
                "image-path": ""
            },

            {
                "startTime": "41:42",
                "arxivId": "2407.15138",
                "arxivLink": "https://arxiv.org/abs/2407.15138",
                "title": "Dataset Distillation: Diffusion Models Ditch the Matching Game!",
                "institute": "Chinese Academy of Sciences, University of Chinese Academy of Sciences, North Carolina State University",
                "text": "This research proposes a new dataset distillation framework called D4M that uses a disentangled diffusion model to generate synthetic datasets. Unlike previous methods that rely on matching architectures, D4M is architecture-free, meaning it can generate datasets that are compatible with various network architectures.",
                "paper-title": "D$^4$M: Dataset Distillation via Disentangled Diffusion Model",
                "image-path": ""
            },

            {
                "startTime": "42:12",
                "arxivId": "2407.14558",
                "arxivLink": "https://arxiv.org/abs/2407.14558",
                "title": "Soccer's Next Move: A Foundation Model Predicts the Play",
                "institute": "University of Toronto",
                "text": "This research proposes a foundation model for soccer, trained on action data from historical matches, to predict subsequent actions in a match. Unlike previous work, this model considers longer input sequences and includes turnovers, where possession changes hands.",
                "paper-title": "A Foundation Model for Soccer",
                "image-path": ""
            },

            {
                "startTime": "42:38",
                "arxivId": "2407.14684",
                "arxivLink": "https://arxiv.org/abs/2407.14684",
                "title": "Data Poisoning: The Silent Hacker Attack on Your Power Grid",
                "institute": "University of Texas at Austin, United States Air Force",
                "text": "This research focuses on data poisoning attacks, a type of cyberattack that manipulates training data used by power grid optimization models, highlighting a gap in previous research that primarily focused on evasion attacks.",
                "paper-title": "Data Poisoning: An Overlooked Threat to Power Grid Resilience",
                "image-path": ""
            },

            {
                "startTime": "42:59",
                "arxivId": "2407.15264",
                "arxivLink": "https://arxiv.org/abs/2407.15264",
                "title": "GNN Training Gets a Speed Boost: How a Shared Cache Makes Graphs Fly!",
                "institute": "University of Illinois, Nvidia",
                "text": "This research proposes a novel communication layer that allows GPUs to share their software caches, effectively creating a system-wide shared cache. This approach avoids the use of high-overhead system-scope operations, maximizing collective cache capacity and minimizing redundant storage accesses.",
                "paper-title": "LSM-GNN: Large-scale Storage-based Multi-GPU GNN Training by Optimizing Data Transfer Scheme",
                "image-path": ""
            },

            {
                "startTime": "43:21",
                "arxivId": "2407.14766",
                "arxivLink": "https://arxiv.org/abs/2407.14766",
                "title": "AI Fairness: When Equal Odds Beat Equal Chances",
                "institute": "France Travail, Institut Jean-Nicod, Linedata...",
                "text": "This research explores the implementation of fairness in AI classification models by comparing two fairness metrics: Demographic Parity and Equalized Odds. The study uses a novel fairness package called FairDream to demonstrate that even when aiming for Demographic Parity, the model converges towards Equalized Odds.",
                "paper-title": "Implementing Fairness: the view from a FairDream",
                "image-path": ""
            },

            {
                "startTime": "43:43",
                "arxivId": "2407.14668",
                "arxivLink": "https://arxiv.org/abs/2407.14668",
                "title": "Brain Translator: Unlocking the Language of Neurons with a Universal Decoder",
                "institute": "Columbia University, Stanford University, MIT...",
                "text": "This research introduces a novel multi-task-masking (MtM) approach for self-supervised learning of neural activity. Unlike previous methods that focus on temporal masking, MtM incorporates masking across different time steps, neurons, and brain regions, allowing the model to learn a more comprehensive representation of neural dynamics.",
                "paper-title": "Towards a"universal translator"for neural dynamics at single-cell, single-spike resolution",
                "image-path": ""
            },

            {
                "startTime": "44:15",
                "arxivId": "2407.14725",
                "arxivLink": "https://arxiv.org/abs/2407.14725",
                "title": "Crowd Forecasting: When Missing People Make a Big Difference!",
                "institute": "Keio University, Nvidia",
                "text": "This research introduces CrowdMAC, a new framework for crowd density forecasting that tackles the issue of missing pedestrian data. Unlike previous methods that rely on complete trajectories, CrowdMAC simultaneously reconstructs missing data in past observations while predicting future crowd density maps.",
                "paper-title": "CrowdMAC: Masked Crowd Density Completion for Robust Crowd Density Forecasting",
                "image-path": ""
            },

            {
                "startTime": "44:41",
                "arxivId": "2407.15724",
                "arxivLink": "https://arxiv.org/abs/2407.15724",
                "title": "Deep Learning's New BFF: Alpha Diversity for Better Image Classification!",
                "institute": "UC San Francisco, Harvard University",
                "text": "This research introduces a new metric called \"alpha diversity\" to measure dataset quality in deep learning. Unlike traditional metrics like dataset size and class balance, alpha diversity considers the similarities and differences among images within a dataset.",
                "paper-title": "Beyond Size and Class Balance: Alpha as a New Dataset Quality Metric for Deep Learning",
                "image-path": ""
            },

            {
                "startTime": "45:08",
                "arxivId": "2407.14575",
                "arxivLink": "https://arxiv.org/abs/2407.14575",
                "title": "Lizard-Powered Predictions: A New Algorithm for Cloud Energy Efficiency",
                "institute": "University of Illinois Urbana-Champaign, The University of Tokyo, Georgia Institute of Technology...",
                "text": "This research introduces a novel approach to predicting cloud energy consumption by combining a bio-inspired optimization algorithm, the Horned Lizard Optimization Algorithm (HLOA), with a deep learning model, Convolutional Neural Networks-Bidirectional Gated Recurrent Units (CNN-BiGRU). This differs from previous work by utilizing HLOA to optimize the parameters of the CNN-BiGRU model, leading to improved prediction accuracy.",
                "paper-title": "Regression prediction algorithm for energy consumption regression in cloud computing based on horned lizard algorithm optimised convolutional neural network-bidirectional gated recurrent unit",
                "image-path": ""
            },

            {
                "startTime": "45:43",
                "arxivId": "2407.15734",
                "arxivLink": "https://arxiv.org/abs/2407.15734",
                "title": "TaskGen: Taming the LLMs with StrictJSON and Shared Memory",
                "institute": "ETH Zurich, National University of Singapore",
                "text": "TaskGen introduces a novel approach to agentic frameworks by utilizing StrictJSON for concise LLM output and a shared memory system for efficient information exchange between agents and equipped functions. This contrasts with existing frameworks that rely on free-form text output, often leading to verbosity and increased processing costs.",
                "paper-title": "TaskGen: A Task-Based, Memory-Infused Agentic Framework using StrictJSON",
                "image-path": ""
            },

            {
                "startTime": "46:07",
                "arxivId": "2407.15631",
                "arxivLink": "https://arxiv.org/abs/2407.15631",
                "title": "Building Better Hearts: AI Designs Customized Coronary Arteries for Virtual Surgery",
                "institute": "MIT, Harvard University",
                "text": "This research introduces a new method for generating realistic and controllable 3D models of coronary arteries using Latent Diffusion Models (LDMs). Unlike previous methods that rely on simplified geometries or real patient data, this approach allows for the creation of customized arteries with specific morphological and skeletal features, enabling researchers to study the impact of anatomical variations on medical interventions.",
                "paper-title": "A Diffusion Model for Simulation Ready Coronary Anatomy with Morpho-skeletal Control",
                "image-path": ""
            },

            {
                "startTime": "46:32",
                "arxivId": "2407.15817",
                "arxivLink": "https://arxiv.org/abs/2407.15817",
                "title": "AI Fills the Gaps: A Deep Learning Fix for Fuzzy Cell Boundaries in SEM Images",
                "institute": "Sorbonne University, \u00c9cole des Ponts ParisTech, \u00c9cole Normale Sup\u00e9rieure",
                "text": "This research introduces a novel AI-driven approach for refining cell boundary delineation in SEM images. Unlike previous methods that rely on end-to-end segmentation, this study proposes a dedicated CNN-based closing operator (COp-Net) to address gaps in cell contours.",
                "paper-title": "Enhancing Cell Instance Segmentation in Scanning Electron Microscopy Images via a Deep Contour Closing Operator",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 103,
        "num_total": 487,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202407231649_audio.mp3"
}
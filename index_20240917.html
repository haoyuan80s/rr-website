
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ribbit Ribbit - AI Paper Picks of the Day</title>
    <meta name="description"
        content="Discover top ArXiv papers in AI and machine learning daily with our fresh picks. Browse easily through tweet-sized summaries or listen on-the-go. Make learning engaging and accessible anytime, anywhere.">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Amatic+SC:wght@400;700&family=Dosis:wght@200..800&family=Roboto:wght@300..700&display=swap">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
    <link rel="icon" href="assets/frogFavicon.png" type="image/x-icon">
    <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>
</head>

<body>
    <div id="headerId" class="header"></div>
    <div class="container">
        <div id="topblock">
            <div style="height: 80px;"></div>
            <div class="institute-text" style="padding-top: 3px; line-height: 1.2;">
                Freshest
                Top Picks:
                <span class="highlightNumber" style="font-size: 28px;">111</span> out of <span
                    class="highlightNumber">481</span> arXiv AI
                papers
            </div>
            <div style="display: flex; flex-direction: column; justify-content: flex-start; align-items: flex-start;">
                <div class="institute-text" style="line-height: 1.2;">just released on</div>
                <div id="data-default-date" data-date="2024-09-17"></div>
                <input type="text" id="selectedDate" style="text-decoration: underline;" />
            </div>
            <div style=" height: 10px;">
            </div>
        </div>


        <div class="tweet" id="tweet0">
            <div class="start-time-icon" title="Play from here">01:10</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09781" target="_blank">@arXiv 2409.09781</a>
                    <span class="tweet-title">Out-of-Sample Risk Estimation:  Fast, Accurate, and Debiased!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Stanford University</span>
                </div>
                <div class="primary-text">
                    This paper proposes a randomized approximate leave-one-out (RandALO) risk estimator that is both consistent and computationally efficient, unlike traditional cross-validation methods. RandALO leverages randomized numerical linear algebra techniques to reduce the computational cost of approximate leave-one-out (ALO) to a constant number of quadratic programs, making it significantly faster than even 5-fold cross-validation.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet1">
            <div class="start-time-icon" title="Play from here">01:34</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09894" target="_blank">@arXiv 2409.09894</a>
                    <span class="tweet-title">Foundation Models:  Unmasking the Gender Wage Gap's Hidden Secrets</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Harvard University, Stanford University, Columbia University</span>
                </div>
                <div class="primary-text">
                    This research uses foundation models, like large language models, to estimate the gender wage gap. Unlike traditional methods that rely on simple summaries of career history, this approach leverages the full complexity of a worker's history to provide a more accurate estimate of the unexplained wage gap.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet2">
            <div class="start-time-icon" title="Play from here">01:50</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10304" target="_blank">@arXiv 2409.10304</a>
                    <span class="tweet-title">AI for Chemistry:  From Predicting Properties to Designing Drugs</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Toronto, Vector Institute for Artificial Intelligence, Tinbergen Institute...</span>
                </div>
                <div class="primary-text">
                    This research provides a comprehensive overview of machine learning applications in chemistry, highlighting the current state of the field and identifying key areas for future development. It also emphasizes the importance of collaboration between chemists and machine learning researchers to maximize the impact of AI in chemistry.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet3">
            <div class="start-time-icon" title="Play from here">02:11</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09788" target="_blank">@arXiv 2409.09788</a>
                    <span class="tweet-title">AI Gets a Spatial Sense:  How Reference Objects Help Vision Models Measure Up</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Toronto</span>
                </div>
                <div class="primary-text">
                    This research introduces a new benchmark, Q-SpatialBench, specifically designed to evaluate quantitative spatial reasoning in vision-language models (VLMs).  The study also proposes a prompting technique, SpatialPrompt, that encourages VLMs to use reference objects within images to improve their accuracy in estimating distances and sizes. This approach differs from previous work that relied on fine-tuning models with additional data or architectural modifications.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet4">
            <div class="start-time-icon" title="Play from here">02:43</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09511" target="_blank">@arXiv 2409.09511</a>
                    <span class="tweet-title">Deep Learning's Got Rhythm: Unmasking the Secrets of Speech Emotion Recognition</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU, Harvard University, MIT</span>
                </div>
                <div class="primary-text">
                    This research uses a novel probing approach to explain deep learning embeddings in speech emotion recognition. Unlike previous work that focused on general information content, this study specifically investigates the interpretable acoustic features encoded in these embeddings.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet5">
            <div class="start-time-icon" title="Play from here">02:59</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09968" target="_blank">@arXiv 2409.09968</a>
                    <span class="tweet-title">AI Detects Heart Trouble in Lung Scans:  A New Way to Spot Silent Killers</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Veterans Affairs Long Beach Healthcare System, University of California  Irvine, Veterans Health Administration...</span>
                </div>
                <div class="primary-text">
                    This research differs from previous work by training an AI model on a massive dataset of non-gated CT scans from 98 VA medical centers, encompassing diverse imaging protocols and patient populations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet6">
            <div class="start-time-icon" title="Play from here">03:20</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10323" target="_blank">@arXiv 2409.10323</a>
                    <span class="tweet-title">Local Minima:  The Search for Meaningful Guarantees is Hard!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Weizmann Institute of Science, MIT</span>
                </div>
                <div class="primary-text">
                    This paper focuses on the hardness of finding local minima in non-smooth, non-convex optimization problems. Unlike previous work that focused on asymptotic convergence, this study proves that local algorithms cannot guarantee meaningful local improvements in sub-exponential time, even when all near-stationary points are global minima.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet7">
            <div class="start-time-icon" title="Play from here">03:41</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09614" target="_blank">@arXiv 2409.09614</a>
                    <span class="tweet-title">Solving Inverse Problems with a Hamilton-Jacobi Twist: A New Bayesian Sampler</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">UC Los Angeles, Brown University</span>
                </div>
                <div class="primary-text">
                    This research introduces a new Bayesian sampler, HJ-sampler, that leverages the log transform and connects it to stochastic optimal control problems. Unlike previous methods, this approach does not require an explicit analytical formula for the target distribution and can handle cases where only prior samples are available.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet8">
            <div class="start-time-icon" title="Play from here">04:03</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09432" target="_blank">@arXiv 2409.09432</a>
                    <span class="tweet-title">Satellite Sleuths:  Unmasking Looted Archaeological Sites with Time-Traveling Images!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">École des Ponts ParisTech, École Normale Supérieure</span>
                </div>
                <div class="primary-text">
                    This research introduces a new dataset, DAFA-LS, containing multi-temporal satellite images of Afghan archaeological sites. Unlike previous datasets, DAFA-LS focuses on detecting looting, which involves subtle changes in appearance, and is publicly available.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet9">
            <div class="start-time-icon" title="Play from here">04:19</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09785" target="_blank">@arXiv 2409.09785</a>
                    <span class="tweet-title">LLMs:  Speech Whisperers,  Not Just Text Twisters!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">MIT, University of Edinburgh</span>
                </div>
                <div class="primary-text">
                    This research introduces a new challenge called GenSEC, focusing on using large language models (LLMs) to improve speech recognition tasks beyond just correcting transcription errors. It explores how LLMs can be used for speaker tagging and emotion recognition, leveraging only the text output from an ASR system.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet10">
            <div class="start-time-icon" title="Play from here">04:42</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10102" target="_blank">@arXiv 2409.10102</a>
                    <span class="tweet-title">RAG Systems: Trustworthy or Just Trust-Falling?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University, Renmin University of China</span>
                </div>
                <div class="primary-text">
                    This research focuses on the trustworthiness of Retrieval-Augmented Generation (RAG) systems, a crucial aspect often overlooked in previous studies that primarily focused on performance optimization.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet11">
            <div class="start-time-icon" title="Play from here">05:05</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09099" target="_blank">@arXiv 2409.09099</a>
                    <span class="tweet-title">Sparse Training Gets a Smooth Makeover:  S-STE Solves the Discontinuity Dilemma</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research proposes a new method called S-STE for training sparse neural networks. Unlike previous methods that rely on discontinuous pruning functions, S-STE uses a continuous projection function to sparsify weights, leading to more stable and accurate training.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet12">
            <div class="start-time-icon" title="Play from here">05:32</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09951" target="_blank">@arXiv 2409.09951</a>
                    <span class="tweet-title">Ablation Revolution:  Finding the Brains of AI Models</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Harvard University</span>
                </div>
                <div class="primary-text">
                    This paper introduces a new method called "optimal ablation" (OA) for measuring the importance of individual components within machine learning models. Unlike previous methods that replace components with arbitrary values, OA finds the constant value that minimizes the model's loss when that component is removed.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet13">
            <div class="start-time-icon" title="Play from here">05:55</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09401" target="_blank">@arXiv 2409.09401</a>
                    <span class="tweet-title">Audio Captioning Gets a Diffusion Makeover: Faster, More Diverse, and Still Sounds Great!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tencent AI Lab, Beijing Institute of Technology, University of California  Berkeley...</span>
                </div>
                <div class="primary-text">
                    This paper introduces a new approach to audio captioning using diffusion models, a technique typically used for image generation. Unlike traditional autoregressive models, diffusion models generate captions in parallel, leading to faster generation speeds and increased diversity.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet14">
            <div class="start-time-icon" title="Play from here">06:19</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09497" target="_blank">@arXiv 2409.09497</a>
                    <span class="tweet-title">Semantic Segmentation Gets a Multi-Scale Makeover: Prototypes Learn to Group Up!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">École Polytechnique Fédérale de Lausanne, French Institute for Research in Computer Science and Automation</span>
                </div>
                <div class="primary-text">
                    This research introduces a new method for interpretable semantic segmentation that leverages multi-scale image representation for prototypical part learning. Unlike previous work, it explicitly learns prototypes at several scales and groups them using a sparse grouping mechanism.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet15">
            <div class="start-time-icon" title="Play from here">06:43</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09245" target="_blank">@arXiv 2409.09245</a>
                    <span class="tweet-title">Training Neural Networks at Ultra-Low Precision:  A Denoising Approach to Beat the Noise!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Google</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel approach to training neural networks at ultra-low precision and sparsity levels by modeling quantization and sparsification as perturbations and introducing a denoising affine transform to stabilize training. This differs from previous work that primarily focused on adapting gradient descent algorithms to handle non-differentiable operations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet16">
            <div class="start-time-icon" title="Play from here">07:08</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09906" target="_blank">@arXiv 2409.09906</a>
                    <span class="tweet-title">Constrained Optimization:  When Certainty Matters More Than Average!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Minnesota</span>
                </div>
                <div class="primary-text">
                    This research proposes a new method for solving stochastic optimization problems with deterministic constraints. Unlike previous methods that focus on minimizing expected constraint violations, this approach guarantees near-exact constraint satisfaction with certainty.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet17">
            <div class="start-time-icon" title="Play from here">07:29</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09903" target="_blank">@arXiv 2409.09903</a>
                    <span class="tweet-title">Softmax Mixtures:  A Recipe for Learning with Lots of Ingredients!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Toronto, Cornell University, New York University</span>
                </div>
                <div class="primary-text">
                    This paper provides the first theoretical analysis of the method of moments (MoM) and expectation-maximization (EM) algorithms for estimating parameters in softmax mixtures, a model commonly used in AI applications. Previous work has focused on these algorithms for Gaussian mixtures, but not for softmax mixtures.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet18">
            <div class="start-time-icon" title="Play from here">07:57</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10473" target="_blank">@arXiv 2409.10473</a>
                    <span class="tweet-title">Skeleton Modeling Gets a Diffusion Makeover:  MacDiff Unifies Representation Learning and Generation!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Peking University</span>
                </div>
                <div class="primary-text">
                    This paper proposes Masked Conditional Diffusion (MacDiff), a novel framework for skeleton modeling that leverages diffusion models for both representation learning and generation. Unlike previous methods that rely on contrastive learning or reconstruction, MacDiff utilizes a semantic encoder to guide a diffusion decoder, enabling the model to learn more powerful representations for both discriminative and generative tasks.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet19">
            <div class="start-time-icon" title="Play from here">08:24</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09506" target="_blank">@arXiv 2409.09506</a>
                    <span class="tweet-title">ESPnet-EZ:  Speech Processing Made Easy (and Python-y!)</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Carnegie Mellon University, Hugging Face</span>
                </div>
                <div class="primary-text">
                    This research introduces ESPnet-EZ, an extension of the ESPnet toolkit that simplifies speech model development by replacing Bash scripts with a Python-only interface. This shift aims to reduce engineering effort, particularly for tasks like fine-tuning existing models.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet20">
            <div class="start-time-icon" title="Play from here">08:41</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09253" target="_blank">@arXiv 2409.09253</a>
                    <span class="tweet-title">LLMs Get a Semantic Makeover: Twin Towers for Better Recommendations!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Central South University, Microsoft, Griffith University</span>
                </div>
                <div class="primary-text">
                    This research introduces a dynamic semantic index paradigm for recommender systems, which differs from previous static index approaches by integrating semantic and collaborative knowledge within a single LLM backbone.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet21">
            <div class="start-time-icon" title="Play from here">09:08</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09469" target="_blank">@arXiv 2409.09469</a>
                    <span class="tweet-title">Hypergraph Wavelets: Unraveling the Secrets of Cellular Niches in Alzheimer's</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Yale University</span>
                </div>
                <div class="primary-text">
                    This research introduces hypergraph diffusion wavelets, a novel method for representing and analyzing higher-order relationships in data. Unlike traditional graph representations that focus on pairwise interactions, hypergraphs allow for edges to connect multiple nodes, capturing complex interactions within cellular niches.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet22">
            <div class="start-time-icon" title="Play from here">09:31</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09570" target="_blank">@arXiv 2409.09570</a>
                    <span class="tweet-title">AI Journaling: Your Phone Knows What You Need to Write!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Dartmouth College, Colby College, Brown University...</span>
                </div>
                <div class="primary-text">
                    This research integrates passively collected behavioral data from smartphones with LLMs to generate personalized journaling prompts, unlike previous studies that relied on generic prompts or limited contextual data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet23">
            <div class="start-time-icon" title="Play from here">09:59</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10452" target="_blank">@arXiv 2409.10452</a>
                    <span class="tweet-title">Signed Graph Autoencoder:  Unmasking the Hidden Polarization in Networks</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">École Polytechnique, ENS Paris-Saclay, University of Peloponnese</span>
                </div>
                <div class="primary-text">
                    This research introduces a new type of graph autoencoder specifically designed for signed networks, which are networks where connections can be positive or negative. The model, called SGAAE, learns two sets of embeddings for each node, one for positive connections and one for negative connections, allowing it to capture the complex interplay of both types of relationships. This is different from previous work that typically focused on unsigned networks or only considered one set of embeddings for each node.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet24">
            <div class="start-time-icon" title="Play from here">10:42</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10245" target="_blank">@arXiv 2409.10245</a>
                    <span class="tweet-title">Emojis Unleashed: How LLMs Got Their Personality Through Fine-Tuning</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University College London</span>
                </div>
                <div class="primary-text">
                    This research uses Parameter-Efficient Fine-Tuning (PEFT) to manipulate personality traits in LLMs, specifically the Big Five, which is different from previous methods like prompt engineering and knowledge editing that have shown inconsistency and variability.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet25">
            <div class="start-time-icon" title="Play from here">11:02</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09714" target="_blank">@arXiv 2409.09714</a>
                    <span class="tweet-title">Hand-in-Hand with AI:  Pre-training 3D Hand Pose Estimation with a Million-Image Makeover!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Tokyo</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel contrastive learning framework for pre-training 3D hand pose estimators. Unlike previous methods that rely on augmenting single images, this approach leverages similar hand poses from different images, creating a more diverse and informative training set.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet26">
            <div class="start-time-icon" title="Play from here">11:25</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09549" target="_blank">@arXiv 2409.09549</a>
                    <span class="tweet-title">Foundation Models for Healthcare:  A Continual Fine-Tuning Framework for WMS Data</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Princeton University</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel framework called COMFORT for pre-training a Transformer-based foundation model on a large dataset of physiological signals collected from healthy individuals using commercially available wearable medical sensors (WMSs). This approach differs from previous work by focusing on pre-training with healthy individual data, which is more readily available than patient data, and then fine-tuning the model for specific disease detection tasks using parameter-efficient fine-tuning (PEFT) methods.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet27">
            <div class="start-time-icon" title="Play from here">11:49</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10168" target="_blank">@arXiv 2409.10168</a>
                    <span class="tweet-title">YouTube's Algorithm: Is It Fairer in the US or South Africa?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Washington</span>
                </div>
                <div class="primary-text">
                    This research compares the prevalence of COVID-19 misinformation on YouTube search results in the United States and South Africa, a contrast rarely explored in previous studies.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet28">
            <div class="start-time-icon" title="Play from here">12:14</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09563" target="_blank">@arXiv 2409.09563</a>
                    <span class="tweet-title">AI Stargazer: Neural Network Spots Binary Stars Faster Than Ever!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Boyce Research Initiatives and Education Foundation, European Space Agency</span>
                </div>
                <div class="primary-text">
                    This research proposes an artificial neural network (ANN) to automatically classify astrometric binary stars, a significant improvement over existing computationally expensive methods. The ANN utilizes six astrometric parameters as features, including proper motions, parallaxes, and angular and physical separations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet29">
            <div class="start-time-icon" title="Play from here">12:34</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09130" target="_blank">@arXiv 2409.09130</a>
                    <span class="tweet-title">DNNs Got Overconfident? FAST Helps Them See the Error of Their Ways!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Zhejiang University, University of Oxford, University of Manchester</span>
                </div>
                <div class="primary-text">
                    This research proposes FAST, a method that improves existing test case prioritization techniques for deep neural networks (DNNs) by incorporating feature selection. Unlike previous methods that rely solely on the model's output confidence, FAST identifies and prunes "noisy" features that contribute to high-confidence errors, leading to more accurate uncertainty estimation.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet30">
            <div class="start-time-icon" title="Play from here">13:02</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09347" target="_blank">@arXiv 2409.09347</a>
                    <span class="tweet-title">Schrödinger's Cat Got a Flow: New Algorithm Makes Data Translation a Breeze!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Google DeepMind</span>
                </div>
                <div class="primary-text">
                    This paper introduces a novel algorithm called α-DSBM for computing the Schrödinger Bridge, a dynamic entropy-regularized version of Optimal Transport. Unlike previous methods that require training multiple DDM-like models, α-DSBM eliminates this need by leveraging a flow of path measures.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet31">
            <div class="start-time-icon" title="Play from here">13:22</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10476" target="_blank">@arXiv 2409.10476</a>
                    <span class="tweet-title">Text-to-Image Editing Gets a Tune-Up: SimInversion Makes Diffusion Models Smarter</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Alibaba, University of Washington</span>
                </div>
                <div class="primary-text">
                    This research focuses on improving the accuracy of text-guided image editing by addressing the approximation error in the DDIM inversion process. The authors propose a simple framework called SimInversion that disentangles the guidance scale for the source and target branches, leading to a more accurate reconstruction of the source image.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet32">
            <div class="start-time-icon" title="Play from here">13:44</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09354" target="_blank">@arXiv 2409.09354</a>
                    <span class="tweet-title">PeriGuru:  The Robotic Arm That's Got Your Apps Under Control!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Peking University</span>
                </div>
                <div class="primary-text">
                    This research introduces PeriGuru, a peripheral robotic mobile app operation assistant that uses computer vision to understand GUI images and prompts a large language model (LLM) to make decisions. Unlike previous work that relies on software-level access, PeriGuru operates purely peripherally, avoiding privacy concerns and permission issues.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet33">
            <div class="start-time-icon" title="Play from here">14:11</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09260" target="_blank">@arXiv 2409.09260</a>
                    <span class="tweet-title">Word Embeddings:  Are They Really Biased?  A New Study Uncovers the Truth!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Tokyo</span>
                </div>
                <div class="primary-text">
                    This research re-examines the relationship between intrinsic and extrinsic bias metrics in word embeddings. Unlike previous studies, it ensures that both metrics measure the same type of bias by carefully selecting word sets from extrinsic bias datasets.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet34">
            <div class="start-time-icon" title="Play from here">14:28</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09046" target="_blank">@arXiv 2409.09046</a>
                    <span class="tweet-title">AI Lawyers Get Smarter:  New System Adapts to Legal Jargon</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University College London</span>
                </div>
                <div class="primary-text">
                    This research introduces a hybrid parameter-adaptive retrieval-augmented generation (HyPA-RAG) system specifically tailored for AI legal and policy applications. Unlike previous RAG systems, HyPA-RAG dynamically adjusts parameters based on query complexity, incorporating both dense and sparse retrieval methods, as well as knowledge graph techniques.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet35">
            <div class="start-time-icon" title="Play from here">14:54</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09500" target="_blank">@arXiv 2409.09500</a>
                    <span class="tweet-title">Remote Control: Can We Really Tele-Supervise Self-Driving Cars?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">MIT</span>
                </div>
                <div class="primary-text">
                    This research uses real-world traffic data to simulate the number of human supervisors needed for autonomous vehicle (AV) merges, unlike previous work that relied on theoretical models.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet36">
            <div class="start-time-icon" title="Play from here">15:13</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09191" target="_blank">@arXiv 2409.09191</a>
                    <span class="tweet-title">LLMs Get a Process Makeover: New Dataset Tests Their Planning Prowess</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Technical University of Denmark, Microsoft</span>
                </div>
                <div class="primary-text">
                    This research introduces ProcessTBench, a dataset designed to evaluate LLMs' plan generation capabilities within a process mining framework. Unlike previous datasets, ProcessTBench incorporates multi-lingual query paraphrases, a planning framework tailored for process mining, and a comprehensive planning dataset.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet37">
            <div class="start-time-icon" title="Play from here">15:38</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09071" target="_blank">@arXiv 2409.09071</a>
                    <span class="tweet-title">LLMs on Mobile:  Making Big Brains Fit Tiny Phones!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Peking University, Beijing University of Posts and Telecommunications</span>
                </div>
                <div class="primary-text">
                    This research introduces ELMS, an on-device LLM service that tackles the challenge of providing different levels of performance (latency) for various mobile apps. Unlike previous work that focuses on model pruning alone, ELMS introduces a novel technique called "one-shot reordering" of permutation consistent units, which allows for efficient switching between sub-models without incurring significant runtime overhead.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet38">
            <div class="start-time-icon" title="Play from here">16:09</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09261" target="_blank">@arXiv 2409.09261</a>
                    <span class="tweet-title">Tired of Your ML Model's Bad Behavior? SemSlicer to the Rescue!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Carnegie Mellon University, Carnegie Mellon Software Engineering Institute</span>
                </div>
                <div class="primary-text">
                    This research introduces SemSlicer, a framework that uses Large Language Models (LLMs) to perform semantic data slicing. Unlike traditional programmatic slicing, which relies on existing features, SemSlicer can identify slices based on any user-defined criteria, even those without readily available features.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet39">
            <div class="start-time-icon" title="Play from here">16:36</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09621" target="_blank">@arXiv 2409.09621</a>
                    <span class="tweet-title">Stutter-Solver:  YOLO for Speech,  No Templates Needed!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">UC Berkeley</span>
                </div>
                <div class="primary-text">
                    This research proposes Stutter-Solver, an end-to-end framework for dysfluency detection that utilizes a YOLO-inspired approach. Unlike previous methods that rely on template matching, Stutter-Solver directly predicts dysfluency types and time boundaries, making it more scalable and generalizable across languages.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet40">
            <div class="start-time-icon" title="Play from here">17:00</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09300" target="_blank">@arXiv 2409.09300</a>
                    <span class="tweet-title">ManiDext:  Giving Virtual Hands a Grip on Reality with Continuous Correspondence Embeddings</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Beijing University of Posts and Telecommunications, Tsinghua University, Beijing Normal University</span>
                </div>
                <div class="primary-text">
                    This research introduces a continuous correspondence embedding representation to model hand-object contact more accurately than previous methods that used contact probability maps or discrete hand part labels.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet41">
            <div class="start-time-icon" title="Play from here">17:28</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09828" target="_blank">@arXiv 2409.09828</a>
                    <span class="tweet-title">RNA Diffusion:  A New Way to Design Life's Tiny Machines</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Princeton University</span>
                </div>
                <div class="primary-text">
                    This paper introduces a latent diffusion model for generating and optimizing RNA sequences. Unlike previous work that focused on autoregressive models, this approach utilizes a sequence autoencoder to map RNA sequences into a fixed-length latent space, allowing for more efficient training and generation.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet42">
            <div class="start-time-icon" title="Play from here">18:01</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09586" target="_blank">@arXiv 2409.09586</a>
                    <span class="tweet-title">AI's Got Values:  A Compass for Ethical AI Development</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Washington, Google, Microsoft...</span>
                </div>
                <div class="primary-text">
                    This research introduces ValueCompass, a framework that systematically identifies and evaluates fundamental human values for AI alignment. It goes beyond previous work by incorporating a systematic review of AI alignment literature to supplement Schwartz's Theory of Basic Values, resulting in a more comprehensive set of values.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet43">
            <div class="start-time-icon" title="Play from here">18:23</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09745" target="_blank">@arXiv 2409.09745</a>
                    <span class="tweet-title">SGD:  The  Momentum  Master  of  High-Dimensional  Problems!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Peking University</span>
                </div>
                <div class="primary-text">
                    This research investigates the optimality of SGD and its accelerated variants for high-dimensional quadratic optimization problems, focusing on the impact of exponentially decaying step sizes and momentum. It identifies specific conditions under which these techniques achieve optimal convergence rates, expanding upon previous work that primarily focused on vanilla SGD in narrower settings.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet44">
            <div class="start-time-icon" title="Play from here">18:49</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09240" target="_blank">@arXiv 2409.09240</a>
                    <span class="tweet-title">Hyperparameter Optimization:  Adam's New Best Friend?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">MIT</span>
                </div>
                <div class="primary-text">
                    This paper proposes a novel hyperparameter optimization method for stochastic gradient-based approaches, specifically focusing on Adam and its variants, using cross-entropy optimization. This differs from existing methods by employing a probability distribution over the hyperparameter space and utilizing rare event simulation techniques to find optimal values.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet45">
            <div class="start-time-icon" title="Play from here">19:11</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09756" target="_blank">@arXiv 2409.09756</a>
                    <span class="tweet-title">Shrinking 3D Scenes: A New Codec for Compressing 3D Gaussian Splatting</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University, Peng Cheng Laboratory, The Chinese University of Hong Kong...</span>
                </div>
                <div class="primary-text">
                    This research proposes a post-training compression method for 3D Gaussian Splatting, focusing on attribute transformation and Gaussian pruning, unlike previous methods that rely on extensive training.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet46">
            <div class="start-time-icon" title="Play from here">19:36</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09479" target="_blank">@arXiv 2409.09479</a>
                    <span class="tweet-title">Stereo VO Gets a Covariance Makeover: MAC-VO Sees the World with More Confidence!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Carnegie Mellon University, Shanghai Jiao Tong University</span>
                </div>
                <div class="primary-text">
                    This research introduces MAC-VO, a stereo visual odometry (VO) system that utilizes a learned metrics-aware covariance model. Unlike previous methods that rely on scale-agnostic or simplified covariance models, MAC-VO captures the spatial error during keypoint registration and the correlations between different axes.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet47">
            <div class="start-time-icon" title="Play from here">20:05</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09480" target="_blank">@arXiv 2409.09480</a>
                    <span class="tweet-title">Neumann Series: The Secret Weapon for Solving Inverse Medium Problems</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel approach to solving inverse medium problems by integrating the Neumann series structure within a neural network framework. This method differs from previous work by explicitly decoupling multi-parameter inputs, enhancing generalization performance and computational speed.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet48">
            <div class="start-time-icon" title="Play from here">20:25</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10038" target="_blank">@arXiv 2409.10038</a>
                    <span class="tweet-title">LLMs Get a Brain: New Framework Models Reasoning as a Directed Acyclic Graph</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This paper introduces Diagram of Thought (DoT), a framework that models reasoning in LLMs as the construction of a directed acyclic graph (DAG) within a single model. Unlike previous approaches that represent reasoning as linear chains or trees, DoT organizes propositions, critiques, refinements, and verifications into a cohesive DAG structure.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet49">
            <div class="start-time-icon" title="Play from here">20:52</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09085" target="_blank">@arXiv 2409.09085</a>
                    <span class="tweet-title">Pruning Made Easy: A New Optimizer That Makes Neural Network Compression a Breeze!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Microsoft</span>
                </div>
                <div class="primary-text">
                    This research introduces HESSO, a novel optimizer that automatically trains and prunes neural networks in a single run, eliminating the need for multi-stage procedures and manual tuning. Unlike previous methods that rely on hyperparameter-heavy sparse optimizers, HESSO employs a progressive pruning strategy and a hybrid training schema to achieve efficient and reliable compression.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet50">
            <div class="start-time-icon" title="Play from here">21:14</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09464" target="_blank">@arXiv 2409.09464</a>
                    <span class="tweet-title">LLMs:  Code-Savvy or Code-Blind?  New Study Tests Their Limits!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Hong Kong, King’s College London, National University of Singapore...</span>
                </div>
                <div class="primary-text">
                    This research investigates the impact of incorrect source code on the effectiveness of test cases generated by LLMs. Unlike previous work that primarily focused on generating code from task descriptions, this study explores how LLMs handle flawed code and its implications for testing.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet51">
            <div class="start-time-icon" title="Play from here">21:42</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10320" target="_blank">@arXiv 2409.10320</a>
                    <span class="tweet-title">Driving Bots to the Edge: New AI Makes Self-Driving Cars Smarter (and Safer) by Learning from Their Mistakes</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU, Bosch</span>
                </div>
                <div class="primary-text">
                    This research introduces a new approach to generating scenarios for training autonomous driving systems. Unlike previous methods that focus on inducing collisions, this approach prioritizes realistic, reactive adversarial behavior by leveraging learned scoring functions and adversarial skill policies.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet52">
            <div class="start-time-icon" title="Play from here">22:10</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09931" target="_blank">@arXiv 2409.09931</a>
                    <span class="tweet-title">AI Force Fields: Can They Predict Solid-State Behavior?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Stanford University</span>
                </div>
                <div class="primary-text">
                    This research goes beyond previous work by testing the ability of a graph neural network (GNN)-based machine-learned force field (MLFF) to predict solid-state properties, including phonon density of states, thermal conductivity, and vacancy migration rates, even for configurations not explicitly included in the training data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet53">
            <div class="start-time-icon" title="Play from here">22:32</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09582" target="_blank">@arXiv 2409.09582</a>
                    <span class="tweet-title">Vision Models:  Learning to Ignore the Noise!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Johns Hopkins University, University of California  Berkeley, University of California San Diego...</span>
                </div>
                <div class="primary-text">
                    This paper introduces NEVLP, a framework for vision-language pre-training that uses frozen image encoders and LLMs. It tackles the issue of noisy web data by incorporating two novel learning strategies: noise-adaptive learning and concept-enhanced learning.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet54">
            <div class="start-time-icon" title="Play from here">23:05</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10096" target="_blank">@arXiv 2409.10096</a>
                    <span class="tweet-title">Reinforcement Learning Goes Robust:  When AI Needs a Safety Net</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Toronto, Imperial College London</span>
                </div>
                <div class="primary-text">
                    This research introduces a new framework for robust risk-aware reinforcement learning by incorporating dynamic distortion risk measures and Wasserstein uncertainty sets. This approach simultaneously accounts for environmental uncertainty and risk, which is a significant departure from previous work that often focused on either risk or uncertainty in isolation.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet55">
            <div class="start-time-icon" title="Play from here">23:31</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09642" target="_blank">@arXiv 2409.09642</a>
                    <span class="tweet-title">Speech Enhancement Gets a Boost:  Latent Integration Makes Diffusion Models Sing!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University, University of Cambridge, Chinese University of Hong Kong</span>
                </div>
                <div class="primary-text">
                    This research introduces Extract and Diffuse (Ex-Diff), a novel approach that combines latent representations from a discriminative model with a diffusion-based generative model for improved speech and vocal enhancement. Unlike previous work that directly conditions on the audio mixture, Ex-Diff leverages latent representations to provide a clearer indication of what to extract and enhance, reducing the likelihood of generating unexpected sounds.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet56">
            <div class="start-time-icon" title="Play from here">24:00</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09371" target="_blank">@arXiv 2409.09371</a>
                    <span class="tweet-title">Weather Models:  Stop Cheating on Reanalysis, Get Real with In-Situ Data!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Microsoft</span>
                </div>
                <div class="primary-text">
                    This research introduces WeatherReal, a benchmark dataset for evaluating weather models that uses in-situ observations instead of reanalysis data. This is significant because reanalysis data, while convenient, can contain biases and inaccuracies, especially for crucial variables like near-surface temperature, wind, precipitation, and clouds.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet57">
            <div class="start-time-icon" title="Play from here">24:24</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09083" target="_blank">@arXiv 2409.09083</a>
                    <span class="tweet-title">Training AI on a Budget: How to Build a Brain on a Raspberry Pi Cluster</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Texas at Austin</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel method for distributed CNN training on resource-constrained mobile and edge clusters, focusing on partitioning feature maps and delta gradients for both forward and backward passes. Unlike previous approaches that rely on centralized servers, this method allows for training exclusively on edge devices, minimizing communication overhead and maximizing locality.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet58">
            <div class="start-time-icon" title="Play from here">24:49</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10141" target="_blank">@arXiv 2409.10141</a>
                    <span class="tweet-title">Single Image, Full Body:  Diffusion Makes 3D Human Modeling a Breeze!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">HKUST, Southeast University, Tsinghua University...</span>
                </div>
                <div class="primary-text">
                    This paper introduces a novel approach to 3D human reconstruction from a single image using a multi-view diffusion model. Unlike previous methods that rely on implicit functions, this approach leverages explicit mesh carving, resulting in more detailed and realistic reconstructions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet59">
            <div class="start-time-icon" title="Play from here">25:13</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09811" target="_blank">@arXiv 2409.09811</a>
                    <span class="tweet-title">Fluid Dynamics Forecasting: A Multimodal Model Learns to Predict the Flow!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">UCLA, Carnegie Mellon University, Florida State University</span>
                </div>
                <div class="primary-text">
                    This research introduces PROSE-FD, a multimodal PDE foundation model that learns to predict fluid dynamics by incorporating both data and symbolic information about the governing equations. This approach differs from previous work by simultaneously learning multiple operators for different physical systems, enabling more accurate and generalizable predictions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet60">
            <div class="start-time-icon" title="Play from here">25:36</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09273" target="_blank">@arXiv 2409.09273</a>
                    <span class="tweet-title">FedD2P:  AI's  New  Trick  to  Train  Smart  Devices  Without  Breaking  the  Bank</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Concordia University, University of Toronto, Yazd University</span>
                </div>
                <div class="primary-text">
                    This research proposes a new framework called FedD2P that leverages the power of Foundation Models (FMs) for federated learning in resource-constrained edge networks. Unlike previous approaches that require deploying FMs on each device, FedD2P keeps the FM on a central server and distills knowledge from local devices to a prompt generator, making it more efficient and practical for IoT devices.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet61">
            <div class="start-time-icon" title="Play from here">26:08</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09484" target="_blank">@arXiv 2409.09484</a>
                    <span class="tweet-title">Polyp-Hunting with YOLO-SAM 2: A Self-Prompting Approach to Colonoscopy Segmentation</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Concordia University, University of Toronto, Yazd University</span>
                </div>
                <div class="primary-text">
                    This research introduces a self-prompting polyp segmentation model that integrates YOLOv8 for bounding box predictions with SAM 2 for precise segmentation, reducing the need for manual annotations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet62">
            <div class="start-time-icon" title="Play from here">26:35</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10176" target="_blank">@arXiv 2409.10176</a>
                    <span class="tweet-title">Predicting Sports Wins?  Let's Get Momentum!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research introduces a new model called TM2, which uses a momentum transfer approach to predict long-term sports outcomes. Unlike previous models that rely on complex mathematical techniques, TM2  encodes momentum in large-scale unstructured time series using the Local Linear Scaling Approximation (LLSA) module.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet63">
            <div class="start-time-icon" title="Play from here">27:04</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10095" target="_blank">@arXiv 2409.10095</a>
                    <span class="tweet-title">Driving Like a Human: A Single Brain for a Self-Driving Car</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">MIT</span>
                </div>
                <div class="primary-text">
                    This research proposes a single encoder trained on multiple computer vision tasks, such as depth, pose, and segmentation, to improve steering angle estimation in autonomous driving. This differs from previous work that typically uses separate encoders for each task.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet64">
            <div class="start-time-icon" title="Play from here">27:23</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09668" target="_blank">@arXiv 2409.09668</a>
                    <span class="tweet-title">Video Editing Models Get a Reality Check: EditBoard Benchmark Unveils the Truth!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">The Chinese University of Hong Kong  Shenzhen, Nanjing University, University of Oxford</span>
                </div>
                <div class="primary-text">
                    This research introduces EditBoard, a comprehensive evaluation benchmark specifically designed for text-based video editing models. Unlike previous benchmarks that focused on limited metrics and tasks, EditBoard encompasses nine metrics across four dimensions, including fidelity, execution, consistency, and style. It also introduces three new metrics to assess fidelity, which is crucial for evaluating how well edited videos preserve the original video's motion and structure.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet65">
            <div class="start-time-icon" title="Play from here">27:49</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09095" target="_blank">@arXiv 2409.09095</a>
                    <span class="tweet-title">EHR Data: From Slowpoke to Speed Demon!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Stanford University, Prealize Health, Harvard Medical School</span>
                </div>
                <div class="primary-text">
                    This research introduces meds_reader, a Python package designed to process electronic health record (EHR) data more efficiently than existing pipelines. It leverages the event stream nature of EHR data and optimizes for its unique properties, such as sparseness and repetition.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet66">
            <div class="start-time-icon" title="Play from here">28:12</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10516" target="_blank">@arXiv 2409.10516</a>
                    <span class="tweet-title">LLMs Get a Speed Boost:  RetrievalAttention Makes Long Texts a Breeze!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Microsoft</span>
                </div>
                <div class="primary-text">
                    This paper proposes RetrievalAttention, a method that uses vector retrieval to accelerate attention computation in LLMs. Unlike previous methods that rely on static or heuristic approaches, RetrievalAttention dynamically identifies the most relevant key vectors for each query, leading to more accurate results.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet67">
            <div class="start-time-icon" title="Play from here">28:38</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10085" target="_blank">@arXiv 2409.10085</a>
                    <span class="tweet-title">Optimal Transport Gets a Geometry Makeover: Learning the Right Metric for the Job!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Microsoft, University of Sydney</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel approach to ground metric learning in optimal transport (OT) by jointly learning the transport plan and the ground metric. Unlike previous work that relies on pre-defined metrics, this method learns a suitable metric from the data itself, making OT more flexible and applicable across diverse domains.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet68">
            <div class="start-time-icon" title="Play from here">29:02</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09721" target="_blank">@arXiv 2409.09721</a>
                    <span class="tweet-title">CLIP's Got a New Trick: Reasoning About Differences!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel approach to finetune CLIP, a vision-language model, to reason about differences between images. Unlike previous work that focuses on aligning image and text embeddings, this paper leverages large language models (LLMs) to generate synthetic descriptions of image differences and incorporates them into the training process.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet69">
            <div class="start-time-icon" title="Play from here">29:26</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10259" target="_blank">@arXiv 2409.10259</a>
                    <span class="tweet-title">DAS Detects Cars:  A Semi-Supervised Learning Approach to Urban Traffic Monitoring</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Hong Kong</span>
                </div>
                <div class="primary-text">
                    This research introduces a semi-supervised learning framework for vehicle monitoring using Distributed Acoustic Sensing (DAS) data. Unlike previous work that relies heavily on labeled data, this framework leverages unlabeled data to improve model performance, reducing the need for extensive manual labeling.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet70">
            <div class="start-time-icon" title="Play from here">29:48</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09760" target="_blank">@arXiv 2409.09760</a>
                    <span class="tweet-title">AI-Powered Karaoke for Sign Language:  Singing with a Chatbot!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Toronto</span>
                </div>
                <div class="primary-text">
                    This research focuses on developing a tool that assists song-signers in translating lyrics into sign language. Unlike previous work that focused on general sign language translation, this tool specifically addresses the challenges of translating lyrics, including semantic, syntactic, expressive, and rhythmic considerations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet71">
            <div class="start-time-icon" title="Play from here">30:08</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09653" target="_blank">@arXiv 2409.09653</a>
                    <span class="tweet-title">KAN vs. MLP:  Who's the Offline RL King?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Chinese Academy of Sciences, Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This paper explores the use of Kolmogorov-Arnold Networks (KAN) as an alternative to Multi-Layer Perceptrons (MLP) in offline reinforcement learning (RL), a field where agents learn from past data without interacting with the environment.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet72">
            <div class="start-time-icon" title="Play from here">30:29</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09725" target="_blank">@arXiv 2409.09725</a>
                    <span class="tweet-title">Robots Get a Grip: Diffusion Networks for Super-Precise Pick-and-Place</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">National Tsing Hua University, National Taiwan University, National Yang Ming Chiao Tung University</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel coarse-to-fine continuous pose diffusion method for robotic manipulation tasks. Unlike previous methods that rely on discrete pose outputs, this approach generates continuous poses, enabling more precise object manipulation, particularly concerning rotational angles.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet73">
            <div class="start-time-icon" title="Play from here">30:53</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09573" target="_blank">@arXiv 2409.09573</a>
                    <span class="tweet-title">Robot Swarms: No More Deadlock Drama!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Texas at Austin, University of Virginia</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel algorithm for safe and scalable multi-agent control, combining learning-based and optimization-based methods to address limitations in existing approaches. The key innovation lies in embedding a lightweight Model Predictive Control (MPC) framework within a neural network policy to guarantee safety and input constraint satisfaction while maintaining scalability.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet74">
            <div class="start-time-icon" title="Play from here">31:19</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09536" target="_blank">@arXiv 2409.09536</a>
                    <span class="tweet-title">Robot Control:  From "Go Fetch" to Formal Specs!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Eindhoven University of Technology, Peking University</span>
                </div>
                <div class="primary-text">
                    This research proposes a novel robot motion planner, VernaCopter, that uses Signal Temporal Logic (STL) as a bridge between natural language commands and specific task objectives. This approach aims to reduce ambiguity and uncertainty inherent in natural language-driven robot control.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet75">
            <div class="start-time-icon" title="Play from here">31:47</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10064" target="_blank">@arXiv 2409.10064</a>
                    <span class="tweet-title">MindGuard: Your Mental Health's New Best Friend (and It's on Your Phone!)</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">California Institute of Technology, University of California  Los Angeles</span>
                </div>
                <div class="primary-text">
                    This research introduces MindGuard, a mobile mental health system that integrates objective sensor data from mobile devices with subjective LLM-powered conversational data. This approach differs from previous work by focusing on accessible and stigma-free mental health first aid (MHFA) through continuous monitoring and personalized intervention.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet76">
            <div class="start-time-icon" title="Play from here">32:11</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09610" target="_blank">@arXiv 2409.09610</a>
                    <span class="tweet-title">Texture Transfer:  Say Goodbye to Boring Wood and Gold!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research proposes a new method called TextureDiffusion that allows for the transfer of complex textures like clouds or fire to images, unlike previous methods that were limited to simple textures. The key difference lies in disentangling the texture from the input image description in the target prompt, allowing for a more accurate representation of the desired texture.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet77">
            <div class="start-time-icon" title="Play from here">32:39</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09041" target="_blank">@arXiv 2409.09041</a>
                    <span class="tweet-title">AI's New Rules:  Foundation Models Get a "Do Not" List!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Stanford University</span>
                </div>
                <div class="primary-text">
                    This research focuses on the acceptable use policies (AUPs) implemented by foundation model developers, analyzing the specific restrictions they impose on users. It goes beyond simply identifying risks and delves into how companies are actively shaping the use of these powerful models.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet78">
            <div class="start-time-icon" title="Play from here">33:04</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09887" target="_blank">@arXiv 2409.09887</a>
                    <span class="tweet-title">Leiden-Fusion:  Graph Partitioning Gets a Community Makeover!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Sorbonne University</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel graph partitioning method called Leiden-Fusion, which ensures that each subgraph remains a single connected component with no isolated nodes. This is different from previous methods that often result in multiple components and isolated nodes, hindering the effectiveness of GNN training.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet79">
            <div class="start-time-icon" title="Play from here">33:29</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10371" target="_blank">@arXiv 2409.10371</a>
                    <span class="tweet-title">Robots Learn Gentle Grasping Without Human Help!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research proposes a method for learning gentle grasping from human-free force control demonstrations. Unlike previous work that relies on human demonstrations or complex slip detection algorithms, this approach utilizes pre-measured frictional properties of objects to automatically generate reference force curves.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet80">
            <div class="start-time-icon" title="Play from here">33:52</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09774" target="_blank">@arXiv 2409.09774</a>
                    <span class="tweet-title">Text-to-Image Alignment:  Beyond the Reverse KL Divergence!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research generalizes the alignment paradigm of text-to-image models from solely relying on the reverse Kullback-Leibler divergence to a broader framework based on f-divergence constraints. This allows for exploring a wider range of divergences, including Jensen-Shannon divergence, forward Kullback-Leibler divergence, and α-divergence.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet81">
            <div class="start-time-icon" title="Play from here">34:16</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10164" target="_blank">@arXiv 2409.10164</a>
                    <span class="tweet-title">Reward Models Get a Dose of Reality: Quantile Regression for RLHF</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Freiburg, Agile Loop</span>
                </div>
                <div class="primary-text">
                    This paper introduces Quantile Reward Models (QRM), which learn a distribution over rewards instead of a single scalar value. This approach uses quantile regression to estimate a full, potentially multimodal distribution over preferences, providing a more nuanced representation of human values.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet82">
            <div class="start-time-icon" title="Play from here">34:43</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09603" target="_blank">@arXiv 2409.09603</a>
                    <span class="tweet-title">Data-Centric RLHF:  Is Bigger Always Better?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Stanford University, Apple Inc.</span>
                </div>
                <div class="primary-text">
                    This research focuses on comparing different preference datasets used in Reinforcement Learning from Human Feedback (RLHF) by introducing three metrics: effective sample size, noise invariance, and information content. This is a departure from previous work that primarily focused on algorithms for learning from preference data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet83">
            <div class="start-time-icon" title="Play from here">35:00</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09217" target="_blank">@arXiv 2409.09217</a>
                    <span class="tweet-title">WENO Schemes Get a Neural Network Makeover: Less Dissipation, More Accuracy!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Google Research, Technical University of Munich, Georgia Institute of Technology</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel approach for dynamically adapting WENO weights using rational neural networks. Unlike previous work that uses other types of neural networks, this method leverages the ability of rational functions to efficiently approximate discontinuous functions, resulting in a more accurate and less dissipative scheme.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet84">
            <div class="start-time-icon" title="Play from here">35:20</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09455" target="_blank">@arXiv 2409.09455</a>
                    <span class="tweet-title">Keypoint Discovery for Multi-Agent Behavior:  No More Annoying Annotations!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">California Institute of Technology, Cornell University</span>
                </div>
                <div class="primary-text">
                    This research introduces B-KinD-multi, a self-supervised keypoint discovery method for videos containing multiple agents. Unlike previous methods that struggle with visually similar agents, B-KinD-multi leverages pre-trained video segmentation models to guide keypoint discovery, eliminating the need for manual annotations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet85">
            <div class="start-time-icon" title="Play from here">35:44</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09201" target="_blank">@arXiv 2409.09201</a>
                    <span class="tweet-title">LLMs for Tropical Diseases:  Location, Location, Location!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Google</span>
                </div>
                <div class="primary-text">
                    This research expands on a previous dataset of tropical and infectious diseases (TRINDs) by adding demographic and semantic augmentations, creating a larger dataset for evaluating LLMs. It also explores the impact of contextual factors like location, race, and gender on LLM performance.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet86">
            <div class="start-time-icon" title="Play from here">36:02</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09907" target="_blank">@arXiv 2409.09907</a>
                    <span class="tweet-title">Flood Detection Gets a Speed Boost: LoRA Makes Earth Observation Models Faster and Smarter!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Luxembourg, University of Antioquia, University of Oxford</span>
                </div>
                <div class="primary-text">
                    This research explores the use of Low-Rank Adaptation (LoRA) to fine-tune Earth Observation (EO) foundation models for flood segmentation. Unlike previous work that focused on full fine-tuning, this study demonstrates the effectiveness of LoRA in achieving comparable performance with significantly reduced computational costs.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet87">
            <div class="start-time-icon" title="Play from here">36:27</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09177" target="_blank">@arXiv 2409.09177</a>
                    <span class="tweet-title">Transformers Get a Time-Out: New Model Makes Motion Captioning More Synchronized</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">IMT Mines Ales, University of Montpellier, LIPN-University Sorbonne Paris Nord</span>
                </div>
                <div class="primary-text">
                    This research introduces a new approach to synchronous motion captioning using a Transformer architecture. Unlike previous methods that relied on RNNs, this paper incorporates mechanisms to control self- and cross-attention distributions, enabling more precise alignment between motion and language.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet88">
            <div class="start-time-icon" title="Play from here">36:55</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09569" target="_blank">@arXiv 2409.09569</a>
                    <span class="tweet-title">Bias Begets Bias: When Your AI's "Brain" is Prejudiced</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Harvard University</span>
                </div>
                <div class="primary-text">
                    This research focuses on the impact of biased text embeddings on the fairness of diffusion models, a class of models used in text-to-image generation. Unlike previous work that primarily focused on debiasing the training data or the generated images, this paper investigates the role of biased embeddings in both generating and evaluating the fairness of these models.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet89">
            <div class="start-time-icon" title="Play from here">37:20</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09135" target="_blank">@arXiv 2409.09135</a>
                    <span class="tweet-title">LLMs: The New Language of Engagement?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU, University of Southern California</span>
                </div>
                <div class="primary-text">
                    This research uses a large language model (LLM) to analyze multimodal data from smart glasses, creating a "multimodal transcript" that can be used to predict engagement levels in natural conversations. This approach differs from previous work that primarily focused on classical fusion techniques.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet90">
            <div class="start-time-icon" title="Play from here">37:43</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10046" target="_blank">@arXiv 2409.10046</a>
                    <span class="tweet-title">Lightning Strikes: New Model Predicts Wildfire Risk From Above!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Bar Ilan University, Ariel University, University College London...</span>
                </div>
                <div class="primary-text">
                    This research distinguishes itself by developing a global machine learning model to predict lightning-ignited wildfires, unlike previous models which were typically tailored to specific regions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet91">
            <div class="start-time-icon" title="Play from here">38:16</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10502" target="_blank">@arXiv 2409.10502</a>
                    <span class="tweet-title">Sudoku-Solving AI:  It's Not Just About the Numbers, It's About the Thinking!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Texas at Austin, Google</span>
                </div>
                <div class="primary-text">
                    This research explores whether causal language models can learn to solve logic puzzles like Sudoku and Zebra puzzles by training them on a sequence of steps taken by a solver. This differs from previous work that focused on simpler tasks or relied on more descriptive training data.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet92">
            <div class="start-time-icon" title="Play from here">38:36</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09787" target="_blank">@arXiv 2409.09787</a>
                    <span class="tweet-title">Bootstrapping Boltzmann: A New Sampler That's Less Noisy and More Robust</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Cambridge, University of Washington</span>
                </div>
                <div class="primary-text">
                    This paper introduces a new method for training neural samplers called EnDEM, which targets the MC estimated noised energies instead of scores. This approach is theoretically shown to have lower variance compared to previous methods like iDEM. Additionally, the paper proposes BEnDEM, which further reduces variance by bootstrapping energy estimates from lower noise levels.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet93">
            <div class="start-time-icon" title="Play from here">38:56</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09740" target="_blank">@arXiv 2409.09740</a>
                    <span class="tweet-title">3D Face Reconstruction:  Geometry Gets a Texture Makeover!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Renmin University of China, Tsinghua University, Beihang University</span>
                </div>
                <div class="primary-text">
                    This research proposes VGG-Tex, a model that uses 3D geometric priors to guide the estimation of facial textures in monocular 3D face reconstruction. Unlike previous methods that primarily focus on geometry, VGG-Tex emphasizes the importance of texture in creating realistic 3D faces.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet94">
            <div class="start-time-icon" title="Play from here">39:30</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09263" target="_blank">@arXiv 2409.09263</a>
                    <span class="tweet-title">Chile's Wind Power Gets a Brain: Hybrid AI Predicts Gusts for Cleaner Energy</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Stanford University, DeepMind, Google</span>
                </div>
                <div class="primary-text">
                    This research introduces a hybrid machine learning model for wind speed forecasting in Chile, combining a short-term TiDE model with a medium-term GraphCast model. This approach differs from traditional methods by leveraging the strengths of both models to improve accuracy across different time horizons.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet95">
            <div class="start-time-icon" title="Play from here">39:54</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10330" target="_blank">@arXiv 2409.10330</a>
                    <span class="tweet-title">Self-Driving Cars:  Explaining Their Moves, One Concept at a Time!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Hong Kong University of Science and Technology</span>
                </div>
                <div class="primary-text">
                    This research focuses on making explainable autonomous driving models more dependable. It tackles the issue of instability in the Driving through the Concept Gridlock (DCG) model, which is a popular method for explaining how self-driving cars make decisions. The paper proposes a new framework called DRIVE, which aims to improve the consistency and stability of explanations generated by these models.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet96">
            <div class="start-time-icon" title="Play from here">40:20</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09171" target="_blank">@arXiv 2409.09171</a>
                    <span class="tweet-title">Belief Contraction: Can We Even Do It?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Freiburg, Cardiff University</span>
                </div>
                <div class="primary-text">
                    This paper investigates the computability of AGM contraction in non-finitary logics, a topic largely unexplored in previous research. It shows that uncomputability is unavoidable in these logics, even when restricting the space of epistemic states.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet97">
            <div class="start-time-icon" title="Play from here">40:44</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09927" target="_blank">@arXiv 2409.09927</a>
                    <span class="tweet-title">LLMs: Cheaters Never Prosper? New Study Exposes Data Contamination in AI Models!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">CMU, University of Illinois at Chicago</span>
                </div>
                <div class="primary-text">
                    This research goes beyond traditional benchmarks and early-stage LLMs, evaluating five contamination detection methods on eight challenging datasets, including six frequently used to evaluate modern LLMs. It also investigates the impact of instruction fine-tuning on contamination detection, a previously overlooked area.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet98">
            <div class="start-time-icon" title="Play from here">41:08</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10161" target="_blank">@arXiv 2409.10161</a>
                    <span class="tweet-title">Sim2Real Transfer Just Got a Whole Lot Realer: Gaussian Splatting Makes Robots See the World Like We Do</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Carnegie Mellon University</span>
                </div>
                <div class="primary-text">
                    This paper proposes SplatSim, a framework that uses Gaussian Splatting to generate photorealistic synthetic data for training robotic manipulation policies. Unlike previous methods that rely on depth or point cloud inputs, SplatSim leverages RGB images, bridging the Sim2Real gap for vision-based tasks.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet99">
            <div class="start-time-icon" title="Play from here">41:29</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09831" target="_blank">@arXiv 2409.09831</a>
                    <span class="tweet-title">Masked Language Models: The Secret Weapon for Generating Fake Medical Records (That Are Actually Useful!)</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Cambridge, University of Manchester, Tsinghua University</span>
                </div>
                <div class="primary-text">
                    This research uses Masked Language Modeling (MLM) to generate synthetic medical records, a novel approach compared to previous work that relied on Casual Language Modeling (CLM). MLM offers more control over the resemblance between synthetic and real data, allowing for greater diversity in the generated records.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet100">
            <div class="start-time-icon" title="Play from here">41:56</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09905" target="_blank">@arXiv 2409.09905</a>
                    <span class="tweet-title">LLMs:  The Big Five's New BFFs?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">UC Berkeley</span>
                </div>
                <div class="primary-text">
                    This research explores the latent personality dimensions encoded in large language models (LLMs) by analyzing the log-probabilities of trait-descriptive adjectives. Unlike previous work that relies on direct prompts or questionnaires, this study uses an unsupervised approach to uncover personality traits without explicit input.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet101">
            <div class="start-time-icon" title="Play from here">42:19</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09387" target="_blank">@arXiv 2409.09387</a>
                    <span class="tweet-title">Brain Mapping Gets a Speed Boost: New Technique Makes Diffusion MRI Faster and More Detailed!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Harvard University, Technical University of Munich</span>
                </div>
                <div class="primary-text">
                    This research introduces a new method called HashEnc, which uses grid-like local embeddings to estimate the Orientation Distribution Function (ODF) field in high-resolution diffusion MRI scans. This approach differs from previous methods that relied on Implicit Neural Representations (INRs) like SIREN, which often struggled with training time and over-smoothing.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet102">
            <div class="start-time-icon" title="Play from here">42:41</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09313" target="_blank">@arXiv 2409.09313</a>
                    <span class="tweet-title">Trifocal Tensor Tango:  A New Way to Sync Cameras with a Low-Rank Twist!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Minnesota, University of Texas at Austin</span>
                </div>
                <div class="primary-text">
                    This research introduces a novel approach to camera synchronization by leveraging the block tensor of trifocal tensors. Unlike previous methods that rely on pairwise measurements, this method utilizes higher-order relationships between three or more cameras, potentially leading to more accurate and robust results.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet103">
            <div class="start-time-icon" title="Play from here">43:03</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10357" target="_blank">@arXiv 2409.10357</a>
                    <span class="tweet-title">2D or Not 2D:  The Great Gesture Generation Debate!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Sorbonne University</span>
                </div>
                <div class="primary-text">
                    This research investigates the impact of using 2D versus 3D gesture representations for training speech-to-gesture generative models. Unlike previous work that primarily focused on 3D data, this study explores the trade-offs of using 2D data and then lifting it to 3D.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet104">
            <div class="start-time-icon" title="Play from here">43:23</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10338" target="_blank">@arXiv 2409.10338</a>
                    <span class="tweet-title">20 Questions to Bust a Fake AI: Can You Tell the Real Deal From a Copycat?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">ENS Paris-Saclay, INRIA, IRISA...</span>
                </div>
                <div class="primary-text">
                    This paper introduces a novel method for distinguishing between large language models (LLMs) using a limited set of binary questions. Unlike previous work that focuses on adversarial attacks or model-specific vulnerabilities, this approach utilizes benign questions to effectively differentiate models in a black-box setting.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet105">
            <div class="start-time-icon" title="Play from here">43:44</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09550" target="_blank">@arXiv 2409.09550</a>
                    <span class="tweet-title">Robot Swarms:  Task Masters or Task Clumpers?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">MIT</span>
                </div>
                <div class="primary-text">
                    This research explores dynamic task allocation in unknown environments, where tasks appear randomly and independently, unlike previous work that assumed static tasks or prior knowledge of task locations.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet106">
            <div class="start-time-icon" title="Play from here">44:06</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09324" target="_blank">@arXiv 2409.09324</a>
                    <span class="tweet-title">Doc-Bot: AI Makes Medical Notes, Docs Can Chill!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">University of Chicago</span>
                </div>
                <div class="primary-text">
                    This research focuses on fine-tuning a large language model (LLM) specifically for generating medical reports from doctor-patient dialogues. The study utilizes a combination of advanced fine-tuning techniques, including Quantized Low-Rank Adaptation (QLoRA) and Parameter-Efficient Fine-Tuning (PEFT), to optimize the model's performance while minimizing computational resource requirements. This approach distinguishes it from previous work that often relied on more computationally expensive models.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet107">
            <div class="start-time-icon" title="Play from here">44:33</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09980" target="_blank">@arXiv 2409.09980</a>
                    <span class="tweet-title">Famine Forecasting: From Global Models to Country-Specific Bites!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Harvard University</span>
                </div>
                <div class="primary-text">
                    This research distinguishes itself by employing country-specific machine learning models, tailoring the analysis to the unique data availability and importance of different variables in each region.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet108">
            <div class="start-time-icon" title="Play from here">44:51</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09741" target="_blank">@arXiv 2409.09741</a>
                    <span class="tweet-title">AI Detectives:  Can LLMs Crack the Code of Online Toxicity?</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Leiden University, Universidad Diego Portales</span>
                </div>
                <div class="primary-text">
                    This research benchmarks the ability of various LLMs, including open-source models, to perform annotation tasks on political content, specifically identifying toxicity and incivility in online discussions. This differs from previous work by focusing on the performance of open-source LLMs in this context.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet109">
            <div class="start-time-icon" title="Play from here">45:16</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.10267" target="_blank">@arXiv 2409.10267</a>
                    <span class="tweet-title">Recipe Recommender:  From Garlic to Gourmet, It's All About the Ingredients!</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">Michigan State University</span>
                </div>
                <div class="primary-text">
                    This research focuses on recommending recipes based solely on ingredients, unlike previous systems that rely on factors like cuisine or dietary restrictions.
                </div>
            </div>
        </div>
        <div class="tweet" id="tweet110">
            <div class="start-time-icon" title="Play from here">45:41</div>
            <div class="tweet-content">
                <div class="tweet-header">
                    <a class="arxiv-id" href="https://arxiv.org/abs/2409.09305" target="_blank">@arXiv 2409.09305</a>
                    <span class="tweet-title">Speech Quality:  A Deep Dive into Image Recognition for Synthetic Speech</span>
                </div>
                <div class="institute-line">
                    <img class="institute-icon" src="assets/buttonInstitute.svg" alt="Institute Icon">
                    <span class="institute-text">The University of Tokyo</span>
                </div>
                <div class="primary-text">
                    This research explores the use of a pretrained image feature extractor, specifically EfficientNetV2, to capture the differences in synthetic speech spectrograms for accurate naturalness MOS prediction. This approach differs from previous work that primarily relied on self-supervised learning (SSL) based speech features.
                </div>
            </div>
        </div>

        <div
            style="padding: 50px 0; text-align: center; margin: 5px 0; font-weight: 300; font-size: 10px; color: #000000;">
            Opening music
            from <a href="https://ikson.com" target="_blank" style="color: black; text-decoration: none;">TELL
                YOUR STORY by ikson</a></div>
        <div style="height: 50px;"></div>
    </div>

    <footer class="player-footer">
        <div class="player-detail-hidden-on-small-screen">
            <div id="audio-title" class="tweet-title-small">Hit play and learn on the go!</div>
            <div style="height: 2px;"></div>
            <div id="audio-institutes" class="institute-text-small"></div>
        </div>
        <div class="control-panel">
            <div class="control-horizontal">
                <div id="playSpeedButton" title="Adjust speed">
                    <div id="selectedSpeed">1&times;</div>
                    <div class="speedMenuItems">
                        <div data-value="0.6">Speed 0.6&times;</div>
                        <div data-value="0.8">Speed 0.8&times;</div>
                        <div data-value="1" class="selected">Speed 1&times;</div>
                        <div data-value="1.2">Speed 1.2&times;</div>
                        <div data-value="1.4">Speed 1.4&times;</div>
                        <div data-value="1.6">Speed 1.6&times;</div>
                    </div>
                    <select id="speedOptionsHidden">
                        <option value="0.6">0.6&times;</option>
                        <option value="0.8">0.8&times;</option>
                        <option value="1" selected>1&times;</option>
                        <option value="1.2">1.2&times;</option>
                        <option value="1.4">1.4&times;</option>
                        <option value="1.6">1.6&times;</option>
                    </select>
                </div>
                <div id="playLastButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(false)" title="Play last" disabled>
                        <img src="assets/buttonLastEpisode.svg" alt="Last" style="width: 12px;">
                    </button>
                </div>
                <button class="controllerButton" onclick="scrollToCurrentTweet()" title="Scoll to the current episode">
                    <img id="locateImage" src="assets/buttonTarget.svg" alt="Locate">
                </button>
                <button class="controllerButton" onclick="togglePlayPause()" title="Play/Pause">
                    <img id="playPauseImage" src="assets/buttonPlay.svg" alt="Play">
                </button>
                <div id="playNextButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(true)" title="Play next" disabled>
                        <img src="assets/buttonNextEpisode.svg" alt="Next" style="width: 12px;">
                    </button>
                </div>
            </div>
            <div class="control-horizontal">
                <div id="progressTime">0:00</div>
                <div id="progressContainer" onclick="seek(event)">
                    <div id="progressBar"></div>
                    <div id="progressCircle" draggable="true"></div>
                </div>
                <audio id="audioPlayer"
                    src="https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202409172224_audio.mp3"></audio>
                <div id="progressTime"><span id="audioDuration">Loading...</span></div>
            </div>
        </div>
    </footer>
    <div id="privacyModal" class="modal"></div>
    <script src="script.js"></script>
    <script src="calendar.js"></script>    
    <script>
        fetch('https://ribbitribbit.co/header.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('headerId').innerHTML = data;
            })
            .catch(error => console.error('Error loading header.html:', error));
        fetch('https://ribbitribbit.co/terms.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('privacyModal').innerHTML = data;
            })
            .catch(error => console.error('Error loading terms.html:', error));
    </script>
</body>
</html>
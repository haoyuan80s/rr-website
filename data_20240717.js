
daily_data = {
    "date": "2024-07-17",
    "tweets": [
            {
                "startTime": "00:47",
                "arxivId": "2407.10949",
                "arxivLink": "https://arxiv.org/abs/2407.10949",
                "title": "Eliza, the Chatbot, Gets a Neural Makeover!",
                "institute": "Princeton University",
                "text": "This research constructs a Transformer model that implements the classic ELIZA chatbot algorithm, a departure from previous work that focused on single-sentence tasks.",
                "paper-title": "Representing Rule-based Chatbots with Transformers",
                "image-path": ""
            },

            {
                "startTime": "01:08",
                "arxivId": "2407.10031",
                "arxivLink": "https://arxiv.org/abs/2407.10031",
                "title": "Robots Get a Brain: Language Models Help Multi-Agent Teams Plan Long-Term Tasks",
                "institute": "MIT, TCS, USAF-MIT AI Accelerator...",
                "text": "This research introduces LLaMAR, a multi-agent planner that uses Language Models (LMs) to break down complex tasks into smaller steps. Unlike previous methods, LLaMAR doesn't rely on perfect knowledge of the environment or oracle feedback, making it more adaptable to real-world scenarios.",
                "paper-title": "Long-Horizon Planning for Multi-Agent Robots in Partially Observable Environments",
                "image-path": ""
            },

            {
                "startTime": "01:35",
                "arxivId": "2407.10329",
                "arxivLink": "https://arxiv.org/abs/2407.10329",
                "title": "AI Gone Wild: How Generative AI Is Discriminating, and What We Can Do About It",
                "institute": "Oxford University Press, European University Viadrina, European New School of Digital Studies",
                "text": "This research focuses on the unique ways generative AI (genAI) can perpetuate discrimination, going beyond traditional AI bias analysis. It examines how genAI's outputs, like text and images, can create harmful stereotypes and inadequate representation, even when individual outputs aren't overtly discriminatory.",
                "paper-title": "Generative Discrimination: What Happens When Generative AI Exhibits Bias, and What Can Be Done About It",
                "image-path": ""
            },

            {
                "startTime": "02:08",
                "arxivId": "2407.10341",
                "arxivLink": "https://arxiv.org/abs/2407.10341",
                "title": "Robots Learn New Tricks with a Vision-Language Model's Help!",
                "institute": "Stanford University",
                "text": "This research uses a vision-language model (VLM) to generate dense rewards for reinforcement learning (RL) in robotics, which helps robots learn more efficiently and with less reliance on human demonstrations. This differs from previous work that primarily used VLMs for generating sparse rewards.",
                "paper-title": "Affordance-Guided Reinforcement Learning via Visual Prompting",
                "image-path": ""
            },

            {
                "startTime": "02:27",
                "arxivId": "2407.10817",
                "arxivLink": "https://arxiv.org/abs/2407.10817",
                "title": "LLMs as Judges: Training AI to Grade AI, and It's Getting Pretty Good!",
                "institute": "Google DeepMind, Google, UMass Amherst",
                "text": "This research introduces FLAMe, a family of large language models (LLMs) trained on a curated collection of over 100 quality assessment tasks, comprising over 5.3 million human judgments. This approach differs from previous work by relying solely on publicly available, permissively licensed human evaluations, rather than model-generated outputs.",
                "paper-title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation",
                "image-path": ""
            },

            {
                "startTime": "02:54",
                "arxivId": "2407.09975",
                "arxivLink": "https://arxiv.org/abs/2407.09975",
                "title": "GPT in Class: Coding Boost, Engagement Bust?",
                "institute": "Stanford University",
                "text": "This study is unique because it examines the impact of a general-purpose LLM, GPT-4, on student engagement and learning outcomes in a large-scale online coding course. Previous research has focused on the use of LLMs in specific educational contexts or on the potential benefits of LLMs for learning, but this study provides a more nuanced picture of the potential risks and benefits of integrating LLMs into classrooms.",
                "paper-title": "The GPT Surprise: Offering Large Language Model Chat in a Massive Coding Class Reduced Engagement but Increased Adopters Exam Performances",
                "image-path": ""
            },

            {
                "startTime": "03:24",
                "arxivId": "2407.09690",
                "arxivLink": "https://arxiv.org/abs/2407.09690",
                "title": "Privacy-Preserving Federated Learning: A Trust-Free, Communication-Efficient Algorithm",
                "institute": "University of Wisconsin-Madison",
                "text": "This research extends previous work on private federated learning by addressing the challenge of heterogeneous data, where each participant's data is unique. It proposes new algorithms that achieve optimal accuracy while requiring fewer communication rounds and less computation.",
                "paper-title": "Private Heterogeneous Federated Learning Without a Trusted Server Revisited: Error-Optimal and Communication-Efficient Algorithms for Convex Losses",
                "image-path": ""
            },

            {
                "startTime": "03:50",
                "arxivId": "2407.09739",
                "arxivLink": "https://arxiv.org/abs/2407.09739",
                "title": "Active Learning for Sensitivity Analysis: A Derivative-Driven Approach",
                "institute": "Stanford University, Meta, Washington State University",
                "text": "This research proposes novel active learning acquisition functions that directly target derivative-based global sensitivity measures (DGSMs) under Gaussian process surrogate models. This is a departure from previous work that focused on general uncertainty reduction methods or targeted only the function itself.",
                "paper-title": "Active Learning for Derivative-Based Global Sensitivity Analysis with Gaussian Processes",
                "image-path": ""
            },

            {
                "startTime": "04:17",
                "arxivId": "2407.10930",
                "arxivLink": "https://arxiv.org/abs/2407.10930",
                "title": "Prompt Engineering: It's Not Just About the Words, It's About the Weights Too!",
                "institute": "Stanford University",
                "text": "This research explores a novel approach to optimizing language model (LM) programs by simultaneously fine-tuning the LM weights and optimizing the prompts used to guide the model's behavior. This differs from previous work that focused on optimizing either prompts or weights in isolation.",
                "paper-title": "Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together",
                "image-path": ""
            },

            {
                "startTime": "04:36",
                "arxivId": "2407.09578",
                "arxivLink": "https://arxiv.org/abs/2407.09578",
                "title": "Anomaly Detection: Diffusion Models Get a Trend Makeover!",
                "institute": "Samsung Display, Stanford University",
                "text": "This research proposes a novel approach to anomaly detection using diffusion models by analyzing the trend of reconstruction as the noise level increases. Unlike previous methods that rely on a single noise level, this method leverages the gradual change in the reconstructed image to identify anomalies more effectively.",
                "paper-title": "Unsupervised Anomaly Detection Using Diffusion Trend Analysis",
                "image-path": ""
            },

            {
                "startTime": "05:05",
                "arxivId": "2407.09835",
                "arxivLink": "https://arxiv.org/abs/2407.09835",
                "title": "Low-Rank Transformers: Making Big Models Slim and Speedy!",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Google",
                "text": "This research focuses on applying low-rank parametrization to the feedforward networks (FFNs) within Transformer-based language models, specifically training these models from scratch. Previous work has explored low-rank techniques for compression or fine-tuning, but this study investigates their impact on training efficiency and scaling.",
                "paper-title": "Investigating Low-Rank Training in Transformer Language Models: Efficiency and Scaling Analysis",
                "image-path": ""
            },

            {
                "startTime": "05:26",
                "arxivId": "2407.10315",
                "arxivLink": "https://arxiv.org/abs/2407.10315",
                "title": "Deep Learning's Memory: When Too Much Knowledge is a Bad Thing!",
                "institute": "Harvard University",
                "text": "This research presents a statistical-mechanics theory of continual learning in deep, wide neural networks, which characterizes the network's input-output mapping as it learns a sequence of tasks. This approach differs from previous work by not relying on data assumptions, allowing the analysis of continual learning in a broader range of tasks.",
                "paper-title": "Order parameters and phase transitions of continual learning in deep neural networks",
                "image-path": ""
            },

            {
                "startTime": "05:44",
                "arxivId": "2407.10943",
                "arxivLink": "https://arxiv.org/abs/2407.10943",
                "title": "GRUtopia: Robots Learn to Live in a City, One Simulated Scene at a Time!",
                "institute": "Shanghai AI Laboratory, Zhejiang University, Shanghai Jiao Tong University...",
                "text": "This research introduces GRUtopia, a simulated 3D city environment designed for training embodied AI robots. Unlike previous platforms that focus on home environments, GRUtopia includes a wider range of scene categories, including supermarkets, hospitals, and offices, to better prepare robots for real-world service applications.",
                "paper-title": "GRUtopia: Dream General Robots in a City at Scale",
                "image-path": ""
            },

            {
                "startTime": "06:09",
                "arxivId": "2407.09590",
                "arxivLink": "https://arxiv.org/abs/2407.09590",
                "title": "Pruning Experts: How to Slim Down Your Giant Language Model Without Losing Its Smarts",
                "institute": "University of Rochester, Microsoft",
                "text": "This research focuses on task-agnostic pruning of Mixture-of-Experts (MoE) models, which means it aims to reduce the model's size without relying on specific tasks for guidance. Unlike previous work that often uses task-specific information to prune experts, this study explores a more general approach based on expert similarity in the feature space.",
                "paper-title": "Diversifying the Expert Knowledge for Task-Agnostic Pruning in Sparse Mixture-of-Experts",
                "image-path": ""
            },

            {
                "startTime": "06:32",
                "arxivId": "2407.10910",
                "arxivLink": "https://arxiv.org/abs/2407.10910",
                "title": "DataDream: AI's New BFF for Few-Shot Learning",
                "institute": "University of T\u00fcbingen, Helmholtz Munich, MCML...",
                "text": "This research proposes DataDream, a method that fine-tunes a text-to-image diffusion model using a small set of real images to generate synthetic data that better aligns with the real data distribution. This differs from previous work that primarily focused on using class names or pre-trained captioning models to guide the generation process.",
                "paper-title": "DataDream: Few-shot Guided Dataset Generation",
                "image-path": ""
            },

            {
                "startTime": "07:04",
                "arxivId": "2407.09512",
                "arxivLink": "https://arxiv.org/abs/2407.09512",
                "title": "AI Copilots: From Shopping Spree to Store Ops, They're Here to Help!",
                "institute": "Microsoft",
                "text": "This research focuses on the design and evaluation of AI copilots, specifically highlighting the importance of a systematic approach to building and testing these assistants. It goes beyond simply using LLMs and emphasizes the need for plugins, orchestration, and responsible AI guardrails.",
                "paper-title": "Design and evaluation of AI copilots -- case studies of retail copilot templates",
                "image-path": ""
            },

            {
                "startTime": "07:28",
                "arxivId": "2407.10040",
                "arxivLink": "https://arxiv.org/abs/2407.10040",
                "title": "Thinking Out Loud: How AI Learned to Prove Theorems with a Chatty Sidekick",
                "institute": "CMU",
                "text": "This research introduces a novel approach to theorem proving by incorporating informal \"thoughts\" into the process. Unlike previous methods that solely rely on formal proofs, this study trains a language model to generate natural language explanations before each step of a formal proof, enhancing its theorem-proving capabilities.",
                "paper-title": "Lean-STaR: Learning to Interleave Thinking and Proving",
                "image-path": ""
            },

            {
                "startTime": "07:51",
                "arxivId": "2407.09905",
                "arxivLink": "https://arxiv.org/abs/2407.09905",
                "title": "Reinforcement Learning Goes Global: Beyond the Sum of Its Parts",
                "institute": "ETH Zurich",
                "text": "This research introduces Global Reinforcement Learning (GRL), where rewards are defined over entire trajectories instead of individual states. This allows for modeling complex interactions between states, which is crucial for tasks like experiment design and exploration.",
                "paper-title": "Global Reinforcement Learning: Beyond Linear and Convex Rewards via Submodular Semi-gradient Methods",
                "image-path": ""
            },

            {
                "startTime": "08:17",
                "arxivId": "2407.10627",
                "arxivLink": "https://arxiv.org/abs/2407.10627",
                "title": "LLMs Get a Fight Club Makeover: Arena Learning Makes Them Stronger!",
                "institute": "Microsoft, Tsinghua University, SIAT-UCAS",
                "text": "This research introduces Arena Learning, a novel approach to post-training LLMs that simulates offline chatbot battles using AI-driven annotations. This differs from previous work that relied on human-based evaluations, which are costly and time-consuming.",
                "paper-title": "Arena Learning: Build Data Flywheel for LLMs Post-training via Simulated Chatbot Arena",
                "image-path": ""
            },

            {
                "startTime": "08:46",
                "arxivId": "2407.09941",
                "arxivLink": "https://arxiv.org/abs/2407.09941",
                "title": "Hydra: The Double-Headed Mamba Slaying Sequence Modeling!",
                "institute": "CMU",
                "text": "This paper introduces a new framework for understanding sequence models, called the Matrix Mixer framework. It uses structured matrices to represent the sequence mixer, which allows for more efficient and expressive models. The paper also introduces a new type of matrix mixer called the quasiseparable matrix mixer, which is a bidirectional extension of the semiseparable matrix mixer used in state-space models.",
                "paper-title": "Hydra: Bidirectional State Space Models Through Generalized Matrix Mixers",
                "image-path": ""
            },

            {
                "startTime": "09:12",
                "arxivId": "2407.10725",
                "arxivLink": "https://arxiv.org/abs/2407.10725",
                "title": "LLMs: Value Judgments, But Can They Judge a Value?",
                "institute": "Microsoft",
                "text": "This research introduces CLAVE, a framework that combines a large language model (LLM) with a smaller, fine-tuned LLM to evaluate the values reflected in LLM-generated responses. This approach addresses the challenges of adaptability and generalizability in value assessment, which are limitations of existing methods.",
                "paper-title": "CLAVE: An Adaptive Framework for Evaluating Values of LLM Generated Responses",
                "image-path": ""
            },

            {
                "startTime": "09:43",
                "arxivId": "2407.10960",
                "arxivLink": "https://arxiv.org/abs/2407.10960",
                "title": "LLMs on a Diet: New Kernel Makes Quantized Models Run Faster!",
                "institute": "MIT, CMU",
                "text": "This paper introduces FLUTE, a kernel that optimizes matrix multiplications for lookup table-quantized LLMs. Unlike previous kernels, FLUTE supports non-uniform quantization with odd bit-widths, making it more flexible for various quantization methods.",
                "paper-title": "Fast Matrix Multiplications for Lookup Table-Quantized LLMs",
                "image-path": ""
            },

            {
                "startTime": "10:12",
                "arxivId": "2407.10971",
                "arxivLink": "https://arxiv.org/abs/2407.10971",
                "title": "Q-Learning the Reward: A Bayesian IRL Algorithm That's Faster Than a Speeding Bullet!",
                "institute": "University of Oxford, University of Southampton",
                "text": "This research proposes a new Bayesian inverse reinforcement learning (IRL) algorithm called ValueWalk. Unlike previous methods that primarily focused on sampling in the space of reward functions, ValueWalk focuses on sampling in the space of Q-values, which is computationally cheaper.",
                "paper-title": "Walking the Values in Bayesian Inverse Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "10:43",
                "arxivId": "2407.09522",
                "arxivLink": "https://arxiv.org/abs/2407.09522",
                "title": "Querying the Unstructured: A New Engine for Data Insights",
                "institute": "Google",
                "text": "This research proposes a novel Universal Query Engine (UQE) that leverages Large Language Models (LLMs) to perform analytics on unstructured databases. Unlike previous approaches that rely on full database scans or pre-processing, UQE utilizes statistically sound sampling techniques and a compilation system to achieve efficient and accurate query execution.",
                "paper-title": "UQE: A Query Engine for Unstructured Databases",
                "image-path": ""
            },

            {
                "startTime": "11:06",
                "arxivId": "2407.10704",
                "arxivLink": "https://arxiv.org/abs/2407.10704",
                "title": "Tiny Tweaks, Big Gains: Quantizing Prompts for Vision-Language Model Generalization",
                "institute": "Tsinghua University",
                "text": "This research explores the use of quantization, a technique for compressing model parameters, to improve the generalization ability of vision-language models. Unlike previous work that focuses on minimizing quantization error, this study proposes that a moderate level of quantization error can actually enhance generalization by acting as a form of regularization.",
                "paper-title": "Quantized Prompt for Efficient Generalization of Vision-Language Models",
                "image-path": ""
            },

            {
                "startTime": "11:42",
                "arxivId": "2407.10625",
                "arxivLink": "https://arxiv.org/abs/2407.10625",
                "title": "WildVidFit: Virtual Try-On Goes Wild, Ditching the Warping!",
                "institute": "Sun Yat-sen University, University of Oxford",
                "text": "This research proposes a novel approach to video virtual try-on that utilizes image-based controlled diffusion models, eliminating the need for explicit warping and temporal modules. This differs from previous methods that relied on warping techniques, which struggled with complex movements and occlusions in real-world videos.",
                "paper-title": "WildVidFit: Video Virtual Try-On in the Wild via Image-Based Controlled Diffusion Models",
                "image-path": ""
            },

            {
                "startTime": "12:14",
                "arxivId": "2407.10633",
                "arxivLink": "https://arxiv.org/abs/2407.10633",
                "title": "Model Mistakes: Unmasking Bias with SKEWSIZE",
                "institute": "Google",
                "text": "This research introduces SKEWSIZE, a new metric for evaluating model bias that focuses on characterizing the distribution of prediction errors across subgroups, rather than simply quantifying accuracy. This approach goes beyond traditional metrics like worst-group accuracy and accuracy gap, which often fail to capture subtle biases in how models make mistakes.",
                "paper-title": "Evaluating Model Bias Requires Characterizing its Mistakes",
                "image-path": ""
            },

            {
                "startTime": "12:37",
                "arxivId": "2407.10969",
                "arxivLink": "https://arxiv.org/abs/2407.10969",
                "title": "LLMs Go on a Diet: Sparsity Makes Them Slim and Smart!",
                "institute": "Microsoft Research, University of Chinese Academy of Sciences",
                "text": "This paper introduces Q-Sparse, a method for training sparsely-activated large language models (LLMs). Unlike previous approaches that focus on weight sparsity or achieve partial activation sparsity, Q-Sparse enables full sparsity of activations, leading to significant efficiency gains during inference.",
                "paper-title": "Q-Sparse: All Large Language Models can be Fully Sparsely-Activated",
                "image-path": ""
            },

            {
                "startTime": "13:09",
                "arxivId": "2407.09801",
                "arxivLink": "https://arxiv.org/abs/2407.09801",
                "title": "IOT-LM: Giving Your Smart Home a Brain (and a Mouth)",
                "institute": "Carnegie Mellon University",
                "text": "This research introduces IOT-LM, a large multisensory language model specifically designed to process data from the Internet of Things (IoT). Unlike previous work that focused on single-modality or single-task models, IOT-LM integrates multiple sensory modalities and can perform a range of tasks, including question-answering and reasoning.",
                "paper-title": "IoT-LM: Large Multisensory Language Models for the Internet of Things",
                "image-path": ""
            },

            {
                "startTime": "13:32",
                "arxivId": "2407.10887",
                "arxivLink": "https://arxiv.org/abs/2407.10887",
                "title": "LLM Fingerprinting: Chain & Hash - A New Way to Prove Your Model's the Real Deal",
                "institute": "Microsoft",
                "text": "This research proposes a new fingerprinting technique called Chain & Hash, which uses a cryptographic approach to link multiple fingerprints together. Unlike previous methods, Chain & Hash operates in a black-box setting, meaning it only requires access to the model through an API, without needing to see the model's internal workings.",
                "paper-title": "Hey, That's My Model! Introducing Chain&Hash, An LLM Fingerprinting Technique",
                "image-path": ""
            },

            {
                "startTime": "13:58",
                "arxivId": "2407.10955",
                "arxivLink": "https://arxiv.org/abs/2407.10955",
                "title": "ROOT-SGD Goes on a Diet: Diminishing Stepsize for Optimal Optimization",
                "institute": "University of Illinois, University of California",
                "text": "This research revisits the ROOT-SGD algorithm, introducing a diminishing stepsize strategy that improves its convergence rate and statistical efficiency. Unlike previous work, this approach achieves optimal asymptotic covariance without requiring prior knowledge of the sample size.",
                "paper-title": "Enhancing Stochastic Optimization for Statistical Efficiency Using ROOT-SGD with Diminishing Stepsize",
                "image-path": ""
            },

            {
                "startTime": "14:19",
                "arxivId": "2407.10937",
                "arxivLink": "https://arxiv.org/abs/2407.10937",
                "title": "Depth-Charged Videos: A New Way to Make Videos Pop!",
                "institute": "State University of New York at Buffalo, Microsoft, AdvancedMicroDevices",
                "text": "This research introduces a novel approach to generating videos and their corresponding depth maps simultaneously. Unlike previous methods that focus on either video or depth generation, this paper proposes a unified dual-modal U-Net that learns to denoise both video and depth features jointly.",
                "paper-title": "IDOL: Unified Dual-Modal Latent Diffusion for Human-Centric Joint Video-Depth Generation",
                "image-path": ""
            },

            {
                "startTime": "14:42",
                "arxivId": "2407.10468",
                "arxivLink": "https://arxiv.org/abs/2407.10468",
                "title": "Audio Diffusion Models Get a Speed Boost: LiteFocus Makes Long Audio Synthesis a Breeze!",
                "institute": "National University of Singapore",
                "text": "This research introduces LiteFocus, a method that accelerates the inference of audio latent diffusion models for long audio synthesis. Unlike previous work that focuses on reducing the number of inference steps, LiteFocus specifically targets the self-attention mechanism within the model, which is a major bottleneck for long audio generation.",
                "paper-title": "LiteFocus: Accelerated Diffusion Inference for Long Audio Synthesis",
                "image-path": ""
            },

            {
                "startTime": "15:08",
                "arxivId": "2407.10264",
                "arxivLink": "https://arxiv.org/abs/2407.10264",
                "title": "Safety Fine-Tuning: LLMs Learn to Say \"No\" (But Jailbreaks Still Say \"Yes\")",
                "institute": "Five AI Ltd., University of Michigan, CBS Harvard University...",
                "text": "This research uses a synthetic data generation framework to study the mechanisms of safety fine-tuning in LLMs. It goes beyond simply observing changes in model behavior and delves into the specific transformations learned by the model during safety fine-tuning.",
                "paper-title": "What Makes and Breaks Safety Fine-tuning? Mechanistic Study",
                "image-path": ""
            },

            {
                "startTime": "15:30",
                "arxivId": "2407.10318",
                "arxivLink": "https://arxiv.org/abs/2407.10318",
                "title": "Caustics Be Gone! 3D Gaussian Splatting Takes on Underwater Illusions",
                "institute": "CMU",
                "text": "This research introduces a novel method called Recurrent Gaussian Splatting (RecGS) for removing water caustics from underwater imagery. Unlike previous methods that rely on 2D filtering or supervised deep learning, RecGS leverages the 3D consistency of the scene to iteratively refine the 3D representation and separate caustics.",
                "paper-title": "RecGS: Removing Water Caustic with Recurrent Gaussian Splatting",
                "image-path": ""
            },

            {
                "startTime": "15:58",
                "arxivId": "2407.09709",
                "arxivLink": "https://arxiv.org/abs/2407.09709",
                "title": "Graph Language Modeling: LLMs Get a Graph Makeover!",
                "institute": "Washington University in St. Louis, Peking University",
                "text": "This paper proposes a novel generative graph language model called GOFA, which interleaves GNN layers into a frozen pre-trained LLM. This approach allows the model to learn both semantic and structural information from graph data, unlike previous methods that either focused on language-based prediction or used LLMs as assistants for GNNs.",
                "paper-title": "GOFA: A Generative One-For-All Model for Joint Graph Language Modeling",
                "image-path": ""
            },

            {
                "startTime": "16:27",
                "arxivId": "2407.10456",
                "arxivLink": "https://arxiv.org/abs/2407.10456",
                "title": "Don't Be a One-Trick Pony: Knowledge Distillation Gets a Multi-Sequence Makeover!",
                "institute": "University of Melbourne, Google",
                "text": "This research explores using multiple high-scoring translations from a teacher model during knowledge distillation, rather than just the single best one. This differs from previous work that primarily relied on a single sequence for training the student model.",
                "paper-title": "Don't Throw Away Data: Better Sequence Knowledge Distillation",
                "image-path": ""
            },

            {
                "startTime": "16:49",
                "arxivId": "2407.10179",
                "arxivLink": "https://arxiv.org/abs/2407.10179",
                "title": "AI's New Weapon: Text-Guided Attacks That Fool Even the Smartest Models",
                "institute": "Tsinghua University, Harbin Institute of Technology",
                "text": "This research introduces a new method for crafting adversarial attacks that can fool AI models even when they haven't seen the attack before. The key difference is that the attack uses text descriptions of the target class to guide the generation of the attack, making it more effective than previous methods that relied solely on visual information.",
                "paper-title": "CLIP-Guided Networks for Transferable Targeted Attacks",
                "image-path": ""
            },

            {
                "startTime": "17:13",
                "arxivId": "2407.10897",
                "arxivLink": "https://arxiv.org/abs/2407.10897",
                "title": "Light Up Your Images: Optical Diffusion Models for Faster, Greener Image Generation",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Google",
                "text": "This research proposes using the propagation of light through specially designed transparent layers to implement denoising diffusion models for image generation. This approach differs from traditional methods that rely on digital electronic hardware like GPUs.",
                "paper-title": "Optical Diffusion Models for Image Generation",
                "image-path": ""
            },

            {
                "startTime": "17:40",
                "arxivId": "2407.09503",
                "arxivLink": "https://arxiv.org/abs/2407.09503",
                "title": "AI for AR: Giving Your Glasses a Brain with PARSE-Ego4D",
                "institute": "University of Groningen, University of Central Florida, Google",
                "text": "This research introduces PARSE-Ego4D, a dataset specifically designed for training AI systems to provide personalized action recommendations in egocentric videos, a task not addressed by previous datasets.",
                "paper-title": "PARSE-Ego4D: Personal Action Recommendation Suggestions for Egocentric Videos",
                "image-path": ""
            },

            {
                "startTime": "18:06",
                "arxivId": "2407.10448",
                "arxivLink": "https://arxiv.org/abs/2407.10448",
                "title": "Causal Inference Gets a Spectral Makeover: Unveiling Hidden Confounders with a Low-Rank Twist!",
                "institute": "UT Austin, Georgia Tech, Universitat Pompeu Fabra...",
                "text": "This research introduces a novel approach to causal effect estimation in the presence of hidden confounders. Unlike previous methods that rely on fixed feature dictionaries or deep neural networks, this paper leverages a low-rank assumption on conditional densities to explicitly characterize function classes within a saddle-point optimization problem.",
                "paper-title": "Spectral Representation for Causal Estimation with Hidden Confounders",
                "image-path": ""
            },

            {
                "startTime": "18:42",
                "arxivId": "2407.10457",
                "arxivLink": "https://arxiv.org/abs/2407.10457",
                "title": "LLMs: Greedy or Random? The Decoding Debate Heats Up!",
                "institute": "Peking University, Allen Institute for AI",
                "text": "This research delves into the non-determinism of LLMs, examining the performance differences between greedy decoding and sampling methods. Unlike previous work that often focuses on a single output per example, this study explores the variability of LLM performance across multiple generations.",
                "paper-title": "The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism",
                "image-path": ""
            },

            {
                "startTime": "19:07",
                "arxivId": "2407.10973",
                "arxivLink": "https://arxiv.org/abs/2407.10973",
                "title": "Make-An-Agent: Turning Agent Behaviors into Policies with Diffusion Magic!",
                "institute": "University of Maryland, Tsinghua University",
                "text": "This paper proposes a novel method for generating control policies for agents using diffusion models. Unlike previous work that focuses on learning policies from data, this approach directly generates policy parameters from behavior embeddings, which encode trajectory information.",
                "paper-title": "Make-An-Agent: A Generalizable Policy Network Generator with Behavior-Prompted Diffusion",
                "image-path": ""
            },

            {
                "startTime": "19:31",
                "arxivId": "2407.10220",
                "arxivLink": "https://arxiv.org/abs/2407.10220",
                "title": "Pose-ing for the Future: Diffusion Models Get a Body Part Makeover!",
                "institute": "Valeo.ai, LIGM, \u00c9cole des Ponts ParisTech...",
                "text": "This research introduces a novel part-based approach for 3D whole-body pose estimation, where the model predicts poses for different body parts (body, hands, and face) separately, conditioned on their respective root joints. This differs from previous methods that typically process all keypoints in a single network.",
                "paper-title": "PAFUSE: Part-based Diffusion for 3D Whole-Body Pose Estimation",
                "image-path": ""
            },

            {
                "startTime": "19:56",
                "arxivId": "2407.10005",
                "arxivLink": "https://arxiv.org/abs/2407.10005",
                "title": "In-Context Learning: It's Not Just Attention, It's the Algorithm!",
                "institute": "University of Michigan, Google",
                "text": "This research goes beyond the typical assumption that in-context learning (ICL) is solely driven by attention mechanisms. It explores the optimization landscape of ICL, considering both linear attention and state-space models (SSMs), and demonstrates that both can implement gradient-based algorithms.",
                "paper-title": "Fine-grained Analysis of In-context Linear Estimation: Data, Architecture, and Beyond",
                "image-path": ""
            },

            {
                "startTime": "20:23",
                "arxivId": "2407.09694",
                "arxivLink": "https://arxiv.org/abs/2407.09694",
                "title": "Body Part Puzzle: Reconstructing Humans from Tiny Clues",
                "institute": "University at Buffalo, Peking University, Johns Hopkins University...",
                "text": "This research introduces a \"Divide and Fuse\" approach for human body mesh reconstruction, focusing on scenarios where only a small portion of the body is visible. Unlike traditional methods that rely on whole-body models, this approach reconstructs individual body parts independently before fusing them together, making it more robust to occlusions.",
                "paper-title": "Divide and Fuse: Body Part Mesh Recovery from Partially Visible Human Images",
                "image-path": ""
            },

            {
                "startTime": "20:50",
                "arxivId": "2407.10918",
                "arxivLink": "https://arxiv.org/abs/2407.10918",
                "title": "PartImageNet++: Giving AI a Part-Time Job in Robust Recognition!",
                "institute": "Tsinghua University, Harbin Institute of Technology, Beijing Institute of Technology",
                "text": "This research introduces PartImageNet++, a dataset with part-level annotations for all categories in ImageNet-1K. This differs from previous work by providing a large-scale, high-quality dataset for training part-based models, which are designed to improve the robustness of object recognition systems.",
                "paper-title": "PartImageNet++ Dataset: Scaling up Part-based Models for Robust Recognition",
                "image-path": ""
            },

            {
                "startTime": "21:16",
                "arxivId": "2407.10916",
                "arxivLink": "https://arxiv.org/abs/2407.10916",
                "title": "Graph Learning Goes Heterophilic: A New Benchmark for Real-World Networks",
                "institute": "MIT, IBM, Virginia Tech",
                "text": "This research introduces a new graph benchmark, H2GB, specifically designed to evaluate graph learning methods on graphs that exhibit both heterophily and heterogeneity. This benchmark addresses the limitations of existing benchmarks that focus on either homogeneous graphs or heterogeneous graphs with the homophily assumption.",
                "paper-title": "When Heterophily Meets Heterogeneity: New Graph Benchmarks and Effective Methods",
                "image-path": ""
            },

            {
                "startTime": "21:39",
                "arxivId": "2407.09499",
                "arxivLink": "https://arxiv.org/abs/2407.09499",
                "title": "Curated AI: How Internet Filters Are Shaping Our Future",
                "institute": "Mila, Universit\u00e9 de Montr\u00e9al, Ecole Normale Sup\u00e9rieure de Paris...",
                "text": "This research explores the impact of data curation on the training of generative models, specifically focusing on how human preferences influence the models' output. Unlike previous work that focused on the stability of retraining models on synthetic data, this paper examines the effects of curated synthetic data, where users select preferred outputs.",
                "paper-title": "Self-Consuming Generative Models with Curated Data Provably Optimize Human Preferences",
                "image-path": ""
            },

            {
                "startTime": "22:13",
                "arxivId": "2407.10603",
                "arxivLink": "https://arxiv.org/abs/2407.10603",
                "title": "Speech Recognition: When Less is More (and Faster!)",
                "institute": "National Taiwan University, NVIDIA",
                "text": "This research focuses on knowledge distillation for code-switching automatic speech recognition (CS-ASR) using unlabeled, realistic data. Unlike previous work that relies on labeled datasets, this study proposes a novel framework called K2D that leverages a small auxiliary model to filter out inaccurate pseudo-labels generated from a large teacher model.",
                "paper-title": "Leave No Knowledge Behind During Knowledge Distillation: Towards Practical and Effective Knowledge Distillation for Code-Switching ASR Using Realistic Data",
                "image-path": ""
            },

            {
                "startTime": "22:39",
                "arxivId": "2407.10330",
                "arxivLink": "https://arxiv.org/abs/2407.10330",
                "title": "Tree-mendous 3D Trees: From Single Images to Simulation-Ready Models!",
                "institute": "Purdue University, Massachusetts Institute of Technology, Google",
                "text": "This research introduces Tree-D Fusion, a dataset of 600,000 3D tree models generated from single images using diffusion priors. This approach differs from previous work by leveraging diffusion models to reconstruct complete 3D volumes of trees, which are then refined by a genus-conditioned developmental model.",
                "paper-title": "Tree-D Fusion: Simulation-Ready Tree Dataset from Single Images with Diffusion Priors",
                "image-path": ""
            },

            {
                "startTime": "23:06",
                "arxivId": "2407.10070",
                "arxivLink": "https://arxiv.org/abs/2407.10070",
                "title": "ASkotch: KRR's New Trick for Handling Big Data",
                "institute": "Stanford University",
                "text": "This paper introduces ASkotch, a new method for solving kernel ridge regression (KRR) problems that uses block coordinate descent with Hessian preconditioning and acceleration. Unlike previous methods, ASkotch scales linearly with the number of data points and does not scale with the preconditioner rank, allowing it to run on a single inexpensive GPU.",
                "paper-title": "Have ASkotch: Fast Methods for Large-scale, Memory-constrained Kernel Ridge Regression",
                "image-path": ""
            },

            {
                "startTime": "23:27",
                "arxivId": "2407.10482",
                "arxivLink": "https://arxiv.org/abs/2407.10482",
                "title": "NeRFs Get a Speed Boost: Attention is All You Need (and a Little Occupancy Distance)",
                "institute": "Tsinghua University, Horizon Robotics, Huawei Technologies...",
                "text": "This paper proposes NGP-RT, a real-time NeRF method that uses a lightweight attention mechanism to aggregate multi-level hash features. This approach differs from previous methods that rely on computationally intensive MLPs for feature aggregation.",
                "paper-title": "NGP-RT: Fusing Multi-Level Hash Features with Lightweight Attention for Real-Time Novel View Synthesis",
                "image-path": ""
            },

            {
                "startTime": "23:57",
                "arxivId": "2407.10528",
                "arxivLink": "https://arxiv.org/abs/2407.10528",
                "title": "Motion Control: Text-to-Motion with Local Action Guidance!",
                "institute": "Peking University, Tsinghua University",
                "text": "This research introduces a new approach to text-to-motion generation by using local actions as control signals. Unlike previous methods that focus on directly synthesizing global motions, this method breaks down the motion into smaller, more manageable actions, making it easier to generate complex and diverse motions.",
                "paper-title": "Local Action-Guided Motion Diffusion Model for Text-to-Motion Generation",
                "image-path": ""
            },

            {
                "startTime": "24:22",
                "arxivId": "2407.09704",
                "arxivLink": "https://arxiv.org/abs/2407.09704",
                "title": "LLMs: Gender-Biased, But Surprisingly Consistent Across Languages!",
                "institute": "University of Oxford",
                "text": "This research investigates the biases of multilingual LLMs through the lens of grammatical gender. Unlike previous work that focused on individual languages, this study examines how these biases transfer across different languages.",
                "paper-title": "What an Elegant Bridge: Multilingual LLMs are Biased Similarly in Different Languages",
                "image-path": ""
            },

            {
                "startTime": "24:46",
                "arxivId": "2407.10833",
                "arxivLink": "https://arxiv.org/abs/2407.10833",
                "title": "MoE-DiffIR: Image Restoration Gets a Prompt-Boost!",
                "institute": "University of Science and Technology of China, Peking University, ByteDance",
                "text": "This research introduces a novel approach to compressed image restoration (CIR) using a Mixture-of-Experts (MoE) prompt module. Unlike previous methods that rely on single or multiple weighted prompts, MoE-DiffIR dynamically selects and combines prompts based on the specific compression task, enabling more effective extraction of task-customized diffusion priors from Stable Diffusion.",
                "paper-title": "MoE-DiffIR: Task-customized Diffusion Priors for Universal Compressed Image Restoration",
                "image-path": ""
            },

            {
                "startTime": "25:08",
                "arxivId": "2407.10583",
                "arxivLink": "https://arxiv.org/abs/2407.10583",
                "title": "Reinforcement Learning's Three Dogmas: Time to Shed Some Fur?",
                "institute": "Google, NYU",
                "text": "This paper challenges three common assumptions in reinforcement learning (RL), arguing that they limit the field's potential. The authors propose shifting focus from modeling environments to understanding agents, moving beyond finding solutions to embracing continuous adaptation, and recognizing the limitations of using reward maximization as the sole goal-defining mechanism.",
                "paper-title": "Three Dogmas of Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "25:26",
                "arxivId": "2407.10328",
                "arxivLink": "https://arxiv.org/abs/2407.10328",
                "title": "AI Music: Can Robots Understand Our Musical Whispers?",
                "institute": "Queen Mary University of London, Independent Researcher",
                "text": "This paper focuses on the \"interpretation gap\" in text-to-music generation models, arguing that current models struggle to understand the nuances of human musical communication, unlike human musicians who excel at interpreting ambiguous instructions.",
                "paper-title": "The Interpretation Gap in Text-to-Music Generation Models",
                "image-path": ""
            },

            {
                "startTime": "25:58",
                "arxivId": "2407.09646",
                "arxivLink": "https://arxiv.org/abs/2407.09646",
                "title": "Hand Reconstruction Gets a Graph-Guided Makeover: Mamba's New Trick!",
                "institute": "CMU",
                "text": "This research introduces a novel approach to 3D hand reconstruction by integrating graph learning and state space modeling within a Mamba framework. Unlike previous transformer-based methods, this approach utilizes a graph-guided bidirectional scan, which effectively captures the spatial relations between hand joints while using significantly fewer tokens.",
                "paper-title": "Hamba: Single-view 3D Hand Reconstruction with Graph-guided Bi-Scanning Mamba",
                "image-path": ""
            },

            {
                "startTime": "26:24",
                "arxivId": "2407.10899",
                "arxivLink": "https://arxiv.org/abs/2407.10899",
                "title": "AI Students Ace Algebra: Can Robots Replace Humans in Testing?",
                "institute": "UC Berkeley",
                "text": "This research explores using Large Language Models (LLMs) to generate responses to assessment questions, simulating human responses for psychometric analysis. Unlike previous work that focused on generating questions or hints, this study investigates the feasibility of using LLMs to directly mimic student abilities.",
                "paper-title": "Leveraging LLM-Respondents for Item Evaluation: a Psychometric Analysis",
                "image-path": ""
            },

            {
                "startTime": "26:44",
                "arxivId": "2407.09818",
                "arxivLink": "https://arxiv.org/abs/2407.09818",
                "title": "Arabic Banking Bots Get a Dialect Makeover: AraFinNLP2024 Shared Task",
                "institute": "Birzeit University, Lancaster University, King Saud University...",
                "text": "This research introduces the first Arabic Financial NLP shared task, focusing on multi-dialect intent detection and cross-dialect translation within the banking domain. This is distinct from previous work that primarily focused on English financial NLP or Arabic morphological and semantic annotations.",
                "paper-title": "AraFinNLP 2024: The First Arabic Financial NLP Shared Task",
                "image-path": ""
            },

            {
                "startTime": "27:15",
                "arxivId": "2407.09705",
                "arxivLink": "https://arxiv.org/abs/2407.09705",
                "title": "Multimodal Learning: Diagnosing & Re-learning for a Balanced Model",
                "institute": "Renmin University of China, Tsinghua University",
                "text": "This research proposes a new method for balancing multimodal learning by diagnosing the learning state of each modality and then softly re-initializing the corresponding uni-modal encoder. This approach differs from previous work by considering the intrinsic limitation of modality capacity and taking all modalities into account during balancing.",
                "paper-title": "Diagnosing and Re-learning for Balanced Multimodal Learning",
                "image-path": ""
            },

            {
                "startTime": "27:44",
                "arxivId": "2407.10956",
                "arxivLink": "https://arxiv.org/abs/2407.10956",
                "title": "Data Science Bots: Can They Handle the Real World?",
                "institute": "The University of Hong Kong, Shanghai Jiao Tong University, Google Cloud AI Research...",
                "text": "This research introduces Spider2-V, a new benchmark for evaluating multimodal agents in data science and engineering workflows. Unlike previous benchmarks that focus on specific tasks like code generation or data analysis, Spider2-V encompasses the entire data pipeline, including data warehousing, ingestion, transformation, visualization, and orchestration. It also incorporates real-world enterprise applications and intensive GUI operations, making it a more realistic and challenging test for these agents.",
                "paper-title": "Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?",
                "image-path": ""
            },

            {
                "startTime": "28:09",
                "arxivId": "2407.09816",
                "arxivLink": "https://arxiv.org/abs/2407.09816",
                "title": "MaskMoE: Giving Infrequent Words a Voice in the Language Model Choir!",
                "institute": "Chinese Academy of Sciences, Tsinghua University, Beihang University",
                "text": "This research introduces MaskMoE, a new routing strategy for Mixture-of-Experts (MoE) models. Unlike previous dynamic routing methods that can lead to underfitting for infrequent words, MaskMoE uses a masking technique to ensure that infrequent words are consistently routed to the same expert, allowing for more thorough training.",
                "paper-title": "MaskMoE: Boosting Token-Level Learning via Routing Mask in Mixture-of-Experts",
                "image-path": ""
            },

            {
                "startTime": "28:46",
                "arxivId": "2407.10267",
                "arxivLink": "https://arxiv.org/abs/2407.10267",
                "title": "NeRFs Go Rolling: How to Make 3D Models from Shaky Camera Footage",
                "institute": "University of Tokyo",
                "text": "This paper introduces RS-NeRF, a method that directly incorporates the physics of rolling shutter distortions into the NeRF model. Unlike previous approaches that correct distortions in 2D image space, RS-NeRF jointly optimizes the NeRF parameters and camera poses for each image row, leading to more accurate 3D reconstructions.",
                "paper-title": "RS-NeRF: Neural Radiance Fields from Rolling Shutter Images",
                "image-path": ""
            },

            {
                "startTime": "29:09",
                "arxivId": "2407.10125",
                "arxivLink": "https://arxiv.org/abs/2407.10125",
                "title": "Pedestrian Detection Goes Multi-Modal: A Model That Sees It All!",
                "institute": "Tsinghua University",
                "text": "This research introduces a generalist model, MMPedestron, that can process multiple sensor modalities (like RGB, IR, Depth, LiDAR, and Event data) for pedestrian detection. Unlike previous models that focus on specific modality pairs, MMPedestron can handle diverse combinations, making it more flexible and adaptable.",
                "paper-title": "When Pedestrian Detection Meets Multi-Modal Learning: Generalist Model and Benchmark Dataset",
                "image-path": ""
            },

            {
                "startTime": "29:40",
                "arxivId": "2407.09697",
                "arxivLink": "https://arxiv.org/abs/2407.09697",
                "title": "LiDAR and Camera: A Love Story of 3D Semantic Segmentation",
                "institute": "University of Toronto, Huawei",
                "text": "This research proposes a new method called LaCRange for 3D point cloud semantic segmentation. It uses a distortion-compensating knowledge distillation (DCKD) strategy to address the information loss caused by projecting RGB images onto the sparse LiDAR point cloud. Additionally, it introduces a context-based feature fusion module to combine camera and LiDAR features effectively.",
                "paper-title": "Uplifting Range-View-based 3D Semantic Segmentation in Real-Time with Multi-Sensor Fusion",
                "image-path": ""
            },

            {
                "startTime": "30:01",
                "arxivId": "2407.10550",
                "arxivLink": "https://arxiv.org/abs/2407.10550",
                "title": "Fake Videos Can't Keep Up: New AI Detects Inconsistent Faces",
                "institute": "Chinese Academy of Sciences, Tsinghua University",
                "text": "This research proposes a self-supervised learning approach for face forgery detection that leverages the natural consistency of real face videos. Unlike previous methods that rely on specific forgery patterns or require additional modalities like audio, this method focuses on the inherent spatiotemporal coherence of real faces, making it more robust to unseen forgery methods and perturbations.",
                "paper-title": "Learning Natural Consistency Representation for Face Forgery Video Detection",
                "image-path": ""
            },

            {
                "startTime": "30:35",
                "arxivId": "2407.10252",
                "arxivLink": "https://arxiv.org/abs/2407.10252",
                "title": "Multilingual Text Gets a Subjectivity Checkup: BERT's Got Your Back!",
                "institute": "CMU, Northwestern University",
                "text": "This research focuses on classifying text as subjective or objective across five languages, including Arabic, Bulgarian, English, German, and Italian, using a fine-tuned BERT model and addressing the data imbalance issue.",
                "paper-title": "Nullpointer at CheckThat! 2024: Identifying Subjectivity from Multilingual Text Sequence",
                "image-path": ""
            },

            {
                "startTime": "31:02",
                "arxivId": "2407.10954",
                "arxivLink": "https://arxiv.org/abs/2407.10954",
                "title": "Fuzzy Logic Makes CSG Shapes Smooth and Differentiable!",
                "institute": "Roblox, University of British Columbia, Stanford University...",
                "text": "This research introduces a unified differentiable boolean operator for CSG modeling, which allows continuous optimization of both the primitive shapes and the boolean operations. Unlike previous methods that rely on discrete choices for boolean operations, this approach uses fuzzy logic to create a continuous function that can be differentiated with respect to the type of operation.",
                "paper-title": "A Unified Differentiable Boolean Operator with Fuzzy Logic",
                "image-path": ""
            },

            {
                "startTime": "31:29",
                "arxivId": "2407.09533",
                "arxivLink": "https://arxiv.org/abs/2407.09533",
                "title": "Predicting the Future, One Frame at a Time: Video Occupancy Models for Control",
                "institute": "University of Alberta, UT Austin, Microsoft Research...",
                "text": "This paper introduces Video Occupancy Models (VOCs), which directly predict the discounted distribution of future states in a single step, unlike prior latent-space world models that require multistep rollouts.",
                "paper-title": "Video Occupancy Models",
                "image-path": ""
            },

            {
                "startTime": "31:59",
                "arxivId": "2407.10207",
                "arxivLink": "https://arxiv.org/abs/2407.10207",
                "title": "Steering Agents: A Game of Incentives and Uncertainty",
                "institute": "ETH Zurich, University of Zurich",
                "text": "This research focuses on designing incentives to steer multi-agent systems towards desired outcomes without knowing the agents' learning dynamics. It introduces a model-based non-episodic reinforcement learning formulation for this steering problem, emphasizing the learning of history-dependent steering strategies to handle model uncertainty. This approach differs from previous work by explicitly tackling the challenge of learning in a single, finite-horizon episode, where the mediator cannot simply learn from repeated trial-and-error.",
                "paper-title": "Learning to Steer Markovian Agents under Model Uncertainty",
                "image-path": ""
            },

            {
                "startTime": "32:22",
                "arxivId": "2407.10794",
                "arxivLink": "https://arxiv.org/abs/2407.10794",
                "title": "LLMs Go Global: Building Knowledge Graphs with a Fusion Twist!",
                "institute": "Duke-NUS Medical School, University of Tokyo, Smartor Inc....",
                "text": "This research introduces Graphusion, a framework for constructing knowledge graphs (KGs) from free text using large language models (LLMs). Unlike previous approaches that focus on extracting knowledge from individual sentences or documents, Graphusion takes a global perspective, merging and resolving conflicts across multiple sources to create a more comprehensive and accurate KG.",
                "paper-title": "Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education",
                "image-path": ""
            },

            {
                "startTime": "32:54",
                "arxivId": "2407.09580",
                "arxivLink": "https://arxiv.org/abs/2407.09580",
                "title": "Don't Fear the Funky Functions: New Activation Function Makes Deep Learning More Powerful",
                "institute": "The Chinese University of Hong Kong, The Hong Kong Polytechnic University, Southern Medical University...",
                "text": "This research introduces a new activation function called PEUAF, which is a parameterized version of the Elementary Universal Activation Function (EUAF). Unlike previous super-expressive activation functions, PEUAF can adaptively learn the frequency of stationary signals, making it more versatile and effective in real-world applications.",
                "paper-title": "Don't Fear Peculiar Activation Functions: EUAF and Beyond",
                "image-path": ""
            },

            {
                "startTime": "33:28",
                "arxivId": "2407.09661",
                "arxivLink": "https://arxiv.org/abs/2407.09661",
                "title": "Bridging the Divide: A Dictionary for Politically Charged Words",
                "institute": "MIT",
                "text": "This research introduces the Bridging Dictionary, an interactive tool that uses a large language model (LLM) to analyze how words are used differently by Republicans and Democrats. Unlike previous work that focused on measuring and debiasing NLP models, this study aims to help humans understand and write less biased content.",
                "paper-title": "Bridging Dictionary: AI-Generated Dictionary of Partisan Language Use",
                "image-path": ""
            },

            {
                "startTime": "33:54",
                "arxivId": "2407.10844",
                "arxivLink": "https://arxiv.org/abs/2407.10844",
                "title": "Predicting Molecular Uncertainty: When to Trust Your AI Chemist!",
                "institute": "Meta, CMU",
                "text": "This research focuses on uncertainty quantification for relaxed energy calculations using graph neural networks (GNNs), a task that is more complex than other molecular property predictions due to the impact of structure optimizations on the error distribution. The paper proposes using distribution-free techniques for assessing calibration and developing uncertainty prediction methods for GNNs performing relaxed energy calculations.",
                "paper-title": "Rotationally Invariant Latent Distances for Uncertainty Estimation of Relaxed Energy Predictions by Graph Neural Network Potentials",
                "image-path": ""
            },

            {
                "startTime": "34:22",
                "arxivId": "2407.09853",
                "arxivLink": "https://arxiv.org/abs/2407.09853",
                "title": "Image Compression: A Tune-Up for Machine Vision!",
                "institute": "Shanghai Jiao Tong University, Tsinghua University, Chinese University of Hong Kong",
                "text": "This research proposes a novel Spatial-Frequency Modulation Adapter (SFMA) to fine-tune pre-trained image compression models for machine vision tasks. Unlike previous methods that rely on task-specific networks, SFMA adapts the existing model by modulating features in both spatial and frequency domains, leading to more efficient fine-tuning.",
                "paper-title": "Image Compression for Machine and Human Vision with Spatial-Frequency Adaptation",
                "image-path": ""
            },

            {
                "startTime": "34:52",
                "arxivId": "2407.09602",
                "arxivLink": "https://arxiv.org/abs/2407.09602",
                "title": "Neutron Star Mergers: Machine Learning Makes Inference a Breeze!",
                "institute": "Max Planck Society, University of Nottingham",
                "text": "This research introduces a new machine learning method called \"prior-conditioning\" that allows for rapid and accurate inference of binary neutron star (BNS) parameters from gravitational wave data. This method differs from previous work by enabling the neural network to be instantly tuned to an event-specific prior, which significantly improves the speed and accuracy of inference.",
                "paper-title": "Real-time gravitational-wave inference for binary neutron stars using machine learning",
                "image-path": ""
            },

            {
                "startTime": "35:14",
                "arxivId": "2407.09897",
                "arxivLink": "https://arxiv.org/abs/2407.09897",
                "title": "Chatbots Gone Wild: New Framework Tames LLM-Powered Conversations",
                "institute": "University of Tokyo",
                "text": "This research focuses on the quality of multi-agent dialogues in simulations powered by LLMs, specifically examining how these dialogues evolve over multiple sessions. Unlike previous work that primarily evaluated single sessions or interactions between two agents, this study analyzes the long-term impact of LLM-generated conversations on the consistency and factual accuracy of the simulated world.",
                "paper-title": "Cohesive Conversations: Enhancing Authenticity in Multi-Agent Simulated Dialogues",
                "image-path": ""
            },

            {
                "startTime": "35:39",
                "arxivId": "2407.10244",
                "arxivLink": "https://arxiv.org/abs/2407.10244",
                "title": "Social Workers Say \"No\" to AI Decision-Making: A New Study Reveals Why",
                "institute": "University of Cambridge",
                "text": "This research focuses on the perspectives of UK social work practitioners on AI, specifically exploring their experiences, attitudes, and needs, rather than focusing on the impacts of specific AI systems.",
                "paper-title": "Reimagining AI in Social Work: Practitioner Perspectives on Incorporating Technology in their Practice",
                "image-path": ""
            },

            {
                "startTime": "36:05",
                "arxivId": "2407.10639",
                "arxivLink": "https://arxiv.org/abs/2407.10639",
                "title": "Traffic Trouble? New AI Predicts Risky Driving, One Intersection at a Time!",
                "institute": "University of Oxford",
                "text": "This research focuses on improving trajectory prediction by analyzing the spatial and temporal patterns of risky interactions within a dataset. Unlike previous work that uses risk metrics based on current information, this study leverages historical data to identify high-risk locations and incorporate this knowledge into the prediction model.",
                "paper-title": "Risk-aware Trajectory Prediction by Incorporating Spatio-temporal Traffic Interaction Analysis",
                "image-path": ""
            },

            {
                "startTime": "36:32",
                "arxivId": "2407.09679",
                "arxivLink": "https://arxiv.org/abs/2407.09679",
                "title": "Smoke and Mirrors: Neural Trajectories for Realistic Fluid Reconstruction",
                "institute": "ETH Zurich, Peking University",
                "text": "This research introduces Neural Characteristic Trajectory Fields, a novel representation that implicitly models Lagrangian fluid trajectories using Eulerian neural fields. This differs from previous work by enabling efficient flow map calculations between arbitrary frames and facilitating end-to-end supervision covering long-term conservation and short-term physics priors.",
                "paper-title": "Physics-Informed Learning of Characteristic Trajectories for Smoke Reconstruction",
                "image-path": ""
            },

            {
                "startTime": "37:04",
                "arxivId": "2407.10382",
                "arxivLink": "https://arxiv.org/abs/2407.10382",
                "title": "Robot Teams: Less Talk, More Action!",
                "institute": "University of Michigan",
                "text": "This research introduces a new distributed coordination algorithm for multi-robot networks that prioritizes speed over absolute optimality. Unlike previous methods that either sacrifice real-time performance for near-optimal solutions or rely on heuristics without guarantees, this algorithm balances the trade-off by enabling robots to choose their communication partners strategically.",
                "paper-title": "Communication- and Computation-Efficient Distributed Decision-Making in Multi-Robot Networks",
                "image-path": ""
            },

            {
                "startTime": "37:29",
                "arxivId": "2407.09879",
                "arxivLink": "https://arxiv.org/abs/2407.09879",
                "title": "Multilingual LLMs: A Recipe for Success with a Dash of N-Shot Prompting!",
                "institute": "Microsoft",
                "text": "This research introduces SPHINX, a novel multilingual instruction tuning dataset created by selectively translating English instruction-response pairs into 50 languages using GPT-4. This approach aims to preserve semantic information and linguistic diversity, unlike previous methods that relied on direct translation APIs or self-instruct techniques.",
                "paper-title": "sPhinX: Sample Efficient Multilingual Instruction Fine-Tuning Through N-shot Guided Prompting",
                "image-path": ""
            },

            {
                "startTime": "37:59",
                "arxivId": "2407.10275",
                "arxivLink": "https://arxiv.org/abs/2407.10275",
                "title": "Knowledge Editing Goes Global: LLMs Learn New Facts in Any Language!",
                "institute": "Microsoft, UNC Chapel Hill, Massachusetts Institute of Technology...",
                "text": "This research focuses on cross-lingual multi-hop knowledge editing, a new paradigm that addresses the limitations of existing monolingual knowledge editing techniques. Unlike previous work, this study explores how to efficiently update LLMs with new information from various languages, considering the ripple effects of these edits on related facts.",
                "paper-title": "Cross-Lingual Multi-Hop Knowledge Editing -- Benchmarks, Analysis and a Simple Contrastive Learning based Approach",
                "image-path": ""
            },

            {
                "startTime": "38:21",
                "arxivId": "2407.10279",
                "arxivLink": "https://arxiv.org/abs/2407.10279",
                "title": "Doudizhu AI Gets a Bidding Boost: AlphaDou Learns to Bluff!",
                "institute": "Shanghai Jiao Tong University, Tsinghua University",
                "text": "This research introduces AlphaDou, a Doudizhu AI that integrates bidding into its training and testing phases, unlike previous models that focused solely on the card-playing phase.",
                "paper-title": "AlphaDou: High-Performance End-to-End Doudizhu AI Integrating Bidding",
                "image-path": ""
            },

            {
                "startTime": "38:47",
                "arxivId": "2407.10886",
                "arxivLink": "https://arxiv.org/abs/2407.10886",
                "title": "LLMs on the Edge? No Problem! New Method Keeps Your AI Secrets Safe",
                "institute": "Microsoft",
                "text": "This paper introduces a novel hybrid inference algorithm called SLIP, which aims to protect the intellectual property of large language models (LLMs) deployed on edge devices. Unlike previous methods that focus on cost, performance, or privacy, SLIP prioritizes model security while maintaining accuracy and minimal latency. It achieves this by strategically decomposing the model's weight matrices, ensuring that the most sensitive information is stored on a secure resource, while the less valuable parts are offloaded to a vulnerable edge device.",
                "paper-title": "SLIP: Securing LLMs IP Using Weights Decomposition",
                "image-path": ""
            },

            {
                "startTime": "39:17",
                "arxivId": "2407.09486",
                "arxivLink": "https://arxiv.org/abs/2407.09486",
                "title": "LLM Serving: From Costly to Cost-Effective with ENOVA's Autoscaling Magic",
                "institute": "Sun Yat-sen University, University of Toronto",
                "text": "This research focuses on building a service called ENOVA that automates the deployment, monitoring, and autoscaling of large language models (LLMs) on multi-GPU clusters. Unlike previous work that primarily focuses on optimizing LLM inference, ENOVA addresses the challenges of providing stable and scalable LLM services in real-world environments.",
                "paper-title": "ENOVA: Autoscaling towards Cost-effective and Stable Serverless LLM Serving",
                "image-path": ""
            },

            {
                "startTime": "39:47",
                "arxivId": "2407.10649",
                "arxivLink": "https://arxiv.org/abs/2407.10649",
                "title": "Patch It Up: A New Way to Segment Images with Less Data",
                "institute": "Xi\u2019an Jiaotong-Liverpool University, University of Aberdeen, Microsoft...",
                "text": "This paper proposes a new method for weakly supervised semantic segmentation that uses Vision Transformers (ViT) without relying on Class Activation Maps (CAM). It introduces Adaptive-K Pooling to select the most relevant patches for prediction and Patch Contrastive Learning to improve the quality of patch embeddings.",
                "paper-title": "APC: Adaptive Patch Contrast for Weakly Supervised Semantic Segmentation",
                "image-path": ""
            },

            {
                "startTime": "40:36",
                "arxivId": "2407.10967",
                "arxivLink": "https://arxiv.org/abs/2407.10967",
                "title": "Reinforcement Learning's New Trick: Unmasking the Hidden Causes for Better Decisions",
                "institute": "CMU",
                "text": "This research tackles the objective mismatch problem in offline model-based reinforcement learning (MBRL) by introducing a novel approach called BilinEar CAUSal rEpresentation (BECAUSE). Unlike previous methods that focus on reweighting the entire model or jointly training the model and policy, BECAUSE identifies and models the underlying causal structures in the environment, specifically addressing the spurious correlations introduced by confounders in offline data.",
                "paper-title": "BECAUSE: Bilinear Causal Representation for Generalizable Offline Model-based Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "41:09",
                "arxivId": "2407.10061",
                "arxivLink": "https://arxiv.org/abs/2407.10061",
                "title": "InfiniMotion: Making AI Dance for Hours, Not Seconds!",
                "institute": "Monash University, The Australian National University, The University of Adelaide...",
                "text": "This research introduces InfiniMotion, a method that uses a memory-enhanced transformer to generate long motion sequences. Unlike previous methods that struggle with long sequences, InfiniMotion leverages the Bidirectional Mamba Memory block to improve the transformer's memory capacity, enabling the generation of continuous motion sequences of arbitrary length.",
                "paper-title": "InfiniMotion: Mamba Boosts Memory in Transformer for Arbitrary Long Motion Generation",
                "image-path": ""
            },

            {
                "startTime": "41:33",
                "arxivId": "2407.09541",
                "arxivLink": "https://arxiv.org/abs/2407.09541",
                "title": "VLMs Meet LLMs: A Match Made in Embedding Heaven!",
                "institute": "Meta AI, Georgia Institute of Technology, University of Wisconsin-Madison...",
                "text": "This research introduces a novel approach called MATE (Meet At The Embedding) that connects images with long texts, such as lengthy captions or documents, by aligning embeddings from Vision Language Models (VLMs) with those from Large Language Models (LLMs). Unlike previous work that primarily focused on aligning images with short captions, MATE leverages the strengths of both VLMs and LLMs to handle complex textual interactions.",
                "paper-title": "MATE: Meet At The Embedding -- Connecting Images with Long Texts",
                "image-path": ""
            },

            {
                "startTime": "42:05",
                "arxivId": "2407.10795",
                "arxivLink": "https://arxiv.org/abs/2407.10795",
                "title": "Decoding Decoding: Skipping Layers for Multilingual Language Models",
                "institute": "Nanjing University, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research proposes a new contrastive decoding algorithm that addresses the language mismatch issue in previous methods, specifically by skipping language-agnostic layers in the model.",
                "paper-title": "Multilingual Contrastive Decoding via Language-Agnostic Layers Skipping",
                "image-path": ""
            },

            {
                "startTime": "42:29",
                "arxivId": "2407.10062",
                "arxivLink": "https://arxiv.org/abs/2407.10062",
                "title": "Spike Cameras: Seeing the Unseen, Blur-Free, and in 3D!",
                "institute": "Peking University",
                "text": "This research introduces SpikeGS, a novel approach for 3D scene reconstruction using spike cameras. Unlike previous methods that rely on traditional cameras and suffer from motion blur, SpikeGS leverages the ultra-high temporal resolution of spike cameras to capture dense and continuous views, enabling accurate 3D modeling even in high-speed scenarios.",
                "paper-title": "SpikeGS: 3D Gaussian Splatting from Spike Streams with High-Speed Camera Motion",
                "image-path": ""
            },

            {
                "startTime": "42:53",
                "arxivId": "2407.09545",
                "arxivLink": "https://arxiv.org/abs/2407.09545",
                "title": "Chaos on Command: Scientists Design Chaotic Attractors with a Semi-Supervised Twist",
                "institute": "University of Tokyo",
                "text": "This research proposes a novel semi-supervised method for designing chaotic attractors using reservoir computing. Unlike previous methods that rely solely on supervised learning, this approach leverages the intrinsic dynamics of the reservoir to generate chaos with a desired shape.",
                "paper-title": "Designing Chaotic Attractors: A Semi-supervised Approach",
                "image-path": ""
            },

            {
                "startTime": "43:21",
                "arxivId": "2407.10454",
                "arxivLink": "https://arxiv.org/abs/2407.10454",
                "title": "Deflating Value Iteration: A Faster Way to Learn from Experience",
                "institute": "Seoul National University, University of Toronto, Vector Institute...",
                "text": "This paper introduces a novel approach to accelerate Value Iteration (VI), a fundamental algorithm in reinforcement learning, by modifying the eigenvalues of the transition dynamics. This method, called Deflated Dynamics Value Iteration (DDVI), effectively removes the top dominant eigenvalues of the transition matrix, leading to a faster convergence rate.",
                "paper-title": "Deflated Dynamics Value Iteration",
                "image-path": ""
            },

            {
                "startTime": "43:50",
                "arxivId": "2407.09648",
                "arxivLink": "https://arxiv.org/abs/2407.09648",
                "title": "2D to 3D: Part Segmentation Without Training!",
                "institute": "Georgia Institute of Technology, Meta AI, University of Illinois Urbana-Champaign",
                "text": "This paper proposes a training-free method for 3D object part segmentation that leverages semantic correspondences from 2D images. Unlike previous methods that rely on language inputs or 3D segmentation priors, this approach uses features from pretrained image diffusion models to transfer part labels from a 2D database to 3D objects.",
                "paper-title": "3x2: 3D Object Part Segmentation by 2D Semantic Correspondences",
                "image-path": ""
            },

            {
                "startTime": "44:17",
                "arxivId": "2407.10118",
                "arxivLink": "https://arxiv.org/abs/2407.10118",
                "title": "Parsing Speech Without Words: A Textless Approach to Dependency Parsing",
                "institute": "University of Tokyo, Keio University",
                "text": "This research proposes a textless method for dependency parsing, directly predicting a dependency tree from speech representations without relying on an automatic speech recognition (ASR) system. This differs from previous work like Wav2tree, which cascades an ASR system into a dependency parser.",
                "paper-title": "Textless Dependency Parsing by Labeled Sequence Prediction",
                "image-path": ""
            },

            {
                "startTime": "44:40",
                "arxivId": "2407.09497",
                "arxivLink": "https://arxiv.org/abs/2407.09497",
                "title": "Simulating Squishy Things: A Neural Network That Doesn't Need a Mesh!",
                "institute": "Nvidia, Texas A&M University, University of Toronto",
                "text": "This research introduces a mesh-free, geometry-agnostic approach for elastic simulation. Unlike previous methods that rely on specific geometric representations like meshes or grids, this technique uses neural fields to represent the object's deformation, making it adaptable to various 3D representations.",
                "paper-title": "Simplicits: Mesh-Free, Geometry-Agnostic, Elastic Simulation",
                "image-path": ""
            },

            {
                "startTime": "45:03",
                "arxivId": "2407.09555",
                "arxivLink": "https://arxiv.org/abs/2407.09555",
                "title": "DMMs on Steroids: Parallel Evolution for Faster Memory Management",
                "institute": "Universidad Complutense de Madrid, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research introduces a parallel evolutionary algorithm for optimizing dynamic memory managers (DMMs) in embedded systems. Unlike previous approaches that rely on sequential exploration, this method leverages a master-worker scheme to distribute the simulation and evaluation tasks across multiple processors, significantly reducing the optimization time.",
                "paper-title": "A parallel evolutionary algorithm to optimize dynamic memory managers in embedded systems",
                "image-path": ""
            },

            {
                "startTime": "45:28",
                "arxivId": "2407.10078",
                "arxivLink": "https://arxiv.org/abs/2407.10078",
                "title": "Missing Data? No Problem! LLMs to the Rescue!",
                "institute": "Columbia University, Georgia Institute of Technology, University of Texas at Austin...",
                "text": "This research proposes using fine-tuned Large Language Models (LLMs) to impute missing data in recommendation systems, a novel approach compared to traditional statistical methods.",
                "paper-title": "Semantic Understanding and Data Imputation using Large Language Model to Accelerate Recommendation System",
                "image-path": ""
            },

            {
                "startTime": "45:57",
                "arxivId": "2407.10195",
                "arxivLink": "https://arxiv.org/abs/2407.10195",
                "title": "LiDAR Love: How to Make Vehicle and Infrastructure Sensors See Eye-to-Eye",
                "institute": "Tsinghua University",
                "text": "This research introduces a novel calibration method for cooperative vehicle and infrastructure LiDAR systems that leverages spatial association information between detection boxes, enabling real-time monitoring of calibration results. Unlike previous methods that rely on high-precision maps or complex perception algorithms, this approach utilizes a novel Overall IoU metric to identify common targets detected by both vehicle and infrastructure LiDARs, simplifying the calibration process and reducing computational complexity.",
                "paper-title": "V2I-Calib: A Novel Calibration Approach for Collaborative Vehicle and Infrastructure LiDAR Systems",
                "image-path": ""
            },

            {
                "startTime": "46:24",
                "arxivId": "2407.10369",
                "arxivLink": "https://arxiv.org/abs/2407.10369",
                "title": "AI Act's Governance: A Bureaucratic Circus, But With Rules!",
                "institute": "University of Bologna, European University Viadrina, Yale University...",
                "text": "This research focuses on the institutional design of the EU's AI Act, analyzing the roles and responsibilities of various supranational and national bodies involved in its implementation and enforcement. It differs from previous work by providing a detailed analysis of the governance framework and offering recommendations for a more robust and coordinated approach.",
                "paper-title": "A Robust Governance for the AI Act: AI Office, AI Board, Scientific Panel, and National Authorities",
                "image-path": ""
            },

            {
                "startTime": "47:03",
                "arxivId": "2407.10487",
                "arxivLink": "https://arxiv.org/abs/2407.10487",
                "title": "Relighting Portraits: From Flat to 3D with a Single Click!",
                "institute": "Max Planck Society, Google, Friedrich-Alexander University Erlangen-N\u00fcrnberg...",
                "text": "This research introduces Lite2Relight, a method that can relight a portrait image from a single input, achieving 3D-consistent head poses and physically plausible lighting at interactive speeds. Unlike previous methods that rely on multi-view images or slow optimization processes, Lite2Relight leverages a pre-trained 3D generative model and a lightstage dataset to implicitly disentangle face reflectance and perform relighting under target HDRI environment maps.",
                "paper-title": "Lite2Relight: 3D-aware Single Image Portrait Relighting",
                "image-path": ""
            },

            {
                "startTime": "47:31",
                "arxivId": "2407.10657",
                "arxivLink": "https://arxiv.org/abs/2407.10657",
                "title": "Stop Feeding LLMs Junk Data: How to Validate Synthetic Formulas for Better Spreadsheet Predictions",
                "institute": "Microsoft",
                "text": "This research focuses on validating synthetic natural language (NL) data generated by LLMs for fine-tuning models in the NL-to-Formula task. Unlike previous work that focuses on manual annotation or data selection based on alignment, this study proposes and empirically evaluates three surrogate objectives for validating the accuracy of synthetic NL.",
                "paper-title": "An Empirical Study of Validating Synthetic Data for Formula Generation",
                "image-path": ""
            },

            {
                "startTime": "48:00",
                "arxivId": "2407.10645",
                "arxivLink": "https://arxiv.org/abs/2407.10645",
                "title": "ChatGPT's Got a New Trick: Prompt Engineering for Social Science Research",
                "institute": "Universit\u00e9 Paris 1 Panth\u00e9on-Sorbonne, Universit\u00e9 Paris-Saclay, CNRS...",
                "text": "This research focuses on the impact of prompt selection on the accuracy of text annotation tasks using Large Language Models (LLMs) in social sciences. Unlike previous studies that used simple, hand-crafted prompts, this paper investigates the effectiveness of automatic prompt optimization, a method that systematically crafts high-quality prompts.",
                "paper-title": "Prompt Selection Matters: Enhancing Text Annotations for Social Sciences with Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "48:35",
                "arxivId": "2407.09719",
                "arxivLink": "https://arxiv.org/abs/2407.09719",
                "title": "AI Gets a Material Makeover: New Dataset Tests AI's Design Smarts",
                "institute": "CMU, Autodesk",
                "text": "This research introduces a new dataset, MSEval, specifically designed to evaluate the performance of large language models (LLMs) in the context of material selection for conceptual design. Unlike existing benchmarks that focus on general language tasks, MSEval focuses on a niche application with real-world relevance.",
                "paper-title": "MSEval: A Dataset for Material Selection in Conceptual Design to Evaluate Algorithmic Models",
                "image-path": ""
            },

            {
                "startTime": "49:00",
                "arxivId": "2407.10188",
                "arxivLink": "https://arxiv.org/abs/2407.10188",
                "title": "Self-Modeling: The Secret to Making Your Brain (and AI) More Predictable?",
                "institute": "Princeton University",
                "text": "This research explores the impact of self-modeling on neural networks, proposing that learning to predict one's internal states leads to a reduction in network complexity. Unlike previous work focusing on performance improvements, this study investigates the underlying mechanism of self-modeling, specifically its effect on network structure.",
                "paper-title": "Unexpected Benefits of Self-Modeling in Neural Systems",
                "image-path": ""
            },

            {
                "startTime": "49:22",
                "arxivId": "2407.10247",
                "arxivLink": "https://arxiv.org/abs/2407.10247",
                "title": "AI Boss: Why Every Company Needs a Chief AI Officer",
                "institute": "University of Oxford, Siemens AG",
                "text": "This research examines the emergence of the Chief AI Officer (CAIO) role within the C-suite, focusing on the unique pressures and opportunities presented by AI-driven transformations. It distinguishes the CAIO from the traditional CIO role, highlighting the need for specialized AI leadership in navigating the complexities of AI integration and governance.",
                "paper-title": "Strategic Integration of Artificial Intelligence in the C-Suite: The Role of the Chief AI Officer",
                "image-path": ""
            },

            {
                "startTime": "49:41",
                "arxivId": "2407.10086",
                "arxivLink": "https://arxiv.org/abs/2407.10086",
                "title": "AI Doctor Diagnoses Research Gaps: Pandemic PACT's New Tool",
                "institute": "University of Oxford",
                "text": "This research introduces a fine-tuned language model called PPACE, which automatically classifies biomedical research abstracts based on WHO-aligned research priorities. Unlike previous work, PPACE leverages human-annotated data and incorporates rationales generated by a larger language model to explain its classifications.",
                "paper-title": "Rapid Biomedical Research Classification: The Pandemic PACT Advanced Categorisation Engine",
                "image-path": ""
            },

            {
                "startTime": "50:06",
                "arxivId": "2407.10331",
                "arxivLink": "https://arxiv.org/abs/2407.10331",
                "title": "Robots Get a Grip: 3D Models Help Robots Understand Objects They Hold",
                "institute": "CMU",
                "text": "This research introduces a new method for jointly estimating the geometry and pose of objects grasped by a robot using 3D foundation models. Unlike previous methods that rely on calibrated cameras or pre-existing object models, this approach leverages uncalibrated external cameras and does not require prior knowledge of the object's geometry.",
                "paper-title": "3D Foundation Models Enable Simultaneous Geometry and Pose Estimation of Grasped Objects",
                "image-path": ""
            },

            {
                "startTime": "50:30",
                "arxivId": "2407.09994",
                "arxivLink": "https://arxiv.org/abs/2407.09994",
                "title": "Rocket Science Just Got a Speed Boost: Distributed Computing Makes Model Reduction Fly!",
                "institute": "Jacobs Engineering Group Inc., Air Force Research Laboratory, The University of Texas at Austin",
                "text": "This research introduces a distributed algorithm for constructing reduced-order models (ROMs) that can handle extremely large datasets generated by high-performance computing (HPC) simulations. This approach differs from previous work by incorporating HPC into the data-driven learning process, enabling faster and more scalable learning of structured ROMs.",
                "paper-title": "Distributed computing for physics-based data-driven reduced modeling at scale: Application to a rotating detonation rocket engine",
                "image-path": ""
            },

            {
                "startTime": "50:56",
                "arxivId": "2407.10510",
                "arxivLink": "https://arxiv.org/abs/2407.10510",
                "title": "AI Doctor's Prescription: Fine-Tuning LLMs for Herbal Remedies",
                "institute": "Hong Kong University of Science and Technology, Beijing Jiaotong University, Nvidia",
                "text": "This research introduces TCM-FTP, a method that fine-tunes large language models (LLMs) on a new dataset called DigestDS, which contains clinical records from TCM experts specializing in digestive system diseases. This approach differs from previous work by utilizing a low-rank adaptation technique for efficient fine-tuning and incorporating data augmentation through herb permutation.",
                "paper-title": "TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription Prediction",
                "image-path": ""
            },

            {
                "startTime": "51:26",
                "arxivId": "2407.10022",
                "arxivLink": "https://arxiv.org/abs/2407.10022",
                "title": "AI Agents: Building Better Alloys, One Atom at a Time!",
                "institute": "MIT",
                "text": "This research introduces AtomAgents, a multi-agent AI system that combines large language models (LLMs) with physics-based simulations to design alloys. Unlike previous data-driven models, AtomAgents can integrate knowledge from diverse sources and adapt to new challenges.",
                "paper-title": "AtomAgents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence",
                "image-path": ""
            },

            {
                "startTime": "51:47",
                "arxivId": "2407.10481",
                "arxivLink": "https://arxiv.org/abs/2407.10481",
                "title": "SuperPADL: Teaching AI to Dance (and Do Kung Fu!) with Text Commands",
                "institute": "Nvidia",
                "text": "This research introduces SuperPADL, a framework that combines reinforcement learning (RL) and supervised learning to train physics-based animation models on large datasets. Unlike previous work that primarily relied on RL, SuperPADL uses a progressive distillation approach, starting with smaller, specialized controllers and gradually merging them into a single, versatile controller capable of performing thousands of motions.",
                "paper-title": "SuperPADL: Scaling Language-Directed Physics-Based Control with Progressive Supervised Distillation",
                "image-path": ""
            },

            {
                "startTime": "52:20",
                "arxivId": "2407.10935",
                "arxivLink": "https://arxiv.org/abs/2407.10935",
                "title": "Skeleton-Based Action Recognition: Masked Prediction Gets a Contrastive Tune-Up!",
                "institute": "University of Toronto",
                "text": "This research proposes a sequential approach called STARS that combines masked prediction with contrastive learning to improve the performance of skeleton-based action recognition models. Unlike previous work, STARS uses a contrastive tuning stage to enhance the encoder's output representation, leading to better-separated clusters for different actions.",
                "paper-title": "STARS: Self-supervised Tuning for 3D Action Recognition in Skeleton Sequences",
                "image-path": ""
            },

            {
                "startTime": "52:43",
                "arxivId": "2407.10371",
                "arxivLink": "https://arxiv.org/abs/2407.10371",
                "title": "AI's Silent Curriculum: How LLMs Are Shaping Our Kids' Minds",
                "institute": "CMU",
                "text": "This research explores the concept of \"LLM monoculture,\" where the convergence of training data and techniques across different LLMs leads to a uniform perspective, potentially shaping the cultural lens of future generations. This differs from previous work by focusing on the implicit influence of LLMs on children's understanding of the world.",
                "paper-title": "The Silent Curriculum: How Does LLM Monoculture Shape Educational Content and Its Accessibility?",
                "image-path": ""
            },

            {
                "startTime": "53:13",
                "arxivId": "2407.10237",
                "arxivLink": "https://arxiv.org/abs/2407.10237",
                "title": "AI's Carbon Footprint: How Big Is Too Big?",
                "institute": "The University of Tokyo, Fraunhofer Institute for Reliability and Microintegration IZM",
                "text": "This research proposes a life-cycle-based system thinking approach to assess the environmental impact of AI systems, considering both software and hardware components. This differs from previous work that primarily focused on energy efficiency during the model training phase.",
                "paper-title": "Towards Green AI: Current status and future research",
                "image-path": ""
            },

            {
                "startTime": "53:41",
                "arxivId": "2407.10543",
                "arxivLink": "https://arxiv.org/abs/2407.10543",
                "title": "AI's Got a Blind Spot: New Research Reveals How to See What Deep Learning Misses",
                "institute": "UC Berkeley",
                "text": "This research focuses on explaining why a deep learning model might lack confidence in its predictions, going beyond simply identifying uncertainty. It explores five novel methods to pinpoint specific image regions that contribute to this lack of confidence.",
                "paper-title": "Understanding the Dependence of Perception Model Competency on Regions in an Image",
                "image-path": ""
            },

            {
                "startTime": "54:11",
                "arxivId": "2407.09642",
                "arxivLink": "https://arxiv.org/abs/2407.09642",
                "title": "Time Travel for AI: A New Benchmark for Learning from the Past",
                "institute": "MIT, UC Berkeley",
                "text": "This research introduces a new benchmark for evaluating how well machine learning models can learn from a sequence of datasets that change over time. The benchmark allows researchers to construct synthetic sequences of shifts, which can be used to study different types of temporal distribution shift.",
                "paper-title": "Seq-to-Final: A Benchmark for Tuning from Sequential Distributions to a Final Time Point",
                "image-path": ""
            },

            {
                "startTime": "54:35",
                "arxivId": "2407.09926",
                "arxivLink": "https://arxiv.org/abs/2407.09926",
                "title": "CGENNs Get a Makeover: Learning Metrics for Geometric Deep Learning",
                "institute": "University of Cambridge",
                "text": "This research introduces a method for learning the metric within Clifford Group Equivariant Neural Networks (CGENNs). Unlike previous work that relied on fixed, diagonal metrics, this approach allows the network to dynamically adapt its internal geometric representations based on the data.",
                "paper-title": "Metric Learning for Clifford Group Equivariant Neural Networks",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 121,
        "num_total": 525,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202407172112_audio.mp3"
}

daily_data = {
    "date": "2024-09-27",
    "tweets": [
            {
                "startTime": "01:08",
                "arxivId": "2409.17436",
                "arxivLink": "https://arxiv.org/abs/2409.17436",
                "title": "Say Goodbye to Live Experiments: YouTube Music's New User Onboarding Simulation",
                "institute": "Google",
                "text": "This research introduces a simulation methodology for evaluating preference elicitation policies in recommender systems, specifically for onboarding new users. Unlike previous work that primarily focused on algorithm development, this study integrates simulation into production infrastructure, allowing for more realistic evaluation and reducing the need for costly live experiments.",
                "paper-title": "Minimizing Live Experiments in Recommender Systems: User Simulation to Evaluate Preference Elicitation Policies",
                "image-path": "flux_paper_image/2409.17436_1727473963.png"
            },

            {
                "startTime": "01:30",
                "arxivId": "2409.18121",
                "arxivLink": "https://arxiv.org/abs/2409.18121",
                "title": "Robot Learns to Play with Toys by Watching You!",
                "institute": "UC Berkeley",
                "text": "This research proposes a method called Robot See Robot Do (RSRD) that enables robots to learn articulated object manipulation from a single monocular human demonstration. Unlike previous work that relies on extensive training data or specific object categories, RSRD leverages large pretrained vision models and a 4D Differentiable Part Model (4D-DPM) to track object motion from a single video.",
                "paper-title": "Robot See Robot Do: Imitating Articulated Object Manipulation with Monocular 4D Reconstruction",
                "image-path": "flux_paper_image/2409.18121_1727473612.png"
            },

            {
                "startTime": "01:53",
                "arxivId": "2409.17958",
                "arxivLink": "https://arxiv.org/abs/2409.17958",
                "title": "Vision Models: Hard Negatives, Easy Lies?",
                "institute": "University of Washington",
                "text": "This research introduces the concept of \"hard positives\" to evaluate vision-language models' understanding of compositionality. Unlike previous work that focused solely on \"hard negatives,\" this study investigates how models handle semantic-preserving changes in captions.",
                "paper-title": "The Hard Positive Truth about Vision-Language Compositionality",
                "image-path": "flux_paper_image/2409.17958_1727472499.png"
            },

            {
                "startTime": "02:19",
                "arxivId": "2409.17778",
                "arxivLink": "https://arxiv.org/abs/2409.17778",
                "title": "Diffusion Models Get a Speed Boost: Super-Resolution with a Domain Shift",
                "institute": "Advanced Micro Devices, Tsinghua University",
                "text": "This research introduces a novel diffusion equation that incorporates a \"domain shift\" strategy. Unlike previous methods that start from random noise, this approach leverages low-resolution images as the starting point for the diffusion process, significantly improving inference efficiency.",
                "paper-title": "Taming Diffusion Prior for Image Super-Resolution with Domain Shift SDEs",
                "image-path": "flux_paper_image/2409.17778_1727474689.png"
            },

            {
                "startTime": "02:37",
                "arxivId": "2409.17156",
                "arxivLink": "https://arxiv.org/abs/2409.17156",
                "title": "AI Censored My Art? A New Look at Nudity Moderation",
                "institute": "ELLIS Alicante, University of Notre Dame, ETH Zurich",
                "text": "This research focuses on the specific challenge of AI-based content moderation of artistic nudity, going beyond general NSFW classification. It investigates the performance of existing NSFW classifiers on artistic nudity datasets and proposes a multi-modal approach using CLIP to improve accuracy.",
                "paper-title": "An Art-centric perspective on AI-based content moderation of nudity",
                "image-path": "flux_paper_image/2409.17156_1727473051.png"
            },

            {
                "startTime": "02:59",
                "arxivId": "2409.17995",
                "arxivLink": "https://arxiv.org/abs/2409.17995",
                "title": "Diffusion Does Navigation: A New Way to Plan Paths with a Little Noise",
                "institute": "MIT",
                "text": "This paper explores using diffusion models for joint localization and planning in 2D environments. Unlike previous work that focuses on specific tasks like manipulation or path planning, this research combines perception and planning into a single end-to-end system.",
                "paper-title": "Joint Localization and Planning using Diffusion",
                "image-path": "flux_paper_image/2409.17995_1727473268.png"
            },

            {
                "startTime": "03:19",
                "arxivId": "2409.17691",
                "arxivLink": "https://arxiv.org/abs/2409.17691",
                "title": "Training Models Without the Bias Blues: A Hyperparameter-Free Fix for Fairness",
                "institute": "University of Cambridge, Sony",
                "text": "This research proposes a new bias mitigation technique called Targeted Augmentations for Bias Mitigation (TAB). Unlike previous methods, TAB doesn't require group labels during training or validation, making it more practical for real-world scenarios where biases are often unknown.",
                "paper-title": "Efficient Bias Mitigation Without Privileged Information",
                "image-path": "flux_paper_image/2409.17691_1727473989.png"
            },

            {
                "startTime": "03:40",
                "arxivId": "2409.17988",
                "arxivLink": "https://arxiv.org/abs/2409.17988",
                "title": "Blurry Events? No Problem! Deblur e-NeRF Reconstructs Sharp Scenes from Motion-Blurred Event Cameras",
                "institute": "National University of Singapore",
                "text": "This research introduces a novel method, Deblur e-NeRF, that directly reconstructs sharp 3D scenes from motion-blurred events captured by event cameras. Unlike previous work, it incorporates a physically accurate pixel bandwidth model to account for the unique blur characteristics of event cameras.",
                "paper-title": "Deblur e-NeRF: NeRF from Motion-Blurred Events under High-speed or Low-light Conditions",
                "image-path": "flux_paper_image/2409.17988_1727474045.png"
            },

            {
                "startTime": "04:00",
                "arxivId": "2409.18073",
                "arxivLink": "https://arxiv.org/abs/2409.18073",
                "title": "Robots Can Now Read Your Mind (Almost) - New Research Decodes Human Intentions!",
                "institute": "University of Washington, MIT",
                "text": "This research introduces a new framework called FISER, which explicitly models human intentions as intermediate reasoning steps when following natural language instructions. Unlike previous work that focuses on directly mapping language to actions, FISER separates social and embodied reasoning, allowing AI agents to better understand the context and hidden goals behind human requests.",
                "paper-title": "Infer Human's Intentions Before Following Natural Language Instructions",
                "image-path": "flux_paper_image/2409.18073_1727474160.png"
            },

            {
                "startTime": "04:26",
                "arxivId": "2409.17996",
                "arxivLink": "https://arxiv.org/abs/2409.17996",
                "title": "Lensless Cameras Get a Photorealistic Makeover: New Algorithm Blurs the Lines Between Reality and Reconstruction!",
                "institute": "Chinese University of Hong Kong, Tsinghua University, SenseTime",
                "text": "This research introduces a two-stage approach for lensless image reconstruction that combines a spatially varying deconvolution network with a conditional diffusion model. This approach addresses the limitations of previous methods that either struggled with data consistency or photorealism.",
                "paper-title": "PhoCoLens: Photorealistic and Consistent Reconstruction in Lensless Imaging",
                "image-path": "flux_paper_image/2409.17996_1727473513.png"
            },

            {
                "startTime": "04:51",
                "arxivId": "2409.17376",
                "arxivLink": "https://arxiv.org/abs/2409.17376",
                "title": "Lens-ing Trouble: How a Tiny Lens Can Trick Self-Driving Cars",
                "institute": "Michigan State University, Peking University",
                "text": "This research introduces a novel physical attack, called LensAttack, that uses optical lenses to manipulate the depth perception of monocular depth estimation (MDE) algorithms used in autonomous driving systems. Unlike previous digital attacks, LensAttack operates in the physical world, making it more realistic and impactful.",
                "paper-title": "Optical Lens Attack on Deep Learning Based Monocular Depth Estimation",
                "image-path": "flux_paper_image/2409.17376_1727472872.png"
            },

            {
                "startTime": "05:16",
                "arxivId": "2409.17487",
                "arxivLink": "https://arxiv.org/abs/2409.17487",
                "title": "Diffusion Models: Traffic Lights for Faster Image Generation!",
                "institute": "Peking University, Huawei",
                "text": "This paper proposes a novel approach to accelerate diffusion models by introducing adaptive conditions, which are learned quantized representations of the input image. This method differs from previous work by avoiding trajectory relocation and additional regularization terms, leading to a more efficient and effective training process.",
                "paper-title": "Learning Quantized Adaptive Conditions for Diffusion Models",
                "image-path": "flux_paper_image/2409.17487_1727472797.png"
            },

            {
                "startTime": "05:40",
                "arxivId": "2409.18128",
                "arxivLink": "https://arxiv.org/abs/2409.18128",
                "title": "FlowTurbo: Speeding Up Image Generation with a Velocity Refresher!",
                "institute": "Tsinghua University",
                "text": "This research proposes FlowTurbo, a framework that accelerates the sampling process of flow-based generative models by learning a lightweight velocity refiner. Unlike previous one-step distillation methods, FlowTurbo preserves the multi-step sampling paradigm, allowing it to be applied to various tasks such as image editing and inpainting.",
                "paper-title": "FlowTurbo: Towards Real-time Flow-Based Image Generation with Velocity Refiner",
                "image-path": "flux_paper_image/2409.18128_1727473110.png"
            },

            {
                "startTime": "06:02",
                "arxivId": "2409.18127",
                "arxivLink": "https://arxiv.org/abs/2409.18127",
                "title": "EgoLM: Giving AI a Body and a Brain, One Motion at a Time!",
                "institute": "Meta, Nanyang Technological University, University of Tuebingen",
                "text": "This research proposes EgoLM, a multi-modal language model that unifies egocentric motion tracking and understanding. Unlike previous work, EgoLM incorporates multiple modalities, including sparse motion sensor data and egocentric videos, to provide richer context for motion learning.",
                "paper-title": "EgoLM: Multi-Modal Language Model of Egocentric Motions",
                "image-path": "flux_paper_image/2409.18127_1727472764.png"
            },

            {
                "startTime": "06:24",
                "arxivId": "2409.17808",
                "arxivLink": "https://arxiv.org/abs/2409.17808",
                "title": "Molecular Movies: Deep Learning Makes MD Simulations a Breeze!",
                "institute": "MIT",
                "text": "This research introduces a new paradigm for learning surrogate models of molecular dynamics (MD) by directly modeling full trajectories as time-series of 3D molecular structures. Unlike previous work that focuses on learning the transition density or equilibrium distribution, this approach leverages the rich dynamical information in MD training data, enabling a wider range of applications.",
                "paper-title": "Generative Modeling of Molecular Dynamics Trajectories",
                "image-path": "flux_paper_image/2409.17808_1727473490.png"
            },

            {
                "startTime": "07:06",
                "arxivId": "2409.17490",
                "arxivLink": "https://arxiv.org/abs/2409.17490",
                "title": "MathDSL: Solving Equations with Style (and Less Work!)",
                "institute": "MIT",
                "text": "This research introduces MathDSL, a Domain-Specific Language (DSL) designed for solving linear equations. Unlike previous methods that rely on reinforcement learning, MathDSL uses program synthesis to generate solutions.",
                "paper-title": "MathDSL: A Domain-Specific Language for Concise Mathematical Solutions Via Program Synthesis",
                "image-path": "flux_paper_image/2409.17490_1727473233.png"
            },

            {
                "startTime": "07:28",
                "arxivId": "2409.17643",
                "arxivLink": "https://arxiv.org/abs/2409.17643",
                "title": "Fairness vs. Performance: A New Way to Find the Sweet Spot",
                "institute": "Technion - Israel Institute of Technology, NVIDIA",
                "text": "This paper proposes a method to compute the optimal Pareto front for fairness and performance in representation learning without training complex models. It leverages structural properties of optimal fair representations to reduce the computation to a compact discrete problem.",
                "paper-title": "Efficient Fairness-Performance Pareto Front Computation",
                "image-path": "flux_paper_image/2409.17643_1727473437.png"
            },

            {
                "startTime": "07:49",
                "arxivId": "2409.17481",
                "arxivLink": "https://arxiv.org/abs/2409.17481",
                "title": "LLMs on a Diet: Learnable Sparsity Makes Big Models Slim and Smart",
                "institute": "National University of Singapore, Nvidia",
                "text": "This research introduces MaskLLM, a method that learns to prune large language models (LLMs) by introducing semi-structured sparsity. Unlike previous methods that rely on handcrafted importance criteria, MaskLLM models the sparsity pattern as a learnable distribution, allowing for end-to-end training on large datasets.",
                "paper-title": "MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models",
                "image-path": "flux_paper_image/2409.17481_1727473282.png"
            },

            {
                "startTime": "08:15",
                "arxivId": "2409.18114",
                "arxivLink": "https://arxiv.org/abs/2409.18114",
                "title": "Meshing with Magic: A New Auto-Encoder for Artistic 3D Generation",
                "institute": "Peking University, NVIDIA Research",
                "text": "This paper introduces a novel mesh tokenization algorithm that compresses triangular meshes into 1D token sequences, significantly enhancing training efficiency. It also proposes an Auto-regressive Auto-encoder (ArAE) model that compresses variable-length triangular meshes into fixed-length latent codes, enabling training latent diffusion models for better generalization.",
                "paper-title": "EdgeRunner: Auto-regressive Auto-encoder for Artistic Mesh Generation",
                "image-path": "flux_paper_image/2409.18114_1727473402.png"
            },

            {
                "startTime": "08:36",
                "arxivId": "2409.17652",
                "arxivLink": "https://arxiv.org/abs/2409.17652",
                "title": "Simulations on Demand: LLMs Build Games and Robots from Scratch!",
                "institute": "Stanford University",
                "text": "This research introduces FACTORSIM, a framework that generates full simulations in code from language input. Unlike previous work that focuses on generating specific components of simulations, FACTORSIM generates the entire simulation, including the dynamics, reward functions, and even the user interface.",
                "paper-title": "FactorSim: Generative Simulation via Factorized Representation",
                "image-path": "flux_paper_image/2409.17652_1727472598.png"
            },

            {
                "startTime": "09:03",
                "arxivId": "2409.17924",
                "arxivLink": "https://arxiv.org/abs/2409.17924",
                "title": "Panoramic Photos Get a Neural Makeover: Stitching and Viewing Made Easy!",
                "institute": "Princeton University, Google Inc.",
                "text": "This research introduces a neural light sphere model for panoramic image stitching and view synthesis. Unlike previous methods that rely on volumetric representations, this approach uses a compact spherical representation, decomposing the scene into view-dependent ray offset and color components.",
                "paper-title": "Neural Light Spheres for Implicit Image Stitching and View Synthesis",
                "image-path": "flux_paper_image/2409.17924_1727473349.png"
            },

            {
                "startTime": "09:19",
                "arxivId": "2409.17285",
                "arxivLink": "https://arxiv.org/abs/2409.17285",
                "title": "SpoofCeleb: Deepfakes Go Wild, But Can We Tell?",
                "institute": "Carnegie Mellon University, Renmin University of China, National Institute of Informatics...",
                "text": "This research introduces SpoofCeleb, a dataset for Speech Deepfake Detection (SDD) and Spoofing-robust Automatic Speaker Verification (SASV) that utilizes real-world, noisy speech data, unlike previous datasets that primarily used clean, studio-quality recordings.",
                "paper-title": "SpoofCeleb: Speech Deepfake Detection and SASV In The Wild",
                "image-path": "flux_paper_image/2409.17285_1727473556.png"
            },

            {
                "startTime": "09:40",
                "arxivId": "2409.17189",
                "arxivLink": "https://arxiv.org/abs/2409.17189",
                "title": "Federated Learning Goes Viral: New Algorithm Makes Agents Chatty and Efficient!",
                "institute": "Arizona State University, Princeton University",
                "text": "This research proposes a new decentralized federated learning algorithm called DSGTm-TV that incorporates gradient tracking and heavy-ball momentum to improve convergence in time-varying directed networks. Unlike previous work, this algorithm allows for uncoordinated stepsizes and momentum parameters, making it more adaptable to heterogeneous network settings.",
                "paper-title": "Decentralized Federated Learning with Gradient Tracking over Time-Varying Directed Networks",
                "image-path": "flux_paper_image/2409.17189_1727473067.png"
            },

            {
                "startTime": "10:01",
                "arxivId": "2409.17659",
                "arxivLink": "https://arxiv.org/abs/2409.17659",
                "title": "Autonomous Driving Gets a Bird's-Eye View: DRL Meets BEV for Safer Roads!",
                "institute": "Tsinghua University, Central South University",
                "text": "This research integrates Bird's-Eye-View (BEV) perception with Deep Reinforcement Learning (DRL) for autonomous driving, bridging the gap between feature extraction and perception. Unlike previous DRL approaches, this method maps the feature extraction network directly to the perception phase, enabling clearer interpretation through semantic segmentation.",
                "paper-title": "Hierarchical End-to-End Autonomous Driving: Integrating BEV Perception with Deep Reinforcement Learning",
                "image-path": "flux_paper_image/2409.17659_1727473261.png"
            },

            {
                "startTime": "10:22",
                "arxivId": "2409.18026",
                "arxivLink": "https://arxiv.org/abs/2409.18026",
                "title": "Occupancy Networks: Seeing is Believing, But Can We Trust It?",
                "institute": "Zhejiang University, Huawei Noah\u2019s Ark Lab, Udeer.ai",
                "text": "This research focuses on the reliability of semantic occupancy prediction models, particularly those using cameras. It introduces a new method called RELIOCC that enhances reliability by incorporating both individual and relative voxel uncertainties.",
                "paper-title": "ReliOcc: Towards Reliable Semantic Occupancy Prediction via Uncertainty Learning",
                "image-path": "flux_paper_image/2409.18026_1727474572.png"
            },

            {
                "startTime": "10:48",
                "arxivId": "2409.17991",
                "arxivLink": "https://arxiv.org/abs/2409.17991",
                "title": "Neural Networks: Breaking the Curse of Dimensionality, One Smooth Boundary at a Time!",
                "institute": "University of Oxford, University of Vienna, Vienna University of Technology",
                "text": "This research focuses on approximating and estimating classification functions with decision boundaries defined by RBV2 functions, a class of functions that can be approximated without the curse of dimensionality. This differs from previous work that focused on Barron functions or imposed different assumptions on the boundaries.",
                "paper-title": "Dimension-independent learning rates for high-dimensional classification problems",
                "image-path": "flux_paper_image/2409.17991_1727474109.png"
            },

            {
                "startTime": "11:12",
                "arxivId": "2409.17505",
                "arxivLink": "https://arxiv.org/abs/2409.17505",
                "title": "Unnormalized Densities Get a Sequential Makeover: Kernel Stein Discrepancy Goes Anytime!",
                "institute": "CMU",
                "text": "This research introduces a sequential version of the kernelized Stein discrepancy (KSD) for goodness-of-fit tests. Unlike previous work, it does not require the Stein kernel to be uniformly bounded, instead exploiting potential boundedness at specific points.",
                "paper-title": "Sequential Kernelized Stein Discrepancy",
                "image-path": "flux_paper_image/2409.17505_1727473388.png"
            },

            {
                "startTime": "11:33",
                "arxivId": "2409.17917",
                "arxivLink": "https://arxiv.org/abs/2409.17917",
                "title": "3D Style Transfer: It's Not Just About the Colors, It's About the Shapes!",
                "institute": "Meta, Texas A&M University, LMU Munich",
                "text": "This research introduces a novel method for 3D scene stylization that directly matches the distributions of Gaussians between style and content scenes using the Earth Mover's Distance (EMD). This approach differs from previous work by focusing on geometric stylization rather than just texture transfer.",
                "paper-title": "WaSt-3D: Wasserstein-2 Distance for Scene-to-Scene Stylization on 3D Gaussians",
                "image-path": "flux_paper_image/2409.17917_1727473893.png"
            },

            {
                "startTime": "11:59",
                "arxivId": "2409.18014",
                "arxivLink": "https://arxiv.org/abs/2409.18014",
                "title": "LLMs on a Mission: Role-RL Makes Them Work Together!",
                "institute": "South China Normal University, University of Toronto",
                "text": "This research introduces a new paradigm called Online Long-context Processing (OLP) for handling streaming media transcripts of unlimited length. It also proposes a novel Role Reinforcement Learning (Role-RL) framework to automatically assign different LLMs to their optimal roles within the OLP pipeline based on their performance. This approach differs from previous work by focusing on real-time processing of long contexts and dynamically optimizing LLM deployment for improved efficiency and accuracy.",
                "paper-title": "Role-RL: Online Long-Context Processing with Role Reinforcement Learning for Distinct LLMs in Their Optimal Roles",
                "image-path": "flux_paper_image/2409.18014_1727472494.png"
            },

            {
                "startTime": "12:25",
                "arxivId": "2409.17448",
                "arxivLink": "https://arxiv.org/abs/2409.17448",
                "title": "Financial Sentiment Analysis: Numbers Talk, LLMs Listen!",
                "institute": "National Institute of Advanced Industrial Science and Technology, Ochanomizu University, University of Tokyo",
                "text": "This research explores the impact of expert-designed hints on the performance of large language models (LLMs) in financial sentiment analysis. Unlike previous studies that focused on extracting numerical information or analyzing the role of numbers in financial documents, this paper investigates whether LLMs can inherently recognize and utilize these hints without explicit guidance.",
                "paper-title": "Enhancing Financial Sentiment Analysis with Expert-Designed Hint",
                "image-path": "flux_paper_image/2409.17448_1727473104.png"
            },

            {
                "startTime": "12:48",
                "arxivId": "2409.17417",
                "arxivLink": "https://arxiv.org/abs/2409.17417",
                "title": "Investing Like a Pro: New AI Uncovers Hidden Gems in Online Opinions",
                "institute": "Academia Sinica, National Taiwan University, National Institute of Advanced Industrial Science and Technology...",
                "text": "This research introduces a novel approach to analyzing investment opinions by incorporating argument mining techniques. Unlike previous work that focused on author-centric analysis or simple content analysis, this study delves into the structure of arguments within opinions, examining the relationship between claims and premises to determine their strength and potential profitability.",
                "paper-title": "Enhancing Investment Opinion Ranking through Argument-Based Sentiment Analysis",
                "image-path": "flux_paper_image/2409.17417_1727472753.png"
            },

            {
                "startTime": "13:12",
                "arxivId": "2409.17622",
                "arxivLink": "https://arxiv.org/abs/2409.17622",
                "title": "Neural P3M: Meshing Up Molecular Geometry for Long-Range Love!",
                "institute": "Xi\u2019an Jiaotong University, University of Illinois, Chinese University of Hong Kong...",
                "text": "This paper introduces Neural P3M, a framework that enhances geometric GNNs by incorporating mesh points alongside atoms. This allows for the modeling of long-range interactions, which are often overlooked in traditional GNNs.",
                "paper-title": "Neural P$^3$M: A Long-Range Interaction Modeling Enhancer for Geometric GNNs",
                "image-path": "flux_paper_image/2409.17622_1727473640.png"
            },

            {
                "startTime": "13:39",
                "arxivId": "2409.17642",
                "arxivLink": "https://arxiv.org/abs/2409.17642",
                "title": "AI Delegates: The Privacy-Conscious Chatbots That Know When to Spill the Beans",
                "institute": "Beijing Institute for General Artificial Intelligence (BIGAI), Microsoft, Beijing Normal University",
                "text": "This research focuses on AI delegates that can strategically self-disclose private information to achieve social goals, unlike previous work that primarily focused on minimizing privacy leaks.",
                "paper-title": "AI Delegates with a Dual Focus: Ensuring Privacy and Strategic Self-Disclosure",
                "image-path": "flux_paper_image/2409.17642_1727474219.png"
            },

            {
                "startTime": "14:02",
                "arxivId": "2409.17287",
                "arxivLink": "https://arxiv.org/abs/2409.17287",
                "title": "Blockchain-Enabled Data Diet: How to Slim Down Your Car's Data Without Starving It!",
                "institute": "Jiangnan University, Tsinghua University, Shanghai Jiao Tong University...",
                "text": "This research combines blockchain technology with the Variational Information Bottleneck (VIB) method to address the computational burden and security concerns in vehicle-to-vehicle networks. Unlike previous work that focused on either blockchain or VIB separately, this paper proposes a novel approach that integrates both technologies to achieve a more efficient and secure data transmission system.",
                "paper-title": "Blockchain-Enabled Variational Information Bottleneck for Data Extraction Based on Mutual Information in Internet of Vehicles",
                "image-path": "flux_paper_image/2409.17287_1727474059.png"
            },

            {
                "startTime": "14:24",
                "arxivId": "2409.17446",
                "arxivLink": "https://arxiv.org/abs/2409.17446",
                "title": "FedAWE: Federated Learning's New Trick to Handle Flaky Clients",
                "institute": "CMU",
                "text": "This research tackles the problem of clients dropping in and out of federated learning systems, which is a common issue in real-world deployments. Unlike previous work that either assumes perfect knowledge of client availability or requires significant memory overhead, this paper proposes a new algorithm, FedAWE, that handles both heterogeneous and non-stationary client availability with minimal additional memory and computation.",
                "paper-title": "Efficient Federated Learning against Heterogeneous and Non-stationary Client Unavailability",
                "image-path": "flux_paper_image/2409.17446_1727472973.png"
            },

            {
                "startTime": "14:47",
                "arxivId": "2409.18051",
                "arxivLink": "https://arxiv.org/abs/2409.18051",
                "title": "IRL with Multiple Planning Horizons: When Robots Get Short-Term Memory",
                "institute": "UC San Francisco, Harvard University, Stanford University",
                "text": "This research focuses on inverse reinforcement learning (IRL) where experts share a common reward function but have different, unknown planning horizons. This is different from previous work that assumes a single planning horizon or that experts optimize for different reward functions.",
                "paper-title": "Inverse Reinforcement Learning with Multiple Planning Horizons",
                "image-path": "flux_paper_image/2409.18051_1727473410.png"
            },

            {
                "startTime": "15:10",
                "arxivId": "2409.17216",
                "arxivLink": "https://arxiv.org/abs/2409.17216",
                "title": "AI Regulation: It's Not Just About Big Models, It's About Big Data!",
                "institute": "University of California Berkeley, OpenAI, Meta...",
                "text": "This research argues that current AI governance efforts are too focused on the size of models and not enough on the data they are trained on. It suggests that smaller models can be just as capable as larger ones if they are trained on the right data.",
                "paper-title": "Data-Centric AI Governance: Addressing the Limitations of Model-Focused Policies",
                "image-path": "flux_paper_image/2409.17216_1727474305.png"
            },

            {
                "startTime": "15:35",
                "arxivId": "2409.17486",
                "arxivLink": "https://arxiv.org/abs/2409.17486",
                "title": "Global-Local Love: A New Way to Fine-Tune AI for Medical Images",
                "institute": "Liaoning Technical University, Northeastern University, China Medical University",
                "text": "This research introduces a novel approach called Global-Local Medical SAM Adaptor (GLMed-SA) that combines two techniques: full adaption (GMed-SA) and partial adaption (Med-SA). This allows for a more comprehensive fine-tuning of the Segment Anything Model (SAM) for medical image segmentation.",
                "paper-title": "Global-Local Medical SAM Adaptor Based on Full Adaption",
                "image-path": "flux_paper_image/2409.17486_1727472785.png"
            },

            {
                "startTime": "15:56",
                "arxivId": "2409.18119",
                "arxivLink": "https://arxiv.org/abs/2409.18119",
                "title": "Mammograms Get a Language Lesson: New AI Learns to \"Read\" Breast Images",
                "institute": "Yale University",
                "text": "This research adapts the CLIP model for mammography, a modality with limited labeled data and high-resolution images. It introduces a multi-view contrastive learning framework that leverages the multi-view nature of mammograms and aligns image-image and image-text features.",
                "paper-title": "Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography",
                "image-path": "flux_paper_image/2409.18119_1727472718.png"
            },

            {
                "startTime": "16:18",
                "arxivId": "2409.17610",
                "arxivLink": "https://arxiv.org/abs/2409.17610",
                "title": "Doctor's Orders: AI Learns to See What Matters in Patient Photos",
                "institute": "Tsinghua University",
                "text": "This research focuses on improving vision-language alignment in multi-turn multimodal medical dialogues, a scenario where patients send images and text to doctors in multiple rounds of interaction. Unlike previous work that focuses on single-turn or stitched multi-turn dialogues, this study leverages the preceding text conversations to infer the regions of interest (RoIs) in the image, effectively enhancing the model's understanding of the visual content.",
                "paper-title": "ZALM3: Zero-Shot Enhancement of Vision-Language Alignment via In-Context Information in Multi-Turn Multimodal Medical Dialogue",
                "image-path": "flux_paper_image/2409.17610_1727473709.png"
            },

            {
                "startTime": "16:48",
                "arxivId": "2409.17677",
                "arxivLink": "https://arxiv.org/abs/2409.17677",
                "title": "Transformers: Memory Masters, But Feedforward's the Bottleneck!",
                "institute": "University of Tokyo",
                "text": "This paper analyzes the memorization capacity of Transformers, focusing on the efficiency of parameter usage. Unlike previous work, it establishes both upper and lower bounds on the number of parameters needed for memorization in both next-token prediction and sequence-to-sequence settings.",
                "paper-title": "Optimal Memorization Capacity of Transformers",
                "image-path": "flux_paper_image/2409.17677_1727472581.png"
            },

            {
                "startTime": "17:08",
                "arxivId": "2409.17527",
                "arxivLink": "https://arxiv.org/abs/2409.17527",
                "title": "LLMs: Unlocking the Secret Recipe of Their Data Diet!",
                "institute": "Peking University, Beijing University of Posts and Telecommunications",
                "text": "This research introduces a new concept called \"data proportion detection,\" which aims to estimate the proportions of different types of data used to train a large language model (LLM) without access to the original training data. This differs from previous work that focuses on analyzing the model's performance or internal representations to understand its training data.",
                "paper-title": "Data Proportion Detection for Optimized Data Management for Large Language Models",
                "image-path": "flux_paper_image/2409.17527_1727473178.png"
            },

            {
                "startTime": "17:31",
                "arxivId": "2409.17625",
                "arxivLink": "https://arxiv.org/abs/2409.17625",
                "title": "Attention, Please! Transformers Can Overfit...But It Might Be a Good Thing!",
                "institute": "University of Tokyo",
                "text": "This paper analyzes benign overfitting in the token selection mechanism of attention architectures, a core component of transformer models. Unlike previous work that focused on linear models or two-layer neural networks, this study delves into the unique challenges of understanding overfitting in the context of attention.",
                "paper-title": "Benign or Not-Benign Overfitting in Token Selection of Attention Mechanism",
                "image-path": "flux_paper_image/2409.17625_1727474277.png"
            },

            {
                "startTime": "17:53",
                "arxivId": "2409.17582",
                "arxivLink": "https://arxiv.org/abs/2409.17582",
                "title": "Logit Adjustment Gets a Theoretical Makeover: Neural Collapse Makes Long-Tailed Recognition Easier!",
                "institute": "University of Tokyo",
                "text": "This research provides a theoretical justification for the effectiveness of multiplicative logit adjustment (MLA) in long-tailed recognition (LTR) by connecting it to the concept of neural collapse (NC). Unlike previous work, this paper demonstrates that MLA approximates an optimal decision boundary adjustment method derived from NC.",
                "paper-title": "Multiplicative Logit Adjustment Approximates Neural-Collapse-Aware Decision Boundary Adjustment",
                "image-path": "flux_paper_image/2409.17582_1727473682.png"
            },

            {
                "startTime": "18:19",
                "arxivId": "2409.17320",
                "arxivLink": "https://arxiv.org/abs/2409.17320",
                "title": "Learning to Optimize: A Multi-Block ADMM That's Not Afraid to Learn!",
                "institute": "National University of Singapore, University of Maryland",
                "text": "This research focuses on applying Learning to Optimize (L2O) techniques to a specific type of multi-block ADMM method called MPALM. Unlike previous L2O work that primarily focused on two-block ADMM, this paper explores the application of L2O to a more complex multi-block setting.",
                "paper-title": "Accelerating Multi-Block Constrained Optimization Through Learning to Optimize",
                "image-path": "flux_paper_image/2409.17320_1727473365.png"
            },

            {
                "startTime": "18:38",
                "arxivId": "2409.17858",
                "arxivLink": "https://arxiv.org/abs/2409.17858",
                "title": "Neural Networks: Learning to Learn, Faster!",
                "institute": "Google, University of California Berkeley, Sloan Foundation...",
                "text": "This paper introduces a solvable model of neural scaling laws that incorporates feature learning, going beyond the kernel limit. It identifies three scaling regimes based on task difficulty and shows that feature learning can improve scaling exponents for hard tasks, but not for easy or super-easy tasks.",
                "paper-title": "How Feature Learning Can Improve Neural Scaling Laws",
                "image-path": "flux_paper_image/2409.17858_1727472807.png"
            },

            {
                "startTime": "18:53",
                "arxivId": "2409.17500",
                "arxivLink": "https://arxiv.org/abs/2409.17500",
                "title": "Neural Networks Get a Constraint Makeover: GLinSAT Makes Them Play by the Rules!",
                "institute": "Tsinghua University, Alibaba",
                "text": "This research introduces GLinSAT, a new neural network layer that can handle general linear constraints on outputs. Unlike previous methods that rely on matrix factorization or black-box solvers, GLinSAT uses an accelerated gradient descent algorithm, making it more efficient and GPU-friendly.",
                "paper-title": "GLinSAT: The General Linear Satisfiability Neural Network Layer By Accelerated Gradient Descent",
                "image-path": "flux_paper_image/2409.17500_1727472619.png"
            },

            {
                "startTime": "19:21",
                "arxivId": "2409.18057",
                "arxivLink": "https://arxiv.org/abs/2409.18057",
                "title": "LightAvatar: Neural Light Fields Make Head Avatars Super Speedy!",
                "institute": "Google, Northeastern University, Simon Fraser University",
                "text": "This research introduces LightAvatar, a head avatar model that uses neural light fields (NeLFs) instead of the more common neural radiance fields (NeRFs). This approach allows for faster rendering speeds because it requires only a single network forward pass, unlike NeRFs which require multiple passes.",
                "paper-title": "LightAvatar: Efficient Head Avatar as Dynamic Neural Light Field",
                "image-path": "flux_paper_image/2409.18057_1727474526.png"
            },

            {
                "startTime": "19:43",
                "arxivId": "2409.17567",
                "arxivLink": "https://arxiv.org/abs/2409.17567",
                "title": "Derandomizing Multi-Distribution Learning: Can We Ditch the Dice?",
                "institute": "Aarhus University, Yale University, UC Berkeley",
                "text": "This paper explores the computational complexity of derandomizing multi-distribution learning algorithms, which are used to train models that perform well across multiple datasets. Unlike previous work that outputs randomized predictors, this research investigates the possibility of producing deterministic predictors.",
                "paper-title": "Derandomizing Multi-Distribution Learning",
                "image-path": "flux_paper_image/2409.17567_1727473455.png"
            },

            {
                "startTime": "20:07",
                "arxivId": "2409.17909",
                "arxivLink": "https://arxiv.org/abs/2409.17909",
                "title": "Graphing Your Way to Better SME Credit Scores: A Neural Network Revolution",
                "institute": "University of California Irvine, New York University, Trine University...",
                "text": "This research uses a graph neural network (GNN) to model the relationships between financial indicators for SMEs, going beyond traditional methods that rely on isolated feature analysis.",
                "paper-title": "Unveiling the Potential of Graph Neural Networks in SME Credit Risk Assessment",
                "image-path": "flux_paper_image/2409.17909_1727472791.png"
            },

            {
                "startTime": "20:32",
                "arxivId": "2409.17655",
                "arxivLink": "https://arxiv.org/abs/2409.17655",
                "title": "Office Assistant Bot: LLM-Powered, Proactive, and (Almost) Human-Like!",
                "institute": "Tsinghua University",
                "text": "This research introduces AssistantX, an LLM-powered robot assistant that operates in a physical office environment. Unlike previous service robots, AssistantX utilizes a multi-agent architecture called PPDR4X, which enables it to reason logically and collaborate with humans to complete tasks.",
                "paper-title": "AssistantX: An LLM-Powered Proactive Assistant in Collaborative Human-Populated Environment",
                "image-path": "flux_paper_image/2409.17655_1727473090.png"
            },

            {
                "startTime": "20:55",
                "arxivId": "2409.17502",
                "arxivLink": "https://arxiv.org/abs/2409.17502",
                "title": "Tensor Multiplication Gets a Shape-Shifting Makeover!",
                "institute": "University of Tokyo, Nagoya Institute of Technology",
                "text": "This paper introduces a new operator called the \"broadcast product\" that extends the Hadamard product by aligning the shapes of tensors before performing element-wise multiplication. This addresses the issue of inconsistent mathematical descriptions of broadcast operations in libraries like NumPy.",
                "paper-title": "Broadcast Product: Shape-aligned Element-wise Multiplication and Beyond",
                "image-path": "flux_paper_image/2409.17502_1727472834.png"
            },

            {
                "startTime": "21:16",
                "arxivId": "2409.17954",
                "arxivLink": "https://arxiv.org/abs/2409.17954",
                "title": "Big Brains, Tiny Clues: How Attention Differences Help Language Models Learn Faster",
                "institute": "Tsinghua University",
                "text": "This research proposes a novel method for enhancing knowledge learning in language models by contrasting the attention patterns of large and small models. Unlike previous work that focuses on knowledge distillation from large models to smaller ones, this approach leverages the attention differences to identify elusive clues in text and uses them to guide data augmentation.",
                "paper-title": "Enhancing elusive clues in knowledge learning by contrasting attention of language models",
                "image-path": "flux_paper_image/2409.17954_1727472684.png"
            },

            {
                "startTime": "21:35",
                "arxivId": "2409.18104",
                "arxivLink": "https://arxiv.org/abs/2409.18104",
                "title": "Finding Rhinos Without Finding Rhinos: A New Way to Track Endangered Species",
                "institute": "Harvard University, MIT, University of Michigan",
                "text": "This research introduces a novel approach to tracking rhinos by mapping their communal defecation sites, called middens, using remotely sensed imagery. This method differs from previous work that focused on directly tracking rhinos, which can be challenging due to their elusive nature.",
                "paper-title": "Find Rhinos without Finding Rhinos: Active Learning with Multimodal Imagery of South African Rhino Habitats",
                "image-path": "flux_paper_image/2409.18104_1727472643.png"
            },

            {
                "startTime": "21:59",
                "arxivId": "2409.17604",
                "arxivLink": "https://arxiv.org/abs/2409.17604",
                "title": "RmGPT: The AI That's Got Your Machinery's Back!",
                "institute": "Shanghai Jiao Tong University, Polytechnic University of Milan, Tsinghua University",
                "text": "This research proposes RmGPT, a unified model for diagnosis and prognosis tasks in rotating machinery. Unlike previous work that relies on task-specific models, RmGPT uses a single set of parameters to handle diverse datasets with varying signal characteristics, fault modes, and operating conditions.",
                "paper-title": "RmGPT: Rotating Machinery Generative Pretrained Model",
                "image-path": "flux_paper_image/2409.17604_1727474344.png"
            },

            {
                "startTime": "22:29",
                "arxivId": "2409.17972",
                "arxivLink": "https://arxiv.org/abs/2409.17972",
                "title": "LLMs Get Math-Savvy: New Technique Makes AI Smarter Than GPT-4!",
                "institute": "Chinese Academy of Sciences, Peking University",
                "text": "This research introduces a novel approach called BEATS, which uses a pruning tree search to enhance the mathematical problem-solving abilities of LLMs. Unlike previous methods that rely on supervised fine-tuning or complex search algorithms, BEATS focuses on carefully designed prompts and a back-verification technique to improve accuracy and efficiency.",
                "paper-title": "BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search",
                "image-path": "flux_paper_image/2409.17972_1727472817.png"
            },

            {
                "startTime": "22:59",
                "arxivId": "2409.18061",
                "arxivLink": "https://arxiv.org/abs/2409.18061",
                "title": "Forgetful AI Gets a Memory Boost: Optimal Training Protocols for Continual Learning",
                "institute": "University of Oxford, Chalmers University of Technology, University of Gothenburg...",
                "text": "This research differs from previous work by applying optimal control theory to the training dynamics of neural networks in a continual learning setting. It uses statistical physics techniques to reduce the dimensionality of the problem, allowing for the derivation of closed-form formulae for optimal task-selection protocols and learning rate schedules.",
                "paper-title": "Optimal Protocols for Continual Learning via Statistical Physics and Control Theory",
                "image-path": "flux_paper_image/2409.18061_1727473005.png"
            },

            {
                "startTime": "23:27",
                "arxivId": "2409.17508",
                "arxivLink": "https://arxiv.org/abs/2409.17508",
                "title": "Uni-Med: A Medical AI That's Got All the Answers (and Images!)",
                "institute": "Tsinghua University, Beijing University of Posts and Telecommunications",
                "text": "This research focuses on improving the \"connector\" in multi-modal medical AI models, which bridges the gap between visual and textual information. Unlike previous work that primarily focused on the language model component, this paper introduces a novel approach called Connector-MoE (CMoE) to enhance the connector's ability to handle diverse medical tasks.",
                "paper-title": "Uni-Med: A Unified Medical Generalist Foundation Model For Multi-Task Learning Via Connector-MoE",
                "image-path": "flux_paper_image/2409.17508_1727473518.png"
            },

            {
                "startTime": "23:49",
                "arxivId": "2409.17345",
                "arxivLink": "https://arxiv.org/abs/2409.17345",
                "title": "SeaSplat: Underwater Scenes Get a Color Makeover with 3D Gaussians!",
                "institute": "MIT, Woods Hole Oceanographic Institution",
                "text": "This research introduces SeaSplat, a method that combines 3D Gaussian Splatting with a physically grounded underwater image formation model. Unlike previous methods that rely on dense sampling or per-viewing direction estimation, SeaSplat learns global medium parameters, enabling efficient real-time rendering.",
                "paper-title": "SeaSplat: Representing Underwater Scenes with 3D Gaussian Splatting and a Physically Grounded Image Formation Model",
                "image-path": "flux_paper_image/2409.17345_1727474443.png"
            },

            {
                "startTime": "24:17",
                "arxivId": "2409.17264",
                "arxivLink": "https://arxiv.org/abs/2409.17264",
                "title": "Serving Up 10 Million Tokens: How Researchers Made LLMs Eat Their Words (and Still Be Fast)",
                "institute": "Georgia Institute of Technology, Microsoft",
                "text": "This research introduces a novel 3D parallelism strategy for long-context LLM inference, combining sequence pipeline parallelism (SPP), KV parallelism (KVP), and tensor parallelism (TP). This approach differs from previous work by enabling efficient prefill and decode phases for context lengths up to 10 million tokens, a significant leap compared to existing systems that typically handle up to 1 million tokens.",
                "paper-title": "Mnemosyne: Parallelization Strategies for Efficiently Serving Multi-Million Context Length LLM Inference Requests Without Approximations",
                "image-path": "flux_paper_image/2409.17264_1727474430.png"
            },

            {
                "startTime": "24:45",
                "arxivId": "2409.17348",
                "arxivLink": "https://arxiv.org/abs/2409.17348",
                "title": "AI Teams Learn to Talk Like Humans, But Can They Work Together?",
                "institute": "University of Pittsburgh, Honda Research Institute, CMU",
                "text": "This research introduces a novel computational pipeline that aligns the communication space of multi-agent reinforcement learning (MARL) agents with human natural language. It does this by grounding agent communications on synthetic data generated by embodied large language models (LLMs) in interactive teamwork scenarios. This approach differs from previous work by explicitly incorporating human language into the training process, aiming to create more interpretable and generalizable communication protocols.",
                "paper-title": "Language Grounded Multi-agent Communication for Ad-hoc Teamwork",
                "image-path": "flux_paper_image/2409.17348_1727472866.png"
            },

            {
                "startTime": "25:11",
                "arxivId": "2409.17946",
                "arxivLink": "https://arxiv.org/abs/2409.17946",
                "title": "Backdoor Attacks: LLMs Get Schooled by Tiny Teacher Models!",
                "institute": "Nanyang Technological University",
                "text": "This research explores the effectiveness of backdoor attacks targeting parameter-efficient fine-tuning (PEFT) algorithms for LLMs. It proposes a novel method called W2SAttack, which uses contrastive knowledge distillation to transfer backdoor features from a small-scale poisoned teacher model to a large-scale student model. This approach aims to enhance the effectiveness of backdoor attacks while minimizing computational resource consumption.",
                "paper-title": "Weak-To-Strong Backdoor Attacks for LLMs with Contrastive Knowledge Distillation",
                "image-path": "flux_paper_image/2409.17946_1727473431.png"
            },

            {
                "startTime": "25:35",
                "arxivId": "2409.17383",
                "arxivLink": "https://arxiv.org/abs/2409.17383",
                "title": "VectorSearch: Finding Your Needle in the Haystack of Text, Faster!",
                "institute": "University of Washington",
                "text": "This research proposes VectorSearch, a hybrid system that combines vector embeddings with traditional indexing techniques to improve document retrieval efficiency. Unlike previous work that primarily focuses on index-centric approaches, VectorSearch integrates query engines and CPU optimization for a more comprehensive solution.",
                "paper-title": "VectorSearch: Enhancing Document Retrieval with Semantic Embeddings and Optimized Search",
                "image-path": "flux_paper_image/2409.17383_1727472695.png"
            },

            {
                "startTime": "25:57",
                "arxivId": "2409.18000",
                "arxivLink": "https://arxiv.org/abs/2409.18000",
                "title": "Safeguarding Robots from Time-Traveling Trouble: A New Algorithm for Time-Varying Optimization!",
                "institute": "ETH Zurich, Norwegian University of Science and Technology, Zurich University of Applied Sciences",
                "text": "This research introduces TVSAFEOPT, an algorithm that tackles time-varying optimization problems with unknown reward and safety functions. Unlike previous methods, TVSAFEOPT uses a spatio-temporal kernel and time Lipschitz constants to safely track changes in the safe region without explicit change detection.",
                "paper-title": "Safe Time-Varying Optimization based on Gaussian Processes with Spatio-Temporal Kernel",
                "image-path": "flux_paper_image/2409.18000_1727474372.png"
            },

            {
                "startTime": "26:21",
                "arxivId": "2409.17823",
                "arxivLink": "https://arxiv.org/abs/2409.17823",
                "title": "Ranking Loss: A New Way to Distill Knowledge from Deep Learning Models",
                "institute": "Tsinghua University",
                "text": "This research proposes a new ranking loss function based on Kendall's \u03c4 coefficient to improve knowledge distillation. Unlike previous methods that rely solely on KL divergence, this approach considers the order of channel values in the logits, providing more inter-class relational information.",
                "paper-title": "Kendall's $\tau$ Coefficient for Logits Distillation",
                "image-path": "flux_paper_image/2409.17823_1727473255.png"
            },

            {
                "startTime": "26:44",
                "arxivId": "2409.17565",
                "arxivLink": "https://arxiv.org/abs/2409.17565",
                "title": "Pixel-Perfect Post-Training: Giving Diffusion Models a Vision Checkup!",
                "institute": "Princeton University, Meta",
                "text": "This research proposes adding a pixel-space supervision term during the post-training process of latent diffusion models (LDMs). This is different from previous work, which only trained LDMs in the latent space.",
                "paper-title": "Pixel-Space Post-Training of Latent Diffusion Models",
                "image-path": "flux_paper_image/2409.17565_1727473324.png"
            },

            {
                "startTime": "27:06",
                "arxivId": "2409.18084",
                "arxivLink": "https://arxiv.org/abs/2409.18084",
                "title": "Robots Learn to Queue Like Humans: New AI Helps Robots Navigate Crowds Without Being a Jerk",
                "institute": "Tsinghua University",
                "text": "This research introduces a novel approach to social navigation for robots by leveraging the visual reasoning capabilities of Large Multimodal Models (LMMs) to understand social structures in crowds. Unlike previous methods that rely on predefined rules or in-domain training, this approach enables zero-shot reasoning of social structure, allowing robots to navigate complex social environments without prior training.",
                "paper-title": "GSON: A Group-based Social Navigation Framework with Large Multimodal Model",
                "image-path": "flux_paper_image/2409.18084_1727472657.png"
            },

            {
                "startTime": "27:29",
                "arxivId": "2409.17166",
                "arxivLink": "https://arxiv.org/abs/2409.17166",
                "title": "Bashing the Code: LLMs Automate Script Generation, Assessment, and Refinement",
                "institute": "IBM",
                "text": "This research proposes a framework called ScriptSmith that automates the generation, assessment, and refinement of Bash scripts without relying on an execution environment. Unlike previous work that focuses on execution-based evaluation, ScriptSmith leverages a text-to-text approach for script assessment, making it suitable for scenarios where execution environments are unavailable or unreliable.",
                "paper-title": "ScriptSmith: A Unified LLM Framework for Enhancing IT Operations via Automated Bash Script Generation, Assessment, and Refinement",
                "image-path": "flux_paper_image/2409.17166_1727473627.png"
            },

            {
                "startTime": "27:57",
                "arxivId": "2409.17313",
                "arxivLink": "https://arxiv.org/abs/2409.17313",
                "title": "VLN Models: Not as Smart as We Thought? A Fine-Grained Look at Their Flaws",
                "institute": "KU Leuven, Peking University, Nanyang Technological University...",
                "text": "This research introduces a new evaluation framework for Vision-Language Navigation (VLN) tasks that focuses on assessing models' understanding of individual instructions, rather than just their overall success rate. This framework is based on a context-free grammar (CFG) that systematically breaks down VLN instructions into atomic categories.",
                "paper-title": "Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation",
                "image-path": "flux_paper_image/2409.17313_1727472613.png"
            },

            {
                "startTime": "28:17",
                "arxivId": "2409.17431",
                "arxivLink": "https://arxiv.org/abs/2409.17431",
                "title": "DPO Gets a Tie-Breaker: New Research Makes Room for Uncertainty in AI Preference Learning",
                "institute": "University of Cambridge",
                "text": "This research introduces two variants of Direct Preference Optimization (DPO) that explicitly model the possibility of ties in pairwise comparisons, unlike the original DPO formulation which only allows for clear preferences.",
                "paper-title": "On Extending Direct Preference Optimization to Accommodate Ties",
                "image-path": "flux_paper_image/2409.17431_1727472887.png"
            },

            {
                "startTime": "28:45",
                "arxivId": "2409.17512",
                "arxivLink": "https://arxiv.org/abs/2409.17512",
                "title": "Open-Set Learning: When OODs Get a Label of Their Own!",
                "institute": "University of Tokyo, Beijing University of Posts and Telecommunications",
                "text": "This research tackles the \"overtrusting\" issue in open-set semi-supervised learning (OSSL). Unlike previous methods that rely heavily on limited labeled data, this paper proposes treating out-of-distribution (OOD) samples as a new class, forming a (K+1)-class SSL process. This approach allows the model to learn from both labeled in-distribution (ID) and selected OOD samples, leading to a more robust decision boundary.",
                "paper-title": "SCOMatch: Alleviating Overtrusting in Open-set Semi-supervised Learning",
                "image-path": "flux_paper_image/2409.17512_1727472913.png"
            },

            {
                "startTime": "29:12",
                "arxivId": "2409.18044",
                "arxivLink": "https://arxiv.org/abs/2409.18044",
                "title": "Speech Translation: Pretraining? Nah, We Got This!",
                "institute": "Meta, Polytechnic University of Catalonia",
                "text": "This paper analyzes the training dynamics of direct speech-to-text translation systems, comparing a standard system with a pretrained encoder to one trained from scratch. It proposes a subtle modification in the Transformer architecture to bypass the pretraining stage.",
                "paper-title": "Unveiling the Role of Pretraining in Direct Speech Translation",
                "image-path": "flux_paper_image/2409.18044_1727473029.png"
            },

            {
                "startTime": "29:37",
                "arxivId": "2409.17421",
                "arxivLink": "https://arxiv.org/abs/2409.17421",
                "title": "Sunspots on the Horizon: AI Predicts Solar Active Regions 12 Hours in Advance!",
                "institute": "NASA Ames Research Center, New Jersey Institute of Technology",
                "text": "This research uses Long Short-Term Memory (LSTM) networks to predict the emergence of solar active regions (ARs) based on acoustic power and magnetic flux data, a novel approach compared to previous studies that focused on detecting ARs using helioseismic methods.",
                "paper-title": "Solar Active Regions Emergence Prediction Using Long Short-Term Memory Networks",
                "image-path": "flux_paper_image/2409.17421_1727474208.png"
            },

            {
                "startTime": "30:00",
                "arxivId": "2409.17876",
                "arxivLink": "https://arxiv.org/abs/2409.17876",
                "title": "AI Donations: Not Charity, Just Smart Business",
                "institute": "University of Oxford",
                "text": "This research goes beyond simply stating that companies donate AI open source software for altruistic reasons. It delves into the specific commercial incentives driving these donations, analyzing 43 cases from various companies.",
                "paper-title": "Why Companies"Democratise"Artificial Intelligence: The Case of Open Source Software Donations",
                "image-path": "flux_paper_image/2409.17876_1727473900.png"
            },

            {
                "startTime": "30:21",
                "arxivId": "2409.17519",
                "arxivLink": "https://arxiv.org/abs/2409.17519",
                "title": "Robots Learn to Talk Like Us, See Like Us, and Now, Understand Our World!",
                "institute": "University of Tokyo",
                "text": "This research uses pre-trained vision-language models (VLMs) to enable robots to recognize environmental states, like whether a door is open or closed, without requiring specific training for each state. This differs from previous approaches that relied on individual methods for each state.",
                "paper-title": "Robotic environmental state recognition with pre-trained vision-language models and black-box optimization",
                "image-path": "flux_paper_image/2409.17519_1727474065.png"
            },

            {
                "startTime": "30:40",
                "arxivId": "2409.17190",
                "arxivLink": "https://arxiv.org/abs/2409.17190",
                "title": "AI in Healthcare: Guardrails to Stop LLMs from Hallucinating!",
                "institute": "Ethriva Inc.",
                "text": "This research proposes a framework that combines existing guardrail systems, Llama Guard and NVIDIA NeMo Guardrails, to enhance the safety and reliability of large language models (LLMs) in healthcare applications. This approach aims to address the unique challenges of hallucinations and misinformation in medical contexts.",
                "paper-title": "Enhancing Guardrails for Safe and Secure Healthcare AI",
                "image-path": "flux_paper_image/2409.17190_1727474561.png"
            },

            {
                "startTime": "31:00",
                "arxivId": "2409.17699",
                "arxivLink": "https://arxiv.org/abs/2409.17699",
                "title": "Jailbreak-Proofing LLMs: A Simple Recipe for Robust Security",
                "institute": "IBM",
                "text": "This research introduces MoJE, a novel guardrail architecture that utilizes simple linguistic statistical techniques to detect jailbreak attacks on LLMs. Unlike previous guardrails that rely on complex fine-tuning strategies or large language models, MoJE achieves high detection accuracy with minimal computational overhead.",
                "paper-title": "MoJE: Mixture of Jailbreak Experts, Naive Tabular Classifiers as Guard for Prompt Attacks",
                "image-path": "flux_paper_image/2409.17699_1727472539.png"
            },

            {
                "startTime": "31:20",
                "arxivId": "2409.18023",
                "arxivLink": "https://arxiv.org/abs/2409.18023",
                "title": "Vision Models: Not So Smart After All? DARE Tests Their Limits!",
                "institute": "University of Cambridge, Google",
                "text": "This research introduces DARE, a new benchmark for evaluating Vision-Language Models (VLMs) that focuses on their robustness to variations in prompts, answer options, output formats, and the number of correct answers. This is different from previous work that primarily focused on evaluating VLM performance on specific tasks and instances.",
                "paper-title": "DARE: Diverse Visual Question Answering with Robustness Evaluation",
                "image-path": "flux_paper_image/2409.18023_1727473370.png"
            },

            {
                "startTime": "31:40",
                "arxivId": "2409.17572",
                "arxivLink": "https://arxiv.org/abs/2409.17572",
                "title": "Dr. GPT: Can AI Really Be Our Therapist?",
                "institute": "Princeton University, Stanford University",
                "text": "This research explores the potential of LLMs in mental health services by examining student opinions on their use in five specific scenarios, a novel approach compared to previous studies that focused on general applications.",
                "paper-title": "Dr. GPT in Campus Counseling: Understanding Higher Education Students' Opinions on LLM-assisted Mental Health Services",
                "image-path": "flux_paper_image/2409.17572_1727472533.png"
            },

            {
                "startTime": "31:56",
                "arxivId": "2409.17704",
                "arxivLink": "https://arxiv.org/abs/2409.17704",
                "title": "Transfer Learning: Support is King, Value is a Jester!",
                "institute": "University of Tokyo, Kyoto University",
                "text": "This research focuses on hyperparameter selection for transfer learning in L1 regularized regression, specifically analyzing the impact of transferring support information versus the actual feature vector values.",
                "paper-title": "Transfer Learning in $\ell_1$ Regularized Regression: Hyperparameter Selection Strategy based on Sharp Asymptotic Analysis",
                "image-path": "flux_paper_image/2409.17704_1727472940.png"
            },

            {
                "startTime": "32:24",
                "arxivId": "2409.17256",
                "arxivLink": "https://arxiv.org/abs/2409.17256",
                "title": "Super-Resolution on a Budget: Making Videos Crystal Clear Without Breaking the Bank!",
                "institute": "University of W\u00fcrzburg, Sony PlayStation, Meta...",
                "text": "This research focuses on developing efficient video super-resolution methods that are optimized for real-time performance and low computational demands, particularly on mobile devices. Unlike previous work that prioritized high-fidelity results, this study emphasizes the development of solutions with reduced parameters and operations, allowing for high frame rates while maintaining acceptable video quality.",
                "paper-title": "AIM 2024 Challenge on Efficient Video Super-Resolution for AV1 Compressed Content",
                "image-path": "flux_paper_image/2409.17256_1727473376.png"
            },

            {
                "startTime": "33:04",
                "arxivId": "2409.17267",
                "arxivLink": "https://arxiv.org/abs/2409.17267",
                "title": "Model Aggregation: Stop Averaging, Start Error-Estimating!",
                "institute": "Caltech",
                "text": "This research proposes a new method for aggregating predictions from diverse models by minimizing the variance of the aggregate, rather than directly minimizing its prediction error. This approach is distinct from previous work that focuses on training strategies for building and combining multiple models.",
                "paper-title": "Model aggregation: minimizing empirical variance outperforms minimizing empirical error",
                "image-path": "flux_paper_image/2409.17267_1727473911.png"
            },

            {
                "startTime": "33:27",
                "arxivId": "2409.17424",
                "arxivLink": "https://arxiv.org/abs/2409.17424",
                "title": "Big ANN Challenge: Searching for Needles in a Haystack, Faster Than Ever!",
                "institute": "Microsoft, IT University of Copenhagen, Meta",
                "text": "This research focuses on four challenging variants of Approximate Nearest Neighbor (ANN) search: filtered search, out-of-distribution data, sparse vectors, and streaming scenarios. Unlike previous work that emphasized scaling up classical ANN search, this competition addresses these more complex and realistic scenarios.",
                "paper-title": "Results of the Big ANN: NeurIPS'23 competition",
                "image-path": "flux_paper_image/2409.17424_1727473701.png"
            },

            {
                "startTime": "33:56",
                "arxivId": "2409.17872",
                "arxivLink": "https://arxiv.org/abs/2409.17872",
                "title": "Unmasking the Hidden Cause: A New Method for Peeking Inside Nonlinear Systems",
                "institute": "University of Cambridge",
                "text": "This research introduces a novel method for identifying the causal component of input-output data in nonlinear dynamical systems, even when the system is noisy and a perfect model is unavailable. This differs from previous work that relied on complete models or controlled inputs.",
                "paper-title": "A method for identifying causality in the response of nonlinear dynamical systems",
                "image-path": "flux_paper_image/2409.17872_1727474630.png"
            },

            {
                "startTime": "34:18",
                "arxivId": "2409.17265",
                "arxivLink": "https://arxiv.org/abs/2409.17265",
                "title": "CodonMPNN: A New Way to Fold Proteins, One Codon at a Time!",
                "institute": "MIT",
                "text": "This research introduces CodonMPNN, a model that directly generates codon sequences conditioned on a protein structure and the host organism. This differs from previous inverse folding approaches that generate amino acid sequences and then map them to codons.",
                "paper-title": "CodonMPNN for Organism Specific and Codon Optimal Inverse Folding",
                "image-path": "flux_paper_image/2409.17265_1727474087.png"
            },

            {
                "startTime": "34:44",
                "arxivId": "2409.17332",
                "arxivLink": "https://arxiv.org/abs/2409.17332",
                "title": "Retinal AI Gets a Brain Boost: New Model Learns from Natural Images, Avoids Forgetting!",
                "institute": "Stadtspital Z\u00fcrich, Spross Research Institute, Gutblick Research...",
                "text": "This research introduces a novel method called \"block expansion\" for adapting natural domain vision transformers to retinal imaging tasks. This method aims to mitigate catastrophic forgetting, a common problem in machine learning where models lose performance on previously learned data after being fine-tuned on new data.",
                "paper-title": "Block Expanded DINORET: Adapting Natural Domain Foundation Models for Retinal Imaging Without Catastrophic Forgetting",
                "image-path": "flux_paper_image/2409.17332_1727472506.png"
            },

            {
                "startTime": "35:03",
                "arxivId": "2409.17270",
                "arxivLink": "https://arxiv.org/abs/2409.17270",
                "title": "LLMs Get a Logic Lesson: PROOF OF THOUGHT Makes AI Reasoning Verifiable",
                "institute": "Case Western Reserve University, Microsoft",
                "text": "This research introduces PROOF OF THOUGHT, a framework that combines LLM-generated ideas with formal logic verification. It uses a custom interpreter to convert LLM outputs into First Order Logic constructs for theorem prover scrutiny.",
                "paper-title": "Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning",
                "image-path": "flux_paper_image/2409.17270_1727474398.png"
            },

            {
                "startTime": "35:33",
                "arxivId": "2409.17228",
                "arxivLink": "https://arxiv.org/abs/2409.17228",
                "title": "Planet Hunters: AI Tool Finds Hidden Worlds in Dusty Disks!",
                "institute": "University of Victoria, Peking University",
                "text": "This research introduces Disk2Planet, a machine learning tool that infers planet parameters from protoplanetary disk structures. Unlike previous methods that rely on limited scalar metrics or require extensive simulations, Disk2Planet utilizes a neural network to analyze entire disk images, achieving higher accuracy and robustness.",
                "paper-title": "Disk2Planet: A Robust and Automated Machine Learning Tool for Parameter Inference in Disk-Planet Systems",
                "image-path": "flux_paper_image/2409.17228_1727474009.png"
            }
    ],
    "stats": {
        "num_pick": 88,
        "num_total": 370,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202409271551_audio.mp3"
}

daily_data = {
    "date": "2024-10-21",
    "tweets": [
        
        {
            "startTime": "00:59",
            "arxivId": "2410.14669",
            "arxivLink": "https://arxiv.org/abs/2410.14669",
            "title": "VLMs: They Can't Even Handle a Giraffe!",
            "institute": "Carnegie Mellon University, University of Washington",
            "text": "This research introduces NaturalBench, a new benchmark for evaluating vision-language models (VLMs) that focuses on natural image-question pairs. Unlike previous benchmarks, NaturalBench is designed to prevent \"blind\" solutions, where models can answer questions without actually looking at the images.",
            "paper-title": "NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples",
            "image-path": "flux_paper_image/2410.14669_1729544725.png"
        },

        {
            "startTime": "01:19",
            "arxivId": "2410.14670",
            "arxivLink": "https://arxiv.org/abs/2410.14670",
            "title": "Sparse Autoencoders: The Dark Matter of Language Models",
            "institute": "MIT",
            "text": "This research focuses on the error vectors produced by sparse autoencoders (SAEs) when they try to reconstruct language model activations. Unlike previous work that focused on downstream benchmarks or simple cross entropy loss, this paper investigates the error vector itself, revealing surprising patterns and insights into the limitations of SAEs.",
            "paper-title": "Decomposing The Dark Matter of Sparse Autoencoders",
            "image-path": "flux_paper_image/2410.14670_1729543655.png"
        },

        {
            "startTime": "01:43",
            "arxivId": "2410.14623",
            "arxivLink": "https://arxiv.org/abs/2410.14623",
            "title": "Neutrinos and Dark Energy: A Symbolic Power Spectrum Party!",
            "institute": "Tsinghua University, Institut d\u2019Astrophysique de Paris",
            "text": "This research extends previous symbolic emulators for the matter power spectrum to include massive neutrinos and a time-dependent dark energy equation of state. Unlike previous work, it directly fits the nonlinear power spectrum without relying on existing halofit formulae.",
            "paper-title": "syren-new: Precise formulae for the linear and nonlinear matter power spectra with massive neutrinos and dynamical dark energy",
            "image-path": "flux_paper_image/2410.14623_1729544798.png"
        },

        {
            "startTime": "02:15",
            "arxivId": "2410.14072",
            "arxivLink": "https://arxiv.org/abs/2410.14072",
            "title": "VLMs: Visual Tokens Get a Makeover, Registers Rule the Day!",
            "institute": "University of Maryland, Apple, Meta",
            "text": "This paper proposes a new method called Victor, which summarizes visual tokens into a smaller set of register tokens, reducing computational overhead during training and inference. Unlike previous methods that rely on attention scores or separate transformers, Victor leverages the language model itself to perform this summarization, requiring minimal additional parameters.",
            "paper-title": "Efficient Vision-Language Models by Summarizing Visual Tokens into Compact Registers",
            "image-path": "flux_paper_image/2410.14072_1729544506.png"
        },

        {
            "startTime": "02:43",
            "arxivId": "2410.14148",
            "arxivLink": "https://arxiv.org/abs/2410.14148",
            "title": "Vision-Language Models Get a Fine-Grained Tune-Up: Token-Level Rewards for Better Alignment!",
            "institute": "National University of Singapore, UNC-Chapel Hill, Chicago University...",
            "text": "This research proposes a novel self-alignment method called FiSAO that uses the model's own visual encoder as a fine-grained verifier to improve vision-language alignment without the need for additional data. Unlike previous methods that rely on coarse feedback, FiSAO leverages token-level feedback, marking the first instance of such an approach for VLLMs.",
            "paper-title": "Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in Vision-Language Alignment",
            "image-path": "flux_paper_image/2410.14148_1729544564.png"
        },

        {
            "startTime": "03:17",
            "arxivId": "2410.14255",
            "arxivLink": "https://arxiv.org/abs/2410.14255",
            "title": "LLMs Get a Brain: Iterative Planning Makes AI Ideas More Novel",
            "institute": "CMU, University of Electronic Science and Technology of China, Westlake University",
            "text": "This research introduces an iterative planning framework for LLM-based idea generation, which aims to enhance the novelty and diversity of generated ideas by strategically retrieving external knowledge. Unlike previous methods that rely on keyword or entity retrieval, this approach uses the LLM's internal knowledge to plan and search for relevant information, leading to a more directed and effective knowledge acquisition process.",
            "paper-title": "Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas",
            "image-path": "flux_paper_image/2410.14255_1729542822.png"
        },

        {
            "startTime": "03:36",
            "arxivId": "2410.14569",
            "arxivLink": "https://arxiv.org/abs/2410.14569",
            "title": "LLMs Go Rogue: When Chatbots Turn into Cybercriminals",
            "institute": "KAIST, OpenAI, Google",
            "text": "This research explores the potential for Large Language Models (LLMs) to be used in cyberattacks when they are given access to web-based tools. Previous research has focused on the misuse of LLMs in isolation, but this study examines the risks associated with LLMs interacting with the internet.",
            "paper-title": "When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs",
            "image-path": "flux_paper_image/2410.14569_1729543661.png"
        },

        {
            "startTime": "03:57",
            "arxivId": "2410.14204",
            "arxivLink": "https://arxiv.org/abs/2410.14204",
            "title": "MediTOD: Doctor-Patient Chatbot Gets a Medical Makeover!",
            "institute": "Indian Institute of Technology Delhi, IBM",
            "text": "This research introduces MediTOD, a new English dialogue dataset for medical history taking. Unlike previous datasets, MediTOD uses a comprehensive medical attribute schema (CMAS) to capture the inherent complexity of medical slots and their attributes, such as symptoms and their onset, progression, and severity.",
            "paper-title": "MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations",
            "image-path": "flux_paper_image/2410.14204_1729542354.png"
        },

        {
            "startTime": "04:28",
            "arxivId": "2410.14154",
            "arxivLink": "https://arxiv.org/abs/2410.14154",
            "title": "RA-BLIP: A Multimodal Model That's Not Just Looking, It's Listening!",
            "institute": "Peking University, University of Sydney",
            "text": "This research introduces a multimodal adaptive retrieval-augmented framework called RA-BLIP, which uses questions to guide the extraction of visual information, minimizing irrelevant interference during retrieval and generation. This differs from previous work by explicitly integrating multimodal information and projecting it into a unified semantic space, enabling the model to better understand the relationship between different modalities.",
            "paper-title": "RA-BLIP: Multimodal Adaptive Retrieval-Augmented Bootstrapping Language-Image Pre-training",
            "image-path": "flux_paper_image/2410.14154_1729544326.png"
        },

        {
            "startTime": "04:51",
            "arxivId": "2410.14143",
            "arxivLink": "https://arxiv.org/abs/2410.14143",
            "title": "Knowledge Distillation: A Teacher's Guide to Smarter Students",
            "institute": "Peking University, Alibaba",
            "text": "This research introduces a new knowledge distillation method called Preview-based Category Contrastive Learning (PCKD). Unlike previous methods that focus on instance-level feature representation or prediction, PCKD incorporates category-level information and dynamically adjusts the learning process based on the difficulty of each sample.",
            "paper-title": "Preview-based Category Contrastive Learning for Knowledge Distillation",
            "image-path": "flux_paper_image/2410.14143_1729544968.png"
        },

        {
            "startTime": "05:29",
            "arxivId": "2410.13986",
            "arxivLink": "https://arxiv.org/abs/2410.13986",
            "title": "Time Series Models: A Neural Network's Goodness-of-Fit Test",
            "institute": "Carnegie Mellon University, University of Minnesota",
            "text": "This research proposes a new goodness-of-fit test for generative time series models that leverages recurrent neural networks to transform the time series into conditionally independent data pairs, enabling the application of a chi-square-based test. This approach differs from previous work by addressing the challenges posed by temporal dependencies and high dimensionality in time series data.",
            "paper-title": "Recurrent Neural Goodness-of-Fit Test for Time Series",
            "image-path": "flux_paper_image/2410.13986_1729542989.png"
        },

        {
            "startTime": "05:56",
            "arxivId": "2410.14208",
            "arxivLink": "https://arxiv.org/abs/2410.14208",
            "title": "Teaching LLMs to Teach: A New Way to Train AI with Tailored Data",
            "institute": "Tsinghua University, CMU",
            "text": "This research proposes a novel data synthesis framework called Montessori-Instruct, which optimizes the teacher model's ability to generate training data based on the student model's learning preferences. Unlike previous methods that rely on the teacher's general knowledge, Montessori-Instruct directly measures the impact of each data point on the student's performance and uses this information to guide the teacher's optimization process.",
            "paper-title": "Montessori-Instruct: Generate Influential Training Data Tailored for Student Learning",
            "image-path": "flux_paper_image/2410.14208_1729542621.png"
        },

        {
            "startTime": "06:22",
            "arxivId": "2410.14040",
            "arxivLink": "https://arxiv.org/abs/2410.14040",
            "title": "Diffusion Models: Learning Policies, Not Just Trajectories!",
            "institute": "University of Southern California, Google",
            "text": "This research proposes Latent Weight Diffusion (LWD), a method that uses diffusion models to learn a distribution of policies for robotic tasks, rather than over trajectories. This approach encodes demonstration trajectories into a latent space and then decodes them into policies using a hypernetwork.",
            "paper-title": "Latent Weight Diffusion: Generating Policies from Trajectories",
            "image-path": "flux_paper_image/2410.14040_1729543162.png"
        },

        {
            "startTime": "06:48",
            "arxivId": "2410.14237",
            "arxivLink": "https://arxiv.org/abs/2410.14237",
            "title": "Diffusion Models: A Unified Analysis for Deterministic Samplers",
            "institute": "Peking University, UC Los Angeles",
            "text": "This research introduces a unified framework for analyzing the convergence of diffusion models with deterministic samplers. Unlike previous work that focused on specific examples, this framework can be applied to various forward processes and sampling algorithms.",
            "paper-title": "Unified Convergence Analysis for Score-Based Diffusion Models with Deterministic Samplers",
            "image-path": "flux_paper_image/2410.14237_1729542349.png"
        },

        {
            "startTime": "07:15",
            "arxivId": "2410.14214",
            "arxivLink": "https://arxiv.org/abs/2410.14214",
            "title": "Quad-Bayer Video: MambaSCI Makes Smartphone Cameras See the Future!",
            "institute": "Harbin Institute of Technology, Ghent University, Harvard University...",
            "text": "This research introduces the first algorithm specifically designed for reconstructing color video captured by quad-Bayer sensors, a common feature in modern smartphones. Unlike previous methods that were built for traditional Bayer patterns, MambaSCI leverages the Mamba model to efficiently handle the unique characteristics of quad-Bayer data.",
            "paper-title": "MambaSCI: Efficient Mamba-UNet for Quad-Bayer Patterned Video Snapshot Compressive Imaging",
            "image-path": "flux_paper_image/2410.14214_1729542331.png"
        },

        {
            "startTime": "07:49",
            "arxivId": "2410.14649",
            "arxivLink": "https://arxiv.org/abs/2410.14649",
            "title": "LLMs on a Diet: EvoPress Finds the Perfect Compression Recipe!",
            "institute": "ETH Zurich, Skolkovo Institute of Science and Technology, Institute of Science and Technology Austria",
            "text": "This research challenges the common assumption that minimizing the sum of errors in individual layers of a large language model (LLM) will lead to the best overall compression. Instead, it proposes a new evolutionary search method called EvoPress that directly optimizes the compression profile for the entire model, leading to better accuracy at higher compression ratios.",
            "paper-title": "EvoPress: Towards Optimal Dynamic Model Compression via Evolutionary Search",
            "image-path": "flux_paper_image/2410.14649_1729545067.png"
        },

        {
            "startTime": "08:23",
            "arxivId": "2410.14641",
            "arxivLink": "https://arxiv.org/abs/2410.14641",
            "title": "LLMs: Lost in the Middle, But Now They're Spacing Out!",
            "institute": "Tsinghua University",
            "text": "This research focuses on the impact of the distance between relevant information pieces on the performance of long-context LLMs, a factor not extensively studied before.",
            "paper-title": "Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs",
            "image-path": "flux_paper_image/2410.14641_1729543252.png"
        },

        {
            "startTime": "08:44",
            "arxivId": "2410.13953",
            "arxivLink": "https://arxiv.org/abs/2410.13953",
            "title": "Diffusion Models: Unmasking the Truth in Multi-Agent Mysteries!",
            "institute": "Harvard University",
            "text": "This research explores the use of diffusion models to reconstruct global states in decentralized partially observable Markov decision processes (Dec-POMDPs) from local action-observation histories. Unlike previous work that focuses on learning low-dimensional representations, this paper delves into the inherent stochasticity of mapping local histories to states and proposes a novel composite diffusion process to address the challenges posed by deep learning approximation errors.",
            "paper-title": "On Diffusion Models for Multi-Agent Partial Observability: Shared Attractors, Error Bounds, and Composite Flow",
            "image-path": "flux_paper_image/2410.13953_1729544793.png"
        },

        {
            "startTime": "09:00",
            "arxivId": "2410.13957",
            "arxivLink": "https://arxiv.org/abs/2410.13957",
            "title": "Chatty Robots Learn Your Goals: A New Way to Make AI Assistants More Human-Like",
            "institute": "MIT",
            "text": "This research proposes a method for embodied agents to learn and accomplish diverse user goals through open-ended dialogue. Unlike offline methods that require large datasets, this approach uses Bayesian inference over natural language goal representations extracted from conversations with Large Language Models (LLMs).",
            "paper-title": "Goal Inference from Open-Ended Dialog",
            "image-path": "flux_paper_image/2410.13957_1729544621.png"
        },

        {
            "startTime": "09:17",
            "arxivId": "2410.14311",
            "arxivLink": "https://arxiv.org/abs/2410.14311",
            "title": "AI Robots: Can They Be Too Smart for Their Own Good?",
            "institute": "University of Oxford, CMU",
            "text": "This research explores the impact of allowing AI agents to simulate other agents' mixed strategies, a concept not previously explored in depth. It contrasts this with the existing research on pure-strategy simulation, where the simulator learns the exact strategy of the simulated agent.",
            "paper-title": "Game Theory with Simulation in the Presence of Unpredictable Randomisation",
            "image-path": "flux_paper_image/2410.14311_1729542969.png"
        },

        {
            "startTime": "09:40",
            "arxivId": "2410.14055",
            "arxivLink": "https://arxiv.org/abs/2410.14055",
            "title": "Diffusion Models Get a Guiding Hand: Semi-Supervised Matching for Smarter Transport",
            "institute": "Georgia Institute of Technology, Meta",
            "text": "This paper introduces Feedback Schr\u00f6dinger Bridge Matching (FSBM), a semi-supervised approach to training diffusion models. Unlike previous methods that rely on either fully unsupervised or fully supervised learning, FSBM incorporates a small portion of pre-aligned data pairs to guide the transport map, improving efficiency and generalization.",
            "paper-title": "Feedback Schr{\\\"o}dinger Bridge Matching",
            "image-path": "flux_paper_image/2410.14055_1729544925.png"
        },

        {
            "startTime": "10:08",
            "arxivId": "2410.14109",
            "arxivLink": "https://arxiv.org/abs/2410.14109",
            "title": "GNNs Get Direction: Fuzzy Edges Boost Graph Learning",
            "institute": "Harvard University",
            "text": "This research introduces a novel approach to graph neural networks (GNNs) by incorporating continuous edge directions, allowing information to flow preferentially in one direction between nodes. This differs from traditional GNNs that rely on undirected edges, leading to information homogenization and reduced discriminative power.",
            "paper-title": "Improving Graph Neural Networks by Learning Continuous Edge Directions",
            "image-path": "flux_paper_image/2410.14109_1729544048.png"
        },

        {
            "startTime": "10:35",
            "arxivId": "2410.14042",
            "arxivLink": "https://arxiv.org/abs/2410.14042",
            "title": "LLMs Learn to Whisper: Prompt Compression Gets a Style Makeover",
            "institute": "UC Santa Barbara, Tsinghua University, Peking University",
            "text": "This research proposes Style-Compress, a framework that adapts smaller language models to compress prompts for larger models on new tasks without additional training. Unlike previous work that focuses on task-agnostic compression or requires additional training, Style-Compress leverages style variation and in-context learning to tailor prompt compression to specific tasks.",
            "paper-title": "Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles",
            "image-path": "flux_paper_image/2410.14042_1729544424.png"
        },

        {
            "startTime": "11:04",
            "arxivId": "2410.14528",
            "arxivLink": "https://arxiv.org/abs/2410.14528",
            "title": "CBF Operator Learning: Safety Filters That Learn on the Fly!",
            "institute": "Johns Hopkins University, Microsoft",
            "text": "This research proposes a deep operator learning framework to learn domain-adaptive control barrier functions (CBFs). Unlike previous methods that require retraining for each new environment, this approach learns a mapping from environmental parameters to the corresponding CBF, enabling adaptation to novel or changing environments during deployment.",
            "paper-title": "Domain Adaptive Safety Filters via Deep Operator Learning",
            "image-path": "flux_paper_image/2410.14528_1729543220.png"
        },

        {
            "startTime": "11:31",
            "arxivId": "2410.14189",
            "arxivLink": "https://arxiv.org/abs/2410.14189",
            "title": "3D Gaussians Get a Neural Makeover: Pulling Surfaces Out of Thin Air!",
            "institute": "Tsinghua University, Wayne State University",
            "text": "This research proposes a novel method for inferring neural signed distance functions (SDFs) from multi-view RGB images using 3D Gaussian splatting. The key innovation lies in dynamically aligning 3D Gaussians on the zero-level set of the neural SDF through a differentiable pulling operation. This approach effectively constrains surface inference with multi-view consistency, leading to more accurate, smooth, and complete surfaces with geometry details.",
            "paper-title": "Neural Signed Distance Function Inference through Splatting 3D Gaussians Pulled on Zero-Level Set",
            "image-path": "flux_paper_image/2410.14189_1729542867.png"
        },

        {
            "startTime": "11:58",
            "arxivId": "2410.14083",
            "arxivLink": "https://arxiv.org/abs/2410.14083",
            "title": "SAMReg: Image Registration Gets a Segmentation Makeover!",
            "institute": "University College London, Beijing Institute of Technology",
            "text": "This research introduces a new way to represent spatial correspondence in medical image registration using paired regions of interest (ROIs). Unlike previous methods that rely on dense displacement fields or parametric functions, this approach focuses on identifying corresponding ROIs, which are then used to align the images.",
            "paper-title": "SAMReg: SAM-enabled Image Registration with ROI-based Correspondence",
            "image-path": "flux_paper_image/2410.14083_1729544745.png"
        },

        {
            "startTime": "12:22",
            "arxivId": "2410.14045",
            "arxivLink": "https://arxiv.org/abs/2410.14045",
            "title": "Predicting Your Next Move: A Guide to Human Action Anticipation Research",
            "institute": "Georgia Institute of Technology, UC Berkeley, Meta...",
            "text": "This research paper provides a comprehensive survey of human action anticipation, classifying existing work into seven distinct tasks and analyzing their methods, datasets, and future directions. It also offers a structured framework for understanding the field and highlights the importance of multi-modal models and pretraining strategies.",
            "paper-title": "Human Action Anticipation: A Survey",
            "image-path": "flux_paper_image/2410.14045_1729543740.png"
        },

        {
            "startTime": "12:44",
            "arxivId": "2410.14161",
            "arxivLink": "https://arxiv.org/abs/2410.14161",
            "title": "Unlabeled Action Quality Assessment: DTW Gets a Makeover!",
            "institute": "Fujian Normal University, Minjiang University, Tsinghua University...",
            "text": "This research proposes an unlabeled action quality assessment method called MED-ACDTW, which uses a comparative approach to evaluate test videos against template videos, eliminating the need for labeled scores during training.",
            "paper-title": "Unlabeled Action Quality Assessment Based on Multi-dimensional Adaptive Constrained Dynamic Time Warping",
            "image-path": "flux_paper_image/2410.14161_1729545061.png"
        },

        {
            "startTime": "13:04",
            "arxivId": "2410.13954",
            "arxivLink": "https://arxiv.org/abs/2410.13954",
            "title": "Heavy-Tailed Noise? No Problem! Nonlinear SGD to the Rescue!",
            "institute": "CMU, University of Novi Sad",
            "text": "This research explores the convergence of nonlinear stochastic gradient descent (SGD) in the presence of heavy-tailed noise, a common issue in machine learning. Unlike previous work that focused on clipping and required bounded noise moments, this paper considers a broader class of nonlinearities and makes no assumptions on noise moments.",
            "paper-title": "Nonlinear Stochastic Gradient Descent and Heavy-tailed Noise: A Unified Framework and High-probability Guarantees",
            "image-path": "flux_paper_image/2410.13954_1729542398.png"
        },

        {
            "startTime": "13:28",
            "arxivId": "2410.14030",
            "arxivLink": "https://arxiv.org/abs/2410.14030",
            "title": "Graph Neural Flows: Untangling the Web of Time Series Interactions",
            "institute": "Idiap Research Institute, IBM",
            "text": "This research proposes a novel graph-based continuous-time model called GNeuralFlow, which learns the conditional dependencies of time series data, unlike previous methods that rely on pre-defined or learned graph structures.",
            "paper-title": "Graph Neural Flows for Unveiling Systemic Interactions Among Irregularly Sampled Time Series",
            "image-path": "flux_paper_image/2410.14030_1729542494.png"
        },

        {
            "startTime": "14:01",
            "arxivId": "2410.14153",
            "arxivLink": "https://arxiv.org/abs/2410.14153",
            "title": "Human-Robot Teamwork: Can We Make It Stable?",
            "institute": "University of Sydney, Nanyang Technological University",
            "text": "This research focuses on the stability of wireless human-machine collaboration (WHMC) systems, a crucial aspect often overlooked in previous work. It introduces a novel model that incorporates dual wireless loops for both machine and human control, accounting for practical factors like short-packet transmissions, fading channels, and advanced HARQ schemes.",
            "paper-title": "Wireless Human-Machine Collaboration in Industry 5.0",
            "image-path": "flux_paper_image/2410.14153_1729544679.png"
        },

        {
            "startTime": "14:28",
            "arxivId": "2410.14588",
            "arxivLink": "https://arxiv.org/abs/2410.14588",
            "title": "Clustering for Guarantees: When Groups Are More Than Just Labels",
            "institute": "UC Berkeley",
            "text": "This research proposes a new approach to providing performance guarantees for subpopulations in prediction problems. Instead of defining subpopulations based on predefined feature combinations, it focuses on statistically identifiable groups that emerge naturally from the data distribution. This approach leverages multi-objective learning to provide guarantees for all plausible subgroup structures simultaneously, rather than relying on a two-stage \"cluster-then-predict\" approach.",
            "paper-title": "Learning With Multi-Group Guarantees For Clusterable Subpopulations",
            "image-path": "flux_paper_image/2410.14588_1729543046.png"
        },

        {
            "startTime": "15:01",
            "arxivId": "2410.14522",
            "arxivLink": "https://arxiv.org/abs/2410.14522",
            "title": "Counterfactual Explanations: Not Just a Ball, But a Dance!",
            "institute": "CMU",
            "text": "This research proposes a new framing for counterfactual explanation methods, considering counterfactuals not as independent draws from a region around the reference, but as jointly sampled with the reference from the underlying data distribution. This approach differs from previous work by incorporating the underlying data distribution into the generation process.",
            "paper-title": "Rethinking Distance Metrics for Counterfactual Explainability",
            "image-path": "flux_paper_image/2410.14522_1729543564.png"
        },

        {
            "startTime": "15:23",
            "arxivId": "2410.14375",
            "arxivLink": "https://arxiv.org/abs/2410.14375",
            "title": "Pre-trained Language Models: Causal Fine-Tuning for Robustness",
            "institute": "University College London, King\u2019s College London, The Hong Kong University of Science and Technology",
            "text": "This research proposes a novel method for fine-tuning pre-trained language models (PLMs) to improve their generalizability to out-of-domain (OOD) data. Unlike previous approaches that rely on multi-domain data or strong assumptions about the absence of hidden common causes, this method leverages a causal front-door adjustment using single-domain data and PLMs for data augmentation.",
            "paper-title": "Fine-Tuning Pre-trained Language Models for Robust Causal Representation Learning",
            "image-path": "flux_paper_image/2410.14375_1729544709.png"
        },

        {
            "startTime": "16:03",
            "arxivId": "2410.14581",
            "arxivLink": "https://arxiv.org/abs/2410.14581",
            "title": "Attention, Please! Mirror Descent Makes Token Selection a Breeze!",
            "institute": "MIT, University of Pennsylvania",
            "text": "This research investigates the convergence properties and implicit biases of mirror descent (MD) algorithms tailored for softmax attention mechanisms, expanding on previous work that focused solely on gradient descent (GD).",
            "paper-title": "Optimizing Attention with Mirror Descent: Generalized Max-Margin Token Selection",
            "image-path": "flux_paper_image/2410.14581_1729543431.png"
        },

        {
            "startTime": "16:23",
            "arxivId": "2410.14593",
            "arxivLink": "https://arxiv.org/abs/2410.14593",
            "title": "Fair Division: It's Not Just for Divorce Anymore!",
            "institute": "University of Oxford, Alan Turing Institute, City University of Hong Kong...",
            "text": "This paper explores a new model for fair division where items arrive sequentially and must be allocated immediately. Unlike previous work that assumes no future information, this research considers an informed setting where the algorithm knows the future items and aims to ensure fairness at each round.",
            "paper-title": "Temporal Fair Division of Indivisible Items",
            "image-path": "flux_paper_image/2410.14593_1729544989.png"
        },

        {
            "startTime": "16:53",
            "arxivId": "2410.13872",
            "arxivLink": "https://arxiv.org/abs/2410.13872",
            "title": "Brain-Powered Learning: Teaching AI to Decode Your Thoughts with a Little Help from Behavior!",
            "institute": "Peking University, Hong Kong University of Science and Technology, Beihang University",
            "text": "This research introduces BLEND, a framework that uses privileged knowledge distillation to improve neural dynamics modeling. Unlike previous methods that either rely on complex model designs or make oversimplified assumptions, BLEND leverages behavioral signals as privileged information during training to guide a student model that only uses neural activity during inference.",
            "paper-title": "BLEND: Behavior-guided Neural Population Dynamics Modeling via Privileged Knowledge Distillation",
            "image-path": "flux_paper_image/2410.13872_1729542891.png"
        },

        {
            "startTime": "17:12",
            "arxivId": "2410.14436",
            "arxivLink": "https://arxiv.org/abs/2410.14436",
            "title": "Knowledge Graph Makeover: How to Fix Your Biological Network with a Little Help from Data",
            "institute": "Tsinghua University, Massachusetts Institute of Technology",
            "text": "This research proposes an amortized inference framework for refining noisy graph priors, which are often used to initialize causal structure learning algorithms. Unlike previous approaches that rely on simulating biological data, this method focuses on simulating the types of noise that occur in real-world biological networks.",
            "paper-title": "Learning to refine domain knowledge for biological network inference",
            "image-path": "flux_paper_image/2410.14436_1729545074.png"
        },

        {
            "startTime": "17:36",
            "arxivId": "2410.13887",
            "arxivLink": "https://arxiv.org/abs/2410.13887",
            "title": "AI Uncovers the \"Southern Charm\" of Online Fights",
            "institute": "University of Toronto",
            "text": "This study uses a large language model (LLM) to analyze online conversations, specifically on Reddit, to test the \"culture of honor\" theory. Previous research relied on smaller, controlled experiments.",
            "paper-title": "Observing the Southern US Culture of Honor Using Large-Scale Social Media Analysis",
            "image-path": "flux_paper_image/2410.13887_1729544089.png"
        },

        {
            "startTime": "17:54",
            "arxivId": "2410.13979",
            "arxivLink": "https://arxiv.org/abs/2410.13979",
            "title": "Robot Fails? No Problem! New AI Learns to Recover from Mistakes",
            "institute": "CMU, Mitsubishi Electric Research Laboratories",
            "text": "This research proposes a novel hierarchical reinforcement learning approach called RecoveryChaining, which uses a hybrid action space to learn robust recovery policies for model-based controllers. This approach differs from previous work by not relying on pre-trained preconditions, allowing for more flexible and less pessimistic recovery learning.",
            "paper-title": "RecoveryChaining: Learning Local Recovery Policies for Robust Manipulation",
            "image-path": "flux_paper_image/2410.13979_1729543257.png"
        },

        {
            "startTime": "18:18",
            "arxivId": "2410.14464",
            "arxivLink": "https://arxiv.org/abs/2410.14464",
            "title": "ECG and LLMs: A Love Story for Few-Shot Question Answering",
            "institute": "Eindhoven University of Technology, University of Cambridge",
            "text": "This research proposes a novel multimodal meta-learning method for few-shot ECG question answering, integrating a pre-trained ECG encoder with a frozen LLM via a trainable fusion module. This approach differs from previous work by specifically addressing the challenge of limited labeled data in the ECG domain while leveraging the knowledge encoded within large language models.",
            "paper-title": "Electrocardiogram-Language Model for Few-Shot Question Answering with Meta Learning",
            "image-path": "flux_paper_image/2410.14464_1729544913.png"
        },

        {
            "startTime": "18:41",
            "arxivId": "2410.14586",
            "arxivLink": "https://arxiv.org/abs/2410.14586",
            "title": "Clustering Bandits: A Neural Network's Guide to Recommending Movies You'll Love",
            "institute": "CMU",
            "text": "This research proposes a new algorithm, NeUClust, that uses two neural networks to learn reward functions in a contextual combinatorial bandit setting. Unlike previous work, NeUClust eliminates the need for an oracle by leveraging the clustered structure of the context space.",
            "paper-title": "Neural Combinatorial Clustered Bandits for Recommendation Systems",
            "image-path": "flux_paper_image/2410.14586_1729544512.png"
        },

        {
            "startTime": "19:05",
            "arxivId": "2410.14005",
            "arxivLink": "https://arxiv.org/abs/2410.14005",
            "title": "Whiskers on Robots? They're Not Just for Feeling Water Currents Anymore!",
            "institute": "Stanford University",
            "text": "This research introduces a new approach for underwater contact tracking using whisker sensors. Unlike previous methods that rely on complex models or precise robot proprioception, this study utilizes a sim-to-real learning framework, enabling accurate contact prediction without requiring detailed robot position information.",
            "paper-title": "Whisker-Inspired Tactile Sensing: A Sim2Real Approach for Precise Underwater Contact Tracking",
            "image-path": "flux_paper_image/2410.14005_1729542816.png"
        },

        {
            "startTime": "19:23",
            "arxivId": "2410.14309",
            "arxivLink": "https://arxiv.org/abs/2410.14309",
            "title": "LLMs Get Honest: New Research Makes Chatbots Admit When They Don't Know!",
            "institute": "Fudan University, University of Cambridge, Tencent",
            "text": "This research focuses on long-form text generation with uncertainty expressions, a task that has been largely unexplored. Unlike previous work that primarily focused on short-form question answering, this paper tackles the challenge of enabling LLMs to express uncertainty in longer, more complex responses.",
            "paper-title": "LoGU: Long-form Generation with Uncertainty Expressions",
            "image-path": "flux_paper_image/2410.14309_1729543334.png"
        },

        {
            "startTime": "19:47",
            "arxivId": "2410.14022",
            "arxivLink": "https://arxiv.org/abs/2410.14022",
            "title": "Robot Hand Learns to Grasp Like a Human, Thanks to a Language-Powered Brain!",
            "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
            "text": "This research combines a Vision-Language-Action (VLA) model with a diffusion model for dexterous manipulation. The VLA model handles high-level planning based on language commands, while the diffusion model takes care of precise, low-level interactions. This hybrid approach allows for more robust and adaptable grasping compared to using only a VLA model.",
            "paper-title": "Vision-Language-Action Model and Diffusion Policy Switching Enables Dexterous Control of an Anthropomorphic Hand",
            "image-path": "flux_paper_image/2410.14022_1729544082.png"
        },

        {
            "startTime": "20:12",
            "arxivId": "2410.14655",
            "arxivLink": "https://arxiv.org/abs/2410.14655",
            "title": "LLMs: Learning to Talk the Talk, Not Just Walk the Walk",
            "institute": "CMU, Amazon",
            "text": "This research proposes two new methods, Batch-scheduled Sampling (BASH) and Reference-Answer-based Correction (RAC), to address the training-inference gap in LLMs. Unlike previous approaches, these methods leverage the model's own generations during training, making the training process more closely resemble the inference process.",
            "paper-title": "Bridging the Training-Inference Gap in LLMs by Leveraging Self-Generated Tokens",
            "image-path": "flux_paper_image/2410.14655_1729542695.png"
        },

        {
            "startTime": "20:38",
            "arxivId": "2410.14361",
            "arxivLink": "https://arxiv.org/abs/2410.14361",
            "title": "Susceptibility to Context: A Faster Way to Measure How Language Models Get Swayed",
            "institute": "ETH Zurich",
            "text": "This research proposes a new method called \"Fisher susceptibility\" to efficiently measure how easily language models are influenced by context. Unlike previous methods that relied on Monte Carlo approximations, this approach leverages Fisher information, making it significantly faster and more practical for large-scale analysis.",
            "paper-title": "Efficiently Computing Susceptibility to Context in Language Models",
            "image-path": "flux_paper_image/2410.14361_1729543993.png"
        },

        {
            "startTime": "20:56",
            "arxivId": "2410.14592",
            "arxivLink": "https://arxiv.org/abs/2410.14592",
            "title": "Saddle Up for Linear Convergence: A New Operator-Theoretic Approach to Bilinear Problems",
            "institute": "ETH Zurich",
            "text": "This research introduces a novel operator-theoretic approach to analyze the linear convergence of primal-dual algorithms for solving bilinear saddle-point problems. Unlike previous work that often relies on customized analysis techniques, this paper leverages tools from monotone operator theory to provide a more systematic and interpretable framework.",
            "paper-title": "Contractivity and linear convergence in bilinear saddle-point problems: An operator-theoretic approach",
            "image-path": "flux_paper_image/2410.14592_1729544759.png"
        },

        {
            "startTime": "21:21",
            "arxivId": "2410.14343",
            "arxivLink": "https://arxiv.org/abs/2410.14343",
            "title": "Histology and Micro-CT: A Love Story Made Possible by Machine Learning",
            "institute": "ImFusion GmbH, Technical University of Munich, Heinrich Heine University...",
            "text": "This research introduces a novel 2D-3D deformable image registration method that uses a machine learning (ML)-based initialization followed by an analytical out-of-plane deformation refinement. This approach differs from previous methods that relied on intensity- or keypoint-based initialization, which often struggled with the low image quality and significant deformation present in soft tissue samples.",
            "paper-title": "2D-3D Deformable Image Registration of Histology Slide and Micro-CT with ML-based Initialization",
            "image-path": "flux_paper_image/2410.14343_1729542529.png"
        },

        {
            "startTime": "21:52",
            "arxivId": "2410.14118",
            "arxivLink": "https://arxiv.org/abs/2410.14118",
            "title": "Robots Learn to \"Open\" Anything: A Verb-Based Skill Generalization Method",
            "institute": "MIT",
            "text": "This research focuses on generalizing manipulation skills to novel objects using verbs, unlike previous work that either relies on demonstration data or assumes robots know goal states for primitive verbs.",
            "paper-title": "Skill Generalization with Verbs",
            "image-path": "flux_paper_image/2410.14118_1729543191.png"
        },

        {
            "startTime": "22:16",
            "arxivId": "2410.14426",
            "arxivLink": "https://arxiv.org/abs/2410.14426",
            "title": "Predicting Metabolic Flux: A Neural ODE Process That's Not a Total Mess!",
            "institute": "CISPA Helmholtz Center for Information Security, University of Cambridge",
            "text": "This research proposes a novel Structured Neural ODE Process (SNODEP) model to predict time-varying flux and balance in metabolic systems, bypassing the need for manual optimization problem formulation. Unlike standard neural ODE processes, SNODEP incorporates structural information from context points and uses non-Gaussian distributions for latent and decoder sampling, making it more suitable for modeling metabolic system dynamics.",
            "paper-title": "Predicting time-varying flux and balance in metabolic systems using structured neural-ODE processes",
            "image-path": "flux_paper_image/2410.14426_1729542503.png"
        },

        {
            "startTime": "22:38",
            "arxivId": "2410.14425",
            "arxivLink": "https://arxiv.org/abs/2410.14425",
            "title": "LLMs Got Backdoor Problems? W2SDefense to the Rescue!",
            "institute": "Nanyang Technological University",
            "text": "This research introduces a novel unlearning algorithm called W2SDefense, which utilizes feature alignment knowledge distillation to defend against backdoor attacks in parameter-efficient fine-tuning (PEFT) of LLMs. Unlike previous methods that rely on full-parameter fine-tuning, W2SDefense leverages a smaller-scale clean teacher model to guide the poisoned student model, enabling it to unlearn backdoor features with minimal parameter updates.",
            "paper-title": "Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation",
            "image-path": "flux_paper_image/2410.14425_1729543315.png"
        },

        {
            "startTime": "23:03",
            "arxivId": "2410.13886",
            "arxivLink": "https://arxiv.org/abs/2410.13886",
            "title": "Browser Agents: Jailbreak-Proof? Think Again!",
            "institute": "Carnegie Mellon University, GraySwan AI, Scale AI",
            "text": "This research focuses on the safety of browser agents, which are LLMs that can interact with the real world through web browsers. It introduces a new benchmark called BrowserART, which includes 100 harmful behaviors specifically designed for browser agents. The study finds that existing safety measures designed for chatbots don't translate well to browser agents, and that these agents are easily jailbroken using techniques previously used to attack LLMs.",
            "paper-title": "Refusal-Trained LLMs Are Easily Jailbroken As Browser Agents",
            "image-path": "flux_paper_image/2410.13886_1729543626.png"
        },

        {
            "startTime": "23:27",
            "arxivId": "2410.14177",
            "arxivLink": "https://arxiv.org/abs/2410.14177",
            "title": "Driving Lessons from the Sky: How Aerial Images Teach Cars to Navigate",
            "institute": "MIT, Toyota Research Institute (TRI)",
            "text": "This research uses a Neural Radiance Field (NeRF) to create a compact representation of a scene from aerial images, allowing the generation of novel views from a ground vehicle's perspective. This differs from previous work that relied on expensive photogrammetric simulators or limited ground-view datasets.",
            "paper-title": "Learning autonomous driving from aerial imagery",
            "image-path": "flux_paper_image/2410.14177_1729544577.png"
        },

        {
            "startTime": "23:49",
            "arxivId": "2410.14008",
            "arxivLink": "https://arxiv.org/abs/2410.14008",
            "title": "DRO vs. Robust Stats: Who Wins the Outlier Game?",
            "institute": "\u00c9cole Polytechnique, Centrum Wiskunde & Informatica, MIT",
            "text": "This paper bridges the gap between distributionally robust optimization (DRO) and classical robust statistics by showing that the conservatism often observed in DRO formulations stems from the non-parametric framework. It demonstrates that when parametric assumptions are imposed on the unknown distribution, the ambiguity set is never larger than a confidence set based on the optimal estimator proposed by Huber (1964).",
            "paper-title": "From Distributional Robustness to Robust Statistics: A Confidence Sets Perspective",
            "image-path": "flux_paper_image/2410.14008_1729542564.png"
        },

        {
            "startTime": "24:17",
            "arxivId": "2410.14050",
            "arxivLink": "https://arxiv.org/abs/2410.14050",
            "title": "Kids' Uncertainty: A Multimodal Peek into Little Minds",
            "institute": "University of Pittsburgh, Harvard University, Rutgers University...",
            "text": "This research introduces a new dataset annotated in collaboration with developmental and cognitive psychologists to study nonverbal cues of uncertainty in young children. It differs from previous work by focusing on multimodal cues and analyzing their relationship with task difficulty and performance.",
            "paper-title": "Learning Multimodal Cues of Children\u2019s Uncertainty",
            "image-path": "flux_paper_image/2410.14050_1729542589.png"
        },

        {
            "startTime": "24:37",
            "arxivId": "2410.14481",
            "arxivLink": "https://arxiv.org/abs/2410.14481",
            "title": "AI-Powered Wireless Networks: Intention-Guided Trajectory Generation for Resource Allocation Optimization",
            "institute": "Southwest Jiaotong University, Nanyang Technological University",
            "text": "This research proposes a novel approach to wireless resource allocation optimization by using a generative diffusion model (GDM) guided by wireless network intent (WNI). Unlike traditional deep reinforcement learning (DRL) methods that rely heavily on online deployment and extensive training, this approach leverages offline learning and intent-guided data generation to achieve greater stability and adaptability in dynamic communication systems.",
            "paper-title": "DRL Optimization Trajectory Generation via Wireless Network Intent-Guided Diffusion Models for Optimizing Resource Allocation",
            "image-path": "flux_paper_image/2410.14481_1729544943.png"
        },

        {
            "startTime": "25:04",
            "arxivId": "2410.14411",
            "arxivLink": "https://arxiv.org/abs/2410.14411",
            "title": "Audio Compression Gets a Multi-Scale Makeover: SNAC Makes Music and Speech Sound Better at Lower Bitrates!",
            "institute": "ETH Zurich",
            "text": "This paper introduces a new approach to neural audio compression called Multi-Scale Neural Audio Codec (SNAC). Unlike traditional methods that use a single temporal resolution for quantization, SNAC utilizes a hierarchy of quantizers operating at different temporal resolutions, allowing it to capture both fine and coarse details in audio signals more efficiently.",
            "paper-title": "SNAC: Multi-Scale Neural Audio Codec",
            "image-path": "flux_paper_image/2410.14411_1729544102.png"
        },

        {
            "startTime": "25:27",
            "arxivId": "2410.14485",
            "arxivLink": "https://arxiv.org/abs/2410.14485",
            "title": "AI Gets a Dose of Reality: New Networks Respect Cause and Effect",
            "institute": "University of Lausanne, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
            "text": "This research introduces two new neural network architectures, Causal Fully-Connected Networks (CFCNs) and Causal Transformers (CaTs), which incorporate causal constraints specified by a Directed Acyclic Graph (DAG). This differs from previous work by directly integrating causal knowledge into the model's structure, rather than relying solely on statistical correlations.",
            "paper-title": "CaTs and DAGs: Integrating Directed Acyclic Graphs with Transformers and Fully-Connected Neural Networks for Causally Constrained Predictions",
            "image-path": "flux_paper_image/2410.14485_1729543151.png"
        },

        {
            "startTime": "25:50",
            "arxivId": "2410.14387",
            "arxivLink": "https://arxiv.org/abs/2410.14387",
            "title": "Multilingual Models: Do They Remember Facts Like We Do?",
            "institute": "University of Copenhagen, EPFL",
            "text": "This research investigates how multilingual large language models (LLMs) recall factual knowledge, expanding upon previous work that primarily focused on English-only models. The study examines two different LLM architectures, XGLM and mT5, across ten languages with diverse typological features.",
            "paper-title": "How Do Multilingual Models Remember? Investigating Multilingual Factual Recall Mechanisms",
            "image-path": "flux_paper_image/2410.14387_1729542437.png"
        },

        {
            "startTime": "26:15",
            "arxivId": "2410.14582",
            "arxivLink": "https://arxiv.org/abs/2410.14582",
            "title": "LLMs: Can They Tell When They're Wrong? A New Benchmark Tests Their Uncertainty Estimation Skills!",
            "institute": "University of Cambridge, National University of Singapore, Apple Inc.",
            "text": "This research focuses on evaluating the uncertainty estimation abilities of LLMs specifically in the context of instruction-following tasks, a gap in existing research that primarily focuses on fact-based tasks. The paper introduces a new benchmark dataset with two versions\u2014Controlled and Realistic\u2014designed to provide a comprehensive framework for evaluating uncertainty estimation methods and models under both controlled and real-world conditions.",
            "paper-title": "Do LLMs estimate uncertainty well in instruction-following?",
            "image-path": "flux_paper_image/2410.14582_1729544077.png"
        },

        {
            "startTime": "26:34",
            "arxivId": "2410.14516",
            "arxivLink": "https://arxiv.org/abs/2410.14516",
            "title": "LLMs: They Know When They're Lying, But Can They Follow Instructions?",
            "institute": "University of Cambridge, Apple Inc., University of Pennsylvania",
            "text": "This research delves into the internal workings of LLMs to identify a specific dimension in their input embedding space that's directly linked to instruction-following. Unlike previous work that focused on truthfulness and reducing hallucinations, this study explores how LLMs handle instructions.",
            "paper-title": "Do LLMs\"know\"internally when they follow instructions?",
            "image-path": "flux_paper_image/2410.14516_1729542431.png"
        },

        {
            "startTime": "26:55",
            "arxivId": "2410.14388",
            "arxivLink": "https://arxiv.org/abs/2410.14388",
            "title": "Disease Progression Unraveled: Optimal Transport Makes It Fast and Furious!",
            "institute": "University of Sussex, University College London",
            "text": "This research introduces a new method for modeling disease progression using optimal transport, which allows for faster inference and the ability to handle a much larger number of features compared to previous methods.",
            "paper-title": "Unscrambling disease progression at scale: fast inference of event permutations with optimal transport",
            "image-path": "flux_paper_image/2410.14388_1729544703.png"
        },

        {
            "startTime": "27:16",
            "arxivId": "2410.14660",
            "arxivLink": "https://arxiv.org/abs/2410.14660",
            "title": "LLM-Powered Reward Design: No More Human Feedback, Just Smart Code!",
            "institute": "Tsinghua University",
            "text": "This research introduces CARD, a framework that uses LLMs to iteratively generate and improve reward functions for reinforcement learning tasks. Unlike previous methods that rely on human feedback or numerous LLM queries, CARD utilizes a dynamic feedback mechanism to guide the LLM in refining the reward function code.",
            "paper-title": "A Large Language Model-Driven Reward Design Framework via Dynamic Feedback for Reinforcement Learning",
            "image-path": "flux_paper_image/2410.14660_1729543810.png"
        },

        {
            "startTime": "27:43",
            "arxivId": "2410.13915",
            "arxivLink": "https://arxiv.org/abs/2410.13915",
            "title": "AI Manipulation: Building a Sandbox to Fight Fake News",
            "institute": "Mila, Universit\u00e9 de Montr\u00e9al, Axiom Futures...",
            "text": "This research introduces a simulation environment that integrates a real social media platform (Mastodon) with a framework for simulating agents' online interactions. This allows for more realistic and scalable testing of defenses against AI-driven manipulation.",
            "paper-title": "A Simulation System Towards Solving Societal-Scale Manipulation",
            "image-path": "flux_paper_image/2410.13915_1729544095.png"
        },

        {
            "startTime": "28:08",
            "arxivId": "2410.14171",
            "arxivLink": "https://arxiv.org/abs/2410.14171",
            "title": "Diffusion Models Go Wild: Taming Heavy Tails for Extreme Weather Forecasting",
            "institute": "UC Irvine, Nvidia",
            "text": "This research introduces a new framework for diffusion models that uses multivariate Student-t distributions instead of Gaussian distributions as the base noise distribution. This allows the models to capture heavy-tailed behavior, which is important for modeling rare or extreme events. This approach is different from previous work that focused on learning a mapping from a heavy-tailed prior to the target distribution.",
            "paper-title": "Heavy-Tailed Diffusion Models",
            "image-path": "flux_paper_image/2410.14171_1729544659.png"
        },

        {
            "startTime": "28:44",
            "arxivId": "2410.14185",
            "arxivLink": "https://arxiv.org/abs/2410.14185",
            "title": "ECG Printouts to Digital Signals: A Deep Learning Rescue Mission!",
            "institute": "University of Oxford",
            "text": "This research combines traditional image processing techniques like the Hough transform with deep learning (specifically, nnU-Net) to reconstruct ECG signals from printouts. This approach differs from previous work by using a single model for the entire image, rather than relying on pre-processing steps like grid removal or region of interest detection.",
            "paper-title": "Combining Hough Transform and Deep Learning Approaches to Reconstruct ECG Signals From Printouts",
            "image-path": "flux_paper_image/2410.14185_1729544393.png"
        },

        {
            "startTime": "29:05",
            "arxivId": "2410.14591",
            "arxivLink": "https://arxiv.org/abs/2410.14591",
            "title": "Neural Networks: From Weights to Measures, a Lipschitz Journey!",
            "institute": "Delft University of Technology, University of Twente, University of Bath...",
            "text": "This research explores a new way to represent shallow neural networks using signed measures on unbounded parameter spaces. It leverages the Kantorovich-Rubinstein norm, which is defined by duality with Lipschitz functions, to measure complexity and regularization. This approach differs from previous work that relied on the Riesz-Markov duality and weighted \u21131 norms.",
            "paper-title": "A Lipschitz spaces view of infinitely wide shallow neural networks",
            "image-path": "flux_paper_image/2410.14591_1729543734.png"
        },

        {
            "startTime": "29:34",
            "arxivId": "2410.14544",
            "arxivLink": "https://arxiv.org/abs/2410.14544",
            "title": "Robots on Trial: Who's to Blame When AI Makes Mistakes?",
            "institute": "University of Oxford, Institut de Recherche en Informatique de Toulouse, Sapienza University of Rome",
            "text": "This research explores responsibility attribution and anticipation in AI systems using Linear Temporal Logic on finite traces (LTLf). It differs from previous work by focusing on strategic settings and incorporating notions of dominance and best-effort strategies, which are relevant to responsibility.",
            "paper-title": "Computational Grounding of Responsibility Attribution and Anticipation in LTLf",
            "image-path": "flux_paper_image/2410.14544_1729544066.png"
        },

        {
            "startTime": "30:07",
            "arxivId": "2410.13924",
            "arxivLink": "https://arxiv.org/abs/2410.13924",
            "title": "ARKitLabelMaker: Turning Phones into 3D Scene Labeling Machines!",
            "institute": "ETH Zurich, University of Bonn",
            "text": "This research introduces ARKitLabelMaker, a large-scale, real-world 3D dataset with dense semantic annotations. Unlike previous datasets, ARKitLabelMaker uses an automated pipeline to generate these annotations, making it more scalable and efficient.",
            "paper-title": "ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding",
            "image-path": "flux_paper_image/2410.13924_1729543581.png"
        },

        {
            "startTime": "30:27",
            "arxivId": "2410.14629",
            "arxivLink": "https://arxiv.org/abs/2410.14629",
            "title": "SIMformer: A Single-Layer Transformer That Can Learn Trajectory Similarity Without Breaking a Sweat!",
            "institute": "University of Tokyo, Osaka University",
            "text": "This research proposes a novel approach to trajectory similarity learning by using a single-layer vanilla transformer encoder and tailored representation similarity functions. Unlike previous methods that rely on Euclidean distance, this approach addresses the curse of dimensionality by customizing the similarity function based on the specific distance measure being approximated.",
            "paper-title": "SIMformer: Single-Layer Vanilla Transformer Can Learn Free-Space Trajectory Similarity",
            "image-path": "flux_paper_image/2410.14629_1729542943.png"
        },

        {
            "startTime": "30:49",
            "arxivId": "2410.14639",
            "arxivLink": "https://arxiv.org/abs/2410.14639",
            "title": "Manifold Madness: Neural Networks Go Geometric!",
            "institute": "Boise State University, UC Los Angeles, Yale University",
            "text": "This paper introduces a new framework called \"Manifold Filter-Combine Networks\" (MFCNs) for understanding manifold neural networks (MNNs). Unlike previous work that focused on 2D surfaces, MFCNs can be applied to higher-dimensional manifolds. The paper also proves that the method is consistent, meaning it converges to a continuum limit as the number of data points increases.",
            "paper-title": "Convergence of Manifold Filter-Combine Networks",
            "image-path": "flux_paper_image/2410.14639_1729542950.png"
        },

        {
            "startTime": "31:14",
            "arxivId": "2410.14340",
            "arxivLink": "https://arxiv.org/abs/2410.14340",
            "title": "Zero-Shot Action Localization: AI Now Knows When to \"Swing\" and \"Dunk\" Without Ever Seeing It!",
            "institute": "Stanford University",
            "text": "This research introduces a novel method for zero-shot action localization that leverages the knowledge of large language models (LLMs) to decompose actions into detailed descriptions. These descriptions are then used as queries for a large vision-language model (LVLM) to generate frame-level confidence scores, which are aggregated to produce localization outputs. This approach differs from previous work by relying on the inherent action knowledge of LLMs rather than requiring supervised training on action localization datasets.",
            "paper-title": "Zero-shot Action Localization via the Confidence of Large Vision-Language Models",
            "image-path": "flux_paper_image/2410.14340_1729543448.png"
        },

        {
            "startTime": "31:42",
            "arxivId": "2410.14548",
            "arxivLink": "https://arxiv.org/abs/2410.14548",
            "title": "K-means Clustering for Big Data: A Shaking Good Time!",
            "institute": "University of Washington",
            "text": "This research proposes a new algorithm, BigVNSClust, that combines data streaming with global optimization to improve the efficiency of K-means clustering for big data. It differs from previous work by using a Variable Neighborhood Search (VNS) metaheuristic to explore partial solution landscapes derived from random samples of the original dataset.",
            "paper-title": "Boosting K-means for Big Data by Fusing Data Streaming with Global Optimization",
            "image-path": "flux_paper_image/2410.14548_1729543923.png"
        },

        {
            "startTime": "32:04",
            "arxivId": "2410.14659",
            "arxivLink": "https://arxiv.org/abs/2410.14659",
            "title": "Reinforcement Learning Gets a Bagged Makeover: Tackling Non-Markovian Decisions with a Causal Twist!",
            "institute": "Harvard University, Allen Institute, University of Michigan",
            "text": "This research introduces a new framework for reinforcement learning (RL) that handles non-Markovian and non-stationary transitions within a sequence of consecutive decision times, called \"bags.\" Unlike previous work, it leverages expert-provided causal directed acyclic graphs (DAGs) to construct states that ensure Markov transitions within and across bags.",
            "paper-title": "Harnessing Causality in Reinforcement Learning With Bagged Decision Times",
            "image-path": "flux_paper_image/2410.14659_1729544666.png"
        },

        {
            "startTime": "32:27",
            "arxivId": "2410.14615",
            "arxivLink": "https://arxiv.org/abs/2410.14615",
            "title": "Change Detection: Unnormalized Data? No Problem!",
            "institute": "Princeton University, University of Pittsburgh, Duke University",
            "text": "This paper tackles the challenge of change detection when only unnormalized pre- and post-change distributions are available, a common scenario in physics and machine learning. Unlike previous methods that rely on normalized distributions, this research utilizes thermodynamic integration (TI) to estimate the log-ratio of normalizing constants, offering an unbiased estimator with bounded variance.",
            "paper-title": "Asymptotically Optimal Change Detection for Unnormalized Pre- and Post-Change Distributions",
            "image-path": "flux_paper_image/2410.14615_1729542459.png"
        },

        {
            "startTime": "32:48",
            "arxivId": "2410.13956",
            "arxivLink": "https://arxiv.org/abs/2410.13956",
            "title": "Foundation Models Flunk Biology Class: Simple Tools Ace Perturbation Analysis",
            "institute": "Valence Labs, Recursion, \u00c9cole Normale Sup\u00e9rieure",
            "text": "This research introduces a new benchmark for evaluating the performance of transcriptomics foundation models on perturbation analysis tasks. It differs from previous work by focusing specifically on how well these models can understand and predict the effects of biological interventions, such as gene knockouts or drug treatments.",
            "paper-title": "Benchmarking Transcriptomics Foundation Models for Perturbation Analysis : one PCA still rules them all",
            "image-path": "flux_paper_image/2410.13956_1729544752.png"
        },

        {
            "startTime": "33:08",
            "arxivId": "2410.14466",
            "arxivLink": "https://arxiv.org/abs/2410.14466",
            "title": "Flow-Based Sampling: Entanglement Entropy Gets a Neural Network Makeover!",
            "institute": "University of Turin, INFN, The Cyprus Institute...",
            "text": "This research introduces a novel technique for calculating entanglement entropy using generative models, specifically normalizing flows, which are trained to focus on a localized region near a lattice defect. This approach differs from previous methods that relied on Monte Carlo simulations or tensor networks.",
            "paper-title": "Flow-based Sampling for Entanglement Entropy and the Machine Learning of Defects",
            "image-path": "flux_paper_image/2410.14466_1729544488.png"
        },

        {
            "startTime": "33:28",
            "arxivId": "2410.14483",
            "arxivLink": "https://arxiv.org/abs/2410.14483",
            "title": "Causal Uncertainty: A Spectral Symphony for Smarter Decisions",
            "institute": "University College London",
            "text": "This research introduces a novel method, IMPspec, for quantifying causal uncertainty. Unlike previous approaches that rely on restrictive nuclear dominant kernels, IMPspec leverages a spectral representation of the Hilbert space to avoid these limitations and achieve more accurate uncertainty estimates.",
            "paper-title": "Spectral Representations for Accurate Causal Uncertainty Quantification with Gaussian Processes",
            "image-path": "flux_paper_image/2410.14483_1729543710.png"
        },

        {
            "startTime": "34:01",
            "arxivId": "2410.13947",
            "arxivLink": "https://arxiv.org/abs/2410.13947",
            "title": "Machine Learning Gets a Physics Makeover: Contrastive Learning Tackles Mismodeling!",
            "institute": "MIT, University of Pennsylvania",
            "text": "This research introduces a new method called MACK (Mismodeling Addressed with Contrastive Knowledge) that uses contrastive learning to improve the performance of machine learning models in high energy physics. Unlike previous methods, MACK doesn't require prior knowledge of the specific mismodeling issues.",
            "paper-title": "MACK: Mismodeling Addressed with Contrastive Knowledge",
            "image-path": "flux_paper_image/2410.13947_1729542444.png"
        },

        {
            "startTime": "34:22",
            "arxivId": "2410.14001",
            "arxivLink": "https://arxiv.org/abs/2410.14001",
            "title": "Personalized Language Models: Learning Your Preferences One Chat at a Time!",
            "institute": "University of Toronto, Stanford University",
            "text": "This research proposes a new approach called Preference Pretrained Transformer (PPT) for personalizing language models. Unlike previous methods that train separate models for each user preference, PPT uses in-context learning to adapt a single model to individual preferences during online interactions.",
            "paper-title": "Personalized Adaptation via In-Context Preference Learning",
            "image-path": "flux_paper_image/2410.14001_1729544635.png"
        },

        {
            "startTime": "34:50",
            "arxivId": "2410.13919",
            "arxivLink": "https://arxiv.org/abs/2410.13919",
            "title": "AI Hackers, Beware! Honeypot Catches Bots Red-Handed",
            "institute": "Palisade Research",
            "text": "This research introduces a honeypot specifically designed to identify and analyze AI-driven hacking agents, unlike previous work that focused on using AI to improve traditional honeypots.",
            "paper-title": "LLM Agent Honeypot: Monitoring AI Hacking Agents in the Wild",
            "image-path": "flux_paper_image/2410.13919_1729543400.png"
        },

        {
            "startTime": "35:09",
            "arxivId": "2410.13925",
            "arxivLink": "https://arxiv.org/abs/2410.13925",
            "title": "FiTv2: The Vision Transformer That Can See Any Size Image!",
            "institute": "Shanghai AI Laboratory, Chinese University of Hong Kong, Shanghai Jiao Tong University...",
            "text": "This research introduces a new way to train vision transformers for image generation. Instead of treating images as fixed-resolution grids, it conceptualizes them as sequences of tokens with dynamic sizes. This allows the model to generate images at arbitrary resolutions and aspect ratios without being limited by the training data.",
            "paper-title": "FiTv2: Scalable and Improved Flexible Vision Transformer for Diffusion Model",
            "image-path": "flux_paper_image/2410.13925_1729543410.png"
        },

        {
            "startTime": "35:43",
            "arxivId": "2410.13984",
            "arxivLink": "https://arxiv.org/abs/2410.13984",
            "title": "LLMs: Better at Math Than Poetry? Quantifiers Reveal a Surprising Truth!",
            "institute": "Yale University, Columbia University, Brown University...",
            "text": "This study investigates whether large language models (LLMs) are truly models of distributional semantics by examining their performance on quantifiers, specifically comparing their ability to handle vague quantifiers like \"many\" versus exact quantifiers like \"more than half.\" Previous research has often assumed that LLMs excel at capturing graded meanings based on linguistic conventions, but this study finds the opposite.",
            "paper-title": "Are LLMs Models of Distributional Semantics? A Case Study on Quantifiers",
            "image-path": "flux_paper_image/2410.13984_1729544413.png"
        },

        {
            "startTime": "36:02",
            "arxivId": "2410.13899",
            "arxivLink": "https://arxiv.org/abs/2410.13899",
            "title": "AI Security: It's Not Just About the Bots, It's About the Cloud Too!",
            "institute": "IBM",
            "text": "This research goes beyond the usual focus on securing LLMs themselves, offering a holistic approach that includes securing the cloud platforms where these LLMs are hosted.",
            "paper-title": "Security of and by Generative AI platforms",
            "image-path": "flux_paper_image/2410.13899_1729544778.png"
        },

        {
            "startTime": "36:18",
            "arxivId": "2410.14262",
            "arxivLink": "https://arxiv.org/abs/2410.14262",
            "title": "AI Parents: LLMs Learn to Spot and Fix Their Own Lies!",
            "institute": "Harvard University",
            "text": "This research explores the use of multi-agent workflows to detect and correct hallucinations in AI-generated content. Unlike previous studies that focus on isolated detection or correction tasks, this paper examines how these processes can be orchestrated within a multi-agent framework.",
            "paper-title": "Good Parenting is all you need -- Multi-agentic LLM Hallucination Mitigation",
            "image-path": "flux_paper_image/2410.14262_1729543077.png"
        }
    ],
    "stats": {
        "num_pick": 86,
        "num_total": 342,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202410211419_audio.mp3"
}

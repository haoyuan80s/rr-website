
daily_data = {
    "date": "2024-09-30",
    "tweets": [
            {
                "startTime": "01:00",
                "arxivId": "2409.18314",
                "arxivLink": "https://arxiv.org/abs/2409.18314",
                "title": "Model Merging: A Recipe for Generalization, But Don't Overcook It!",
                "institute": "University of Toronto",
                "text": "This research focuses on evaluating the ability of model merging to achieve compositional generalization, a more realistic goal than simply improving performance on tasks the constituent models were trained on. It benchmarks different merging methods across image classification, image generation, and natural language processing, providing a comprehensive and unified evaluation setup.",
                "paper-title": "Realistic Evaluation of Model Merging for Compositional Generalization",
                "image-path": "flux_paper_image/2409.18314_1727725798.png"
            },

            {
                "startTime": "01:29",
                "arxivId": "2409.18428",
                "arxivLink": "https://arxiv.org/abs/2409.18428",
                "title": "Multilingual Speech Recognition: A Simple Trick for Big Gains!",
                "institute": "Meta, CMU",
                "text": "This research proposes a novel N-best re-ranking approach for multilingual Automatic Speech Recognition (ASR) systems. Unlike previous work that focuses on improving the spoken language identification (SLID) model itself, this paper leverages external features like language models and text-based language identification models to re-rank the ASR outputs, effectively mitigating the impact of SLID errors.",
                "paper-title": "Improving Multilingual ASR in the Wild Using Simple N-best Re-ranking",
                "image-path": "flux_paper_image/2409.18428_1727724084.png"
            },

            {
                "startTime": "01:49",
                "arxivId": "2409.18209",
                "arxivLink": "https://arxiv.org/abs/2409.18209",
                "title": "Unnormalized Distributions: A Unified View Through the Lens of NCE",
                "institute": "MIT",
                "text": "This paper provides a unified perspective on various methods for learning unnormalized distributions, which have been independently proposed and studied in separate research communities, through the lens of Noise-Contrastive Estimation (NCE).",
                "paper-title": "A Unified View on Learning Unnormalized Distributions via Noise-Contrastive Estimation",
                "image-path": "flux_paper_image/2409.18209_1727724898.png"
            },

            {
                "startTime": "02:09",
                "arxivId": "2409.18475",
                "arxivLink": "https://arxiv.org/abs/2409.18475",
                "title": "Data Analysis Gets a Makeover: AI Makes It Easy Peasy!",
                "institute": "Microsoft",
                "text": "This research explores how generative AI can be used to enhance the entire data analysis workflow, going beyond just code generation and focusing on user-centered design principles. It differs from previous work by examining how AI can assist with tasks like data discovery, hypothesis exploration, and report generation.",
                "paper-title": "Data Analysis in the Era of Generative AI",
                "image-path": "flux_paper_image/2409.18475_1727724037.png"
            },

            {
                "startTime": "02:27",
                "arxivId": "2409.18216",
                "arxivLink": "https://arxiv.org/abs/2409.18216",
                "title": "Instruction Following: A Multimodal, Multi-Turn Chat Challenge for LLMs",
                "institute": "Stanford University, Google",
                "text": "This research introduces a new benchmark, MMMT-IF, for evaluating instruction following capabilities of large language models (LLMs) in a multimodal, multi-turn dialogue setting. Unlike previous work that focuses on single-turn or text-based evaluations, MMMT-IF incorporates images and multiple instructions dispersed across a conversation, making it more challenging and realistic.",
                "paper-title": "MMMT-IF: A Challenging Multimodal Multi-Turn Instruction Following Benchmark",
                "image-path": "flux_paper_image/2409.18216_1727724434.png"
            },

            {
                "startTime": "02:51",
                "arxivId": "2409.18582",
                "arxivLink": "https://arxiv.org/abs/2409.18582",
                "title": "Protein Design: A Game of Amino Acid Chess!",
                "institute": "Google, Max Planck Society, ETH Zurich",
                "text": "This research introduces GAMEOPT, a novel game-theoretical approach to combinatorial Bayesian optimization. Unlike previous methods that struggle with large, unstructured search spaces, GAMEOPT defines a cooperative game between the variables, allowing for efficient computation of game equilibria as candidate evaluation points.",
                "paper-title": "Optimistic Games for Combinatorial Bayesian Optimization with Application to Protein Design",
                "image-path": "flux_paper_image/2409.18582_1727724164.png"
            },

            {
                "startTime": "03:13",
                "arxivId": "2409.18313",
                "arxivLink": "https://arxiv.org/abs/2409.18313",
                "title": "Robots Get Memories: Embodied-RAG Gives Bots a Brain Boost!",
                "institute": "CMU",
                "text": "This research introduces Embodied-RAG, a framework that builds a hierarchical memory system for embodied agents, allowing them to store and retrieve experiences at different levels of detail. This differs from previous work by addressing the challenges of applying retrieval-augmented generation (RAG) to the embodied domain, which involves multimodal data, correlated experiences, and varying levels of perception.",
                "paper-title": "Embodied-RAG: General non-parametric Embodied Memory for Retrieval and Generation",
                "image-path": "flux_paper_image/2409.18313_1727724005.png"
            },

            {
                "startTime": "03:36",
                "arxivId": "2409.18390",
                "arxivLink": "https://arxiv.org/abs/2409.18390",
                "title": "From Speech to Stuff: Robots Build Your Words!",
                "institute": "MIT",
                "text": "This research combines 3D generative AI with discrete robotic assembly, using voxels as building blocks, to create physical objects directly from speech input. This differs from previous work that primarily focused on 3D printing or CNC machining of smaller objects.",
                "paper-title": "Speech to Reality: On-Demand Production using Natural Language, 3D Generative AI, and Discrete Robotic Assembly",
                "image-path": "flux_paper_image/2409.18390_1727723793.png"
            },

            {
                "startTime": "03:55",
                "arxivId": "2409.18653",
                "arxivLink": "https://arxiv.org/abs/2409.18653",
                "title": "SAM2: The Camouflage-Busting Vision Model",
                "institute": "ETH Zurich, University of Zurich, University of Bologna",
                "text": "This research explores the application of the Segment Anything Model 2 (SAM2) for video camouflaged object segmentation (VCOS), a task that involves identifying objects that blend seamlessly into their surroundings in videos. Unlike previous work that focused on static images, this study investigates SAM2's performance in dynamic scenarios, where both objects and backgrounds can change over time.",
                "paper-title": "When SAM2 Meets Video Camouflaged Object Segmentation: A Comprehensive Evaluation and Adaptation",
                "image-path": "flux_paper_image/2409.18653_1727723566.png"
            },

            {
                "startTime": "04:19",
                "arxivId": "2409.18431",
                "arxivLink": "https://arxiv.org/abs/2409.18431",
                "title": "Search3D: Giving 3D Scenes a Brain for Open-Vocabulary Queries!",
                "institute": "ETH Zurich",
                "text": "This research introduces Search3D, a hierarchical open-vocabulary 3D segmentation method that goes beyond object-level queries to understand finer-grained scene entities like object parts and attributes. Unlike previous methods that focus on object-centric representations, Search3D builds a hierarchical scene graph representation, enabling more flexible and granular queries.",
                "paper-title": "Search3D: Hierarchical Open-Vocabulary 3D Segmentation",
                "image-path": "flux_paper_image/2409.18431_1727724824.png"
            },

            {
                "startTime": "04:39",
                "arxivId": "2409.18876",
                "arxivLink": "https://arxiv.org/abs/2409.18876",
                "title": "Face Recognition's New Trick: Generating Faces That Look *Almost* Like You!",
                "institute": "Queen Mary University of London, University of Cambridge",
                "text": "This research proposes a new method for generating synthetic faces that are more discriminative for training face recognition models. Unlike previous approaches that focused on generating diverse styles, this method focuses on generating faces with varying levels of similarity to the original image, creating \"semi-hard\" samples that are more effective for training.",
                "paper-title": "CemiFace: Center-based Semi-hard Synthetic Face Generation for Face Recognition",
                "image-path": "flux_paper_image/2409.18876_1727723441.png"
            },

            {
                "startTime": "05:04",
                "arxivId": "2409.18614",
                "arxivLink": "https://arxiv.org/abs/2409.18614",
                "title": "Meta-Surfaces: The New Convolutional Kernel Kings!",
                "institute": "Tsinghua University",
                "text": "This research introduces a novel frequency domain training method for creating large, arbitrary analog convolution kernels using metasurfaces. This approach differs from previous work by enabling the generation of kernels with both positive and negative weights, which is crucial for complex machine vision tasks.",
                "paper-title": "Metasurface-generated large and arbitrary analog convolution kernels for accelerated machine vision",
                "image-path": "flux_paper_image/2409.18614_1727724347.png"
            },

            {
                "startTime": "05:25",
                "arxivId": "2409.18326",
                "arxivLink": "https://arxiv.org/abs/2409.18326",
                "title": "Tired of Manually Measuring Melt Tracks? This AI Does It for You!",
                "institute": "Massachusetts Institute of Technology, University of Illinois at Urbana-Champaign",
                "text": "This research introduces a U-Net neural network specifically designed to automatically segment and analyze microscopy images of laser powder bed fusion melt tracks, a task previously done manually.",
                "paper-title": "Automated Segmentation and Analysis of Microscopy Images of Laser Powder Bed Fusion Melt Tracks",
                "image-path": "flux_paper_image/2409.18326_1727725933.png"
            },

            {
                "startTime": "05:44",
                "arxivId": "2409.18203",
                "arxivLink": "https://arxiv.org/abs/2409.18203",
                "title": "Mapping Out AI's Wildest Behavior: A New Tool for Taming Language Models",
                "institute": "Stanford University, Apple Inc., CMU",
                "text": "This research introduces a novel approach to designing AI policies for large language models (LLMs) by drawing inspiration from mapmaking. Unlike previous methods that focus on defining principles or using past cases, this approach emphasizes explicitly representing policy coverage over an unbounded space of model behaviors.",
                "paper-title": "AI Policy Projector: Grounding LLM Policy Design in Iterative Mapmaking",
                "image-path": "flux_paper_image/2409.18203_1727725661.png"
            },

            {
                "startTime": "06:08",
                "arxivId": "2409.18462",
                "arxivLink": "https://arxiv.org/abs/2409.18462",
                "title": "Brain Waves to Blood Flow: A New Way to Translate Brain Signals!",
                "institute": "Yale University, Mila - Quebec AI Institute, Universit\u00e9 de Montr\u00b4eal...",
                "text": "This research introduces a novel framework called SAMBA, which translates between electrophysiological signals (like EEG) and hemodynamic signals (like fMRI) by learning a unified latent space. Unlike previous work that focused on enhancing fMRI signals with EEG, SAMBA aims to bridge the spatial and temporal resolution gaps between these modalities.",
                "paper-title": "Latent Representation Learning for Multimodal Brain Activity Translation",
                "image-path": "flux_paper_image/2409.18462_1727723586.png"
            },

            {
                "startTime": "06:29",
                "arxivId": "2409.18330",
                "arxivLink": "https://arxiv.org/abs/2409.18330",
                "title": "AI Goes Blind: New Benchmark Tests Robots' Vision in Distracting Worlds",
                "institute": "Google",
                "text": "This research introduces a new dataset, DMC-VB, specifically designed to evaluate how well offline reinforcement learning agents can handle visual distractions. Unlike previous datasets, DMC-VB includes a variety of tasks, distractors, and data quality levels, making it a more comprehensive benchmark for testing the robustness of visual representation learning methods.",
                "paper-title": "DMC-VB: A Benchmark for Representation Learning for Control with Visual Distractors",
                "image-path": "flux_paper_image/2409.18330_1727724460.png"
            },

            {
                "startTime": "06:52",
                "arxivId": "2409.18333",
                "arxivLink": "https://arxiv.org/abs/2409.18333",
                "title": "Similarity Measures: A Framework for Keeping It Real (and Consistent)",
                "institute": "MIT",
                "text": "This research tackles the growing problem of inconsistent naming and implementation conventions for similarity measures, which are used to compare artificial and biological systems. The authors propose a framework for standardizing these measures, creating a repository that benchmarks and validates them.",
                "paper-title": "A Framework for Standardizing Similarity Measures in a Rapidly Evolving Field",
                "image-path": "flux_paper_image/2409.18333_1727724384.png"
            },

            {
                "startTime": "07:16",
                "arxivId": "2409.18303",
                "arxivLink": "https://arxiv.org/abs/2409.18303",
                "title": "Deep Learning Speeds Up Brain Scans by 600 Times!",
                "institute": "Massachusetts General Hospital, Harvard Medical School, Medical University of Vienna...",
                "text": "This research introduces a deep learning model called Deep-ER for reconstructing Magnetic Resonance Spectroscopic Imaging (MRSI) data acquired using the ECCENTRIC pulse sequence. Unlike previous work, Deep-ER operates on non-Cartesian k-space data and reconstructs each time point independently, making it more flexible and generalizable.",
                "paper-title": "Deep-ER: Deep Learning ECCENTRIC Reconstruction for fast high-resolution neurometabolic imaging",
                "image-path": "flux_paper_image/2409.18303_1727723550.png"
            },

            {
                "startTime": "07:36",
                "arxivId": "2409.18901",
                "arxivLink": "https://arxiv.org/abs/2409.18901",
                "title": "Visual Object Tracking Gets a Prompting Makeover: CLIP to the Rescue!",
                "institute": "National Yang Ming Chiao Tung University, Academia Sinica",
                "text": "This research introduces a novel visual prompting mechanism for generic object tracking. Unlike previous methods that rely on predefined language descriptors, this approach leverages the zero-shot capability of CLIP to automatically generate and refine visual prompts, enabling the tracker to adapt to new targets and handle unseen objects.",
                "paper-title": "Improving Visual Object Tracking through Visual Prompting",
                "image-path": "flux_paper_image/2409.18901_1727725493.png"
            },

            {
                "startTime": "08:02",
                "arxivId": "2409.18290",
                "arxivLink": "https://arxiv.org/abs/2409.18290",
                "title": "AI Doctor's In-Basket: Can GPT-4 Handle Prostate Cancer Queries?",
                "institute": "Mayo Clinic",
                "text": "This research focuses on evaluating a specialized Large Language Model (LLM) called RadOnc-GPT, trained specifically for prostate cancer, to generate responses to patient inquiries within an electronic health record (EHR) messaging system. Unlike previous studies that applied LLMs across various disease sites, this study focuses on a specific disease domain, allowing for more accurate and relevant responses.",
                "paper-title": "Retrospective Comparative Analysis of Prostate Cancer In-Basket Messages: Responses from Closed-Domain LLM vs. Clinical Teams",
                "image-path": "flux_paper_image/2409.18290_1727724368.png"
            },

            {
                "startTime": "08:19",
                "arxivId": "2409.18339",
                "arxivLink": "https://arxiv.org/abs/2409.18339",
                "title": "LLMs Feeling Ambiguous: Can AI Understand Our Mixed Emotions?",
                "institute": "University of Melbourne, MIT, University of New South Wales",
                "text": "This research explores the ability of Large Language Models (LLMs) to recognize ambiguous emotions, a concept often overlooked in previous studies. Unlike prior work focusing on single emotion labels, this paper investigates how LLMs can understand and predict the complex, multi-faceted nature of human emotions.",
                "paper-title": "AER-LLM: Ambiguity-aware Emotion Recognition Leveraging Large Language Models",
                "image-path": "flux_paper_image/2409.18339_1727724578.png"
            },

            {
                "startTime": "08:43",
                "arxivId": "2409.18319",
                "arxivLink": "https://arxiv.org/abs/2409.18319",
                "title": "LLMs Get Structured: Lung Cancer Reports Go From Free-Text to Fancy JSON!",
                "institute": "Rensselaer Polytechnic Institute, Wake Forest University, Massachusetts General Hospital...",
                "text": "This research focuses on using large language models (LLMs) to automatically create structured radiology reports for lung cancer screening, a task that has been challenging due to formatting errors and content hallucinations. The authors propose a dynamic template-constrained decoding method to address these issues, which consistently improves the performance of open-source LLMs on cross-institutional datasets.",
                "paper-title": "Cross-Institutional Structured Radiology Reporting for Lung Cancer Screening Using a Dynamic Template-Constrained Large Language Model",
                "image-path": "flux_paper_image/2409.18319_1727724466.png"
            },

            {
                "startTime": "09:08",
                "arxivId": "2409.18961",
                "arxivLink": "https://arxiv.org/abs/2409.18961",
                "title": "ProMerge: Unsupervised Instance Segmentation Gets a Speed Boost!",
                "institute": "University of Oxford",
                "text": "This paper proposes ProMerge, a new method for unsupervised instance segmentation that uses self-supervised visual features to generate initial groupings of patches and then merges them iteratively. This approach differs from previous methods that rely on computationally intensive normalized-cut algorithms.",
                "paper-title": "ProMerge: Prompt and Merge for Unsupervised Instance Segmentation",
                "image-path": "flux_paper_image/2409.18961_1727723986.png"
            },

            {
                "startTime": "09:27",
                "arxivId": "2409.18827",
                "arxivLink": "https://arxiv.org/abs/2409.18827",
                "title": "RL Hyperparameter Tuning: A Benchmark That's Actually Fast!",
                "institute": "Leibniz University Hannover, RWTH Aachen University, University of Freiburg...",
                "text": "This research introduces ARLBench, a benchmark for hyperparameter optimization (HPO) in reinforcement learning (RL) that focuses on efficiency and flexibility. Unlike previous benchmarks, ARLBench allows for large configuration spaces and supports dynamic hyperparameter schedules, making it more representative of real-world HPO applications.",
                "paper-title": "ARLBench: Flexible and Efficient Benchmarking for Hyperparameter Optimization in Reinforcement Learning",
                "image-path": "flux_paper_image/2409.18827_1727725792.png"
            },

            {
                "startTime": "09:54",
                "arxivId": "2409.18680",
                "arxivLink": "https://arxiv.org/abs/2409.18680",
                "title": "AI Gets Two Ears: New Model Listens to Multiple Audios at Once!",
                "institute": "National University of Singapore, A*STAR, Polytechnic University of Madrid...",
                "text": "This research introduces the first multi-audio benchmark (MAE) for evaluating audio large language models (ALLMs). Previous work primarily focused on single-audio tasks, while MAE assesses the ability of ALLMs to process multiple audio streams simultaneously.",
                "paper-title": "Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models",
                "image-path": "flux_paper_image/2409.18680_1727725953.png"
            },

            {
                "startTime": "10:22",
                "arxivId": "2409.18401",
                "arxivLink": "https://arxiv.org/abs/2409.18401",
                "title": "Texturing 3D Models: A New Way to Make Textures Look Real!",
                "institute": "Zhejiang University, Tencent IEG, University College London",
                "text": "This research introduces a novel local attention mechanism that leverages 3D priors to improve the consistency and quality of textures generated for 3D models. Unlike previous methods that rely on global attention or independent view generation, this approach focuses on enhancing local details while preserving cross-view consistency.",
                "paper-title": "GenesisTex2: Stable, Consistent and High-Quality Text-to-Texture Generation",
                "image-path": "flux_paper_image/2409.18401_1727723556.png"
            },

            {
                "startTime": "10:45",
                "arxivId": "2409.18486",
                "arxivLink": "https://arxiv.org/abs/2409.18486",
                "title": "OpenAI's o1: Can This AI Actually Think?",
                "institute": "University of Alberta, University of Georgia, Northwestern Polytechnical University...",
                "text": "This research evaluates OpenAI's o1 model on a diverse set of complex reasoning tasks, going beyond standard benchmarks. The study focuses on o1's ability to handle multi-step reasoning problems across various domains, including coding, mathematics, science, and medicine. This approach differs from previous work by emphasizing the model's reasoning capabilities rather than solely focusing on its ability to generate human-like text.",
                "paper-title": "Evaluation of OpenAI o1: Opportunities and Challenges of AGI",
                "image-path": "flux_paper_image/2409.18486_1727723999.png"
            },

            {
                "startTime": "11:13",
                "arxivId": "2409.18842",
                "arxivLink": "https://arxiv.org/abs/2409.18842",
                "title": "Overfitting's New Trick: It's Not Always Bad, But It Depends!",
                "institute": "University of Cambridge",
                "text": "This paper explores how the bias-variance tradeoff, a fundamental concept in statistics, changes when we move from evaluating models on the same data they were trained on (in-sample) to evaluating them on new, unseen data (out-of-sample).",
                "paper-title": "Classical Statistical (In-Sample) Intuitions Don't Generalize Well: A Note on Bias-Variance Tradeoffs, Overfitting and Moving from Fixed to Random Designs",
                "image-path": "flux_paper_image/2409.18842_1727725292.png"
            },

            {
                "startTime": "11:31",
                "arxivId": "2409.18201",
                "arxivLink": "https://arxiv.org/abs/2409.18201",
                "title": "Loop-Diffusion: A Protein Loop Whisperer Learns to Score and Design!",
                "institute": "University of Washington",
                "text": "This research introduces Loop-Diffusion, a diffusion model trained on a dataset of protein loops to learn an energy function that can be used to predict the effects of mutations on protein function. This approach differs from previous work by focusing specifically on loops, which are often responsible for protein function, and by leveraging a large dataset of general protein loops to learn a more generalizable energy function.",
                "paper-title": "Loop-Diffusion: an equivariant diffusion model for designing and scoring protein loops",
                "image-path": "flux_paper_image/2409.18201_1727724327.png"
            },

            {
                "startTime": "11:54",
                "arxivId": "2409.18448",
                "arxivLink": "https://arxiv.org/abs/2409.18448",
                "title": "Taming the Wild Model Drift: A Multi-Timescale Gradient Correction for Hierarchical Federated Learning",
                "institute": "Purdue University, Yonsei University, IBM",
                "text": "This paper proposes a novel multi-timescale gradient correction (MTGC) method for hierarchical federated learning (HFL). Unlike previous HFL algorithms, MTGC introduces distinct control variables to correct model drift at multiple levels of the hierarchy, addressing the challenge of multi-timescale model drift caused by data heterogeneity.",
                "paper-title": "Hierarchical Federated Learning with Multi-Timescale Gradient Correction",
                "image-path": "flux_paper_image/2409.18448_1727724274.png"
            },

            {
                "startTime": "12:22",
                "arxivId": "2409.18324",
                "arxivLink": "https://arxiv.org/abs/2409.18324",
                "title": "GPU Power: It's Not Just About the Hardware, It's About the Data!",
                "institute": "University of Washington, Microsoft Azure Research",
                "text": "This research explores the impact of input data patterns on GPU power consumption during GEMM operations, a core component of machine learning workloads. Unlike previous work that focused on hardware optimizations, this study investigates how varying input data values, placement, and sparsity can significantly affect power usage.",
                "paper-title": "Input-Dependent Power Usage in GPUs",
                "image-path": "flux_paper_image/2409.18324_1727724014.png"
            },

            {
                "startTime": "12:44",
                "arxivId": "2409.18223",
                "arxivLink": "https://arxiv.org/abs/2409.18223",
                "title": "Light Field Microscopy Gets a Neural Makeover: Sharper Images, Faster Than Ever!",
                "institute": "Tsinghua University",
                "text": "This research introduces PNR, a method for high-resolution light field microscopy (LFM) reconstruction that utilizes an unsupervised and explicit feature representation approach. Unlike previous methods, PNR incorporates a frequency-based training loss, enabling better recovery of high-frequency details.",
                "paper-title": "PNR: Physics-informed Neural Representation for high-resolution LFM reconstruction",
                "image-path": "flux_paper_image/2409.18223_1727724321.png"
            },

            {
                "startTime": "13:05",
                "arxivId": "2409.18924",
                "arxivLink": "https://arxiv.org/abs/2409.18924",
                "title": "AI Patient: EHRs Meet LLMs for a Medical Chatbot That Actually Knows Its Stuff!",
                "institute": "Harvard University",
                "text": "This research introduces AIPatient, a simulated patient system that uses a knowledge graph built from Electronic Health Records (EHRs) and a multi-agent workflow powered by Large Language Models (LLMs) to generate realistic and accurate patient responses to medical questions. This approach differs from previous work by incorporating a more comprehensive and diverse patient knowledgebase, along with a robust reasoning framework to minimize hallucinations and ensure consistency in responses.",
                "paper-title": "AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow",
                "image-path": "flux_paper_image/2409.18924_1727725961.png"
            },

            {
                "startTime": "13:38",
                "arxivId": "2409.18402",
                "arxivLink": "https://arxiv.org/abs/2409.18402",
                "title": "Embeddings for Inference: A New Way to Squeeze Data and Find Parameters!",
                "institute": "The University of Chicago",
                "text": "This paper introduces Embed and Emulate (E&E), a new method for simulation-based inference (SBI) that uses contrastive learning to efficiently handle high-dimensional data. Unlike previous methods that directly model the likelihood or posterior, E&E learns a low-dimensional latent embedding of the data and a corresponding emulator in the latent space.",
                "paper-title": "Embed and Emulate: Contrastive representations for simulation-based inference",
                "image-path": "flux_paper_image/2409.18402_1727725575.png"
            },

            {
                "startTime": "14:01",
                "arxivId": "2409.18158",
                "arxivLink": "https://arxiv.org/abs/2409.18158",
                "title": "Transformer Point Processes: Ditch the Thinning Algorithm, Get Faster Predictions!",
                "institute": "University of Cambridge",
                "text": "This research proposes a new framework for modeling marked point processes that decomposes the likelihood function into separate distributions for event types and inter-event times. This approach eliminates the need for the computationally intensive thinning algorithm used in previous Transformer-based methods.",
                "paper-title": "Decomposable Transformer Point Processes",
                "image-path": "flux_paper_image/2409.18158_1727724728.png"
            },

            {
                "startTime": "14:22",
                "arxivId": "2409.18819",
                "arxivLink": "https://arxiv.org/abs/2409.18819",
                "title": "Swiss Nurses Get a Talking AI: Can It Understand Their Dialects?",
                "institute": "Bern University of Applied Sciences, Bern Academy of the Arts",
                "text": "This research focuses on the challenges of using transcription models in home care nursing in Switzerland, specifically addressing the need for models to handle local dialects and foreign accents in German. This is different from previous work that primarily focuses on English language transcription.",
                "paper-title": "Local Transcription Models in Home Care Nursing in Switzerland: an Interdisciplinary Case Study",
                "image-path": "flux_paper_image/2409.18819_1727724600.png"
            },

            {
                "startTime": "14:37",
                "arxivId": "2409.18382",
                "arxivLink": "https://arxiv.org/abs/2409.18382",
                "title": "Robots Learning to Run? LLMs Are the New Coaches!",
                "institute": "UC Berkeley",
                "text": "This research proposes CurricuLLM, a system that uses large language models (LLMs) to automatically design training curricula for robots. Unlike previous methods that rely on human experts or predefined tasks, CurricuLLM leverages LLMs' ability to understand and translate natural language into executable code to generate a sequence of subtasks that progressively increase in difficulty.",
                "paper-title": "CurricuLLM: Automatic Task Curricula Design for Learning Complex Robot Skills using Large Language Models",
                "image-path": "flux_paper_image/2409.18382_1727723964.png"
            },

            {
                "startTime": "14:57",
                "arxivId": "2409.18359",
                "arxivLink": "https://arxiv.org/abs/2409.18359",
                "title": "AI Makes Fluid Dynamics Flow Faster and More Accurately",
                "institute": "Jua.ai, California Institute of Technology, ETH Zurich...",
                "text": "This research introduces a generative AI algorithm, GenCFD, based on conditional score-based diffusion models, for computing statistical solutions of fluid flow equations. Unlike previous work that focuses on deterministic models, GenCFD leverages the inherent instability of turbulent fluid flows to achieve accurate statistical computation.",
                "paper-title": "Generative AI for fast and accurate Statistical Computation of Fluids",
                "image-path": "flux_paper_image/2409.18359_1727725341.png"
            },

            {
                "startTime": "15:31",
                "arxivId": "2409.18804",
                "arxivLink": "https://arxiv.org/abs/2409.18804",
                "title": "Diffusion Models: Learning Data on Manifolds Without Getting Lost in Dimensions",
                "institute": "University of Oxford",
                "text": "This research explores the convergence of diffusion models under the manifold hypothesis, proving that they achieve rates independent of the ambient dimension in terms of learning the score function. This is a significant departure from previous work, which showed a strong dependence on the ambient dimension.",
                "paper-title": "Convergence of Diffusion Models Under the Manifold Hypothesis in High-Dimensions",
                "image-path": "flux_paper_image/2409.18804_1727724380.png"
            },

            {
                "startTime": "15:55",
                "arxivId": "2409.18417",
                "arxivLink": "https://arxiv.org/abs/2409.18417",
                "title": "RLHF Just Got an Auction Makeover: Bidding for Better Bots!",
                "institute": "State Key Laboratory of General Artificial Intelligence BIGAI, Allianz Global Investors Japan Co. Ltd.",
                "text": "This paper introduces a novel auction-based mechanism for collecting preference data in RLHF, addressing the cost-efficiency concerns of dataset construction. Unlike previous methods, it incentivizes LLM agents to provide truthful bids, leading to a more efficient allocation of resources.",
                "paper-title": "VickreyFeedback: Cost-efficient Data Construction for Reinforcement Learning from Human Feedback",
                "image-path": "flux_paper_image/2409.18417_1727723594.png"
            },

            {
                "startTime": "16:16",
                "arxivId": "2409.18761",
                "arxivLink": "https://arxiv.org/abs/2409.18761",
                "title": "Galaxies Aligned: Deep Learning Predicts Cosmic Web's Orientation",
                "institute": "CMU",
                "text": "This research uses a deep generative model trained on the IllustrisTNG-100 simulation to sample 3D galaxy shapes and orientations, accurately reproducing intrinsic alignments. This approach differs from previous work by employing E(3) equivariant Graph Neural Networks, which explicitly respect the Euclidean symmetries of the universe.",
                "paper-title": "Geometric deep learning for galaxy-halo connection: a case study for galaxy intrinsic alignments",
                "image-path": "flux_paper_image/2409.18761_1727724614.png"
            },

            {
                "startTime": "16:42",
                "arxivId": "2409.18164",
                "arxivLink": "https://arxiv.org/abs/2409.18164",
                "title": "Data Prep Kit: LLM's New BFF for Taming Wild Data",
                "institute": "IBM",
                "text": "This research introduces a new open-source toolkit called Data Prep Kit (DPK) specifically designed for preparing data for Large Language Model (LLM) development. Unlike previous projects that focus on data preparation for specific tasks like pretraining, DPK aims to be more versatile, supporting a wider range of LLM applications, including fine-tuning, RAG, and instruction tuning.",
                "paper-title": "Data-Prep-Kit: getting your data ready for LLM application development",
                "image-path": "flux_paper_image/2409.18164_1727724644.png"
            },

            {
                "startTime": "17:06",
                "arxivId": "2409.18885",
                "arxivLink": "https://arxiv.org/abs/2409.18885",
                "title": "Extreme Weather Forecasting: A Dataset So Hot, It's 3km Resolution!",
                "institute": "University of Manchester, Hunan University, Microsoft Research...",
                "text": "This research introduces a new dataset, HR-Extreme, specifically designed for evaluating extreme weather forecasting models. Unlike previous datasets, HR-Extreme uses high-resolution data from the High-Resolution Rapid Refresh (HRRR) system, providing a more detailed and accurate representation of extreme weather events.",
                "paper-title": "HR-Extreme: A High-Resolution Dataset for Extreme Weather Forecasting",
                "image-path": "flux_paper_image/2409.18885_1727724567.png"
            },

            {
                "startTime": "17:38",
                "arxivId": "2409.18170",
                "arxivLink": "https://arxiv.org/abs/2409.18170",
                "title": "AI Doctors: Can We Trust Them to Summarize Our Medical Records?",
                "institute": "University of Wisconsin Madison, University of Colorado Aurora, Epic Systems...",
                "text": "This research focuses on evaluating the performance of Large Language Models (LLMs) for summarizing medical text, specifically addressing the challenges of ensuring accuracy and reliability in a high-stakes environment like healthcare. It proposes a new approach using LLMs themselves as evaluators, a departure from traditional human or automated methods.",
                "paper-title": "Evaluation of Large Language Models for Summarization Tasks in the Medical Domain: A Narrative Review",
                "image-path": "flux_paper_image/2409.18170_1727725043.png"
            },

            {
                "startTime": "18:01",
                "arxivId": "2409.18459",
                "arxivLink": "https://arxiv.org/abs/2409.18459",
                "title": "Recipe for Success: AI Cooks Up Japanese Cuisine with Multimodal Magic",
                "institute": "University of Tokyo",
                "text": "This research focuses on generating Japanese recipes from food images using Multimodal Large Language Models (MLLMs). Unlike previous work that primarily used English recipes, this study utilizes a Japanese recipe dataset and evaluates the generated recipes based on Japanese food culture.",
                "paper-title": "FoodMLLM-JP: Leveraging Multimodal Large Language Models for Japanese Recipe Generation",
                "image-path": "flux_paper_image/2409.18459_1727723650.png"
            },

            {
                "startTime": "18:21",
                "arxivId": "2409.18239",
                "arxivLink": "https://arxiv.org/abs/2409.18239",
                "title": "Speech Enhancement on Hearables: Sub-Millisecond Latency, No More Lag!",
                "institute": "Google DeepMind, Google Research, Google Platforms & Devices",
                "text": "This research focuses on achieving sub-millisecond latency for real-time speech enhancement, a feat previously unexplored in the field. The paper introduces a Deep FIR filtering method that enables sample-by-sample processing, significantly reducing algorithmic latency compared to traditional techniques.",
                "paper-title": "Towards sub-millisecond latency real-time speech enhancement models on hearables",
                "image-path": "flux_paper_image/2409.18239_1727724219.png"
            },

            {
                "startTime": "18:40",
                "arxivId": "2409.18472",
                "arxivLink": "https://arxiv.org/abs/2409.18472",
                "title": "URIEL+: Giving Languages a Voice, Even the Quiet Ones!",
                "institute": "University of Toronto, Ghent University, Ontario Tech University",
                "text": "This research expands the URIEL knowledge base by integrating five new databases, increasing the number of languages with typological data from 2724 to 4366. It also introduces new imputation algorithms and confidence scores to improve the reliability of distance calculations.",
                "paper-title": "URIEL+: Enhancing Linguistic Inclusion and Usability in a Typological and Multilingual Knowledge Base",
                "image-path": "flux_paper_image/2409.18472_1727725814.png"
            }
    ],
    "stats": {
        "num_pick": 47,
        "num_total": 294,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202409301846_audio.mp3"
}
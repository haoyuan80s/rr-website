
daily_data = {
    "date": "2024-07-11",
    "tweets": [
            {
                "startTime": "00:52",
                "arxivId": "2407.07726",
                "arxivLink": "https://arxiv.org/abs/2407.07726",
                "title": "PaliGemma: A Tiny Vision-Language Model With Big Dreams",
                "institute": "Google",
                "text": "PaliGemma is a Vision-Language Model (VLM) that uses a smaller image encoder and language model compared to previous VLMs. It achieves comparable performance to larger models, demonstrating the potential for smaller, more efficient VLMs.",
                "paper-title": "PaliGemma: A versatile 3B VLM for transfer",
                "image-path": ""
            },

            {
                "startTime": "01:10",
                "arxivId": "2407.07140",
                "arxivLink": "https://arxiv.org/abs/2407.07140",
                "title": "Top-k Classifiers Get a Cardinality Makeover: Learning to Predict Sets with Finesse!",
                "institute": "Google, NYU, Stanford University",
                "text": "This research introduces a novel approach to top-k classification, where the model dynamically adjusts the size of its prediction sets based on the difficulty of the input instance. This differs from previous work that typically uses a fixed size for the prediction set.",
                "paper-title": "Cardinality-Aware Set Prediction and Top-$k$ Classification",
                "image-path": ""
            },

            {
                "startTime": "01:34",
                "arxivId": "2407.07263",
                "arxivLink": "https://arxiv.org/abs/2407.07263",
                "title": "Tired of Retraining? This Recipe Makes Your Language Model a Master Chef!",
                "institute": "Nvidia",
                "text": "This research focuses on improving the general capabilities of already trained language models through continued pretraining, rather than retraining from scratch. It differs from previous work by focusing on improving general abilities, not just adapting to new domains or data shifts.",
                "paper-title": "Reuse, Don't Retrain: A Recipe for Continued Pretraining of Language Models",
                "image-path": ""
            },

            {
                "startTime": "01:56",
                "arxivId": "2407.07860",
                "arxivLink": "https://arxiv.org/abs/2407.07860",
                "title": "4DiM: Diffusion Models That Control Space and Time Like a Boss",
                "institute": "Google DeepMind",
                "text": "This research introduces 4DiM, a diffusion model for novel view synthesis that can be conditioned on both camera pose and time. Unlike previous work, 4DiM is trained on a mixture of 3D, 4D, and video data, allowing it to generate more realistic and diverse views.",
                "paper-title": "Controlling Space and Time with Diffusion Models",
                "image-path": ""
            },

            {
                "startTime": "02:16",
                "arxivId": "2407.07737",
                "arxivLink": "https://arxiv.org/abs/2407.07737",
                "title": "Privacy for Your Tweets: How to Train AI Models Without Spilling Your Secrets",
                "institute": "Google",
                "text": "This research introduces a new method for training large language models (LLMs) with user-level differential privacy, which protects all the data contributed by each user, not just individual examples. This approach is different from previous work that focused on example-level privacy, which can be insufficient to protect user privacy in settings where users contribute multiple correlated examples.",
                "paper-title": "Fine-Tuning Large Language Models with User-Level Differential Privacy",
                "image-path": ""
            },

            {
                "startTime": "02:43",
                "arxivId": "2407.07616",
                "arxivLink": "https://arxiv.org/abs/2407.07616",
                "title": "Satellite Images: Seeing the Changes, But Not the Shifts!",
                "institute": "LIGM, Ecole des Ponts, Univ Gustave Eiffel...",
                "text": "This research focuses on the impact of temporal and spatial domain shifts on satellite image time series semantic change detection (SITS-SCD), an area that has been largely overlooked in previous studies.",
                "paper-title": "Satellite Image Time Series Semantic Change Detection: Novel Architecture and Analysis of Domain Shift",
                "image-path": ""
            },

            {
                "startTime": "03:27",
                "arxivId": "2407.07577",
                "arxivLink": "https://arxiv.org/abs/2407.07577",
                "title": "Movie Magic: AI Learns to Remember Who's Who!",
                "institute": "The University of Hong Kong, Tsinghua University, ByteDance",
                "text": "This research introduces a new approach to visual instruction tuning for Large Vision-Language Models (LVLMs) by incorporating character identity references. This allows the model to associate instances across different scenes, a capability not explored in previous work.",
                "paper-title": "IDA-VLM: Towards Movie Understanding via ID-Aware Large Vision-Language Model",
                "image-path": ""
            },

            {
                "startTime": "03:56",
                "arxivId": "2407.07561",
                "arxivLink": "https://arxiv.org/abs/2407.07561",
                "title": "Robot Chef: Feeding You What You Want, Not What's Easy!",
                "institute": "Cornell University, Stanford University, University of British Columbia",
                "text": "This research introduces FLAIR, a system that uses foundation models to plan long-horizon bite sequences for robot-assisted feeding. Unlike previous work that focuses on individual food manipulation skills, FLAIR considers the entire meal and incorporates user preferences.",
                "paper-title": "FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes",
                "image-path": ""
            },

            {
                "startTime": "04:18",
                "arxivId": "2407.07580",
                "arxivLink": "https://arxiv.org/abs/2407.07580",
                "title": "Layout Synthesis Gets a Semantic Makeover: Graph Diffusion Models Take the Stage!",
                "institute": "Peking University, ByteDance",
                "text": "This research introduces INSTRUCTLAYOUT, a generative framework for 2D and 3D layout synthesis that incorporates a semantic graph prior. Unlike previous methods that implicitly model object relations, INSTRUCTLAYOUT explicitly represents these relationships using a graph, enhancing controllability and fidelity in layout generation.",
                "paper-title": "InstructLayout: Instruction-Driven 2D and 3D Layout Synthesis with Semantic Graph Prior",
                "image-path": ""
            },

            {
                "startTime": "04:45",
                "arxivId": "2407.07810",
                "arxivLink": "https://arxiv.org/abs/2407.07810",
                "title": "LLMs: Not Just Big Brains, But Aligned Ones Too!",
                "institute": "University of Toronto",
                "text": "This research examines the internal workings of LLMs by analyzing the trajectories of individual tokens as they pass through transformer blocks. It introduces the concept of \"Transformer Alignment,\" which describes the alignment of singular vectors in the linearizations of transformer blocks. This is distinct from previous work on Residual Networks, which focused on \"Residual Alignment.\"",
                "paper-title": "Transformer Alignment in Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "05:10",
                "arxivId": "2407.07775",
                "arxivLink": "https://arxiv.org/abs/2407.07775",
                "title": "Robot Navigation Gets a Multimodal Makeover: Tour Videos and Long-Context VLMs Take the Wheel!",
                "institute": "Google",
                "text": "This research introduces a new navigation task called Multimodal Instruction Navigation with Tours (MINT), where a robot navigates based on multimodal instructions (text and images) and a pre-recorded demonstration tour of the environment. This differs from previous work by leveraging long-context Vision-Language Models (VLMs) to understand the tour and instructions, and then using a topological graph to generate navigation actions.",
                "paper-title": "Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs",
                "image-path": ""
            },

            {
                "startTime": "05:32",
                "arxivId": "2407.07575",
                "arxivLink": "https://arxiv.org/abs/2407.07575",
                "title": "Digital Twins Get a Ride: How AI is Optimizing Vehicular Edge Computing",
                "institute": "Jiangnan University, Tsinghua University, Shanghai Jiao Tong University...",
                "text": "This research focuses on resource allocation for both digital twin maintenance and computing task processing in vehicular edge computing networks. It differs from previous work by considering the simultaneous demands of these two tasks, which are often treated separately.",
                "paper-title": "Resource Allocation for Twin Maintenance and Computing Task Processing in Digital Twin Vehicular Edge Computing Network",
                "image-path": ""
            },

            {
                "startTime": "06:08",
                "arxivId": "2407.07427",
                "arxivLink": "https://arxiv.org/abs/2407.07427",
                "title": "Open-Vocabulary Video Segmentation: Aligning Embeddings for Better Object Tracking",
                "institute": "Shandong University, ETH Zurich",
                "text": "This research tackles the problem of open-vocabulary video instance segmentation by introducing a novel unified embedding alignment approach. Unlike previous methods that rely on image-level training, this paper proposes a video-level training paradigm to improve temporal consistency.",
                "paper-title": "Unified Embedding Alignment for Open-Vocabulary Video Instance Segmentation",
                "image-path": ""
            },

            {
                "startTime": "06:36",
                "arxivId": "2407.07755",
                "arxivLink": "https://arxiv.org/abs/2407.07755",
                "title": "Neural Surfaces Get a Geometry Makeover: No More Meshing!",
                "institute": "University College London",
                "text": "This paper introduces a new way to represent surfaces using neural networks, called Spherical Neural Surfaces (SNS). Unlike previous methods that rely on discretizing surfaces into meshes, SNS allows for direct computation of geometric operators like normals, curvatures, and the Laplace-Beltrami operator, without any meshing.",
                "paper-title": "Neural Geometry Processing via Spherical Neural Surfaces",
                "image-path": ""
            },

            {
                "startTime": "06:57",
                "arxivId": "2407.07433",
                "arxivLink": "https://arxiv.org/abs/2407.07433",
                "title": "AI Gets Its Directions: New Model Generates Customizable Navigation Instructions",
                "institute": "Beihang University, Zhejiang University, Tsinghua University",
                "text": "This research introduces a new method for generating navigation instructions that allows for control over both the style and content of the instructions. Unlike previous models that only generate instructions in a single style, this model can generate instructions in different styles, such as step-by-step or high-level, based on the user's needs.",
                "paper-title": "Controllable Navigation Instruction Generation with Chain of Thought Prompting",
                "image-path": ""
            },

            {
                "startTime": "07:28",
                "arxivId": "2407.07885",
                "arxivLink": "https://arxiv.org/abs/2407.07885",
                "title": "Robots Get a Feel for the World: New Tactile Skin Makes In-Hand Manipulation a Breeze!",
                "institute": "Meta, University of Pennsylvania, UC Berkeley...",
                "text": "This research introduces a new tactile skin model that enables zero-shot sim-to-real transfer of shear and normal forces, unlike previous work that often relies on simplified tactile signals.",
                "paper-title": "Learning In-Hand Translation Using Tactile Skin With Shear and Normal Force Sensing",
                "image-path": ""
            },

            {
                "startTime": "07:53",
                "arxivId": "2407.07848",
                "arxivLink": "https://arxiv.org/abs/2407.07848",
                "title": "Transformers: Not All Neurons Are Created Equal!",
                "institute": "Google",
                "text": "This research goes beyond previous work by examining how sparsity patterns evolve over the course of training, not just at the end. It also analyzes sparsity at different levels: per-token, per-sequence, and per-batch.",
                "paper-title": "Uncovering Layer-Dependent Activation Sparsity Patterns in ReLU Transformers",
                "image-path": ""
            },

            {
                "startTime": "08:11",
                "arxivId": "2407.07671",
                "arxivLink": "https://arxiv.org/abs/2407.07671",
                "title": "Should We Let Robots Decide What's Right?",
                "institute": "Carnegie Mellon University, University of Oxford",
                "text": "This paper explores the reasons why we might want to automate moral decision-making, even without a perfect mathematical framework for ethics. It goes beyond simply arguing for or against AI in moral contexts, instead focusing on the practical considerations and potential benefits of using AI for moral reasoning.",
                "paper-title": "Why should we ever automate moral decision making?",
                "image-path": ""
            },

            {
                "startTime": "08:33",
                "arxivId": "2407.07279",
                "arxivLink": "https://arxiv.org/abs/2407.07279",
                "title": "Deep Learning's New Groove: Unlocking the Secrets of State Space Models in the Frequency Domain",
                "institute": "Stanford University, Columbia University",
                "text": "This research delves into the learning dynamics of linear state space models (SSMs) by analyzing them in the frequency domain. This approach offers analytical solutions, unlike previous work that primarily focused on time-domain analysis.",
                "paper-title": "Towards a theory of learning dynamics in deep state space models",
                "image-path": ""
            },

            {
                "startTime": "08:56",
                "arxivId": "2407.07825",
                "arxivLink": "https://arxiv.org/abs/2407.07825",
                "title": "Speech Enhancement on Steroids: Real-Time Audio-Visual Magic with 40ms Latency!",
                "institute": "Meta, Imperial College London",
                "text": "This research focuses on real-time audio-visual speech enhancement (AVSE) with minimal latency. Unlike previous work, it specifically addresses low-SNR scenarios and aims to achieve frame-by-frame enhancement with minimal delay. The paper proposes RT-LA-VocE, a causal AVSE model that re-designs components of the non-causal LA-VocE model to enable real-time inference.",
                "paper-title": "RT-LA-VocE: Real-Time Low-SNR Audio-Visual Speech Enhancement",
                "image-path": ""
            },

            {
                "startTime": "09:20",
                "arxivId": "2407.07333",
                "arxivLink": "https://arxiv.org/abs/2407.07333",
                "title": "Forget Memory, Just Learn to Forget: A New Trick for AI in Partially Observable Worlds",
                "institute": "UC Berkeley, Brown University",
                "text": "This research introduces the \u03bb-discrepancy, a metric that measures how well an agent's observations support Markovian value prediction. Unlike previous methods, it doesn't require knowledge of the underlying state space.",
                "paper-title": "Mitigating Partial Observability in Sequential Decision Processes via the Lambda Discrepancy",
                "image-path": ""
            },

            {
                "startTime": "09:49",
                "arxivId": "2407.07596",
                "arxivLink": "https://arxiv.org/abs/2407.07596",
                "title": "Targeting the Needy While Learning: A Balancing Act for Social Programs",
                "institute": "CMU",
                "text": "This research proposes a framework for designing randomized allocation rules that balance the goal of targeting high-need individuals with learning treatment effects. This differs from previous work that focuses solely on either targeting or learning.",
                "paper-title": "Learning treatment effects while treating those in need",
                "image-path": ""
            },

            {
                "startTime": "10:19",
                "arxivId": "2407.07700",
                "arxivLink": "https://arxiv.org/abs/2407.07700",
                "title": "Conformal Prediction: Outlier-Proofing Your Predictions",
                "institute": "University of Oxford, University of T\u00fcbingen",
                "text": "This research investigates the robustness of split conformal prediction when the calibration data is contaminated with outliers. It quantifies the impact of corrupted data on the coverage and efficiency of prediction sets, and proposes a new method called Contamination Robust Conformal Prediction (CRCP) to address over-coverage in classification settings.",
                "paper-title": "Split Conformal Prediction under Data Contamination",
                "image-path": ""
            },

            {
                "startTime": "10:51",
                "arxivId": "2407.07506",
                "arxivLink": "https://arxiv.org/abs/2407.07506",
                "title": "AI to the Rescue: How Generative AI is Fixing Broken RF Sensors in the IoT",
                "institute": "\u00c9cole des Ponts ParisTech",
                "text": "This research explores the use of Generative AI (GenAI) techniques to address challenges in Radio Frequency (RF) sensing within Internet of Things (IoT) systems. Unlike previous work that primarily focused on traditional deep learning methods, this paper investigates the potential of GenAI models to overcome limitations such as noise, interference, and incomplete data.",
                "paper-title": "Generative AI for RF Sensing in IoT systems",
                "image-path": ""
            },

            {
                "startTime": "11:23",
                "arxivId": "2407.07403",
                "arxivLink": "https://arxiv.org/abs/2407.07403",
                "title": "AI Vision-Language Models: A Guide to Their (Not-So-Secret) Weaknesses",
                "institute": "Peking University, Huazhong University of Science and Technology, Chinese University of Hong Kong",
                "text": "This paper provides a comprehensive survey of attacks targeting Large Vision-Language Models (LVLMs), focusing on the unique challenges and vulnerabilities presented by their multimodal nature. It goes beyond previous surveys by offering a detailed taxonomy of attack methods, including adversarial attacks, jailbreak attacks, prompt injection attacks, and data poisoning/backdoor attacks.",
                "paper-title": "A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends",
                "image-path": ""
            },

            {
                "startTime": "11:52",
                "arxivId": "2407.07402",
                "arxivLink": "https://arxiv.org/abs/2407.07402",
                "title": "Action-Aware Video Segmentation: It's Not Just What You See, It's What You Do!",
                "institute": "University of Tokyo",
                "text": "This research introduces ActionVOS, a new approach to video object segmentation that uses action prompts, like \"putting a carrot in a bowl,\" to identify active objects in egocentric videos. This differs from previous methods that rely solely on static attributes like object names.",
                "paper-title": "ActionVOS: Actions as Prompts for Video Object Segmentation",
                "image-path": ""
            },

            {
                "startTime": "12:20",
                "arxivId": "2407.07786",
                "arxivLink": "https://arxiv.org/abs/2407.07786",
                "title": "AI Red Teaming: The Human Factor in the AI Arms Race",
                "institute": "CMU, Microsoft, University of Chicago...",
                "text": "This research focuses on the human element of AI red teaming, a practice that involves testing AI systems for potential harm. Unlike previous work that primarily focuses on the technical aspects of red teaming, this study examines the social and collaborative aspects of the practice, including the labor involved, the potential for harm to red teamers, and the need for safeguards to protect their well-being.",
                "paper-title": "The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing",
                "image-path": ""
            },

            {
                "startTime": "12:49",
                "arxivId": "2407.07277",
                "arxivLink": "https://arxiv.org/abs/2407.07277",
                "title": "Blood Biomarkers: Your Lifestyle's Secret Code?",
                "institute": "Google",
                "text": "This research proposes a novel deep metric learning framework to predict future blood biomarker values, incorporating lifestyle factors like physical activity and sleep, which is a departure from previous work that primarily relied on population-level statistics and demographics.",
                "paper-title": "Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning",
                "image-path": ""
            },

            {
                "startTime": "13:13",
                "arxivId": "2407.07235",
                "arxivLink": "https://arxiv.org/abs/2407.07235",
                "title": "Trans Voices, Transformed: A Dataset That Makes Speech Models Squirm!",
                "institute": "UC Berkeley",
                "text": "This research introduces the Versatile Voice Dataset (VVD), a collection of audio recordings from three trans-feminine voice teachers who deliberately modify their voices along various axes. This dataset is unique because it focuses on intra-speaker variability, specifically how a single speaker can produce a wide range of vocal textures, challenging the assumptions of current speaker identity models.",
                "paper-title": "Speech After Gender: A Trans-Feminine Perspective on Next Steps for Speech Science and Technology",
                "image-path": ""
            },

            {
                "startTime": "13:34",
                "arxivId": "2407.07884",
                "arxivLink": "https://arxiv.org/abs/2407.07884",
                "title": "Robots Learn to Peel Like Pros: A Dexterous Manipulation Masterclass",
                "institute": "MIT",
                "text": "This research focuses on constrained dexterous manipulation for food peeling, specifically addressing the challenge of stopping object reorientation and firmly holding it in place for downstream tasks. Unlike previous works that primarily focus on continuous object rotation, this study introduces a framework for training a reorientation controller that can stop and hold the object, making it suitable for tasks like peeling.",
                "paper-title": "Vegetable Peeling: A Case Study in Constrained Dexterous Manipulation",
                "image-path": ""
            },

            {
                "startTime": "13:58",
                "arxivId": "2407.07586",
                "arxivLink": "https://arxiv.org/abs/2407.07586",
                "title": "Object Detection: A Simpler, Smarter Approach to Adapting to New Worlds",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research explores simpler approaches to source-free domain adaptation for object detection, focusing on the importance of batch normalization layers and proposing a novel strategy that combines AdaBN with training on a fixed set of pseudo-labels.",
                "paper-title": "Simplifying Source-Free Domain Adaptation for Object Detection: Effective Self-Training Strategies and Performance Insights",
                "image-path": ""
            },

            {
                "startTime": "14:17",
                "arxivId": "2407.07395",
                "arxivLink": "https://arxiv.org/abs/2407.07395",
                "title": "Neural Network Wraps Video Coding: A Slimmer, Faster Way to Stream!",
                "institute": "New York University, Google LLC",
                "text": "This research proposes a new framework for video coding that uses neural networks to improve compression efficiency while keeping decoding complexity low. Unlike previous approaches that focused on replacing entire coding loops with neural networks, this method uses neural networks as \"wrappers\" around a standard video codec, allowing for a more practical implementation.",
                "paper-title": "Standard compliant video coding using low complexity, switchable neural wrappers",
                "image-path": ""
            },

            {
                "startTime": "14:39",
                "arxivId": "2407.07461",
                "arxivLink": "https://arxiv.org/abs/2407.07461",
                "title": "NeRF's Got Blurs? Diffusion to the Rescue!",
                "institute": "University of Science and Technology of China, Microsoft",
                "text": "This paper tackles the aliasing issue in NeRF renderings by treating it as a degradation problem and leveraging a pretrained diffusion model to restore high-quality images from aliased inputs. This approach differs from previous methods that focused on scene parameterization or regularization techniques.",
                "paper-title": "Drantal-NeRF: Diffusion-Based Restoration for Anti-aliasing Neural Radiance Field",
                "image-path": ""
            },

            {
                "startTime": "15:02",
                "arxivId": "2407.07666",
                "arxivLink": "https://arxiv.org/abs/2407.07666",
                "title": "LLMs in Healthcare: Beyond Accuracy, It's All About S.C.O.R.E.",
                "institute": "Singapore National Eye Centre, Singapore Eye Research Institute, Singapore Health Services...",
                "text": "This research proposes a new evaluation framework called S.C.O.R.E. for assessing large language models (LLMs) in healthcare, focusing on qualitative aspects like safety, consensus, objectivity, reproducibility, and explainability, rather than solely relying on traditional quantitative metrics.",
                "paper-title": "A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability",
                "image-path": ""
            },

            {
                "startTime": "15:25",
                "arxivId": "2407.07338",
                "arxivLink": "https://arxiv.org/abs/2407.07338",
                "title": "Expert Knowledge: Unlocking the Secrets of Causal Relationships",
                "institute": "University of Washington",
                "text": "This research expands on previous work by considering a more general class of background knowledge, allowing for any kind of (consistent) edge mark orientations.",
                "paper-title": "Towards Complete Causal Explanation with Expert Knowledge",
                "image-path": ""
            },

            {
                "startTime": "15:43",
                "arxivId": "2407.07356",
                "arxivLink": "https://arxiv.org/abs/2407.07356",
                "title": "Video In-Context Learning: Teaching AI to Mimic Your Moves!",
                "institute": "University of Science and Technology of China, Microsoft",
                "text": "This research extends in-context learning to video data, allowing models to generate video sequences based on demonstrations, unlike previous work that focused on image-based tasks.",
                "paper-title": "Video In-context Learning",
                "image-path": ""
            },

            {
                "startTime": "16:12",
                "arxivId": "2407.07735",
                "arxivLink": "https://arxiv.org/abs/2407.07735",
                "title": "NeRFs Get Watermarked: A Plug-and-Play Copyright Protector",
                "institute": "Hong Kong Baptist University, Nvidia",
                "text": "This research proposes a new method for embedding copyright messages directly into NeRF models during their creation, unlike previous methods that embed watermarks after the model is built.",
                "paper-title": "Protecting NeRFs' Copyright via Plug-And-Play Watermarking Base Model",
                "image-path": ""
            },

            {
                "startTime": "16:37",
                "arxivId": "2407.07239",
                "arxivLink": "https://arxiv.org/abs/2407.07239",
                "title": "RotRNN: Spinning Long Sequences with a Twist!",
                "institute": "University College London",
                "text": "This paper proposes RotRNN, a linear recurrent model that uses rotation matrices to address the challenges of state-of-the-art models like SSMs and LRUs. Unlike previous methods, RotRNN simplifies initialization and normalization, leading to a more robust and efficient model.",
                "paper-title": "RotRNN: Modelling Long Sequences with Rotations",
                "image-path": ""
            },

            {
                "startTime": "17:01",
                "arxivId": "2407.07510",
                "arxivLink": "https://arxiv.org/abs/2407.07510",
                "title": "Invisible Stripes Trick Self-Driving Cars: A New Kind of Optical Illusion",
                "institute": "Nanyang Technological University, University of Pittsburgh, Singapore Institute of Technology",
                "text": "This research differs from previous work by focusing on achieving stable adversarial attacks over a sequence of frames, rather than just single frames. It introduces GhostStripe, a system that adapts to the camera's rolling shutter effect and the victim vehicle's movement to create consistent, invisible stripes that mislead traffic sign recognition.",
                "paper-title": "Invisible Optical Adversarial Stripes on Traffic Sign against Autonomous Vehicles",
                "image-path": ""
            },

            {
                "startTime": "17:24",
                "arxivId": "2407.07612",
                "arxivLink": "https://arxiv.org/abs/2407.07612",
                "title": "Transformers Learn Causal Reasoning: From Simple Chains to Complex Graphs!",
                "institute": "MIT, Indian Institute of Technology Hyderabad, Microsoft",
                "text": "This research explores a novel approach called \"axiomatic training\" where a transformer model learns causal reasoning directly from symbolic demonstrations of axioms, rather than relying on data generated from those axioms. This differs from previous work that typically incorporates axioms as inductive biases or infers them from data values.",
                "paper-title": "Teaching Transformers Causal Reasoning through Axiomatic Training",
                "image-path": ""
            },

            {
                "startTime": "17:56",
                "arxivId": "2407.07342",
                "arxivLink": "https://arxiv.org/abs/2407.07342",
                "title": "LLMs: Multilingual Blending Makes Safety Go \"Poof!\"",
                "institute": "University of Alberta, University of Tokyo",
                "text": "This research explores the safety of LLMs in multilingual contexts, specifically focusing on the impact of mixed-language queries and responses, a concept called \"Multilingual Blending.\" This differs from previous work that primarily focused on single-language safety alignment.",
                "paper-title": "Multilingual Blending: LLM Safety Alignment Evaluation with Language Mixture",
                "image-path": ""
            },

            {
                "startTime": "18:26",
                "arxivId": "2407.07225",
                "arxivLink": "https://arxiv.org/abs/2407.07225",
                "title": "AI-Generated Text? We've Got Eyes for That!",
                "institute": "NYU, IBM",
                "text": "This research proposes a novel approach to AI-generated text detection by using image representations of word embeddings instead of traditional text-based methods. This approach leverages the strengths of vision models, which are known for their efficiency and ability to capture spatial patterns, to analyze text.",
                "paper-title": "ConvNLP: Image-based AI Text Detection",
                "image-path": ""
            },

            {
                "startTime": "18:47",
                "arxivId": "2407.07364",
                "arxivLink": "https://arxiv.org/abs/2407.07364",
                "title": "Traffic Jams? Let's Get Physical! Reinforcement Learning Meets Physics Models for Smarter Routing.",
                "institute": "CMU",
                "text": "This research introduces TransRL, an algorithm that combines reinforcement learning with physics models for real-time traffic routing. Unlike previous methods that rely solely on either physics models or reinforcement learning, TransRL leverages the strengths of both approaches.",
                "paper-title": "Real-time system optimal traffic routing under uncertainties -- Can physics models boost reinforcement learning?",
                "image-path": ""
            },

            {
                "startTime": "19:07",
                "arxivId": "2407.07827",
                "arxivLink": "https://arxiv.org/abs/2407.07827",
                "title": "Can a Neural Network See the \"Stability\" of a Graph?",
                "institute": "RelationalAI, Rice University",
                "text": "This research explores using convolutional neural networks (CNNs) to predict the stability number of a graph by treating its adjacency matrix as an image. This approach differs from previous work that uses graph neural networks (GNNs) to learn representations directly from the graph structure.",
                "paper-title": "Estimating the stability number of a random graph using convolutional neural networks",
                "image-path": ""
            },

            {
                "startTime": "19:29",
                "arxivId": "2407.07296",
                "arxivLink": "https://arxiv.org/abs/2407.07296",
                "title": "AI-Powered Radiation Therapy: ChatGPT Helps Target Tumors!",
                "institute": "Harvard University, Stanford University",
                "text": "This research introduces Radformer, a novel network that integrates large language models (LLMs) with a hierarchical vision transformer for 3D medical image segmentation. Unlike previous approaches that rely solely on visual features, Radformer leverages text-rich clinical information alongside visual features to improve the accuracy of target delineation in radiation therapy.",
                "paper-title": "Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy",
                "image-path": ""
            },

            {
                "startTime": "19:53",
                "arxivId": "2407.07295",
                "arxivLink": "https://arxiv.org/abs/2407.07295",
                "title": "Deforming Images with a Diffusion Model: It's Like Stretching a Rubber Band, But for Pictures!",
                "institute": "University of Oxford, Chinese Academy of Medical Sciences",
                "text": "This research proposes a novel diffusion model, DRDM, that focuses on generating deformation fields rather than directly synthesizing images. Unlike previous methods that rely on intensity or latent features, DRDM emphasizes morphological changes through deformation fields, enabling the generation of diverse and anatomically plausible deformations for individual images.",
                "paper-title": "Deformation-Recovery Diffusion Model (DRDM): Instance Deformation for Image Manipulation and Synthesis",
                "image-path": ""
            },

            {
                "startTime": "20:21",
                "arxivId": "2407.07218",
                "arxivLink": "https://arxiv.org/abs/2407.07218",
                "title": "Machine Learning for Fluids: A Reproducibility Crisis?",
                "institute": "Princeton University, Princeton Plasma Physics Laboratory",
                "text": "This research systematically reviews the literature on machine learning (ML) for solving fluid-related partial differential equations (PDEs). It identifies two common issues: weak baselines and reporting biases, which lead to overoptimistic conclusions about the effectiveness of ML-based PDE solvers.",
                "paper-title": "Weak baselines and reporting biases lead to overoptimism in machine learning for fluid-related partial differential equations",
                "image-path": ""
            },

            {
                "startTime": "20:43",
                "arxivId": "2407.07591",
                "arxivLink": "https://arxiv.org/abs/2407.07591",
                "title": "Tired of the Same Old Soft Robots? This New Method Finds Designs That Actually Work!",
                "institute": "University of Cambridge, CSIRO",
                "text": "This research introduces a new method called OIDD (Optimizing Initial Design Domain) that combines topology optimization with quality diversity algorithms. This allows for a more comprehensive exploration of the design space, leading to the discovery of diverse and high-performing soft robot designs. Unlike traditional topology optimization methods, which focus on finding a single optimal solution, OIDD dynamically adjusts the design domain during the optimization process, enabling the exploration of a wider range of possibilities.",
                "paper-title": "A 'MAP' to find high-performing soft robot designs: Traversing complex design spaces using MAP-elites and Topology Optimization",
                "image-path": ""
            },

            {
                "startTime": "21:14",
                "arxivId": "2407.07796",
                "arxivLink": "https://arxiv.org/abs/2407.07796",
                "title": "LLMs Play Games: Who's the Tic-Tac-Toe Champ?",
                "institute": "Florida Polytechnic University",
                "text": "This research introduces a new benchmark for evaluating large language models (LLMs) using grid-based games like Tic-Tac-Toe, Connect Four, and Gomoku. Unlike previous benchmarks that focus on language understanding tasks, this one assesses LLMs' strategic thinking and decision-making abilities in a game context.",
                "paper-title": "Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard",
                "image-path": ""
            },

            {
                "startTime": "21:37",
                "arxivId": "2407.07873",
                "arxivLink": "https://arxiv.org/abs/2407.07873",
                "title": "Sampling Made Easy: A PDE-Powered Approach to Generative Modeling",
                "institute": "California Institute of Technology, Zuse Institute Berlin, dida Datenschmiede GmbH...",
                "text": "This research proposes a unified framework for sampling from probability densities using partial differential equations (PDEs). Unlike previous methods that rely on time-reversals or trajectory simulations, this approach leverages physics-informed neural networks (PINNs) for simulation-free optimization, leading to improved mode coverage and faster convergence.",
                "paper-title": "Dynamical Measure Transport and Neural PDE Solvers for Sampling",
                "image-path": ""
            },

            {
                "startTime": "22:09",
                "arxivId": "2407.07765",
                "arxivLink": "https://arxiv.org/abs/2407.07765",
                "title": "Trees, Privacy, and the Littlestone Dimension: A Tale of Impossible Learning",
                "institute": "Gran Sasso Science Institute (GSSI), Purdue University, Technion...",
                "text": "This research extends the link between differential privacy and online learning to more general settings, including partial concept classes and multiclass classification with infinite label spaces. Unlike previous work that relied on thresholds, this paper directly reasons about Littlestone trees, establishing new Ramsey-type theorems for trees.",
                "paper-title": "Ramsey Theorems for Trees and a General 'Private Learning Implies Online Learning' Theorem",
                "image-path": ""
            },

            {
                "startTime": "22:38",
                "arxivId": "2407.07439",
                "arxivLink": "https://arxiv.org/abs/2407.07439",
                "title": "SHAPing Up: A New Way to Encode Features for Algorithm Selection in Mixed-Variable Optimization",
                "institute": "Dresden University of Technology, University of M\u00fcnster, Sorbonne University...",
                "text": "This research introduces a new encoding scheme based on SHAP values to represent categorical variables in mixed-variable optimization problems. This approach differs from previous work that used target-encoding, as it considers the individual contribution of each feature to the prediction, rather than aggregating the average effect across all categories.",
                "paper-title": "Hybridizing Target- and SHAP-encoded Features for Algorithm Selection in Mixed-variable Black-box Optimization",
                "image-path": ""
            },

            {
                "startTime": "23:05",
                "arxivId": "2407.07627",
                "arxivLink": "https://arxiv.org/abs/2407.07627",
                "title": "Fake It 'Til You Make It: Boosting Face Recognition with Realistic 3D Faces",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Idiap Research Institute",
                "text": "This research explores the use of image-to-image translation techniques to enhance the realism of 3D-rendered facial images, aiming to improve the performance of face recognition systems trained on these synthetic datasets. Unlike previous work that relies on pre-trained face recognition models or identity labels, this study demonstrates performance gains without these prerequisites.",
                "paper-title": "Synthetic to Authentic: Transferring Realism to 3D Face Renderings for Boosting Face Recognition",
                "image-path": ""
            },

            {
                "startTime": "23:30",
                "arxivId": "2407.07662",
                "arxivLink": "https://arxiv.org/abs/2407.07662",
                "title": "Backdoor Buster: Unlearning Bad Behavior in AI with a Pinch of Activation",
                "institute": "National Institute of Informatics, Technical University of Munich, Imperial College London...",
                "text": "This research proposes a novel backdoor mitigation approach using machine unlearning. Unlike previous unlearning methods, this approach is computationally inexpensive and achieves state-of-the-art performance while requiring only a handful of unseen samples for unlearning.",
                "paper-title": "Mitigating Backdoor Attacks using Activation-Guided Model Editing",
                "image-path": ""
            },

            {
                "startTime": "23:54",
                "arxivId": "2407.07541",
                "arxivLink": "https://arxiv.org/abs/2407.07541",
                "title": "Swiss DINO: A Vision Transformer That's More Than Just a Pretty Face!",
                "institute": "Samsung, University of Oxford",
                "text": "This research proposes a new method for personal object search, which involves identifying and localizing personal items in images captured by robotic devices. Unlike previous methods that rely on large foundation models or adaptation training, Swiss DINO uses a pre-trained DINOv2 transformer model and does not require any adaptation training.",
                "paper-title": "Swiss DINO: Efficient and Versatile Vision Framework for On-device Personal Object Search",
                "image-path": ""
            },

            {
                "startTime": "24:28",
                "arxivId": "2407.07858",
                "arxivLink": "https://arxiv.org/abs/2407.07858",
                "title": "Building Chatbots That Don't Just Talk, They Know!",
                "institute": "Nvidia",
                "text": "This research focuses on building enterprise-grade chatbots using Retrieval Augmented Generation (RAG) and highlights the challenges and solutions for ensuring content freshness, security, and cost-effectiveness. It differs from previous work by presenting a comprehensive framework called FACTS, which addresses these critical aspects.",
                "paper-title": "FACTS About Building Retrieval Augmented Generation-based Chatbots",
                "image-path": ""
            },

            {
                "startTime": "24:52",
                "arxivId": "2407.07325",
                "arxivLink": "https://arxiv.org/abs/2407.07325",
                "title": "Billiards Bot: AI Learns to Talk the Talk and Shoot the Pucks!",
                "institute": "Shenzhen Motern Technology Co. Ltd.",
                "text": "This research introduces a new video encoder called CLIP-ViP+ that incorporates local loss calculations to improve spatial correspondence in video understanding. This approach differs from previous work by explicitly modeling spatial relationships between objects and their corresponding positions in the video.",
                "paper-title": "HiLight: Technical Report on the Motern AI Video Language Model",
                "image-path": ""
            },

            {
                "startTime": "25:18",
                "arxivId": "2407.07294",
                "arxivLink": "https://arxiv.org/abs/2407.07294",
                "title": "Quantum Computing: HPC's New BFF?",
                "institute": "Texas A&M University, Oak Ridge National Laboratory",
                "text": "This research explores the performance of a hybrid quantum machine learning (QML) workflow that combines classical and quantum computations in a high-performance computing (HPC) environment. The study focuses on the practical aspects of running such programs on real HPC systems, analyzing the feasibility and performance of this approach.",
                "paper-title": "Analyzing Machine Learning Performance in a Hybrid Quantum Computing and HPC Environment",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 58,
        "num_total": 250,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202407111341_audio.mp3"
}
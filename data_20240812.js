
daily_data = {
    "date": "2024-08-12",
    "tweets": [
            {
                "startTime": "01:00",
                "arxivId": "2408.04655",
                "arxivLink": "https://arxiv.org/abs/2408.04655",
                "title": "AI's Got Feelings? New Study Uncovers the \"Strong\" Side of Value Alignment",
                "institute": "Sorbonne University",
                "text": "This research distinguishes between \"strong\" and \"weak\" value alignment in AI systems. Previous work focused on technical methods for alignment, while this paper delves into the cognitive abilities required for AI to truly understand and respond to human values.",
                "paper-title": "Strong and weak alignment of large language models with human values",
                "image-path": ""
            },

            {
                "startTime": "01:23",
                "arxivId": "2408.04811",
                "arxivLink": "https://arxiv.org/abs/2408.04811",
                "title": "LLMs on Trial: Jailbreaking AI with Code, Not Just Words!",
                "institute": "Stanford University",
                "text": "This research introduces a dynamic benchmark for evaluating LLM safety, focusing on composable jailbreak attacks. Unlike previous work that relies on static datasets, this approach uses a domain-specific language to represent attacks as compositions of parameterized string transformations.",
                "paper-title": "h4rm3l: A Dynamic Benchmark of Composable Jailbreak Attacks for LLM Safety Assessment",
                "image-path": ""
            },

            {
                "startTime": "01:52",
                "arxivId": "2408.05147",
                "arxivLink": "https://arxiv.org/abs/2408.05147",
                "title": "GemmaScope: Unlocking Language Model Secrets, One Sparse Autoencoder at a Time!",
                "institute": "Google",
                "text": "This research introduces GemmaScope, an open-source suite of sparse autoencoders (SAEs) trained on various layers of the Gemma2 language model. Unlike previous work that focused on smaller models or single layers, GemmaScope provides a comprehensive set of SAEs across multiple layers and sub-layers, making it easier for researchers to explore the internal workings of large language models.",
                "paper-title": "Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2",
                "image-path": ""
            },

            {
                "startTime": "02:13",
                "arxivId": "2408.04720",
                "arxivLink": "https://arxiv.org/abs/2408.04720",
                "title": "AI Simplifies Physics: Machine Learning Tames the Wild World of Scattering Amplitudes",
                "institute": "Caltech, Harvard University",
                "text": "This research introduces a novel approach to simplifying scattering amplitudes by combining contrastive learning with a transformer encoder-decoder architecture. This differs from previous work by focusing on identifying and grouping similar terms within complex expressions, allowing for more efficient simplification of lengthy amplitudes.",
                "paper-title": "Learning the Simplicity of Scattering Amplitudes",
                "image-path": ""
            },

            {
                "startTime": "02:34",
                "arxivId": "2408.04851",
                "arxivLink": "https://arxiv.org/abs/2408.04851",
                "title": "Classifiers Can Be Secretly Likelihood-Based OOD Detectors: A Hyperspherical Twist!",
                "institute": "Stanford University, University of Wisconsin-Madison",
                "text": "This research proposes a new framework called Intrinsic Likelihood (INK) for out-of-distribution (OOD) detection. Unlike previous methods that rely on heuristics or strong assumptions, INK offers a rigorous likelihood interpretation by modeling latent embeddings as a mixture of hyperspherical distributions.",
                "paper-title": "Your Classifier Can Be Secretly a Likelihood-Based OOD Detector",
                "image-path": ""
            },

            {
                "startTime": "03:06",
                "arxivId": "2408.05200",
                "arxivLink": "https://arxiv.org/abs/2408.05200",
                "title": "Language Models Learn New Tricks Without Forgetting the Old Ones!",
                "institute": "Hong Kong Polytechnic University, Peking University, University of Illinois at Chicago",
                "text": "This research introduces a new framework called TaSL (Task Skill Localization and Consolidation) for continual learning in language models. Unlike previous methods that rely on separate parameter blocks for each task, TaSL identifies and consolidates task-specific and shared knowledge within a single block, improving knowledge transfer and mitigating catastrophic forgetting.",
                "paper-title": "TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning",
                "image-path": ""
            },

            {
                "startTime": "03:41",
                "arxivId": "2408.04734",
                "arxivLink": "https://arxiv.org/abs/2408.04734",
                "title": "X-ray Laser's Brain: A Model for Smarter Science",
                "institute": "Stanford University, Pennsylvania State University",
                "text": "This research introduces a multi-scale cognitive interaction model that simulates human decision-making during experiments at the Linac Coherent Light Source (LCLS). This model is unique in its ability to integrate simulations at multiple scales, capturing aspects of individual cognition, teamwork, planning, and decision-making both in the moment and across extended data-taking runs.",
                "paper-title": "A Multi-Scale Cognitive Interaction Model of Instrument Operations at the Linac Coherent Light Source",
                "image-path": ""
            },

            {
                "startTime": "04:08",
                "arxivId": "2408.05097",
                "arxivLink": "https://arxiv.org/abs/2408.05097",
                "title": "Hyperbolic Language Models: When Uncertainty Gets a Curveball!",
                "institute": "Sapienza University of Rome, ItalAIs.r.l., Panasonic Corp. of North America...",
                "text": "This research explores the use of hyperbolic embeddings in large-scale vision-language models (VLMs), specifically BLIP-2, which has 2.7 billion parameters. Unlike previous work that focused on smaller models, this study tackles the challenges of scaling hyperbolic embeddings to such a large model.",
                "paper-title": "Hyperbolic Learning with Multimodal Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "04:38",
                "arxivId": "2408.04870",
                "arxivLink": "https://arxiv.org/abs/2408.04870",
                "title": "Copilot's Got a Case of the \"Confused Deputy\" Blues: How Malicious Documents Can Hijack Your Enterprise AI",
                "institute": "University of Texas at Austin",
                "text": "This research focuses on a new class of security vulnerabilities in retrieval-augmented generation (RAG) systems, specifically targeting how malicious documents can manipulate the responses generated by AI tools like Copilot for Microsoft 365. Unlike previous work that primarily focused on external threats, this study investigates the potential for insider threats to exploit RAG systems for data corruption and information leakage.",
                "paper-title": "ConfusedPilot: Compromising Enterprise Information Integrity and Confidentiality with Copilot for Microsoft 365",
                "image-path": ""
            },

            {
                "startTime": "05:04",
                "arxivId": "2408.04916",
                "arxivLink": "https://arxiv.org/abs/2408.04916",
                "title": "Trajectory Learning Gets a Semantic Makeover: PTrajM Makes Movement Meaningful!",
                "institute": "Aalborg University, CMU, Beijing Jiaotong University",
                "text": "This research introduces PTrajM, a novel method for learning vehicle trajectories that incorporates both movement behavior and travel purposes. Unlike previous methods that focus solely on movement patterns, PTrajM utilizes a pre-training procedure that aligns trajectory embeddings with road and POI information, enabling it to extract travel purposes without additional computational resources during the embedding process.",
                "paper-title": "PTrajM: Efficient and Semantic-rich Trajectory Learning with Pretrained Trajectory-Mamba",
                "image-path": ""
            },

            {
                "startTime": "05:37",
                "arxivId": "2408.04831",
                "arxivLink": "https://arxiv.org/abs/2408.04831",
                "title": "Sparse Views, Big Dreams: 3D Reconstruction Gets a Gaussian Makeover",
                "institute": "Peking University",
                "text": "This research introduces a novel coarse-to-fine Gaussian splatting paradigm for sparse-view 3D reconstruction, incorporating structure-aware masks to enhance the model's robustness to sparse inputs and noise. This approach differs from previous work by utilizing both 3D geometry augmentation and perceptual view augmentation, which are derived from the coarse Gaussian model, to improve the consistency and detail of the reconstructed surfaces.",
                "paper-title": "Self-augmented Gaussian Splatting with Structure-aware Masks for Sparse-view 3D Reconstruction",
                "image-path": ""
            },

            {
                "startTime": "06:03",
                "arxivId": "2408.05141",
                "arxivLink": "https://arxiv.org/abs/2408.05141",
                "title": "RAG-ing Against the Machine: A Hybrid System for Smarter AI Reasoning",
                "institute": "Peking University, University of Wisconsin-Madison",
                "text": "This research introduces a hybrid RAG system that incorporates a suite of optimizations to enhance retrieval quality, reasoning capabilities, and numerical computation ability. It differs from previous work by integrating multiple strategies, including attribute prediction, a numerical calculator, and an LLM knowledge extractor, to address the challenges of hallucination, domain expertise, and time-sensitive information in LLMs.",
                "paper-title": "A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning",
                "image-path": ""
            },

            {
                "startTime": "06:30",
                "arxivId": "2408.04808",
                "arxivLink": "https://arxiv.org/abs/2408.04808",
                "title": "AI Chips Get a Memory Makeover: T10 Compiler Makes Data Dance for Faster Deep Learning!",
                "institute": "University of Illinois, Peking University, Microsoft",
                "text": "This research introduces T10, a deep learning compiler that leverages the inter-core communication bandwidth and distributed on-chip memory of AI chips. Unlike previous compilers that rely on a virtual global memory, T10 utilizes a \"compute-shift\" paradigm, where data is shifted between cores in a predictable pattern, reducing memory footprint and communication overhead.",
                "paper-title": "Scaling Deep Learning Computation over the Inter-Core Connected Intelligence Processor",
                "image-path": ""
            },

            {
                "startTime": "06:54",
                "arxivId": "2408.04660",
                "arxivLink": "https://arxiv.org/abs/2408.04660",
                "title": "COBOL's Got Talent: AI Makes Mainframe Modernization a Breeze!",
                "institute": "FPT Software AI Center",
                "text": "This research introduces XMainframe, a large language model (LLM) specifically trained on mainframe systems and COBOL codebases. Unlike previous CodeLLMs, XMainframe is designed to understand and interact with legacy code, addressing the challenges of mainframe modernization.",
                "paper-title": "XMainframe: A Large Language Model for Mainframe Modernization",
                "image-path": ""
            },

            {
                "startTime": "07:22",
                "arxivId": "2408.04718",
                "arxivLink": "https://arxiv.org/abs/2408.04718",
                "title": "Diffusion Models: Ensemble Up for Zero-Shot Uncertainty!",
                "institute": "CMU",
                "text": "This research explores the use of diffusion probabilistic models for ensemble prediction in regression tasks, focusing on zero-shot uncertainty quantification without requiring explicit uncertainty estimation during model training.",
                "paper-title": "Zero-Shot Uncertainty Quantification using Diffusion Probabilistic Models",
                "image-path": ""
            },

            {
                "startTime": "07:53",
                "arxivId": "2408.04810",
                "arxivLink": "https://arxiv.org/abs/2408.04810",
                "title": "UniBench: 50+ Vision-Language Benchmarks in 5 Minutes!",
                "institute": "Meta",
                "text": "This research introduces UniBench, a unified framework for evaluating vision-language models (VLMs) across a comprehensive set of 50+ benchmarks. UniBench differs from previous work by providing a standardized and efficient way to evaluate VLMs, enabling researchers to quickly compare model performance across various capabilities.",
                "paper-title": "UniBench: Visual Reasoning Requires Rethinking Vision-Language Beyond Scaling",
                "image-path": ""
            },

            {
                "startTime": "08:16",
                "arxivId": "2408.04683",
                "arxivLink": "https://arxiv.org/abs/2408.04683",
                "title": "Code Backdoors: Trigger Inversion to the Rescue!",
                "institute": "Nanjing University, Nanyang Technological University",
                "text": "This research proposes a novel backdoor defense technique called EliBadCode, which utilizes trigger inversion to eliminate backdoors in neural code models (NCMs). Unlike previous work that focuses on detecting poisoned inputs, EliBadCode aims to identify and remove the backdoor itself without affecting the model's performance on clean inputs.",
                "paper-title": "Eliminating Backdoors in Neural Code Models via Trigger Inversion",
                "image-path": ""
            },

            {
                "startTime": "08:46",
                "arxivId": "2408.04760",
                "arxivLink": "https://arxiv.org/abs/2408.04760",
                "title": "Robot's Got a Segmentation Problem: How Uncertainty-Aware Models Help!",
                "institute": "MIT",
                "text": "This research introduces a novel approach to object segmentation by generating a distribution of possible segmentations, rather than just a single prediction. This allows the system to explicitly represent uncertainty and use it to guide robot actions that reduce ambiguity.",
                "paper-title": "Embodied Uncertainty-Aware Object Segmentation",
                "image-path": ""
            },

            {
                "startTime": "09:14",
                "arxivId": "2408.04815",
                "arxivLink": "https://arxiv.org/abs/2408.04815",
                "title": "Brainwave Detectives: Unmasking Alzheimer's with MEG and MRI!",
                "institute": "Universiti Teknologi PETRONAS, Hospital Universiti Sains Malaysia, Ulster University...",
                "text": "This research combines MEG and MRI data to identify biomarkers for Alzheimer's disease, going beyond previous studies that focused on a single modality.",
                "paper-title": "Towards improving Alzheimer's intervention: a machine learning approach for biomarker detection through combining MEG and MRI pipelines",
                "image-path": ""
            },

            {
                "startTime": "09:43",
                "arxivId": "2408.05087",
                "arxivLink": "https://arxiv.org/abs/2408.05087",
                "title": "Graph Self-Supervised Learning: Neighbors Are the New Black!",
                "institute": "Nanjing University, Tsinghua University",
                "text": "This research builds upon Bootstrapped Graph Latents (BGRL), a method for learning graph representations without negative samples. It introduces a novel approach to leverage the inherent homophily in graphs by incorporating node-neighbor pairs as potential positive samples. This differs from previous work by focusing on mining positive pairs from the graph structure itself, rather than relying solely on augmented views.",
                "paper-title": "Bootstrap Latents of Nodes and Neighbors for Graph Self-Supervised Learning",
                "image-path": ""
            },

            {
                "startTime": "10:07",
                "arxivId": "2408.05058",
                "arxivLink": "https://arxiv.org/abs/2408.05058",
                "title": "Phylogeny's New Trick: Semi-Implicit Branch Lengths for Tree-mendous Inference!",
                "institute": "Peking University, Fred Hutchinson Cancer Research Center, UC Los Angeles",
                "text": "This research introduces a new approach to variational Bayesian phylogenetic inference (VBPI) by using semi-implicit hierarchical distributions for branch lengths. Unlike previous methods that rely on explicit distributions, this approach allows for more flexible and accurate modeling of branch length variations across different tree topologies.",
                "paper-title": "Variational Bayesian Phylogenetic Inference with Semi-implicit Branch Length Distributions",
                "image-path": ""
            },

            {
                "startTime": "10:35",
                "arxivId": "2408.04777",
                "arxivLink": "https://arxiv.org/abs/2408.04777",
                "title": "Prostate Cancer Detection: AI Gets a Style Makeover for Multi-Site MRI!",
                "institute": "Siemens Healthineers, Vanderbilt University, Radboud University Medical Center...",
                "text": "This research introduces a novel unsupervised domain adaptation (UDA) method using a unified generative model for multi-site prostate cancer (PCa) detection. Unlike previous UDA methods that require multiple generators for each domain pair, this approach utilizes a single generator with a dynamic filter to translate image styles across multiple domains.",
                "paper-title": "Deep Learning-based Unsupervised Domain Adaptation via a Unified Model for Prostate Lesion Detection Using Multisite Bi-parametric MRI Datasets",
                "image-path": ""
            },

            {
                "startTime": "11:06",
                "arxivId": "2408.05178",
                "arxivLink": "https://arxiv.org/abs/2408.05178",
                "title": "ECG-FM: The Open-Source Heartbeat Whisperer",
                "institute": "University Health Network, Vector Institute for Artificial Intelligence, University of Toronto",
                "text": "This research introduces ECG-FM, an open-source foundation model for ECG analysis, trained on a massive dataset of 2.5 million ECG segments. Unlike previous task-specific models, ECG-FM can be adapted to various downstream tasks with minimal labeled data.",
                "paper-title": "ECG-FM: An Open Electrocardiogram Foundation Model",
                "image-path": ""
            },

            {
                "startTime": "11:27",
                "arxivId": "2408.04913",
                "arxivLink": "https://arxiv.org/abs/2408.04913",
                "title": "Knowledge Graph Embeddings: From Facts to Fancy Geometry!",
                "institute": "DI ENS, ENS, CNRS...",
                "text": "This research examines recent methods for embedding knowledge bases in description logic into vector spaces, focusing on their geometric-based semantics. It identifies several theoretical properties and investigates how concrete embedding methods fit into this framework.",
                "paper-title": "Knowledge Base Embeddings: Semantics and Theoretical Properties",
                "image-path": ""
            },

            {
                "startTime": "11:55",
                "arxivId": "2408.05075",
                "arxivLink": "https://arxiv.org/abs/2408.05075",
                "title": "DeepInteraction++: Autonomous Driving's New BFF - Multi-Modal Interaction Makes the Difference!",
                "institute": "Fudan University, Nanyang Technological University, University of Surrey...",
                "text": "This paper introduces a new approach to multi-modal interaction for autonomous driving, focusing on maintaining separate representations for LiDAR and camera data throughout the entire perception pipeline. This differs from previous methods that typically fuse these modalities into a single representation, potentially losing valuable information.",
                "paper-title": "DeepInteraction++: Multi-Modality Interaction for Autonomous Driving",
                "image-path": ""
            },

            {
                "startTime": "12:24",
                "arxivId": "2408.04746",
                "arxivLink": "https://arxiv.org/abs/2408.04746",
                "title": "XAI for Cybersecurity: Explanations That Don't Explain?",
                "institute": "MIT",
                "text": "This research investigates the effectiveness of Explainable AI (XAI) techniques in a cybersecurity context, specifically for source code classification. It highlights the challenges of using popular XAI methods like SHAP and LIME with non-technical users, finding that their explanations can be confusing and contradictory.",
                "paper-title": "More Questions than Answers? Lessons from Integrating Explainable AI into a Cyber-AI Tool",
                "image-path": ""
            },

            {
                "startTime": "12:49",
                "arxivId": "2408.05006",
                "arxivLink": "https://arxiv.org/abs/2408.05006",
                "title": "LLMs Need a Tutor: New Framework Teaches AI to Debug Code",
                "institute": "Northeastern University, Peking University, Tsinghua University",
                "text": "This research introduces DEBUGEVAL, a benchmark for evaluating LLMs' debugging capabilities, and proposes MASTER, a framework that refines code debugging data for supervised fine-tuning. Unlike previous work, DEBUGEVAL includes tasks beyond code repair, and MASTER uses a communicative agent-based approach to generate high-quality data.",
                "paper-title": "Enhancing the Code Debugging Ability of LLMs via Communicative Agent Based Data Refinement",
                "image-path": ""
            },

            {
                "startTime": "13:16",
                "arxivId": "2408.04872",
                "arxivLink": "https://arxiv.org/abs/2408.04872",
                "title": "Stop Saying \"Hello World!\" - LLMs Learn to Translate with Syntax",
                "institute": "Peking University",
                "text": "This research introduces syntactic knowledge into the selection of in-context examples for machine translation (MT). Unlike previous work that focused on word-level matching or embedding-based scoring, this study leverages the deep syntactic structure of sentences to improve translation quality.",
                "paper-title": "SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation",
                "image-path": ""
            },

            {
                "startTime": "13:38",
                "arxivId": "2408.04745",
                "arxivLink": "https://arxiv.org/abs/2408.04745",
                "title": "AI Sniffs Out Methane Leaks From Space: New System Helps Stop Global Warming",
                "institute": "United Nations Environment Programme, University of Cambridge, Vector Institute...",
                "text": "This research presents MARS-S2L, an automated AI-driven methane emitter monitoring system that uses Sentinel-2 and Landsat satellite imagery. Unlike previous methods that relied on limited areas or synthetic data, MARS-S2L utilizes a large, expert-verified global dataset of real methane plumes for training and evaluation.",
                "paper-title": "AI for operational methane emitter monitoring from space",
                "image-path": ""
            },

            {
                "startTime": "14:07",
                "arxivId": "2408.04713",
                "arxivLink": "https://arxiv.org/abs/2408.04713",
                "title": "Mamba Strikes Again: Modeling Long-Term Graph Dynamics with State-Space Models",
                "institute": "University of Oxford",
                "text": "This paper proposes DyGMamba, a new model for continuous-time dynamic graphs (CTDGs) that uses state-space models (SSMs) to efficiently capture long-term temporal dependencies. Unlike previous methods that rely on Transformers or graph convolutions, DyGMamba leverages the Mamba SSM, which is known for its efficiency in handling long sequences.",
                "paper-title": "DyGMamba: Efficiently Modeling Long-Term Temporal Dependency on Continuous-Time Dynamic Graphs with State Space Models",
                "image-path": ""
            },

            {
                "startTime": "14:47",
                "arxivId": "2408.04678",
                "arxivLink": "https://arxiv.org/abs/2408.04678",
                "title": "LLM Speed Boost: CREST Compresses Data for Faster Decoding",
                "institute": "CMU",
                "text": "This research introduces CREST, a method for compacting the datastore used in REST, a retrieval-based speculative decoding technique. Unlike REST, which stores the entire pre-training dataset, CREST selectively stores only the smallest and most common n-grams, achieving comparable performance with significantly less storage space.",
                "paper-title": "CREST: Effectively Compacting a Datastore For Retrieval-Based Speculative Decoding",
                "image-path": ""
            },

            {
                "startTime": "15:10",
                "arxivId": "2408.05136",
                "arxivLink": "https://arxiv.org/abs/2408.05136",
                "title": "Molecule Design: A New Way to Spot the Difference Between Ortho, Meta, and Para!",
                "institute": "University of Tokyo",
                "text": "This research introduces a new set of descriptors called \"cycle-configurations\" (CC) to the \"two-layered (2L) model\" of molecular inference. CCs capture the arrangement of exterior parts, called \"fringe-trees,\" attached to cycles in a chemical graph, which allows for distinguishing between meta and para patterns in aromatic rings, something the 2L model couldn't do before.",
                "paper-title": "Cycle-Configuration: A Novel Graph-theoretic Descriptor Set for Molecular Inference",
                "image-path": ""
            },

            {
                "startTime": "15:37",
                "arxivId": "2408.04948",
                "arxivLink": "https://arxiv.org/abs/2408.04948",
                "title": "Financial Facts: HybridRAG Makes Knowledge Graphs and Vector Retrieval Sing!",
                "institute": "Nvidia",
                "text": "This research proposes a novel approach called HybridRAG, which combines Knowledge Graphs (KGs) and Vector Retrieval Augmented Generation (RAG) techniques to improve information extraction from financial documents. This approach differs from previous work by integrating both structured and unstructured information retrieval methods, aiming to enhance the accuracy and comprehensiveness of the extracted information.",
                "paper-title": "HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction",
                "image-path": ""
            },

            {
                "startTime": "15:55",
                "arxivId": "2408.05082",
                "arxivLink": "https://arxiv.org/abs/2408.05082",
                "title": "Label Smoothing Gets a Boost: DRO-LS Makes Few Data Go Far!",
                "institute": "Beijing Institute of Technology, Tsinghua University, Beijing University of Posts and Telecommunications",
                "text": "This research integrates label smoothing (LS) into the distributionally robust optimization (DRO) framework, creating a novel two-stage problem called DRO-LS. This approach allows for flexible data shifting to unseen domains, effectively generating new samples without extra annotations.",
                "paper-title": "Generalizing Few Data to Unseen Domains Flexibly Based on Label Smoothing Integrated with Distributionally Robust Optimization",
                "image-path": ""
            },

            {
                "startTime": "16:23",
                "arxivId": "2408.05092",
                "arxivLink": "https://arxiv.org/abs/2408.05092",
                "title": "Deep Learning Goes Undercover: Training Models Without Sharing Sensitive Data!",
                "institute": "Swiss Center for Electronics and Microtechnology, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research proposes a new method called PriPHiT for training deep neural networks on edge-cloud systems while preserving user privacy. Unlike previous methods that focus on privacy during inference, PriPHiT tackles privacy concerns during the training phase itself.",
                "paper-title": "PriPHiT: Privacy-Preserving Hierarchical Training of Deep Neural Networks",
                "image-path": ""
            },

            {
                "startTime": "16:51",
                "arxivId": "2408.04680",
                "arxivLink": "https://arxiv.org/abs/2408.04680",
                "title": "Foggy Thinking: LLMs Get a Decentralized Makeover for Medical Data",
                "institute": "Stanford University",
                "text": "This research proposes a dynamic fog computing architecture for executing LLMs in medical applications, aiming to address privacy, trust, and financial concerns associated with cloud-based solutions. This approach differs from previous work by decentralizing LLM execution and dynamically allocating tasks across edge, fog, and cloud layers based on their capabilities and trust levels.",
                "paper-title": "Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications",
                "image-path": ""
            },

            {
                "startTime": "17:14",
                "arxivId": "2408.04816",
                "arxivLink": "https://arxiv.org/abs/2408.04816",
                "title": "FUSE-ing Language Models: Zero-Shot Adapter Discovery for Prompt Optimization Across Tokenizers",
                "institute": "CMU",
                "text": "This paper proposes a novel approach for approximating gradients across models and tokenizers during prompt optimization. It introduces an adapter that precisely maps across token and embedding spaces in the forward pass. By leveraging a precomputed linear transformation, it efficiently approximates the behavior of a true differentiable mapping between embedding spaces during the backward pass.",
                "paper-title": "FUSE-ing Language Models: Zero-Shot Adapter Discovery for Prompt Optimization Across Tokenizers",
                "image-path": ""
            },

            {
                "startTime": "17:42",
                "arxivId": "2408.05126",
                "arxivLink": "https://arxiv.org/abs/2408.05126",
                "title": "AI's Got the Blues: Can ChatGPT Decode Hate Speech on YouTube?",
                "institute": "University of Cambridge, Technical University of Munich",
                "text": "This research explores the use of GPT-4 for thematic analysis of YouTube comments, focusing on hate speech related to Roma migrants in Sweden. Unlike previous studies, it examines the model's ability to handle sensitive content and its potential for human-AI synergy in qualitative research.",
                "paper-title": "Large Language Models and Thematic Analysis: Human-AI Synergy in Researching Hate Speech on Social Media",
                "image-path": ""
            },

            {
                "startTime": "18:08",
                "arxivId": "2408.04661",
                "arxivLink": "https://arxiv.org/abs/2408.04661",
                "title": "Ontology-Powered Text Mining: A Recipe for Extracting Materials Secrets",
                "institute": "IBM",
                "text": "This research introduces MaterioMiner, a dataset that links a materials mechanics ontology with textual entities from scientific literature. Unlike previous datasets focused on specific subdomains, MaterioMiner aims to be more domain-agnostic, allowing for broader applications in materials science.",
                "paper-title": "MaterioMiner -- An ontology-based text mining dataset for extraction of process-structure-property entities",
                "image-path": ""
            },

            {
                "startTime": "18:40",
                "arxivId": "2408.04658",
                "arxivLink": "https://arxiv.org/abs/2408.04658",
                "title": "Shopping Assistant Wins KDD Cup: AI Makes Online Shopping a Breeze!",
                "institute": "Nvidia",
                "text": "This research stands out by focusing on the development of a training dataset for LLMs specifically tailored to the online shopping domain. The authors created this dataset by processing multiple public datasets and augmenting it with synthetic data generated by LLMs.",
                "paper-title": "Winning Amazon KDD Cup'24",
                "image-path": ""
            },

            {
                "startTime": "19:07",
                "arxivId": "2408.04681",
                "arxivLink": "https://arxiv.org/abs/2408.04681",
                "title": "AI Chatbots: Planting False Memories in Your Head?",
                "institute": "MIT",
                "text": "This study investigates the impact of conversational AI powered by large language models (LLMs) on false memory formation, a topic not extensively explored in previous research. It simulates witness interviews using a generative chatbot and compares its effects to those of a survey-based method and a pre-scripted chatbot.",
                "paper-title": "Conversational AI Powered by Large Language Models Amplifies False Memories in Witness Interviews",
                "image-path": ""
            },

            {
                "startTime": "19:28",
                "arxivId": "2408.04803",
                "arxivLink": "https://arxiv.org/abs/2408.04803",
                "title": "NeRFs on a Diet: Meta-Learning Makes 3D Scenes Slim and Speedy!",
                "institute": "UC Berkeley",
                "text": "This research uses meta-learning to create a \"smart\" starting point for NeRF models, allowing them to learn 3D scenes from fewer images than traditional methods. This is different from previous work that either relied on large datasets or used external priors.",
                "paper-title": "FewShotNeRF: Meta-Learning-based Novel View Synthesis for Rapid Scene-Specific Adaptation",
                "image-path": ""
            },

            {
                "startTime": "19:51",
                "arxivId": "2408.05148",
                "arxivLink": "https://arxiv.org/abs/2408.05148",
                "title": "Floating-Point Fiasco: How Tiny Errors Wreck Big Computations",
                "institute": "ETH Zurich, Oak Ridge National Laboratory",
                "text": "This research investigates the impact of floating-point non-associativity (FPNA) on reproducibility in high-performance computing (HPC) and deep learning (DL) applications. It goes beyond previous work by analyzing the statistical properties of FPNA within parallel programming models and examining the effects on specific PyTorch operations.",
                "paper-title": "Impacts of floating-point non-associativity on reproducibility for HPC and deep learning applications",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 43,
        "num_total": 174,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202408120657_audio.mp3"
}

<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ribbit Ribbit - Fresh AI Paper Top Picks</title>
    <meta name="description"
        content="Discover top ArXiv papers in AI and machine learning daily with our fresh picks. Browse easily through tweet-sized summaries or listen on-the-go. Make learning engaging and accessible anytime, anywhere.">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Amatic+SC:wght@400;700&family=Dosis:wght@200..800&family=Roboto:wght@300..700&display=swap">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
    <link rel="icon" href="assets/frogFavicon.png" type="image/x-icon">    
    <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>
</head>

<body>
    <div id="headerId" class="header"></div>
    <div class="container">
        <div id="topblock">
            <div style="height: 80px;"></div>
            <div class="institute-text" style="padding-top: 3px; line-height: 1.2;">
                Freshest
                Top Picks:
                <span class="highlightNumber" style="font-size: 28px;">53</span> out of <span
                    class="highlightNumber">269</span> arXiv AI
                papers
            </div>
            <div style="display: flex; flex-direction: column; justify-content: flex-start; align-items: flex-start;">
                <div class="institute-text" style="line-height: 1.2;">just released on</div>
                <div id="data-default-date" data-date="2024-07-24"></div>
                <input type="text" id="selectedDate" style="text-decoration: underline;" />
            </div>
            <div style=" height: 10px;">
            </div>
        </div>

<div class="tweet" id="tweet0">
 <div class="start-time-icon" title="Play from here">
  00:56
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16611" target="_blank">
    @arXiv 2407.16611
   </a>
   <span class="tweet-title">
    Continual Learning:  Local vs Global, It's a Battle of the Brains!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    ETH Zurich
   </span>
  </div>
  <div class="primary-text">
   This research classifies continual learning algorithms based on whether they use local or global approximations of the task loss function. This distinction is novel and helps explain why some algorithms struggle when learning becomes non-local.
  </div>
 </div>
</div>
<div class="tweet" id="tweet1">
 <div class="start-time-icon" title="Play from here">
  01:17
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16607" target="_blank">
    @arXiv 2407.16607
   </a>
   <span class="tweet-title">
    Tokenizers Spill the Tea:  Unmasking the Secrets of Language Model Training Data
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Washington
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel approach to data mixture inference, focusing on the previously overlooked information contained within byte-pair encoding (BPE) tokenizers. Unlike previous work that focused on membership inference, this study aims to uncover the proportions of different data categories within a language model's training data.
  </div>
 </div>
</div>
<div class="tweet" id="tweet2">
 <div class="start-time-icon" title="Play from here">
  01:42
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16286" target="_blank">
    @arXiv 2407.16286
   </a>
   <span class="tweet-title">
    Pruning LLMs:  Shapley Value vs. Cosine Distance - A Battle of the Brains!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Cambridge
   </span>
  </div>
  <div class="primary-text">
   This research delves deeper into depth pruning of LLMs by exploring the impact of different block influence metrics, including adaptive metrics like Shapley value, in addition to static metrics like cosine distance. It also examines the pruning of individual self-attention and feed-forward layers within a block.
  </div>
 </div>
</div>
<div class="tweet" id="tweet3">
 <div class="start-time-icon" title="Play from here">
  02:12
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16007" target="_blank">
    @arXiv 2407.16007
   </a>
   <span class="tweet-title">
    Social Media Quotes:  More Than Just Likes, They're Roles!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Google
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel framework for automatically classifying the roles of social media posts embedded in web pages. Unlike previous work that focuses on analyzing social media accounts themselves, this study examines the context surrounding the embedded posts to understand their function within the web page.
  </div>
 </div>
</div>
<div class="tweet" id="tweet4">
 <div class="start-time-icon" title="Play from here">
  02:34
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16186" target="_blank">
    @arXiv 2407.16186
   </a>
   <span class="tweet-title">
    RL's New Frontier:  Automating the Environment Shaping Game!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    MIT
   </span>
  </div>
  <div class="primary-text">
   This research focuses on the often-overlooked bottleneck in reinforcement learning (RL) for robotics: environment shaping. It argues that current RL benchmarks are artificially easy because they rely on human-designed shaping, and proposes a new approach to automate this process.
  </div>
 </div>
</div>
<div class="tweet" id="tweet5">
 <div class="start-time-icon" title="Play from here">
  02:59
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16677" target="_blank">
    @arXiv 2407.16677
   </a>
   <span class="tweet-title">
    Robot Assembly Gets a Tune-Up: Residual Learning Makes Robots More Precise!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Massachusetts Institute of Technology, Improbable AI Lab, Harvard University
   </span>
  </div>
  <div class="primary-text">
   This research proposes training residual policies on top of frozen behavior cloning (BC)-trained diffusion models to improve the performance of robotic assembly tasks. This approach differs from previous work by avoiding direct fine-tuning of the BC model, which can be challenging with complex architectures like diffusion models and action chunking.
  </div>
 </div>
</div>
<div class="tweet" id="tweet6">
 <div class="start-time-icon" title="Play from here">
  03:25
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16602" target="_blank">
    @arXiv 2407.16602
   </a>
   <span class="tweet-title">
    Policy Optimization Gets a Speed Boost:  Functional Acceleration for PMD
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    McGill University, Mila Quebec AI Institute, Google DeepMind...
   </span>
  </div>
  <div class="primary-text">
   This research applies functional acceleration to the Policy Mirror Descent (PMD) family of algorithms, which is a general framework for reinforcement learning. This approach is different from previous work that focused on accelerating the policy parameters.
  </div>
 </div>
</div>
<div class="tweet" id="tweet7">
 <div class="start-time-icon" title="Play from here">
  03:55
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16015" target="_blank">
    @arXiv 2407.16015
   </a>
   <span class="tweet-title">
    Wallcamera: A Peek Behind the Curtain, or Just a DIF-ferent View?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    MIT, University of Southampton
   </span>
  </div>
  <div class="primary-text">
   This paper compares the Wallcamera, a recent innovation in activity recognition, to an earlier technique called Differential Imaging Forensics (DIF). While both methods extract subtle visual cues from wall reflections, the Wallcamera focuses on activity recognition at a finer granularity, while DIF offers a broader range of applications in forensics.
  </div>
 </div>
</div>
<div class="tweet" id="tweet8">
 <div class="start-time-icon" title="Play from here">
  04:17
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.15892" target="_blank">
    @arXiv 2407.15892
   </a>
   <span class="tweet-title">
    Training LLMs on Long Sequences? No Problem, Mini-Sequence Transformer to the Rescue!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Caltech, CMU
   </span>
  </div>
  <div class="primary-text">
   This paper introduces MINI-SEQUENCE TRANSFORMER (MST), a technique that partitions input sequences into smaller "mini-sequences" to reduce memory usage during training. This approach differs from previous methods like activation recomputation by focusing on optimizing the intermediate memory of MLP and LM-Head blocks, rather than just the activation values.
  </div>
 </div>
</div>
<div class="tweet" id="tweet9">
 <div class="start-time-icon" title="Play from here">
  04:42
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16634" target="_blank">
    @arXiv 2407.16634
   </a>
   <span class="tweet-title">
    AI Doctor's New Trick:  Making Up Fake Ultrasound Images to Diagnose Breast Cancer Better!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Peking University, Chinese Academy of Sciences
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new approach to address the long-tail distribution problem in medical image datasets. Instead of relying solely on real data, the researchers propose a pipeline called TAILOR that uses a knowledge-driven generative model to create synthetic images, particularly for rare cases. This approach aims to improve the accuracy and interpretability of diagnostic models.
  </div>
 </div>
</div>
<div class="tweet" id="tweet10">
 <div class="start-time-icon" title="Play from here">
  05:11
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.15866" target="_blank">
    @arXiv 2407.15866
   </a>
   <span class="tweet-title">
    AI Models on a Diet: CXL Makes Weight Quantization Slim and Fast!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Rensselaer Polytechnic Institute, BASIS Independent Fremont, IBM
   </span>
  </div>
  <div class="primary-text">
   This research proposes a CXL-based AI model store that supports runtime configurable weight quantization, enabling dynamic adjustment of weight precision based on their importance during inference. Unlike previous work, this approach focuses on improving DRAM access efficiency by leveraging bit-plane in-memory placement and memory logical space bloating.
  </div>
 </div>
</div>
<div class="tweet" id="tweet11">
 <div class="start-time-icon" title="Play from here">
  05:38
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.15869" target="_blank">
    @arXiv 2407.15869
   </a>
   <span class="tweet-title">
    Time Series Forecasting:  Long-Term Memory Without the Overfitting Blues!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Harbin University of Science and Technology, Harbin Institute of Technology
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel approach to long time series forecasting by decoupling multi-scale temporal patterns and modeling each pattern with its corresponding period length as the token size. This differs from previous methods that often struggle with overfitting when handling long input sequences.
  </div>
 </div>
</div>
<div class="tweet" id="tweet12">
 <div class="start-time-icon" title="Play from here">
  06:05
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16248" target="_blank">
    @arXiv 2407.16248
   </a>
   <span class="tweet-title">
    Livestream Shopping:  A Graph-Guided Journey to Find Your Perfect Product!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Chinese Academy of Sciences, Tsinghua University, Kuaishou Technology
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel Spatiotemporal Graph Guided Multi-modal Network (SGMN) for livestreaming product retrieval. Unlike previous methods that focus on coarse-grained matching, SGMN leverages fine-grained matching by integrating textual embeddings, instance-level similarity mining, and frame-level graph learning.
  </div>
 </div>
</div>
<div class="tweet" id="tweet13">
 <div class="start-time-icon" title="Play from here">
  06:33
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16223" target="_blank">
    @arXiv 2407.16223
   </a>
   <span class="tweet-title">
    Pose Estimation with a Pinch of Probability:  New Metrics for Landing Safely
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Stanford University
   </span>
  </div>
  <div class="primary-text">
   This research introduces novel closed-form expressions for measuring calibration and sharpness specifically for multivariate normal distributions, which are used to evaluate the performance of three probabilistic parameter estimators for pose estimation.
  </div>
 </div>
</div>
<div class="tweet" id="tweet14">
 <div class="start-time-icon" title="Play from here">
  07:00
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16564" target="_blank">
    @arXiv 2407.16564
   </a>
   <span class="tweet-title">
    Music Editing Made Easy: A Tiny AI Tweak for Big Changes
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    National Taiwan University, CMU, UC San Diego
   </span>
  </div>
  <div class="primary-text">
   This paper proposes Audio Prompt Adapter (AP-Adapter), a lightweight module that adds audio input capability to pre-trained text-to-music models. Unlike previous methods that rely on complex prompts or iterative refinements, AP-Adapter allows for zero-shot music editing with a single text prompt and an audio input.
  </div>
 </div>
</div>
<div class="tweet" id="tweet15">
 <div class="start-time-icon" title="Play from here">
  07:29
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16291" target="_blank">
    @arXiv 2407.16291
   </a>
   <span class="tweet-title">
    TAPTRv2:  Tracking Points with a Touch of Attention!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    South China University of Technology, International Digital Economy Academy, The Hong Kong University of Science and Technology...
   </span>
  </div>
  <div class="primary-text">
   This paper introduces TAPTRv2, an improvement on the TAPTR framework for tracking any point in a video. Unlike TAPTR, which relies on cost-volume features that can contaminate the point query's content, TAPTRv2 uses an attention-based position update operation to avoid this issue.
  </div>
 </div>
</div>
<div class="tweet" id="tweet16">
 <div class="start-time-icon" title="Play from here">
  08:01
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16396" target="_blank">
    @arXiv 2407.16396
   </a>
   <span class="tweet-title">
    Learning to Render: A Neural Network Makes 3D Reconstruction a Breeze!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University, Kuaishou Technology, Wayne State University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel differentiable renderer for inferring unsigned distance functions (UDFs) from multi-view images. Unlike previous methods that rely on handcrafted equations, this approach utilizes a neural network trained in a data-driven manner to learn how to render unsigned distances into depth images. This learned "volume rendering prior" is then used to infer UDFs for unseen scenes, resulting in more accurate and robust reconstructions.
  </div>
 </div>
</div>
<div class="tweet" id="tweet17">
 <div class="start-time-icon" title="Play from here">
  08:24
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16008" target="_blank">
    @arXiv 2407.16008
   </a>
   <span class="tweet-title">
    Reward Models Get a Boost: New Method Makes AI Feedback More Reliable
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Google, Emory University
   </span>
  </div>
  <div class="primary-text">
   This research introduces RMBoost, a new method for generating synthetic preference data for training reward models. Unlike previous methods that generate two responses and then predict the preference label, RMBoost first generates one response, selects a preference label, and then generates a second response conditioned on the first response and the label. This approach aims to reduce labeling noise and increase the diversity of generated responses.
  </div>
 </div>
</div>
<div class="tweet" id="tweet18">
 <div class="start-time-icon" title="Play from here">
  08:52
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.15975" target="_blank">
    @arXiv 2407.15975
   </a>
   <span class="tweet-title">
    Headline Hallucination: When AI News Goes Off the Rails!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Google
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new multilingual dataset for detecting fine-grained headline hallucinations, going beyond simple "true" or "false" labels to pinpoint specific types of errors. It also explores how large language models can be used for few-shot learning in this task.
  </div>
 </div>
</div>
<div class="tweet" id="tweet19">
 <div class="start-time-icon" title="Play from here">
  09:19
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.15992" target="_blank">
    @arXiv 2407.15992
   </a>
   <span class="tweet-title">
    Lip-Reading Babies: How Visual Cues Boost Speech Learning
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    MIT
   </span>
  </div>
  <div class="primary-text">
   This research explores the impact of visual information on phonetic learning by training a computational model on both audio and video data. Unlike previous work that focused solely on audio, this study demonstrates that visual cues from a speaker's mouth can significantly improve a model's ability to discriminate between phonemes, even when only audio is available at test time.
  </div>
 </div>
</div>
<div class="tweet" id="tweet20">
 <div class="start-time-icon" title="Play from here">
  09:42
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16237" target="_blank">
    @arXiv 2407.16237
   </a>
   <span class="tweet-title">
    RTL Code Generation:  LLMs Get a Self-Reflection Makeover!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Peking University, Chinese University of Hong Kong, Fudan University...
   </span>
  </div>
  <div class="primary-text">
   This research introduces OriGen, an open-source framework for RTL code generation that utilizes a novel code-to-code augmentation methodology to enhance the quality of open-source RTL code datasets. It also incorporates a self-reflection mechanism that enables the model to autonomously fix syntactic errors by leveraging compiler feedback.
  </div>
 </div>
</div>
<div class="tweet" id="tweet21">
 <div class="start-time-icon" title="Play from here">
  10:11
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16266" target="_blank">
    @arXiv 2407.16266
   </a>
   <span class="tweet-title">
    Beyond Binary Bias:  Translating the World, One Non-Binary Identity at a Time
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Beijing Jiaotong University, Tencent Inc
   </span>
  </div>
  <div class="primary-text">
   This research goes beyond the traditional male/female binary in evaluating gender bias in machine translation. It introduces a new benchmark, AmbGIMT, which assesses bias across a spectrum of 14 gender identities, including non-binary individuals.
  </div>
 </div>
</div>
<div class="tweet" id="tweet22">
 <div class="start-time-icon" title="Play from here">
  10:41
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16355" target="_blank">
    @arXiv 2407.16355
   </a>
   <span class="tweet-title">
    "Best-Action Queries:  A Little Help Goes a Long Way in Online Learning"
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Sapienza University of Rome, Bocconi University, Meta
   </span>
  </div>
  <div class="primary-text">
   This research explores the impact of "best-action queries" in online learning, where the learner can ask an oracle for the best action at a given time step. This differs from previous work that focused on hints or queries that provide correlated information or compare a small subset of actions.
  </div>
 </div>
</div>
<div class="tweet" id="tweet23">
 <div class="start-time-icon" title="Play from here">
  11:09
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16312" target="_blank">
    @arXiv 2407.16312
   </a>
   <span class="tweet-title">
    MOMALAND:  A Playground for Multi-Agent, Multi-Objective Learning!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    ETH Zurich, Utrecht University
   </span>
  </div>
  <div class="primary-text">
   This research introduces MOMALAND, the first standardized benchmark suite for multi-objective multi-agent reinforcement learning (MOMARL). Previous work has focused on either single-agent or single-objective settings, leaving a gap in research for complex scenarios involving multiple agents and objectives.
  </div>
 </div>
</div>
<div class="tweet" id="tweet24">
 <div class="start-time-icon" title="Play from here">
  11:39
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16094" target="_blank">
    @arXiv 2407.16094
   </a>
   <span class="tweet-title">
    Spectra-licious! AI Makes Spectroscopy a Breeze, No Expensive Equipment Needed!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    MIT, Ragon Institute, Jameel Clinic
   </span>
  </div>
  <div class="primary-text">
   This research introduces SpectroGen, a deep generative model that uses physical priors to generate spectral signatures across different modalities. Unlike previous work, SpectroGen doesn't rely on complex physical models or large datasets, instead leveraging the inherent structure of spectral data.
  </div>
 </div>
</div>
<div class="tweet" id="tweet25">
 <div class="start-time-icon" title="Play from here">
  11:53
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16210" target="_blank">
    @arXiv 2407.16210
   </a>
   <span class="tweet-title">
    Table Tennis Bots Learn to Play Like Pros, No More Mode Collapse!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    CMU, Seoul National University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a hierarchical control system for physics-based table tennis animation, addressing the issue of mode collapse in previous approaches. The system includes a strategy-level controller that learns to select skills and targets, and a skill-level controller that executes those skills.
  </div>
 </div>
</div>
<div class="tweet" id="tweet26">
 <div class="start-time-icon" title="Play from here">
  12:23
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16207" target="_blank">
    @arXiv 2407.16207
   </a>
   <span class="tweet-title">
    LLMs Get a Speed Boost: Graph-Structured Decoding Makes Inference a Breeze!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Peking University, Renmin University of China, Tianjin University...
   </span>
  </div>
  <div class="primary-text">
   This research introduces Graph-structured Speculative Decoding (GSD), a new approach to accelerate LLM inference. Unlike previous methods that rely on a single hypothesis or a tree structure, GSD leverages a directed acyclic graph (DAG) to manage multiple hypotheses, efficiently predicting and merging recurring token sequences.
  </div>
 </div>
</div>
<div class="tweet" id="tweet27">
 <div class="start-time-icon" title="Play from here">
  12:51
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16025" target="_blank">
    @arXiv 2407.16025
   </a>
   <span class="tweet-title">
    Reward Confusion: When AI Gets Its Wires Crossed!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    ETH Zurich, UC Berkeley, University of Toronto
   </span>
  </div>
  <div class="primary-text">
   This paper introduces a new problem in offline reinforcement learning called "reward confusion," where the AI model learns to rely on spurious correlations in the data, leading to incorrect behavior. The authors propose a novel algorithm, IMPEC, to address this issue by actively learning a global preference chain and leveraging transitivity of preferences.
  </div>
 </div>
</div>
<div class="tweet" id="tweet28">
 <div class="start-time-icon" title="Play from here">
  13:28
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16067" target="_blank">
    @arXiv 2407.16067
   </a>
   <span class="tweet-title">
    Out-of-Distribution Generalization:  When Models Make Better Mistakes
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    CMU, University of Macau
   </span>
  </div>
  <div class="primary-text">
   This research proposes using the Lowest Common Ancestor (LCA) distance, a measure of the hierarchical distance between labels and predictions within a class taxonomy, to predict a model's out-of-distribution (OOD) performance. This approach differs from previous work that relied on in-distribution accuracy as an indicator of OOD performance.
  </div>
 </div>
</div>
<div class="tweet" id="tweet29">
 <div class="start-time-icon" title="Play from here">
  14:13
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16637" target="_blank">
    @arXiv 2407.16637
   </a>
   <span class="tweet-title">
    AI's Got a New Trick: Teaching Bots to Say "Oops"
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University, Central South University, Alibaba Group...
   </span>
  </div>
  <div class="primary-text">
   This research focuses on "course-correction" in LLMs, a new approach to safety alignment that emphasizes the model's ability to autonomously steer away from generating harmful content, even after an initial unsafe response. Unlike previous work that primarily focuses on preventing harmful content generation, this paper explores the ability of LLMs to correct their course mid-generation.
  </div>
 </div>
</div>
<div class="tweet" id="tweet30">
 <div class="start-time-icon" title="Play from here">
  14:43
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.15855" target="_blank">
    @arXiv 2407.15855
   </a>
   <span class="tweet-title">
    Data Poisoning Attacks:  When Your Car's GPS Goes Rogue!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Washington
   </span>
  </div>
  <div class="primary-text">
   This research focuses specifically on data poisoning attacks against Intelligent Transportation Systems (ITS), a topic that has received less attention than other cybersecurity threats in transportation.
  </div>
 </div>
</div>
<div class="tweet" id="tweet31">
 <div class="start-time-icon" title="Play from here">
  15:08
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16541" target="_blank">
    @arXiv 2407.16541
   </a>
   <span class="tweet-title">
    Masked Image Modeling: The New Recipe for Visual Scoring!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Tsinghua University, Kuaishou Technology
   </span>
  </div>
  <div class="primary-text">
   This research proposes QPTV2, a novel pretraining framework based on Masked Image Modeling (MIM) for visual scoring tasks. Unlike previous work that relies on contrastive learning, QPTV2 leverages MIM's ability to reconstruct masked image regions, enabling it to learn both sample-level and pixel-level information.
  </div>
 </div>
</div>
<div class="tweet" id="tweet32">
 <div class="start-time-icon" title="Play from here">
  15:30
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16521" target="_blank">
    @arXiv 2407.16521
   </a>
   <span class="tweet-title">
    Among Us, But Make It Text-Based: LLMs Play Social Deduction!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    UC Berkeley, Tongji University
   </span>
  </div>
  <div class="primary-text">
   This research differs from previous work by focusing on a complex, multi-agent game environment that goes beyond simple conversation and explicit in-game moves. It uses Among Us as a testbed to evaluate LLMs' abilities in goal-oriented games with incomplete information and a wider range of actions.
  </div>
 </div>
</div>
<div class="tweet" id="tweet33">
 <div class="start-time-icon" title="Play from here">
  15:52
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16370" target="_blank">
    @arXiv 2407.16370
   </a>
   <span class="tweet-title">
    LLMs Get a Makeover: Evolutionary Prompt Design for Speech Error Correction
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Carnegie Mellon University, Southern University of Science and Technology, NVIDIA Research
   </span>
  </div>
  <div class="primary-text">
   This research explores the use of evolutionary algorithms to optimize prompts for large language models (LLMs) in the context of post-automatic speech recognition (ASR) error correction. Unlike previous work that focuses on empirically designed prompts, this study proposes a systematic approach to refine prompts iteratively, leading to improved performance.
  </div>
 </div>
</div>
<div class="tweet" id="tweet34">
 <div class="start-time-icon" title="Play from here">
  16:18
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16537" target="_blank">
    @arXiv 2407.16537
   </a>
   <span class="tweet-title">
    Speech Recognition:  How Much Does Language Matter?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Toronto
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel method for quantifying the role of textual predictability in automatic speech recognition (ASR) systems. Unlike previous work that focused on directly linking perplexity to error rates, this study uses ratios of error rates across different levels of textual predictability to isolate the impact of language modeling.
  </div>
 </div>
</div>
<div class="tweet" id="tweet35">
 <div class="start-time-icon" title="Play from here">
  16:45
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16134" target="_blank">
    @arXiv 2407.16134
   </a>
   <span class="tweet-title">
    Diffusion Transformers:  Unveiling the Secrets of Sequential Data!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Yale University, Princeton University
   </span>
  </div>
  <div class="primary-text">
   This research delves into the theoretical underpinnings of diffusion transformers for learning sequential data, specifically Gaussian process data. Unlike previous work focusing on static data, this paper explores how diffusion transformers capture spatial-temporal dependencies and their impact on learning efficiency.
  </div>
 </div>
</div>
<div class="tweet" id="tweet36">
 <div class="start-time-icon" title="Play from here">
  17:08
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16346" target="_blank">
    @arXiv 2407.16346
   </a>
   <span class="tweet-title">
    Multistage Robust Optimization:  A Nested Distance Tale of Two Formulations
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Texas at Austin
   </span>
  </div>
  <div class="primary-text">
   This research explores multistage distributionally robust optimization (DRO) using the nested distance, demonstrating its equivalence to a multistage-dynamic formulation with one-period Wasserstein distance. This equivalence allows for dynamic programming solutions, which were previously unavailable for nested distance problems.
  </div>
 </div>
</div>
<div class="tweet" id="tweet37">
 <div class="start-time-icon" title="Play from here">
  17:37
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16467" target="_blank">
    @arXiv 2407.16467
   </a>
   <span class="tweet-title">
    OpenVINO Models:  A Side-Channel Sneak Peek into Your Neural Network Secrets!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Nanyang Technological University, Slovak University of Technology in Bratislava
   </span>
  </div>
  <div class="primary-text">
   This research focuses on the vulnerability of quantized neural network models implemented in OpenVINO to side-channel analysis attacks. Unlike previous work that primarily focused on recovering model behavior, this study demonstrates the possibility of recovering exact model parameters with high precision.
  </div>
 </div>
</div>
<div class="tweet" id="tweet38">
 <div class="start-time-icon" title="Play from here">
  18:20
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16485" target="_blank">
    @arXiv 2407.16485
   </a>
   <span class="tweet-title">
    Learning Constraints from Demos: When Robots Need a Little Guidance
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    École Polytechnique Fédérale de Lausanne
   </span>
  </div>
  <div class="primary-text">
   This research proposes a novel approach to inferring continuous, possibly nonlinear constraints from demonstrations using a positive-unlabeled (PU) learning technique. Unlike previous methods that often rely on linear constraints or require strong knowledge of the environment, this method leverages the difference between expert demonstrations and a policy that generates potentially unsafe trajectories to learn the constraint function.
  </div>
 </div>
</div>
<div class="tweet" id="tweet39">
 <div class="start-time-icon" title="Play from here">
  18:48
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.15875" target="_blank">
    @arXiv 2407.15875
   </a>
   <span class="tweet-title">
    Shapley Pruning:  A Fairer Way to Slim Down Your Neural Networks
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    ETH Zürich
   </span>
  </div>
  <div class="primary-text">
   This research proposes a new framework for neural network compression based on the Shapley value, a concept from game theory. Unlike previous methods that focus on individual neurons, this approach considers the collective contribution of groups of neurons, leading to more efficient pruning.
  </div>
 </div>
</div>
<div class="tweet" id="tweet40">
 <div class="start-time-icon" title="Play from here">
  19:10
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16588" target="_blank">
    @arXiv 2407.16588
   </a>
   <span class="tweet-title">
    Clique-ing Mad: A Faster Algorithm for Finding Nearly Complete Groups in Networks
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Electronic Science and Technology of China, Peking University
   </span>
  </div>
  <div class="primary-text">
   This research introduces a new branching algorithm for finding the largest "k-defective clique" in a graph. Unlike previous algorithms, this one leverages the well-established maximum clique algorithm as a subroutine, leading to a better asymptotic running time.
  </div>
 </div>
</div>
<div class="tweet" id="tweet41">
 <div class="start-time-icon" title="Play from here">
  19:34
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16347" target="_blank">
    @arXiv 2407.16347
   </a>
   <span class="tweet-title">
    Fact-Checking Fiction: How to Keep Your Story's Timeline Straight
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Hong Kong, UC Berkeley
   </span>
  </div>
  <div class="primary-text">
   This research introduces FACTTRACK, a method for tracking atomic facts in story outlines and detecting contradictions based on their validity intervals. Unlike previous work, FACTTRACK explicitly considers the temporal nature of facts, allowing it to distinguish between legitimate contradictions and facts simply changing over time.
  </div>
 </div>
</div>
<div class="tweet" id="tweet42">
 <div class="start-time-icon" title="Play from here">
  20:04
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16664" target="_blank">
    @arXiv 2407.16664
   </a>
   <span class="tweet-title">
    Multilingual Pretraining:  Giving Speech Recognition a Language Lesson!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Meta
   </span>
  </div>
  <div class="primary-text">
   This research investigates the effectiveness of multilingual pretraining for improving Automatic Speech Recognition (ASR) models in low-resource languages. The study focuses on the impact of transfer learning at different stages of model training, comparing in-domain and out-of-domain pretraining, and analyzing the effect on rare and non-rare words.
  </div>
 </div>
</div>
<div class="tweet" id="tweet43">
 <div class="start-time-icon" title="Play from here">
  20:32
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.15862" target="_blank">
    @arXiv 2407.15862
   </a>
   <span class="tweet-title">
    Tiny AI Doctors: Can Lightweight LLMs Handle Pediatric Consultations?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Children's Hospital of Chongqing Medical University, Chongqing Medical University, Stanford University...
   </span>
  </div>
  <div class="primary-text">
   This research focuses on the performance of lightweight, open-source LLMs in pediatric consultations, a domain previously underexplored. It compares these models to larger, proprietary LLMs, providing insights into their relative strengths and weaknesses.
  </div>
 </div>
</div>
<div class="tweet" id="tweet44">
 <div class="start-time-icon" title="Play from here">
  20:57
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16556" target="_blank">
    @arXiv 2407.16556
   </a>
   <span class="tweet-title">
    ReLU's Secret Weapon:  DC is the New Black!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    École Polytechnique Fédérale de Lausanne
   </span>
  </div>
  <div class="primary-text">
   This paper provides a mathematical description of the ReLU activation function in the frequency domain, showing that it introduces a DC component and higher frequencies. Previous work has focused on empirical observations or approximations of ReLU's behavior.
  </div>
 </div>
</div>
<div class="tweet" id="tweet45">
 <div class="start-time-icon" title="Play from here">
  21:20
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16110" target="_blank">
    @arXiv 2407.16110
   </a>
   <span class="tweet-title">
    Words Evolve, Senses Too: How Semantic Cells Track Polysemy's Dance
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    The University of Tokyo
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel approach to analyzing word polysemy by modeling it as an evolutionary process. Unlike previous work that focuses on learning "correct" senses, this study uses Semantic Cells (SCs) to capture the dynamic emergence of new senses over time.
  </div>
 </div>
</div>
<div class="tweet" id="tweet46">
 <div class="start-time-icon" title="Play from here">
  21:49
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16264" target="_blank">
    @arXiv 2407.16264
   </a>
   <span class="tweet-title">
    Masks and Manuscripts:  A New Recipe for Medical AI
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Oxford, Oxford Suzhou Centre for Advanced Research
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel approach to medical pre-training by combining self-supervised learning with a standardized triplet format for textual data and a Meijering-based masking strategy for visual data. This differs from previous work by addressing the challenges of inconsistent semantics and morphology in medical text reports, as well as the need for more effective visual pre-training methods for medical images.
  </div>
 </div>
</div>
<div class="tweet" id="tweet47">
 <div class="start-time-icon" title="Play from here">
  22:10
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16641" target="_blank">
    @arXiv 2407.16641
   </a>
   <span class="tweet-title">
    Hyperbolic Embeddings:  A Geometry-Aware Algorithm to Cure Embedding Illnesses
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Alibaba, CMU, UC San Diego...
   </span>
  </div>
  <div class="primary-text">
   This research introduces a geometry-aware algorithm that addresses three categories of "illnesses" that can hinder the performance of hyperbolic embeddings. The algorithm uses a dilation operation and transitive closure regularization to improve the accuracy of embedding hierarchical data.
  </div>
 </div>
</div>
<div class="tweet" id="tweet48">
 <div class="start-time-icon" title="Play from here">
  22:31
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16463" target="_blank">
    @arXiv 2407.16463
   </a>
   <span class="tweet-title">
    Land Surface Forecasting:  AI Models Race to Predict the Weather!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Freiburg, European Centre for Medium-Range Weather Forecasts, World Meteorological Organization
   </span>
  </div>
  <div class="primary-text">
   This research compares three machine learning models for emulating a complex land surface model, ECLand, which is used in weather forecasting.  Previous work has focused on emulating specific aspects of land surface models, but this study emulates the entire system.
  </div>
 </div>
</div>
<div class="tweet" id="tweet49">
 <div class="start-time-icon" title="Play from here">
  22:55
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16526" target="_blank">
    @arXiv 2407.16526
   </a>
   <span class="tweet-title">
    Vision Models Need Glasses:  A New Way to Fix Their Blinders
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Cambridge, Toyota Motor Europe
   </span>
  </div>
  <div class="primary-text">
   This research proposes a method for selectively updating the vision encoder within vision-language models (VLMs) to improve their performance on specific datasets, while preserving their overall robustness. This approach differs from previous work that focused on updating the entire model or only specific layers.
  </div>
 </div>
</div>
<div class="tweet" id="tweet50">
 <div class="start-time-icon" title="Play from here">
  23:21
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16470" target="_blank">
    @arXiv 2407.16470
   </a>
   <span class="tweet-title">
    LLMs: The New Hallucination Detectives?
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University College London, Meta
   </span>
  </div>
  <div class="primary-text">
   This research evaluates the performance of Large Language Models (LLMs) and embedding-based methods for detecting hallucinations in machine translation, focusing on both high and low-resource languages. Unlike previous work, which primarily focused on English-centric translations, this study expands the scope to include a wider range of language pairs, including non-English-centric ones.
  </div>
 </div>
</div>
<div class="tweet" id="tweet51">
 <div class="start-time-icon" title="Play from here">
  23:45
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16092" target="_blank">
    @arXiv 2407.16092
   </a>
   <span class="tweet-title">
    Coalition Formation:  A Faster, Smarter Way to Team Up!
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    Claude Bernard University Lyon 1, CMU
   </span>
  </div>
  <div class="primary-text">
   This research introduces a novel algorithm called SMART for coalition structure generation. SMART combines three techniques: Complementarity-Based Dynamic Programming (CDP), Gradual Search with Dynamic Programming (GRAD), and Distributed Integer Partition Graph Search (DIPS).  The key difference from previous work is that SMART uses offline phases to optimize the choice of coalitions to evaluate, leading to faster run times.
  </div>
 </div>
</div>
<div class="tweet" id="tweet52">
 <div class="start-time-icon" title="Play from here">
  24:10
 </div>
 <div class="tweet-content">
  <div class="tweet-header">
   <a class="arxiv-id" href="https://arxiv.org/abs/2407.16048" target="_blank">
    @arXiv 2407.16048
   </a>
   <span class="tweet-title">
    Time Series Feature Selection:  A Hierarchical Approach to Pruning Redundancy
   </span>
  </div>
  <div class="institute-line">
   <img alt="Institute Icon" class="institute-icon" src="assets/buttonInstitute.svg"/>
   <span class="institute-text">
    University of Toronto
   </span>
  </div>
  <div class="primary-text">
   This research introduces a hierarchical feature selection method called HEIRVAR that combines E-ROCKET with ANOVA to reduce redundant features in time series classification. This approach differs from previous work by using ANOVA to further refine the features selected by E-ROCKET, resulting in a more efficient and accurate model.
  </div>
 </div>
</div>


        <div
            style="padding: 50px 0; text-align: center; margin: 5px 0; font-weight: 300; font-size: 10px; color: #000000;">
            Opening music
            from <a href="https://ikson.com" target="_blank" style="color: black; text-decoration: none;">TELL
                YOUR STORY by ikson</a></div>
        <div style="height: 50px;"></div>
    </div>

    <footer class="player-footer">
        <div class="player-detail-hidden-on-small-screen">
            <div id="audio-title" class="tweet-title-small">Listen and learn ^.^</div>
            <div style="height: 2px;"></div>
            <div id="audio-institutes" class="institute-text-small"></div>
        </div>
        <div class="control-panel">
            <div class="control-horizontal">
                <div id="playSpeedButton" title="Adjust speed">
                    <div id="selectedSpeed">1&times;</div>
                    <div class="speedMenuItems">
                        <div data-value="0.6">Speed 0.6&times;</div>
                        <div data-value="0.8">Speed 0.8&times;</div>
                        <div data-value="1" class="selected">Speed 1&times;</div>
                        <div data-value="1.2">Speed 1.2&times;</div>
                        <div data-value="1.4">Speed 1.4&times;</div>
                        <div data-value="1.6">Speed 1.6&times;</div>
                    </div>
                    <select id="speedOptionsHidden">
                        <option value="0.6">0.6&times;</option>
                        <option value="0.8">0.8&times;</option>
                        <option value="1" selected>1&times;</option>
                        <option value="1.2">1.2&times;</option>
                        <option value="1.4">1.4&times;</option>
                        <option value="1.6">1.6&times;</option>
                    </select>
                </div>
                <div id="playLastButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(false)" title="Play last" disabled>
                        <img src="assets/buttonLastEpisode.svg" alt="Last" style="width: 12px;">
                    </button>
                </div>
                <button class="controllerButton" onclick="scrollToCurrentTweet()" title="Scoll to the current episode">
                    <img id="locateImage" src="assets/buttonTarget.svg" alt="Locate">
                </button>
                <button class="controllerButton" onclick="togglePlayPause()" title="Play/Pause">
                    <img id="playPauseImage" src="assets/buttonPlay.svg" alt="Play">
                </button>
                <div id="playNextButton" style="position: relative;">
                    <div class="footerButtonMask"></div>
                    <button class="controllerButton" onclick="playAdjacentTweet(true)" title="Play next" disabled>
                        <img src="assets/buttonNextEpisode.svg" alt="Next" style="width: 12px;">
                    </button>
                </div>
            </div>
            <div class="control-horizontal">
                <div id="progressTime">0:00</div>
                <div id="progressContainer" onclick="seek(event)">
                    <div id="progressBar"></div>
                    <div id="progressCircle" draggable="true"></div>
                </div>
                <audio id="audioPlayer"
                    src="https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202407241620_audio.mp3"></audio>
                <div id="progressTime"><span id="audioDuration">Loading...</span></div>
            </div>
        </div>
    </footer>
    <div id="privacyModal" class="modal"></div>
    <script src="script.js"></script>
    <script src="calendar.js"></script>    
    <script>
        fetch('https://ribbitribbit.co/header.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('headerId').innerHTML = data;
            })
            .catch(error => console.error('Error loading header.html:', error));
        fetch('https://ribbitribbit.co/privacy.html')
            .then(response => response.text()) // Convert the response to text
            .then(data => {
                document.getElementById('privacyModal').innerHTML = data;
            })
            .catch(error => console.error('Error loading privacy.html:', error));
    </script>
</body>
</html>

daily_data = {
    "date": "2024-08-02",
    "tweets": [
            {
                "startTime": "00:55",
                "arxivId": "2408.00298",
                "arxivLink": "https://arxiv.org/abs/2408.00298",
                "title": "Manga for the Visually Impaired: A Tail-Waggingly Good Transcript Generator!",
                "institute": "University of Oxford",
                "text": "This research extends previous work by generating chapter-wide manga transcripts with consistent character names, improving speaker diarization, and distinguishing between essential and non-essential text.",
                "paper-title": "Tails Tell Tales: Chapter-Wide Manga Transcriptions with Character Names",
                "image-path": ""
            },

            {
                "startTime": "01:16",
                "arxivId": "2408.00714",
                "arxivLink": "https://arxiv.org/abs/2408.00714",
                "title": "Segment Anything, Now in Motion: SAM2 Brings Segmentation to Videos!",
                "institute": "Meta",
                "text": "This research extends the SegmentAnything (SAM) model to the video domain, introducing a new model called SAM2 that can segment objects across multiple frames. Unlike previous video segmentation models, SAM2 utilizes a memory mechanism to store information about the object and previous interactions, enabling it to track objects more effectively and with fewer user prompts.",
                "paper-title": "SAM 2: Segment Anything in Images and Videos",
                "image-path": ""
            },

            {
                "startTime": "01:37",
                "arxivId": "2408.00754",
                "arxivLink": "https://arxiv.org/abs/2408.00754",
                "title": "Stop Staring, LLMs! New Trick Makes 'Em See in 3D",
                "institute": "University of Washington, Tsinghua University, Tencent...",
                "text": "This paper introduces COARSE CORRESPONDENCES, a visual prompting method that helps multimodal language models (MLLMs) understand 3D space and time without requiring any training. Unlike previous methods that focus on either 3D or temporal understanding, COARSE CORRESPONDENCES combines lightweight tracking models to extract object correspondences across multiple frames, enabling the MLLM to reason about both spatial and temporal relationships.",
                "paper-title": "Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal Language Model",
                "image-path": ""
            },

            {
                "startTime": "02:09",
                "arxivId": "2408.00724",
                "arxivLink": "https://arxiv.org/abs/2408.00724",
                "title": "Smaller Brains, Smarter Moves: How to Make LLMs Solve Problems with Less Compute",
                "institute": "Tsinghua University, CMU",
                "text": "This research focuses on optimizing the inference stage of LLMs, specifically exploring how to design models and inference strategies that trade off additional compute for improved performance. This is distinct from previous work that primarily focused on scaling laws during training.",
                "paper-title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models",
                "image-path": ""
            },

            {
                "startTime": "02:42",
                "arxivId": "2408.00283",
                "arxivLink": "https://arxiv.org/abs/2408.00283",
                "title": "Indic Languages Get Their Own Text-to-Image Bias Test!",
                "institute": "IIT Jodhpur, Meta, Weir P.B.C.",
                "text": "This research introduces the IndicTTI benchmark, a new evaluation tool specifically designed to assess the performance and cultural biases of text-to-image models across 30 Indic languages. This benchmark expands upon previous work by focusing on a wider range of languages and using more complex prompts, making it more relevant to real-world applications.",
                "paper-title": "Navigating Text-to-Image Generative Bias across Indic Languages",
                "image-path": ""
            },

            {
                "startTime": "03:05",
                "arxivId": "2408.00713",
                "arxivLink": "https://arxiv.org/abs/2408.00713",
                "title": "Insurance Firms: Stop Guessing, Start Learning!",
                "institute": "University of Cambridge, Accenture",
                "text": "This research introduces a novel reinforcement learning algorithm for the portfolio pursuit problem in insurance, which is different from previous work that focused on either local decision-making or constrained portfolio optimization.",
                "paper-title": "Insurance Portfolio Pursuit with Reinforcement Learning",
                "image-path": ""
            },

            {
                "startTime": "03:37",
                "arxivId": "2408.00712",
                "arxivLink": "https://arxiv.org/abs/2408.00712",
                "title": "MotionFix: Text-to-Motion Editing Gets a Makeover!",
                "institute": "Max Planck Institute for Intelligent Systems, LIGM, \u00c9cole des Ponts...",
                "text": "This research introduces MotionFix, a new dataset specifically designed for training models to edit 3D human motion based on text descriptions. Unlike previous datasets that focus on text-to-motion generation, MotionFix provides triplets of source motion, target motion, and edit text, enabling the development of models that can modify existing motions according to user instructions.",
                "paper-title": "MotionFix: Text-Driven 3D Human Motion Editing",
                "image-path": ""
            },

            {
                "startTime": "04:07",
                "arxivId": "2408.00427",
                "arxivLink": "https://arxiv.org/abs/2408.00427",
                "title": "Spatial Awareness for Cancer Prognosis: A Regularization Revolution",
                "institute": "University of Oxford",
                "text": "This research introduces a novel regularization scheme called CARMIL, which incorporates spatial context into Multiple Instance Learning (MIL) models for Whole Slide Images (WSIs). Unlike previous methods that rely on complex architectures like Graph Neural Networks (GNNs) or Transformers, CARMIL leverages a spatial encoder and decoder to distill spatial information directly into tile embeddings, making it applicable to any MIL model.",
                "paper-title": "CARMIL: Context-Aware Regularization on Multiple Instance Learning models for Whole Slide Images",
                "image-path": ""
            },

            {
                "startTime": "04:31",
                "arxivId": "2408.00211",
                "arxivLink": "https://arxiv.org/abs/2408.00211",
                "title": "Models as Data: A Toolkit for Tinkering with Transformers",
                "institute": "University of Toronto",
                "text": "This research introduces Penzai, a JAX library that treats neural network models as data structures, enabling direct manipulation and visualization. Unlike previous approaches that rely on hooks or tracing, Penzai allows users to modify model components directly, making it easier to understand and control model behavior.",
                "paper-title": "Penzai + Treescope: A Toolkit for Interpreting, Visualizing, and Editing Models As Data",
                "image-path": ""
            },

            {
                "startTime": "04:52",
                "arxivId": "2408.00765",
                "arxivLink": "https://arxiv.org/abs/2408.00765",
                "title": "MM-Vet v2: A New Benchmark for Multimodal Models That Can Handle More Than Just One Image at a Time!",
                "institute": "National University of Singapore, Microsoft",
                "text": "This research introduces MM-Vet v2, a new benchmark for evaluating large multimodal models (LLMs). Unlike previous benchmarks, MM-Vet v2 includes a new capability called \"image-text sequence understanding,\" which assesses the ability of LLMs to process sequences of images and text.",
                "paper-title": "MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities",
                "image-path": ""
            },

            {
                "startTime": "05:24",
                "arxivId": "2408.00118",
                "arxivLink": "https://arxiv.org/abs/2408.00118",
                "title": "Tiny Models, Big Brains: Gemma2 Makes Small LLMs Super Smart",
                "institute": "Google",
                "text": "This research explores the impact of knowledge distillation on smaller language models. Unlike previous work that focused on increasing training data size, this study trains smaller models with distilled knowledge from a larger model, achieving performance comparable to models 2-3 times their size.",
                "paper-title": "Gemma 2: Improving Open Language Models at a Practical Size",
                "image-path": ""
            },

            {
                "startTime": "05:48",
                "arxivId": "2408.00122",
                "arxivLink": "https://arxiv.org/abs/2408.00122",
                "title": "LLMs Go to School: Teaching AI Ethics with a Dose of Clinical Questions",
                "institute": "IBM Research Europe, Technical University of Darmstadt",
                "text": "This research introduces a shared task designed to evaluate the output of Large Language Models (LLMs) when answering clinical questions. The task focuses on identifying harmful content generated by LLMs, a crucial aspect often overlooked in traditional LLM evaluation. This approach differs from previous work by emphasizing the ethical implications of LLM outputs in a real-world context.",
                "paper-title": "A Course Shared Task on Evaluating LLM Output for Clinical Questions",
                "image-path": ""
            },

            {
                "startTime": "06:10",
                "arxivId": "2408.00001",
                "arxivLink": "https://arxiv.org/abs/2408.00001",
                "title": "AI's Got a Memory: How Diffusion Models Remember Their Training Data",
                "institute": "Tsinghua University, Peking University, Zhejiang University",
                "text": "This research paper provides the first comprehensive survey of replication in visual diffusion models, systematically categorizing existing studies into unveiling, understanding, and mitigating this phenomenon.",
                "paper-title": "Replication in Visual Diffusion Models: A Survey and Outlook",
                "image-path": ""
            },

            {
                "startTime": "06:43",
                "arxivId": "2408.00624",
                "arxivLink": "https://arxiv.org/abs/2408.00624",
                "title": "SynesLM: Speech Recognition Gets a Visual Makeover!",
                "institute": "CMU",
                "text": "This research introduces SynesLM, a unified model that can perform audio-visual speech recognition, visual speech translation, and visual machine translation. Unlike previous work that focused on lip movements, SynesLM leverages more general visual information within entire frames, such as objects and actions.",
                "paper-title": "SynesLM: A Unified Approach for Audio-visual Speech Recognition and Translation via Language Model and Synthetic Data",
                "image-path": ""
            },

            {
                "startTime": "07:15",
                "arxivId": "2408.00254",
                "arxivLink": "https://arxiv.org/abs/2408.00254",
                "title": "Looping for Views: A New Trick to Make 3D Images From Sparse Photos",
                "institute": "Peking University, Pengcheng Laboratory, University of Nottingham",
                "text": "This paper introduces LoopSparseGS, a novel 3D Gaussian Splatting framework that leverages a looping mechanism to generate denser Gaussian initialization and precise geometric constraints for sparse-input novel view synthesis. Unlike previous methods that rely on dense input views, LoopSparseGS effectively handles sparse input data by iteratively refining the 3D scene representation using rendered pseudo-images.",
                "paper-title": "LoopSparseGS: Loop Based Sparse-View Friendly Gaussian Splatting",
                "image-path": ""
            },

            {
                "startTime": "07:42",
                "arxivId": "2408.00735",
                "arxivLink": "https://arxiv.org/abs/2408.00735",
                "title": "Turbocharged Editing: Text-to-Image Edits in a Flash!",
                "institute": "Tel-Aviv University, NVIDIA",
                "text": "This paper focuses on adapting a popular text-based image editing technique, DDPM noise inversion, to work with fast-sampling diffusion models. Unlike previous methods that rely on many steps, this approach achieves high-quality edits in just a few steps, significantly speeding up the process.",
                "paper-title": "TurboEdit: Text-Based Image Editing Using Few-Step Diffusion Models",
                "image-path": ""
            },

            {
                "startTime": "08:03",
                "arxivId": "2408.00359",
                "arxivLink": "https://arxiv.org/abs/2408.00359",
                "title": "Fine-Tuning's Secret Weapon: How Many Neurons Does It Take to Memorize?",
                "institute": "Yonsei University, University of Seoul, Korea Institute for Advanced Study...",
                "text": "This research introduces a new metric called Fine-Tuning Capacity (FTC) to analyze the ability of neural networks to adapt to new data during fine-tuning. Unlike previous work focusing on memorization capacity, FTC specifically considers the scenario where a pre-trained network is fine-tuned by adding a new network.",
                "paper-title": "Memorization Capacity for Additive Fine-Tuning with Small ReLU Networks",
                "image-path": ""
            },

            {
                "startTime": "08:36",
                "arxivId": "2408.00278",
                "arxivLink": "https://arxiv.org/abs/2408.00278",
                "title": "Convolution Chaos: New Tensor Layouts Speed Up Deep Learning!",
                "institute": "Nanchang Hangkong University, Microsoft, University of Washington...",
                "text": "This research explores the impact of different tensor data layouts on the performance of convolution operations, a core component of deep neural networks. It introduces three novel layouts for the im2win convolution method, specifically NHWC, CHWN, and CHWN8, and compares their performance with the traditional NCHW layout.",
                "paper-title": "High Performance Im2win and Direct Convolutions using Three Tensor Layouts on SIMD Architectures",
                "image-path": ""
            },

            {
                "startTime": "08:58",
                "arxivId": "2408.00700",
                "arxivLink": "https://arxiv.org/abs/2408.00700",
                "title": "Graph Denoising: When Structure and Features Get Messy, It's Time to Clean Up!",
                "institute": "Peking University, Huawei",
                "text": "This research tackles the problem of graph denoising by considering both structure and feature noise simultaneously, unlike previous methods that focused on only one type of noise.",
                "paper-title": "You Can't Ignore Either: Unifying Structure and Feature Denoising for Robust Graph Learning",
                "image-path": ""
            },

            {
                "startTime": "09:23",
                "arxivId": "2408.00057",
                "arxivLink": "https://arxiv.org/abs/2408.00057",
                "title": "Protein Knowledge Graphs: Giving AI a Brain Boost for Drug Discovery!",
                "institute": "Technion \u2013 Israel Institute of Technology, Meta",
                "text": "This research introduces GOProteinGNN, a novel architecture that integrates protein knowledge graph information into protein language models (PLMs) during the creation of amino acid-level representations. Unlike previous methods that focus on either amino acid level learning or protein level learning, GOProteinGNN uniquely learns the entire protein knowledge graph during training, allowing it to capture broader relational nuances and dependencies beyond mere triplets.",
                "paper-title": "GOProteinGNN: Leveraging Protein Knowledge Graphs for Protein Representation Learning",
                "image-path": ""
            },

            {
                "startTime": "09:52",
                "arxivId": "2408.00550",
                "arxivLink": "https://arxiv.org/abs/2408.00550",
                "title": "Multilingual AI Models: Stop Hallucinating, Start Speaking!",
                "institute": "Huazhong University of Science and Technology, Fudan University, Peking University...",
                "text": "This research focuses on mitigating hallucinations in large vision-language models (LVLMs) when they are used with non-English languages. Unlike previous work that primarily addressed English-language hallucinations, this study proposes a two-stage framework to improve the model's ability to understand instructions and distinguish between accurate and inaccurate responses in multiple languages.",
                "paper-title": "Mitigating Multilingual Hallucination in Large Vision-Language Models",
                "image-path": ""
            },

            {
                "startTime": "10:26",
                "arxivId": "2408.00112",
                "arxivLink": "https://arxiv.org/abs/2408.00112",
                "title": "Sperm Segmentation: A Tailored Approach to Infertility Diagnosis",
                "institute": "Dalian University of Technology, Chinese University of Hong Kong, University of Toronto",
                "text": "This research introduces a novel attention-based instance-aware part segmentation network for sperm morphology analysis. Unlike previous \"detect-then-segment\" methods, this approach addresses context loss and feature distortion by refining preliminary segmented masks using features extracted by a feature pyramid network.",
                "paper-title": "Automated Sperm Morphology Analysis Based on Instance-Aware Part Segmentation",
                "image-path": ""
            },

            {
                "startTime": "10:51",
                "arxivId": "2408.00315",
                "arxivLink": "https://arxiv.org/abs/2408.00315",
                "title": "Diffusion Models Get a Bridge: A New Way to Purify Adversarial Noise!",
                "institute": "Tsinghua University, Peking University, Beijing Institute of Technology...",
                "text": "This research proposes a novel Adversarial Diffusion Bridge Model (ADBM) for adversarial purification. Unlike previous methods that rely on the similarity between diffused clean and adversarial data distributions, ADBM directly constructs a reverse bridge from the diffused adversarial data distribution to the clean data distribution.",
                "paper-title": "ADBM: Adversarial diffusion bridge model for reliable adversarial purification",
                "image-path": ""
            },

            {
                "startTime": "11:23",
                "arxivId": "2408.00129",
                "arxivLink": "https://arxiv.org/abs/2408.00129",
                "title": "\"AI Hijacking: Now Your Model Can Be a Language Translator... Without You Knowing!\"",
                "institute": "CISPA Helmholtz Center for Information Security, Microsoft",
                "text": "This research extends the model hijacking attack to a multimodal setting, allowing an adversary to implement an NLP task within a CV model. This differs from previous work which focused solely on homogeneous-modality tasks.",
                "paper-title": "Vera Verto: Multimodal Hijacking Attack",
                "image-path": ""
            },

            {
                "startTime": "11:52",
                "arxivId": "2408.00303",
                "arxivLink": "https://arxiv.org/abs/2408.00303",
                "title": "Smoothing Out the Noise: A Neural Octahedral Field for Sharp Edge Reconstruction",
                "institute": "Tsinghua University",
                "text": "This research introduces a novel neural field, the octahedral field, which is jointly trained with a neural implicit representation to simultaneously smooth and emphasize sharp edges in unoriented point cloud surface reconstruction. Unlike previous methods that rely on gradient regularization or local neighborhood information, this approach leverages the spherical harmonics representation of octahedral frames to guide the reconstruction process.",
                "paper-title": "Neural Octahedral Field: Octahedral prior for simultaneous smoothing and sharp edge regularization",
                "image-path": ""
            },

            {
                "startTime": "12:15",
                "arxivId": "2408.00521",
                "arxivLink": "https://arxiv.org/abs/2408.00521",
                "title": "Code's New Look: Ditching the Word-by-Word for a Global Image",
                "institute": "Peking University",
                "text": "This research proposes a new paradigm for encoding code, moving away from the autoregressive next-word prediction approach used in GPTs. Instead, it encodes code as a heterogeneous image, capturing global information about the code structure.",
                "paper-title": "A new approach for encoding code and assisting code understanding",
                "image-path": ""
            },

            {
                "startTime": "12:37",
                "arxivId": "2408.00157",
                "arxivLink": "https://arxiv.org/abs/2408.00157",
                "title": "Diffusion Models: Solving PDEs with a Little Help from Their Friends",
                "institute": "Harvard University",
                "text": "This research introduces a generative learning framework for parametric PDEs that uses gradient guidance and virtual observations to improve accuracy and efficiency. Unlike previous work, this approach leverages multi-level information to guide the diffusion model, ensuring that the generated solutions maintain high fidelity to the underlying physical phenomena across different parameter settings.",
                "paper-title": "Generative Learning of the Solution of Parametric Partial Differential Equations Using Guided Diffusion Models and Virtual Observations",
                "image-path": ""
            },

            {
                "startTime": "13:02",
                "arxivId": "2408.00429",
                "arxivLink": "https://arxiv.org/abs/2408.00429",
                "title": "Indoor Positioning Gets a Confidence Boost: New AI Model Cuts Training Costs by 40%",
                "institute": "China Mobile Research Institute, Beijing University of Posts and Telecommunications, The Hong Kong University of Science and Technology...",
                "text": "This research introduces a novel semi-supervised learning approach for indoor positioning that utilizes a biased teacher model to assign confidence scores to unlabeled data, thereby reducing the need for extensive labeled data and lowering training costs.",
                "paper-title": "Augmenting Channel Simulator and Semi- Supervised Learning for Efficient Indoor Positioning",
                "image-path": ""
            },

            {
                "startTime": "13:32",
                "arxivId": "2408.00310",
                "arxivLink": "https://arxiv.org/abs/2408.00310",
                "title": "Online Scheduling: When Delaying Decisions is Actually Smart",
                "institute": "Stanford University",
                "text": "This research explores Online Linear Programming (OLP) with batching, where decisions on customers can be delayed to the end of a batch. Unlike previous work that focused on finite support distributions, this paper analyzes the case where the conditional distribution of the reward given resource consumption is continuous.",
                "paper-title": "Online Linear Programming with Batching",
                "image-path": ""
            },

            {
                "startTime": "13:57",
                "arxivId": "2408.00677",
                "arxivLink": "https://arxiv.org/abs/2408.00677",
                "title": "One Fractal, One Million Images? Scaling Backwards in Pre-training!",
                "institute": "National Institute of Advanced Industrial Science and Technology (AIST), Tohoku University, University of Amsterdam...",
                "text": "This research explores the minimal requirements for successful pre-training in image recognition. Unlike previous work that used large datasets, this study demonstrates that a single fractal image with perturbations can achieve comparable performance to pre-training on millions of images.",
                "paper-title": "Scaling Backwards: Minimal Synthetic Pre-training?",
                "image-path": ""
            },

            {
                "startTime": "14:28",
                "arxivId": "2408.00251",
                "arxivLink": "https://arxiv.org/abs/2408.00251",
                "title": "Deep Learning Cracks the Code of Car-Following Dynamics!",
                "institute": "University of Washington",
                "text": "This research uses deep symbolic regression (DSR) to discover car-following dynamics directly from trajectory data, incorporating a variable intersection selection (VIS) method to guide the search for interpretable and parsimonious mathematical expressions. This approach differs from previous work by minimizing human involvement in the data analysis and hypothesis steps.",
                "paper-title": "Discovering Car-following Dynamics from Trajectory Data through Deep Learning",
                "image-path": ""
            },

            {
                "startTime": "15:05",
                "arxivId": "2408.00766",
                "arxivLink": "https://arxiv.org/abs/2408.00766",
                "title": "Diffusion Models Get a Speed Boost for Autonomous Driving!",
                "institute": "UC Berkeley",
                "text": "This research introduces two novel techniques, Optimal Gaussian Diffusion (OGD) and Estimated Clean Manifold (ECM) Guidance, to improve the computational efficiency of diffusion models for joint trajectory prediction and controllable generation in autonomous driving. Unlike previous work that focused on optimizing the reverse diffusion process or guided sampling separately, this paper tackles both aspects simultaneously.",
                "paper-title": "Optimizing Diffusion Models for Joint Trajectory Prediction and Controllable Generation",
                "image-path": ""
            },

            {
                "startTime": "15:35",
                "arxivId": "2408.00113",
                "arxivLink": "https://arxiv.org/abs/2408.00113",
                "title": "Chess Bots, Sparse Brains: New Metrics for Language Model Interpretability",
                "institute": "MIT, University of Massachusetts Amherst, University of Mannheim...",
                "text": "This research introduces two novel metrics for evaluating the quality of sparse autoencoders (SAEs) trained on language models. Unlike previous work that relied on proxy metrics or subjective evaluations, these metrics leverage the natural interpretable features present in board game transcripts to assess how well SAEs capture the model's internal representation of the game state.",
                "paper-title": "Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models",
                "image-path": ""
            },

            {
                "startTime": "16:04",
                "arxivId": "2408.00706",
                "arxivLink": "https://arxiv.org/abs/2408.00706",
                "title": "Point-Supervised Brain Tumor Segmentation: A Box-Prompted MedSAM Adventure!",
                "institute": "Yale University, Massachusetts General Hospital, Harvard Medical School",
                "text": "This research introduces an iterative framework that leverages the MedSAM model for point-supervised brain tumor segmentation. Unlike previous methods, it uses a semantic box-prompt generator to convert point annotations into potential bounding boxes, which are then refined through a prompt-guided spatial refinement module.",
                "paper-title": "Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM",
                "image-path": ""
            },

            {
                "startTime": "16:31",
                "arxivId": "2408.00024",
                "arxivLink": "https://arxiv.org/abs/2408.00024",
                "title": "AI Explains Itself Into Your Heart (and Maybe Your Head)",
                "institute": "MIT",
                "text": "This research examines the impact of AI-generated explanations on people's beliefs, specifically focusing on how deceptive explanations can amplify belief in misinformation. Previous work has explored the influence of AI-generated misinformation, but this study delves deeper into the persuasive power of explanations.",
                "paper-title": "Deceptive AI systems that give explanations are more convincing than honest AI systems and can amplify belief in misinformation",
                "image-path": ""
            },

            {
                "startTime": "16:56",
                "arxivId": "2408.00620",
                "arxivLink": "https://arxiv.org/abs/2408.00620",
                "title": "Bigger Vision Encoders Don't Always Mean Better Vision Models: A Scaling Law Surprise!",
                "institute": "Peking University",
                "text": "This research investigates scaling laws for vision language models (VLMs) using a connected vision paradigm, a common architecture where a vision encoder (like ViT) is connected to a large language model (LLM) backbone. Unlike previous scaling law studies that focused on training LLMs and modality encoders from scratch, this paper explores the scaling behavior of VLMs when using pre-trained components.",
                "paper-title": "Are Bigger Encoders Always Better in Vision Large Models?",
                "image-path": ""
            },

            {
                "startTime": "17:23",
                "arxivId": "2408.00117",
                "arxivLink": "https://arxiv.org/abs/2408.00117",
                "title": "AI Pose Estimation: Not Just Accurate, But Certified Robust!",
                "institute": "CMU",
                "text": "This research focuses on certifying the robustness of two-stage keypoint-based pose estimation methods, a crucial aspect often overlooked in previous work. The authors introduce a novel approach that transforms the certification problem into a standard neural network verification problem for classification tasks.",
                "paper-title": "Certifying Robustness of Learning-Based Keypoint Detection and Pose Estimation Methods",
                "image-path": ""
            },

            {
                "startTime": "17:56",
                "arxivId": "2408.00764",
                "arxivLink": "https://arxiv.org/abs/2408.00764",
                "title": "AI Agents Get a Planning Power-Up: From Peanut Butter to Perfect Plans!",
                "institute": "Microsoft",
                "text": "This research focuses on automatically generating diverse environments and planning tasks for training AI agents, unlike previous work that relied heavily on manual design.",
                "paper-title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation",
                "image-path": ""
            },

            {
                "startTime": "18:40",
                "arxivId": "2408.00636",
                "arxivLink": "https://arxiv.org/abs/2408.00636",
                "title": "Brain Tumor Detection: MobileNet-BT Takes the Lead!",
                "institute": "Arizona State University, UC Berkeley",
                "text": "This research introduces a new model, MobileNet-BT, based on MobileNetV2, which achieves higher accuracy and F1-score in brain tumor classification compared to other pre-trained models. The key difference lies in unfreezing all layers of MobileNetV2 and modifying the classifier to better capture specific characteristics of the brain tumor dataset.",
                "paper-title": "Deep Learning in Medical Image Classification from MRI-based Brain Tumor Images",
                "image-path": ""
            },

            {
                "startTime": "19:04",
                "arxivId": "2408.00203",
                "arxivLink": "https://arxiv.org/abs/2408.00203",
                "title": "GPT-4V Gets a Vision Makeover: OmniParser Helps AI Agents See the World (and Click the Right Buttons)",
                "institute": "Microsoft",
                "text": "This research introduces OmniParser, a method for parsing user interface screenshots into structured elements. Unlike previous work that relies on HTML information or view hierarchies, OmniParser uses a pure vision-based approach, making it applicable to a wider range of platforms and applications.",
                "paper-title": "OmniParser for Pure Vision Based GUI Agent",
                "image-path": ""
            },

            {
                "startTime": "19:27",
                "arxivId": "2408.00573",
                "arxivLink": "https://arxiv.org/abs/2408.00573",
                "title": "PINNs Get a Speed Boost: Natural Gradient Descent to the Rescue!",
                "institute": "Tsinghua University, Nanjing University of Aeronautics and Astronautics",
                "text": "This paper analyzes the convergence of natural gradient descent (NGD) for training over-parameterized two-layer Physics-Informed Neural Networks (PINNs). Unlike previous work that focused on gradient descent, this study demonstrates that NGD achieves a faster convergence rate and is independent of the smallest eigenvalue of the Gram matrix.",
                "paper-title": "Convergence Analysis of Natural Gradient Descent for Over-parameterized Physics-Informed Neural Networks",
                "image-path": ""
            },

            {
                "startTime": "19:50",
                "arxivId": "2408.00004",
                "arxivLink": "https://arxiv.org/abs/2408.00004",
                "title": "AI's Got Numbers: Teaching Machines to Speak Like Humans (and Format Them Right!)",
                "institute": "Karlsruhe Institute of Technology, CMU",
                "text": "This research focuses on improving the formatting of numeric expressions in automatic speech recognition (ASR) transcripts. Unlike previous work that relied on post-processing techniques, this study explores both cascaded and end-to-end approaches, utilizing large language models (LLMs) and synthetic data generation to adapt ASR models for accurate numeric expression formatting.",
                "paper-title": "Handling Numeric Expressions in Automatic Speech Recognition",
                "image-path": ""
            },

            {
                "startTime": "20:13",
                "arxivId": "2408.00753",
                "arxivLink": "https://arxiv.org/abs/2408.00753",
                "title": "Sleep Tight, Smart Shirt: AI-Powered Garment Tracks Your Snoozing Habits",
                "institute": "University of Cambridge",
                "text": "This research introduces a smart garment with a printed strain sensor array that monitors sleep patterns by detecting subtle vibrations from the extrinsic laryngeal muscles. This approach differs from previous work by using a single modality of strain response signals to comprehensively analyze and recognize sleep patterns, eliminating the need for precise positioning.",
                "paper-title": "A deep learning-enabled smart garment for versatile sleep behaviour monitoring",
                "image-path": ""
            },

            {
                "startTime": "20:36",
                "arxivId": "2408.00741",
                "arxivLink": "https://arxiv.org/abs/2408.00741",
                "title": "LLMs: Big Brains, Big Energy Bills? DynamoLLM to the Rescue!",
                "institute": "University of Illinois at Urbana-Champaign, Microsoft Azure Research",
                "text": "This research focuses on the energy efficiency of LLM inference clusters, a topic often overlooked in previous work. It proposes DynamoLLM, a framework that dynamically adjusts the cluster configuration to optimize energy consumption while meeting performance requirements.",
                "paper-title": "DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency",
                "image-path": ""
            },

            {
                "startTime": "21:02",
                "arxivId": "2408.00690",
                "arxivLink": "https://arxiv.org/abs/2408.00690",
                "title": "MiniCPM Gets a Boost: Tiny Language Models Learn to Speak Big!",
                "institute": "Tsinghua University",
                "text": "This research focuses on improving text embeddings for smaller language models (LLMs) by using contrastive fine-tuning. Unlike previous work that primarily focused on large LLMs, this study explores the potential of smaller models for text embedding tasks.",
                "paper-title": "Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning",
                "image-path": ""
            },

            {
                "startTime": "21:29",
                "arxivId": "2408.00376",
                "arxivLink": "https://arxiv.org/abs/2408.00376",
                "title": "Making AI Forget: Can We Unlearn What We've Taught?",
                "institute": "Tsinghua University",
                "text": "This paper focuses on the limitations of machine unlearning in generative AI models, specifically LLMs and image generative models. It goes beyond simply highlighting the potential of unlearning and delves into the challenges and risks associated with it.",
                "paper-title": "On the Limitations and Prospects of Machine Unlearning for Generative AI",
                "image-path": ""
            },

            {
                "startTime": "21:55",
                "arxivId": "2408.00458",
                "arxivLink": "https://arxiv.org/abs/2408.00458",
                "title": "Reenact Anything: Turning Videos into Motion Magic with Textual Tricks!",
                "institute": "ETH Zurich",
                "text": "This research proposes a novel method for transferring the semantic motion of a reference video to a target image using a pre-trained image-to-video diffusion model. Unlike previous methods that rely on fine-tuning or spatial alignment, this approach optimizes a set of text/image embedding tokens, referred to as a motion-text embedding, directly on the motion reference video.",
                "paper-title": "Reenact Anything: Semantic Video Motion Transfer Using Motion-Textual Inversion",
                "image-path": ""
            },

            {
                "startTime": "22:25",
                "arxivId": "2408.00751",
                "arxivLink": "https://arxiv.org/abs/2408.00751",
                "title": "Policy Gradient Gets a Game Face: New Algorithm Solves Imperfect-Information Games!",
                "institute": "MIT",
                "text": "This research introduces a novel policy gradient approach for solving imperfect-information games, using a new regularizer called the \"bidilated regularizer\" and trajectory Q-values. This differs from previous work that relied on counterfactual values and average-iterate convergence.",
                "paper-title": "A Policy-Gradient Approach to Solving Imperfect-Information Games with Iterate Convergence",
                "image-path": ""
            },

            {
                "startTime": "22:50",
                "arxivId": "2408.00672",
                "arxivLink": "https://arxiv.org/abs/2408.00672",
                "title": "AI Coach: Giving You the Play-by-Play for Better Skills!",
                "institute": "UT Austin, FAIR Meta, Carnegie Mellon University",
                "text": "This research focuses on generating actionable feedback from videos of people performing physical activities, going beyond simply scoring demonstrations. It uses a multimodal approach, combining video, 3D body pose, and expert commentary to provide both verbal and visual feedback.",
                "paper-title": "ExpertAF: Expert Actionable Feedback from Video",
                "image-path": ""
            },

            {
                "startTime": "23:10",
                "arxivId": "2408.00343",
                "arxivLink": "https://arxiv.org/abs/2408.00343",
                "title": "Robots That Push: Navigating the World by Moving Obstacles",
                "institute": "ETH Zurich, Technical University of Munich, Intel",
                "text": "This research introduces a novel approach to visual navigation that allows robots to interact with their environment by pushing movable obstacles out of the way. Unlike previous methods that treat the environment as static, this system learns to identify and manipulate objects, enabling more efficient and adaptable navigation strategies.",
                "paper-title": "IN-Sight: Interactive Navigation through Sight",
                "image-path": ""
            },

            {
                "startTime": "23:36",
                "arxivId": "2408.00738",
                "arxivLink": "https://arxiv.org/abs/2408.00738",
                "title": "Virchow 2: Pathology's New Supermodel, Trained on 3.1 Million Slides!",
                "institute": "Microsoft, Paige",
                "text": "This research introduces two new models, Virchow 2 and Virchow 2G, which are trained on a significantly larger dataset of 3.1 million whole slide images (WSIs) compared to previous work. The study also incorporates domain-specific adaptations to the DINOv2 training algorithm, specifically focusing on augmentations and regularization techniques tailored for pathology images.",
                "paper-title": "Virchow 2: Scaling Self-Supervised Mixed Magnification Models in Pathology",
                "image-path": ""
            },

            {
                "startTime": "24:01",
                "arxivId": "2408.00657",
                "arxivLink": "https://arxiv.org/abs/2408.00657",
                "title": "Unraveling the Secrets of Text: How Sparse Autoencoders Decode Language Models",
                "institute": "Australian National University, Stanford University, Space Telescope Science Institute",
                "text": "This research applies sparse autoencoders (SAEs) to dense text embeddings from large language models, a novel approach that hasn't been explored before.",
                "paper-title": "Disentangling Dense Embeddings with Sparse Autoencoders",
                "image-path": ""
            },

            {
                "startTime": "24:34",
                "arxivId": "2408.00196",
                "arxivLink": "https://arxiv.org/abs/2408.00196",
                "title": "Music's New Maestro: AI Learns to Mimic Styles, Not Just Notes!",
                "institute": "Sorbonne Universit\u00e9 CNRS Ircam",
                "text": "This research proposes a new method for disentangling timbre and structure representations in audio generation, allowing for more precise control over the generated audio's style and content. Unlike previous approaches that rely on text prompts or limited sets of predefined instruments, this method enables one-shot timbre transfer between arbitrary audio examples.",
                "paper-title": "Combining audio control and style transfer using latent diffusion",
                "image-path": ""
            },

            {
                "startTime": "24:59",
                "arxivId": "2408.00181",
                "arxivLink": "https://arxiv.org/abs/2408.00181",
                "title": "SAM's Got a New Trick: Ultrasound Segmentation with a Chatty Sidekick!",
                "institute": "University of Oxford",
                "text": "This research introduces a new method for adapting the Segment Anything Model (SAM) for medical image segmentation, specifically ultrasound images. It differs from previous work by incorporating a frozen convolutional neural network (CNN) branch alongside SAM's original vision transformer (ViT) encoder, using a variational attention fusion module to combine their features. Additionally, the study utilizes text prompts generated by ChatGPT to provide contextual information to SAM, enhancing its understanding of the nuances of ultrasound images.",
                "paper-title": "CC-SAM: SAM with Cross-feature Attention and Context for Ultrasound Image Segmentation",
                "image-path": ""
            },

            {
                "startTime": "25:31",
                "arxivId": "2408.00131",
                "arxivLink": "https://arxiv.org/abs/2408.00131",
                "title": "Taming Wild Tails: A New Way to Handle Extreme Events with Robust Optimization",
                "institute": "Duke University, Stanford University, George Mason University",
                "text": "This research introduces a new framework for robustifying extreme value distributions (EVDs) using distributionally robust optimization (DRO). Unlike previous work that focused on univariate EVDs, this paper tackles the more complex multivariate case, where the dependence structure between variables is crucial. The key innovation lies in incorporating max-stability constraints within the DRO framework, ensuring that the robustified distribution retains the essential properties of EVT.",
                "paper-title": "Distributionally Robust Optimization as a Scalable Framework to Characterize Extreme Value Distributions",
                "image-path": ""
            },

            {
                "startTime": "25:59",
                "arxivId": "2408.00256",
                "arxivLink": "https://arxiv.org/abs/2408.00256",
                "title": "Blurry Vision, Clear Results: Federated Learning for Self-Driving Cars",
                "institute": "Jiangnan University, Tsinghua University",
                "text": "This research proposes a new federated learning algorithm called FLSimCo, which addresses the issue of image blurring caused by vehicle movement during training. Unlike previous methods, FLSimCo incorporates blur level as a weight during model aggregation, leading to more accurate and stable results.",
                "paper-title": "Mobility-Aware Federated Self-supervised Learning in Vehicular Network",
                "image-path": ""
            },

            {
                "startTime": "26:28",
                "arxivId": "2408.00084",
                "arxivLink": "https://arxiv.org/abs/2408.00084",
                "title": "Neural Networks: The New Light in Exoplanet Atmospheres?",
                "institute": "Max Planck Society",
                "text": "This research uses physics-informed neural networks (PINNs) to model radiative transfer in exoplanetary atmospheres, specifically focusing on scattering phenomena. Unlike traditional models that simplify scattering as absorption, PINNs directly incorporate the governing differential equations into their loss function, offering a more precise and potentially faster modeling technique.",
                "paper-title": "Approximating Rayleigh Scattering in Exoplanetary Atmospheres using Physics-informed Neural Networks (PINNs)",
                "image-path": ""
            },

            {
                "startTime": "26:57",
                "arxivId": "2408.00611",
                "arxivLink": "https://arxiv.org/abs/2408.00611",
                "title": "ASL-DVS: Spiking Neural Networks Learn Sign Language, One Spike at a Time!",
                "institute": "University of Tennessee",
                "text": "This research utilizes a convolutional spiking neural network (CSNN) architecture to process and classify event-based data from the ASL-DVS dataset, a neuromorphic dataset containing hand gestures for American Sign Language (ASL). This approach differs from previous work by leveraging the temporal and spatial information inherent in event-based data, which is captured by dynamic vision sensors (DVS).",
                "paper-title": "Using CSNNs to Perform Event-based Data Processing&Classification on ASL-DVS",
                "image-path": ""
            },

            {
                "startTime": "27:20",
                "arxivId": "2408.00527",
                "arxivLink": "https://arxiv.org/abs/2408.00527",
                "title": "Brain Stiffness: The New Age Game Changer?",
                "institute": "University of Cambridge, Cardiff University, University of Delaware",
                "text": "This research introduces a novel contrastive loss function that dynamically focuses on localized neighborhoods of samples during training, improving the accuracy of brain age prediction. This approach differs from previous methods by adapting to the non-uniform distribution of data often found in medical imaging.",
                "paper-title": "Contrastive Learning with Dynamic Localized Repulsion for Brain Age Prediction on 3D Stiffness Maps",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 59,
        "num_total": 247,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202408020659_audio.mp3"
}
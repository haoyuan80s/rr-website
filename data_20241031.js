
daily_data = {
    "date": "2024-10-31",
    "tweets": [
        
        {
            "startTime": "01:00",
            "arxivId": "2410.22391",
            "arxivLink": "https://arxiv.org/abs/2410.22391",
            "title": "Recurrent Robots: xLSTMs Make AI Agents Move Faster!",
            "institute": "JKU Linz, NXAI GmbH, Google DeepMind...",
            "text": "This research explores the use of modern recurrent architectures, like xLSTM and Mamba, as the backbone for large action models (LAMs). Unlike previous work that primarily relied on Transformers, this study demonstrates that recurrent architectures can achieve comparable performance while offering significantly faster inference times.",
            "paper-title": "A Large Recurrent Action Model: xLSTM enables Fast Inference for Robotics Tasks",
            "image-path": "flux_paper_image/2410.22391_1730404883.png"
        },

        {
            "startTime": "01:23",
            "arxivId": "2410.23262",
            "arxivLink": "https://arxiv.org/abs/2410.23262",
            "title": "EMMA: The AI That Drives Like a Human (But With More Text)",
            "institute": "Waymo",
            "text": "This research uses a large language model (LLM) called Gemini to create a single, end-to-end model for autonomous driving. Unlike previous modular systems, EMMA directly maps camera data into driving outputs like trajectories, object detection, and road graph elements.",
            "paper-title": "EMMA: End-to-End Multimodal Model for Autonomous Driving",
            "image-path": "flux_paper_image/2410.23262_1730403284.png"
        },

        {
            "startTime": "01:46",
            "arxivId": "2410.22884",
            "arxivLink": "https://arxiv.org/abs/2410.22884",
            "title": "MoE Models: A Prompt-Stealing Side-Channel!",
            "institute": "Google",
            "text": "This research explores a new vulnerability in Mixture-of-Experts (MoE) models, specifically focusing on how an attacker can exploit the Expert-Choice-Routing strategy to extract a victim's private input. This differs from previous work that focused on Denial-of-Service attacks.",
            "paper-title": "Stealing User Prompts from Mixture of Experts",
            "image-path": "flux_paper_image/2410.22884_1730404003.png"
        },

        {
            "startTime": "02:04",
            "arxivId": "2410.22456",
            "arxivLink": "https://arxiv.org/abs/2410.22456",
            "title": "Image2Struct: VLMs Get a Reality Check on Structure Extraction!",
            "institute": "Stanford University, Hitachi America Ltd",
            "text": "This research introduces Image2Struct, a benchmark that evaluates vision-language models (VLMs) on their ability to extract structure from images. Unlike previous benchmarks that rely on human judgment or multiple-choice questions, Image2Struct uses a fully automatic, round-trip evaluation process.",
            "paper-title": "Image2Struct: Benchmarking Structure Extraction for Vision-Language Models",
            "image-path": "flux_paper_image/2410.22456_1730404249.png"
        },

        {
            "startTime": "02:30",
            "arxivId": "2410.22721",
            "arxivLink": "https://arxiv.org/abs/2410.22721",
            "title": "Search Queries: The Secret Sauce for Spatially Savvy Models?",
            "institute": "Google",
            "text": "This research proposes a novel approach for generating aggregated and anonymized representations of search interest as foundation features at the community level for geospatial modeling. Unlike previous work that focused on handcrafted features for specific use cases, this method utilizes a general representation of web search queries applicable to a wide range of spatial modeling tasks.",
            "paper-title": "Community search signatures as foundation features for human-centered geospatial modeling",
            "image-path": "flux_paper_image/2410.22721_1730402639.png"
        },

        {
            "startTime": "02:43",
            "arxivId": "2410.22360",
            "arxivLink": "https://arxiv.org/abs/2410.22360",
            "title": "AI Turns Literature Reviews into Tables: A Recipe for Scientific Sensemaking",
            "institute": "University of Washington, Korea Advanced Institute of Science and Technology",
            "text": "This research introduces a framework for automatically generating literature review tables using language models. Unlike previous work that focuses on either schema or value generation, this paper tackles both tasks simultaneously.",
            "paper-title": "ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models",
            "image-path": "flux_paper_image/2410.22360_1730404507.png"
        },

        {
            "startTime": "03:07",
            "arxivId": "2410.22592",
            "arxivLink": "https://arxiv.org/abs/2410.22592",
            "title": "AI Cookie Cutters: New Study Reveals Text-to-Image Models Lack Diversity",
            "institute": "Bar-Ilan University, Allen Institute for AI, University of Washington...",
            "text": "This research introduces GRADE, a method for measuring the diversity of images generated by text-to-image models. Unlike previous methods, GRADE focuses on specific attributes of concepts, rather than general feature similarities.",
            "paper-title": "GRADE: Quantifying Sample Diversity in Text-to-Image Models",
            "image-path": "flux_paper_image/2410.22592_1730404581.png"
        },

        {
            "startTime": "03:38",
            "arxivId": "2410.22366",
            "arxivLink": "https://arxiv.org/abs/2410.22366",
            "title": "Unpacking SDXL Turbo: Peeking Inside the Mind of a Text-to-Image AI",
            "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
            "text": "This research applies sparse autoencoders (SAEs) to understand the inner workings of a text-to-image diffusion model, SDXL Turbo. Unlike previous work that focused on language models, this study investigates the interpretability of features learned by SAEs in the visual domain.",
            "paper-title": "Unpacking SDXL Turbo: Interpreting Text-to-Image Models with Sparse Autoencoders",
            "image-path": "flux_paper_image/2410.22366_1730404226.png"
        },

        {
            "startTime": "04:00",
            "arxivId": "2410.22459",
            "arxivLink": "https://arxiv.org/abs/2410.22459",
            "title": "Predicting RL Agents' Next Moves: Plans vs. Simulations",
            "institute": "University of Cambridge",
            "text": "This research compares two approaches for predicting the future actions and events of reinforcement learning agents: the inner state approach, which uses the agent's internal computations, and the simulation-based approach, which uses a learned world model. The study finds that the plans of explicitly planning agents are more informative for prediction than the neuron activations of other types of agents.",
            "paper-title": "Predicting Future Actions of Reinforcement Learning Agents",
            "image-path": "flux_paper_image/2410.22459_1730403063.png"
        },

        {
            "startTime": "04:33",
            "arxivId": "2410.22559",
            "arxivLink": "https://arxiv.org/abs/2410.22559",
            "title": "VAE's Secret Weapon: Diagonal Covariances Unravel Data's Hidden Structure",
            "institute": "\u00c9cole Normale Sup\u00e9rieure",
            "text": "This paper extends previous work by formally proving how the use of diagonal posterior covariance matrices in VAEs leads to disentanglement, connecting linear independence in the decoder's Jacobian to statistical independence in the data distribution.",
            "paper-title": "Unpicking Data at the Seams: VAEs, Disentanglement and Independent Components",
            "image-path": "flux_paper_image/2410.22559_1730403265.png"
        },

        {
            "startTime": "04:56",
            "arxivId": "2410.23275",
            "arxivLink": "https://arxiv.org/abs/2410.23275",
            "title": "Predicting Margin Calls with a Network of Swaps: A DGNN Approach",
            "institute": "University of Milan, ETH Zurich",
            "text": "This research introduces a novel Dynamic Graph Neural Network (DGNN) architecture specifically designed for conditional multi-step ahead forecasting problems in temporal financial networks. Unlike previous work that assumes a static network of contracts, this model incorporates the dynamic behavior of financial entities by allowing them to exchange bilateral contracts in an evolving stochastic environment.",
            "paper-title": "Conditional Forecasting of Margin Calls using Dynamic Graph Neural Networks",
            "image-path": "flux_paper_image/2410.23275_1730403902.png"
        },

        {
            "startTime": "05:19",
            "arxivId": "2410.23266",
            "arxivLink": "https://arxiv.org/abs/2410.23266",
            "title": "AI Can't Tell Time? New Benchmark Tests Video Understanding",
            "institute": "Yale University",
            "text": "This research introduces a new benchmark called TOMATO, designed to specifically evaluate the temporal reasoning capabilities of Multimodal Foundation Models (MFMs) in video understanding. Unlike existing benchmarks, TOMATO ensures that models cannot rely on shortcuts like single frames or out-of-order frames to answer questions.",
            "paper-title": "TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models",
            "image-path": "flux_paper_image/2410.23266_1730404840.png"
        },

        {
            "startTime": "05:43",
            "arxivId": "2410.23022",
            "arxivLink": "https://arxiv.org/abs/2410.23022",
            "title": "LLMs Teach AI to Play NetHack Without Cheating!",
            "institute": "Meta, University of Texas Austin, UCLA",
            "text": "This research proposes ONI, a system that learns intrinsic rewards for reinforcement learning agents using feedback from large language models (LLMs). Unlike previous methods, ONI does not require pre-collected datasets or access to environment source code.",
            "paper-title": "Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback",
            "image-path": "flux_paper_image/2410.23022_1730403609.png"
        },

        {
            "startTime": "06:04",
            "arxivId": "2410.22854",
            "arxivLink": "https://arxiv.org/abs/2410.22854",
            "title": "Hyperparameter Optimization: The Art of Tuning Your Machine Learning Models",
            "institute": "\u00c9cole Normale Sup\u00e9rieure, University of Cambridge, DeepMind...",
            "text": "This research delves into the intricacies of hyperparameter optimization, focusing on the development of novel algorithms that leverage multi-fidelity methods. Unlike previous work, this paper explores the use of different levels of fidelity in evaluating hyperparameter configurations, enabling more efficient and effective optimization.",
            "paper-title": "Hyperparameter Optimization in Machine Learning",
            "image-path": "flux_paper_image/2410.22854_1730404501.png"
        },

        {
            "startTime": "06:31",
            "arxivId": "2410.22690",
            "arxivLink": "https://arxiv.org/abs/2410.22690",
            "title": "AI's Got a New Way to Learn Your Goals, and It's All About Beliefs!",
            "institute": "Stanford University",
            "text": "This paper introduces a new model for learning human preferences from choice data, called the \"bootstrapped return\" model. Unlike previous models that rely on partial return or cumulative advantage, the bootstrapped return model explicitly accounts for human beliefs about the environment.",
            "paper-title": "Choice between Partial Trajectories",
            "image-path": "flux_paper_image/2410.22690_1730403003.png"
        },

        {
            "startTime": "06:51",
            "arxivId": "2410.22629",
            "arxivLink": "https://arxiv.org/abs/2410.22629",
            "title": "CrossEarth: A Vision Foundation Model for Remote Sensing That's Out of This World!",
            "institute": "IEEE",
            "text": "This research introduces CrossEarth, the first vision foundation model (VFM) specifically designed for remote sensing domain generalization (RSDG) semantic segmentation. Unlike previous work that primarily focused on domain adaptation (DA), CrossEarth aims to generalize to unseen domains without requiring target domain data.",
            "paper-title": "CrossEarth: Geospatial Vision Foundation Model for Domain Generalizable Remote Sensing Semantic Segmentation",
            "image-path": "flux_paper_image/2410.22629_1730404236.png"
        },

        {
            "startTime": "07:21",
            "arxivId": "2410.23042",
            "arxivLink": "https://arxiv.org/abs/2410.23042",
            "title": "Transformers: Learning to Forget What They Know (and When)",
            "institute": "University of Alberta, Google",
            "text": "This paper introduces a theoretical model that explains how in-context learning (ICL) emerges and disappears in transformers. It focuses on the interplay between in-weight learning (IWL) and ICL, analyzing how the distribution of training data affects the model's ability to learn and generalize.",
            "paper-title": "Toward Understanding In-context vs. In-weight Learning",
            "image-path": "flux_paper_image/2410.23042_1730402854.png"
        },

        {
            "startTime": "07:45",
            "arxivId": "2410.23232",
            "arxivLink": "https://arxiv.org/abs/2410.23232",
            "title": "Unlearning Made Easy: Datamodel Matching to the Rescue!",
            "institute": "MIT, Harvard University, Stanford University...",
            "text": "This paper introduces a new machine unlearning technique called Datamodel Matching (DMM) that uses data attribution to predict the effect of removing data from a model's training set. This approach differs from previous methods that rely on fine-tuning the model directly.",
            "paper-title": "Attribute-to-Delete: Machine Unlearning via Datamodel Matching",
            "image-path": "flux_paper_image/2410.23232_1730404550.png"
        },

        {
            "startTime": "08:11",
            "arxivId": "2410.22782",
            "arxivLink": "https://arxiv.org/abs/2410.22782",
            "title": "LoRA's Got Talent: A New Trick for Multi-Task Learning",
            "institute": "Tsinghua University, Shanghai University of Finance and Economics",
            "text": "This paper proposes MALoRA, a new fine-tuning framework that leverages asymmetries in LoRA experts within the Mixture-of-LoRA (MoLoRA) architecture. It introduces a shared low-rank subspace in the down-projection module, reducing redundancy and computational overhead.",
            "paper-title": "MALoRA: Mixture of Asymmetric Low-Rank Adaptation for Enhanced Multi-Task Learning",
            "image-path": "flux_paper_image/2410.22782_1730403507.png"
        },

        {
            "startTime": "08:31",
            "arxivId": "2410.23223",
            "arxivLink": "https://arxiv.org/abs/2410.23223",
            "title": "LLM Alignment: A Game of \"Who's Got the Best Moves?\"",
            "institute": "Yale University",
            "text": "This research proposes a new meta-algorithm called COMAL for aligning LLMs with general preferences. Unlike previous methods that rely on the Bradley-Terry model, COMAL models the alignment problem as a two-player zero-sum game, where the Nash equilibrium policy guarantees a 50% win rate against any competing policy.",
            "paper-title": "COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences",
            "image-path": "flux_paper_image/2410.23223_1730403928.png"
        },

        {
            "startTime": "08:51",
            "arxivId": "2410.22656",
            "arxivLink": "https://arxiv.org/abs/2410.22656",
            "title": "SAM's Got a New Trick: Tilted Weights for Flatter Models!",
            "institute": "University of Chicago, University of Maryland, University of Washington",
            "text": "This paper proposes Tilted SAM (TSAM), a new optimization objective that generalizes Sharpness-Aware Minimization (SAM) by using exponential tilting to reweight local minima in the parameter space. Unlike SAM, which focuses on the worst-case loss, TSAM considers a weighted average of losses across the neighborhood, effectively prioritizing flatter minima.",
            "paper-title": "Reweighting Local Mimina with Tilted SAM",
            "image-path": "flux_paper_image/2410.22656_1730403620.png"
        },

        {
            "startTime": "09:19",
            "arxivId": "2410.23230",
            "arxivLink": "https://arxiv.org/abs/2410.23230",
            "title": "AI Audio Editor: Fixing the Sound of Silence in Videos!",
            "institute": "Carnegie Mellon University, Alibaba Group, MBZUAI",
            "text": "This research proposes an agentic workflow using LLMs to align audio and visual data in videos, addressing the issue of misalignment caused by noise and non-synchronization. This approach differs from previous work by focusing on data-centric improvements rather than solely algorithmic enhancements.",
            "paper-title": "Aligning Audio-Visual Joint Representations with an Agentic Workflow",
            "image-path": "flux_paper_image/2410.23230_1730403582.png"
        },

        {
            "startTime": "09:45",
            "arxivId": "2410.23277",
            "arxivLink": "https://arxiv.org/abs/2410.23277",
            "title": "Video Generation Gets a Memory Boost: Slow-Fast Learning for Long Videos",
            "institute": "UCLA, Microsoft Research, State University of New York at Buffalo",
            "text": "This research introduces a dual-speed learning system for video generation, incorporating a \"fast learning\" strategy that stores episodic memory in LoRA parameters. This differs from previous work that primarily focuses on slow learning, often leading to inconsistencies in longer videos.",
            "paper-title": "SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation",
            "image-path": "flux_paper_image/2410.23277_1730404606.png"
        },

        {
            "startTime": "10:05",
            "arxivId": "2410.22499",
            "arxivLink": "https://arxiv.org/abs/2410.22499",
            "title": "Predicting the Future: How LLMs Can Make Machine Translation Faster and Better",
            "institute": "CMU",
            "text": "This research introduces a novel method called Translation by Anticipating Future (TAF) that leverages a large language model (LLM) to predict future source words in simultaneous machine translation (SMT). Unlike previous SMT methods that rely solely on the partial input already received, TAF uses the LLM to anticipate upcoming words, enabling the translation process to start earlier and potentially improve translation quality.",
            "paper-title": "Anticipating Future with Large Language Model for Simultaneous Machine Translation",
            "image-path": "flux_paper_image/2410.22499_1730404529.png"
        },

        {
            "startTime": "10:27",
            "arxivId": "2410.22646",
            "arxivLink": "https://arxiv.org/abs/2410.22646",
            "title": "Sleep Staging Without the Sleep-Stealing Sensors: BCG Takes the Stage!",
            "institute": "Tsinghua University, UC San Francisco",
            "text": "This research proposes a novel method for sleep staging using ballistocardiograms (BCGs) by extracting components from BCGs and aligning them with corresponding channels in polysomnograms (PSGs). This approach leverages large-scale PSG datasets to address the scarcity of annotated BCG data, a limitation of previous BCG-based sleep staging methods.",
            "paper-title": "SleepNetZero: Zero-Burden Zero-Shot Reliable Sleep Staging With Neural Networks Based on Ballistocardiograms",
            "image-path": "flux_paper_image/2410.22646_1730403416.png"
        },

        {
            "startTime": "10:57",
            "arxivId": "2410.23123",
            "arxivLink": "https://arxiv.org/abs/2410.23123",
            "title": "LLMs: Brainiacs or Cheaters? New Study Uncovers the Truth About Reasoning!",
            "institute": "Google, University of Illinois Urbana-Champaign, Princeton University...",
            "text": "This research introduces a new metric, LiMem, to quantify memorization in LLMs' reasoning abilities. Unlike previous work that focused on detecting data contamination, this study investigates how LLMs solve problems they've seen before versus those that are slightly altered.",
            "paper-title": "On Memorization of Large Language Models in Logical Reasoning",
            "image-path": "flux_paper_image/2410.23123_1730403271.png"
        },

        {
            "startTime": "11:18",
            "arxivId": "2410.23274",
            "arxivLink": "https://arxiv.org/abs/2410.23274",
            "title": "Diffusion Models: One Teacher, Many Students, Faster Generation!",
            "institute": "Harvard University, NVIDIA, Vector Institute",
            "text": "This paper introduces Multi-Student Distillation (MSD), a framework for training multiple single-step diffusion models from a single teacher model. Unlike previous work that focuses on a single student, MSD allows for partitioning the training data and assigning each student a subset of the data, leading to faster inference times.",
            "paper-title": "Multi-student Diffusion Distillation for Better One-step Generators",
            "image-path": "flux_paper_image/2410.23274_1730403123.png"
        },

        {
            "startTime": "11:52",
            "arxivId": "2410.23148",
            "arxivLink": "https://arxiv.org/abs/2410.23148",
            "title": "HiBO: Bayesian Optimization Gets a Tree-mendous Upgrade!",
            "institute": "University of Cambridge",
            "text": "This paper introduces HiBO, a hierarchical Bayesian Optimization algorithm that integrates global-level search space partitioning information into the acquisition strategy of a local BO-based optimizer. This differs from previous work that either relies on structural assumptions about the objective function or restricts sampling to a single promising region.",
            "paper-title": "HiBO: Hierarchical Bayesian Optimization via Adaptive Search Space Partitioning",
            "image-path": ""
        },

        {
            "startTime": "12:15",
            "arxivId": "2410.22992",
            "arxivLink": "https://arxiv.org/abs/2410.22992",
            "title": "Refugee Resettlement: Matching with a Side of Service!",
            "institute": "UC Berkeley, Yale University, University of Chicago Booth School of Business...",
            "text": "This research introduces a new dynamic matching problem that incorporates post-allocation service, a crucial aspect often overlooked in refugee resettlement. Unlike previous work, the algorithms developed here do not rely on past years' data, making them more robust to changes in refugee arrival patterns.",
            "paper-title": "Dynamic Matching with Post-Allocation Service and its Application to Refugee Resettlement",
            "image-path": "flux_paper_image/2410.22992_1730403217.png"
        },

        {
            "startTime": "12:40",
            "arxivId": "2410.23214",
            "arxivLink": "https://arxiv.org/abs/2410.23214",
            "title": "LLMs Learn to Search Like Humans: Trying, Failing, and Getting Better!",
            "institute": "Stanford University",
            "text": "This research introduces LeReT, a framework that uses reinforcement learning to improve the search query generation capabilities of LLMs. Unlike previous work that focuses on fine-tuning the retriever or using downstream signals, LeReT directly optimizes the LLM responsible for generating search queries by leveraging retrieval annotations.",
            "paper-title": "Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval",
            "image-path": "flux_paper_image/2410.23214_1730404915.png"
        },

        {
            "startTime": "13:04",
            "arxivId": "2410.22637",
            "arxivLink": "https://arxiv.org/abs/2410.22637",
            "title": "Diffusion Bridges Get a Speed Boost: Consistency Models Make Sampling a Breeze!",
            "institute": "Tsinghua University",
            "text": "This research introduces consistency diffusion bridge models (CDBMs), which learn a consistency function for the probability-flow ordinary differential equation (PF-ODE) of denoising diffusion bridge models (DDBMs). This allows for faster sampling compared to traditional DDBMs.",
            "paper-title": "Consistency Diffusion Bridge Models",
            "image-path": "flux_paper_image/2410.22637_1730402508.png"
        },

        {
            "startTime": "13:25",
            "arxivId": "2410.23182",
            "arxivLink": "https://arxiv.org/abs/2410.23182",
            "title": "Transformers Get a Robust Makeover: Plug-and-Play Defense Against Attacks!",
            "institute": "North Carolina State University, CMU, Oak Ridge National Laboratory",
            "text": "This research proposes a novel robust attention mechanism called ProAttention that can be integrated into existing transformers as a plug-and-play layer, enhancing their resilience against adversarial attacks without requiring additional training or fine-tuning. This approach differs from previous work by focusing on improving the robustness of the transformer architecture itself, rather than relying on external defenses or retraining.",
            "paper-title": "ProTransformer: Robustify Transformers via Plug-and-Play Paradigm",
            "image-path": "flux_paper_image/2410.23182_1730403068.png"
        },

        {
            "startTime": "13:48",
            "arxivId": "2410.22375",
            "arxivLink": "https://arxiv.org/abs/2410.22375",
            "title": "Code Refine-O-Meter: Is Your Code Getting Better or Just Getting Worse?",
            "institute": "Korea Advanced Institute of Science and Technology",
            "text": "This research introduces a novel approach to judging the efficiency of code refinements, focusing on comparing the efficiency of two code versions (original and refined) without actually executing them. This differs from previous work that primarily focused on code enhancement without explicitly evaluating the efficiency of the refined code.",
            "paper-title": "Rethinking Code Refinement: Learning to Judge Code Efficiency",
            "image-path": "flux_paper_image/2410.22375_1730404573.png"
        },

        {
            "startTime": "14:09",
            "arxivId": "2410.23074",
            "arxivLink": "https://arxiv.org/abs/2410.23074",
            "title": "LLMs Get a Sandbox: Multi-Language Code Playground for Smarter AI!",
            "institute": "Fudan University, Peking University, Meituan",
            "text": "This research introduces MPLSandbox, a multi-programming language sandbox that provides unified compiler feedback and comprehensive code analysis for LLMs. Unlike existing sandboxes that focus on single or a few languages, MPLSandbox supports multiple languages, making it more versatile for LLM training and deployment.",
            "paper-title": "Multi-Programming Language Sandbox for LLMs",
            "image-path": "flux_paper_image/2410.23074_1730404146.png"
        },

        {
            "startTime": "14:37",
            "arxivId": "2410.22564",
            "arxivLink": "https://arxiv.org/abs/2410.22564",
            "title": "Missing Features? No Problem! New VFL Method Makes Data Work Harder",
            "institute": "CMU, IBM",
            "text": "This research proposes LASER-VFL, a vertical federated learning method that can handle missing features during both training and inference. Unlike previous methods that either discard incomplete samples or train local predictors that ignore available features, LASER-VFL leverages all available data by strategically sharing model parameters and employing a task-sampling mechanism.",
            "paper-title": "Vertical Federated Learning with Missing Features During Training and Inference",
            "image-path": "flux_paper_image/2410.22564_1730404819.png"
        },

        {
            "startTime": "15:02",
            "arxivId": "2410.22821",
            "arxivLink": "https://arxiv.org/abs/2410.22821",
            "title": "EvoCodeBench: Code Generation's Evolving Challenge!",
            "institute": "Peking University, Alibaba",
            "text": "This research introduces EvoCodeBench, a code generation benchmark that dynamically updates to avoid data leakage and includes domain-specific evaluations. Unlike previous benchmarks, EvoCodeBench focuses on evaluating LLMs in real-world repositories, considering the specific domains of code.",
            "paper-title": "EvoCodeBench: An Evolving Code Generation Benchmark with Domain-Specific Evaluations",
            "image-path": "flux_paper_image/2410.22821_1730404075.png"
        },

        {
            "startTime": "15:24",
            "arxivId": "2410.22901",
            "arxivLink": "https://arxiv.org/abs/2410.22901",
            "title": "Meme Magic: Weaving Attention for High-Fidelity Video Generation",
            "institute": "Peking University, Tianjin University, Shanghai University",
            "text": "This research introduces Spatial Knitting Attention (SKA), a novel attention mechanism that preserves spatial structure in 2D feature maps, improving the performance of adapters in text-to-image models. This approach differs from previous methods that flatten feature maps, potentially losing spatial information.",
            "paper-title": "HelloMeme: Integrating Spatial Knitting Attentions to Embed High-Level and Fidelity-Rich Conditions in Diffusion Models",
            "image-path": "flux_paper_image/2410.22901_1730405072.png"
        },

        {
            "startTime": "15:49",
            "arxivId": "2410.23287",
            "arxivLink": "https://arxiv.org/abs/2410.23287",
            "title": "\"Refer Everything\" in Videos: A Diffusion Model's Wild Ride Through the Visual World",
            "institute": "CMU, University of Illinois, Toyota Research Institute",
            "text": "This research proposes a new approach to referral video segmentation (RVS) that leverages the power of video diffusion models. Unlike previous methods that often replace parts of the generative model with new layers, this approach preserves the original model architecture and fine-tunes it on existing datasets. This allows the model to retain the rich representations learned during pre-training, leading to improved generalization capabilities.",
            "paper-title": "ReferEverything: Towards Segmenting Everything We Can Speak of in Videos",
            "image-path": "flux_paper_image/2410.23287_1730404598.png"
        },

        {
            "startTime": "16:15",
            "arxivId": "2410.23273",
            "arxivLink": "https://arxiv.org/abs/2410.23273",
            "title": "Clustering with a Conscience: Fairness for Non-Centroid Clusters",
            "institute": "Aarhus University, Harvard University, University of Toronto",
            "text": "This paper extends the framework of proportionally fair clustering to non-centroid clustering, where the loss of an agent is a function of the other agents in its cluster. This is different from previous work that focused on centroid clustering, where the loss of an agent is its distance to the centroid assigned to its cluster.",
            "paper-title": "Proportional Fairness in Non-Centroid Clustering",
            "image-path": "flux_paper_image/2410.23273_1730403560.png"
        },

        {
            "startTime": "16:41",
            "arxivId": "2410.23254",
            "arxivLink": "https://arxiv.org/abs/2410.23254",
            "title": "Robot Skills on Autopilot: Large Models Learn Keypoints for Object-Relative Imitation Learning",
            "institute": "MIT",
            "text": "This research proposes a novel framework called KALM that leverages large pre-trained vision-language models (VLMs) to automatically generate task-relevant and cross-instance consistent keypoints for object-relative imitation learning. Unlike previous work that relies on manual keypoint design or additional human labels, KALM distills keypoints by prompting and verifying proposals from VLMs using a small set of robot demonstration data.",
            "paper-title": "Keypoint Abstraction using Large Models for Object-Relative Imitation Learning",
            "image-path": "flux_paper_image/2410.23254_1730403396.png"
        },

        {
            "startTime": "17:06",
            "arxivId": "2410.22949",
            "arxivLink": "https://arxiv.org/abs/2410.22949",
            "title": "MutaPLM: Giving Proteins a Voice, One Mutation at a Time!",
            "institute": "Tsinghua University",
            "text": "This research introduces MutaPLM, a framework that explicitly models protein mutations using a protein delta network and cross-modal supervision from biomedical texts. This differs from previous work that implicitly modeled mutations through evolutionary plausibility.",
            "paper-title": "MutaPLM: Protein Language Modeling for Mutation Explanation and Engineering",
            "image-path": "flux_paper_image/2410.22949_1730403680.png"
        },

        {
            "startTime": "17:28",
            "arxivId": "2410.23084",
            "arxivLink": "https://arxiv.org/abs/2410.23084",
            "title": "AI to the Rescue: Prostate Cancer Detection Gets a Smart Upgrade!",
            "institute": "University College London, University of Westminster",
            "text": "This research focuses on training AI models to classify radiologist-identified positive cases, rather than the entire patient population, to improve prostate cancer detection accuracy. This approach avoids the challenges associated with sparsely sampled and potentially biased histopathology labels in radiologist-negative cases.",
            "paper-title": "AI-assisted prostate cancer detection and localisation on biparametric MR by classifying radiologist-positives",
            "image-path": "flux_paper_image/2410.23084_1730404984.png"
        },

        {
            "startTime": "17:55",
            "arxivId": "2410.22939",
            "arxivLink": "https://arxiv.org/abs/2410.22939",
            "title": "Stop and Smell the Pixels: AI Learns to Optimize Images for Object Detection",
            "institute": "Purple Mountain Observatory, Peking University",
            "text": "This research proposes AdaptiveISP, a system that uses reinforcement learning to dynamically adjust the image signal processing (ISP) pipeline based on the input image and the desired downstream task, such as object detection. Unlike previous methods that optimize ISP parameters or pipelines for image quality, AdaptiveISP focuses on maximizing the performance of high-level computer vision tasks.",
            "paper-title": "AdaptiveISP: Learning an Adaptive Image Signal Processor for Object Detection",
            "image-path": "flux_paper_image/2410.22939_1730402863.png"
        },

        {
            "startTime": "18:23",
            "arxivId": "2410.23137",
            "arxivLink": "https://arxiv.org/abs/2410.23137",
            "title": "Dividing the Pie: When Fairness Meets Market Value",
            "institute": "Indian Institute of Science, University of Toronto",
            "text": "This research introduces a new model for fair division that considers both subjective valuations and market values, unlike previous work that focused solely on subjective valuations.",
            "paper-title": "Fair Division with Market Values",
            "image-path": "flux_paper_image/2410.23137_1730403633.png"
        },

        {
            "startTime": "18:45",
            "arxivId": "2410.22981",
            "arxivLink": "https://arxiv.org/abs/2410.22981",
            "title": "Time Series Forecasting: When One Model Isn't Enough, DisenTS to the Rescue!",
            "institute": "Tsinghua University",
            "text": "This research proposes DisenTS, a framework that uses multiple forecasting models to capture diverse evolving patterns in multivariate time series data. Unlike previous methods that rely on a single model, DisenTS allows for more nuanced modeling of complex data.",
            "paper-title": "DisenTS: Disentangled Channel Evolving Pattern Modeling for Multivariate Time Series Forecasting",
            "image-path": "flux_paper_image/2410.22981_1730403828.png"
        },

        {
            "startTime": "19:06",
            "arxivId": "2410.22530",
            "arxivLink": "https://arxiv.org/abs/2410.22530",
            "title": "Pancreas Segmentation: Fed Up with Uniformity? Adaptive Weights to the Rescue!",
            "institute": "Northwestern University, Istanbul University, University of Catania...",
            "text": "This research introduces a novel approach to federated learning (FL) for pancreas MRI segmentation by incorporating adaptive aggregation weights. Unlike traditional FL methods, which assume equal contributions from all clients, this method dynamically adjusts the weight of each client's contribution based on their local data characteristics, improving model generalization across diverse institutions.",
            "paper-title": "Adaptive Aggregation Weights for Federated Segmentation of Pancreas MRI",
            "image-path": "flux_paper_image/2410.22530_1730404699.png"
        },

        {
            "startTime": "19:27",
            "arxivId": "2410.23156",
            "arxivLink": "https://arxiv.org/abs/2410.23156",
            "title": "Robots Learn to Think Like Humans: Neuro-Symbolic Predicates for Smarter Planning",
            "institute": "University of Cambridge, Cornell University, Massachusetts Institute of Technology...",
            "text": "This research introduces Neuro-Symbolic Predicates (NSPs), a new way to represent knowledge for robots that combines the strengths of both symbolic and neural approaches. Unlike previous methods that rely on fixed, hand-crafted representations, NSPs are learned online from interactions with the environment, allowing robots to adapt to new situations and tasks.",
            "paper-title": "VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning",
            "image-path": "flux_paper_image/2410.23156_1730403659.png"
        },

        {
            "startTime": "19:58",
            "arxivId": "2410.22584",
            "arxivLink": "https://arxiv.org/abs/2410.22584",
            "title": "AI Agents Build Benchmarks: No More Human Annotators!",
            "institute": "University of Amsterdam, Microsoft",
            "text": "This research introduces BENCHAGENTS, a framework that uses multiple interacting LLMs to automate the creation of benchmarks for complex NLP tasks. Unlike previous work that focuses on narrow domains or requires seed datasets, BENCHAGENTS can generate diverse and high-quality benchmarks for a broader range of tasks.",
            "paper-title": "BENCHAGENTS: Automated Benchmark Creation with Agent Interaction",
            "image-path": "flux_paper_image/2410.22584_1730403536.png"
        },

        {
            "startTime": "20:20",
            "arxivId": "2410.22353",
            "arxivLink": "https://arxiv.org/abs/2410.22353",
            "title": "Tired of RAG's Fuzzy Logic? RuleRAG to the Rescue!",
            "institute": "National University of Defense Technology, Beijing Institute of Technology, University of Oxford",
            "text": "This research introduces RuleRAG, a new approach to retrieval-augmented generation (RAG) that explicitly incorporates symbolic rules to guide both the retrieval and generation processes. Unlike previous RAG frameworks that rely solely on query-based retrieval, RuleRAG leverages rules to retrieve logically related documents and inform the generator about how to attribute retrieved content to answers.",
            "paper-title": "RuleRAG: Rule-guided retrieval-augmented generation with language models for question answering",
            "image-path": "flux_paper_image/2410.22353_1730404348.png"
        },

        {
            "startTime": "20:57",
            "arxivId": "2410.23285",
            "arxivLink": "https://arxiv.org/abs/2410.23285",
            "title": "Diffusion Models Get a Speed Boost: New Research Makes Sampling Faster Than Ever!",
            "institute": "Chinese University of Hong Kong, University of Michigan",
            "text": "This research proposes a training-free acceleration scheme for stochastic samplers used in diffusion models. Unlike previous work that relies on additional assumptions about the target distribution or higher-order score estimation, this method only requires L2-accurate score estimates and a finite second-order moment condition on the target distribution.",
            "paper-title": "Provable acceleration for diffusion models under minimal assumptions",
            "image-path": "flux_paper_image/2410.23285_1730402831.png"
        },

        {
            "startTime": "21:25",
            "arxivId": "2410.22520",
            "arxivLink": "https://arxiv.org/abs/2410.22520",
            "title": "Data's Got Talent: Learning to Speak Different Languages",
            "institute": "CMU",
            "text": "This research proposes a novel method called Multimodal Structure Preservation Learning (MSPL) that learns data representations by aligning the clustering structure of one data modality with another. This differs from previous work that focuses on aligning features between modalities.",
            "paper-title": "Multimodal Structure Preservation Learning",
            "image-path": "flux_paper_image/2410.22520_1730403722.png"
        },

        {
            "startTime": "21:57",
            "arxivId": "2410.22578",
            "arxivLink": "https://arxiv.org/abs/2410.22578",
            "title": "Drone Teamwork: How Battery Life Drives Smart Drone Missions",
            "institute": "Colby College, Columbia University",
            "text": "This research focuses on collaborative task execution in drone networks, considering the non-binary length of tasks and the impact of battery levels on mission success. Unlike previous work that primarily focused on trajectory optimization and collision avoidance, this study leverages multi-agent reinforcement learning (MARL) to enable drones to learn and adapt to dynamic environments while managing energy consumption.",
            "paper-title": "Energy-Aware Multi-Agent Reinforcement Learning for Collaborative Execution in Mission-Oriented Drone Networks",
            "image-path": "flux_paper_image/2410.22578_1730403354.png"
        },

        {
            "startTime": "22:18",
            "arxivId": "2410.22370",
            "arxivLink": "https://arxiv.org/abs/2410.22370",
            "title": "Generative AI's User Interface: A Taxonomy of How We Talk to Our Robot Overlords",
            "institute": "UC San Diego, Adobe, University of Waterloo...",
            "text": "This research focuses on the specific user interface designs and interaction patterns used in generative AI applications, unlike previous work that took a broader look at human-AI interaction.",
            "paper-title": "Survey of User Interface Design and Interaction Techniques in Generative AI Applications",
            "image-path": "flux_paper_image/2410.22370_1730404289.png"
        },

        {
            "startTime": "22:40",
            "arxivId": "2410.22448",
            "arxivLink": "https://arxiv.org/abs/2410.22448",
            "title": "Codec Resynthesis: From Tokens to Tunes, A New Way to Make AI Sing!",
            "institute": "MIT",
            "text": "This research focuses on resynthesizing audio from a coarse representation of the audio signal, specifically the first RVQ code, which is a discrete embedding of the audio. This is different from previous work that focused on generating the full sequence of RVQ codes, which are more fine-grained representations of the audio.",
            "paper-title": "A Closer Look at Neural Codec Resynthesis: Bridging the Gap between Codec and Waveform Generation",
            "image-path": "flux_paper_image/2410.22448_1730403425.png"
        },

        {
            "startTime": "23:08",
            "arxivId": "2410.23000",
            "arxivLink": "https://arxiv.org/abs/2410.23000",
            "title": "Long-Form RAG: A New Benchmark for LLMs That Can Actually Read!",
            "institute": "Tsinghua University",
            "text": "This research introduces a new benchmark called LONG2RAG and a metric called Key Point Recall (KPR) to evaluate the ability of large language models (LLMs) to effectively use information from long documents in retrieval-augmented generation (RAG) tasks. Previous benchmarks have focused on short-form answers or have not adequately considered the characteristics of retrieved documents.",
            "paper-title": "\\textsc{Long$^2$RAG}: Evaluating Long-Context \\&Long-Form Retrieval-Augmented Generation with Key Point Recall",
            "image-path": "flux_paper_image/2410.23000_1730404871.png"
        },

        {
            "startTime": "23:34",
            "arxivId": "2410.22705",
            "arxivLink": "https://arxiv.org/abs/2410.22705",
            "title": "Image Cloak: Hiding in Plain Sight, Fooling 3D Reconstruction",
            "institute": "Hong Kong Baptist University, Nvidia",
            "text": "This research proposes a novel approach to protect copyrighted images from unauthorized 3D reconstruction using Triplane Gaussian Splatting (TGS). Unlike previous methods that focus on image features, this paper targets the geometry features of the point cloud, introducing invisible perturbations that induce TGS to generate a specific watermark pattern.",
            "paper-title": "Geometry Cloak: Preventing TGS-based 3D Reconstruction from Copyrighted Images",
            "image-path": "flux_paper_image/2410.22705_1730404016.png"
        },

        {
            "startTime": "24:05",
            "arxivId": "2410.23170",
            "arxivLink": "https://arxiv.org/abs/2410.23170",
            "title": "Constrained Sampling: When Particles Just Want to Stay Inside the Lines!",
            "institute": "Peking University, UC Berkeley",
            "text": "This paper introduces a new method for constrained sampling using functional gradient flows. Unlike previous methods that rely on kernel functions or intricate transformations, this approach uses neural networks to learn the gradient flow directly, incorporating a boundary condition to keep particles within the specified domain.",
            "paper-title": "Functional Gradient Flows for Constrained Sampling",
            "image-path": "flux_paper_image/2410.23170_1730402921.png"
        },

        {
            "startTime": "24:32",
            "arxivId": "2410.22770",
            "arxivLink": "https://arxiv.org/abs/2410.22770",
            "title": "Prompt Injection Defense: Trigger Word Bias, Be Gone!",
            "institute": "University of Wisconsin-Madison",
            "text": "This research introduces a new dataset, NotInject, specifically designed to evaluate the over-defense issue in prompt guard models. It also proposes a novel training strategy, Mitigating Over-defense for Free (MOF), to address this issue.",
            "paper-title": "InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models",
            "image-path": "flux_paper_image/2410.22770_1730402975.png"
        },

        {
            "startTime": "24:53",
            "arxivId": "2410.23004",
            "arxivLink": "https://arxiv.org/abs/2410.23004",
            "title": "DexGraspNet 2.0: Robots Learn to Grasp in Cluttered Scenes, No Hands Needed!",
            "institute": "Peking University",
            "text": "This research introduces DexGraspNet 2.0, a large-scale synthetic dataset for dexterous grasping in cluttered scenes. The paper also proposes a novel two-stage grasping method that uses a diffusion model conditioned on local features to predict grasp pose distributions. This approach differs from previous work by leveraging a generative model to handle the multimodality of grasp distributions and by conditioning on local features to improve generalization to new objects and scenes.",
            "paper-title": "DexGraspNet 2.0: Learning Generative Dexterous Grasping in Large-scale Synthetic Cluttered Scenes",
            "image-path": "flux_paper_image/2410.23004_1730403821.png"
        },

        {
            "startTime": "25:21",
            "arxivId": "2410.22383",
            "arxivLink": "https://arxiv.org/abs/2410.22383",
            "title": "Building Brains: AI Learns to See Buildings in 3D, Not Just Flat Facades!",
            "institute": "EPFL, Schindler",
            "text": "This research uses a neural network to reconstruct 3D building models from 2D images, unlike previous methods that focused on analyzing individual facades.",
            "paper-title": "Exploiting Semantic Scene Reconstruction for Estimating Building Envelope Characteristics",
            "image-path": "flux_paper_image/2410.22383_1730403942.png"
        },

        {
            "startTime": "25:44",
            "arxivId": "2410.22657",
            "arxivLink": "https://arxiv.org/abs/2410.22657",
            "title": "AI's Got a New Job: Teaching Machines to Schedule Like Pros!",
            "institute": "Huazhong University of Science and Technology",
            "text": "This research introduces a novel population self-evolutionary (SeEvo) method that leverages large language models (LLMs) to automatically design and optimize heuristic dispatching rules (HDRs) for dynamic job shop scheduling problems (DJSSP). This approach differs from previous work by incorporating a self-evolution strategy within the LLM framework, enhancing the exploration and exploitation capabilities of the generated heuristics.",
            "paper-title": "Automatic programming via large language models with population self-evolution for dynamic job shop scheduling problem",
            "image-path": "flux_paper_image/2410.22657_1730403526.png"
        },

        {
            "startTime": "26:05",
            "arxivId": "2410.22695",
            "arxivLink": "https://arxiv.org/abs/2410.22695",
            "title": "Forget the Order, Remember the Results: A Particle Filter for Permutation-Invariant Learning",
            "institute": "MIT, Harvard University",
            "text": "This research introduces a novel permutation-invariant learning framework based on high-dimensional particle filters. Unlike traditional gradient-based algorithms, particle filters are inherently insensitive to the order of training data, offering a solution to catastrophic forgetting and loss of plasticity in sequential learning settings.",
            "paper-title": "Permutation Invariant Learning with High-Dimensional Particle Filters",
            "image-path": "flux_paper_image/2410.22695_1730404544.png"
        },

        {
            "startTime": "26:25",
            "arxivId": "2410.23272",
            "arxivLink": "https://arxiv.org/abs/2410.23272",
            "title": "Predicting the Future: A Monte Carlo Framework for Calibrated Uncertainty in Sequences",
            "institute": "MIT, New York University, University of Illinois Urbana-Champaign",
            "text": "This paper proposes a Monte Carlo framework for estimating probabilities and confidence intervals associated with sequences, addressing the challenge of miscalibration in autoregressive simulators. Unlike previous work that focuses on generating the most likely sequence, this framework aims to provide a probabilistic characterization of possible future sequences.",
            "paper-title": "A Monte Carlo Framework for Calibrated Uncertainty Estimation in Sequence Prediction",
            "image-path": "flux_paper_image/2410.23272_1730404520.png"
        },

        {
            "startTime": "26:47",
            "arxivId": "2410.22472",
            "arxivLink": "https://arxiv.org/abs/2410.22472",
            "title": "Unraveling the Cell's Secret Code: New Method Decodes Drug-Cell Interactions",
            "institute": "Genentech, University of Pittsburgh, Stanford University...",
            "text": "This research introduces a novel Factorized Causal Representation (FCR) learning method that disentangles the effects of treatments, cellular covariates, and their interactions in single-cell perturbation data. Unlike previous methods that focus on a single cellular context, FCR explicitly models interactions between treatments and contexts, enabling a more nuanced understanding of cellular responses.",
            "paper-title": "Learning Identifiable Factorized Causal Representations of Cellular Responses",
            "image-path": "flux_paper_image/2410.22472_1730404429.png"
        },

        {
            "startTime": "27:10",
            "arxivId": "2410.22600",
            "arxivLink": "https://arxiv.org/abs/2410.22600",
            "title": "Reinforcement Learning Gets a Cost-Conscious Makeover: Reach Your Goals, But Don't Break the Bank!",
            "institute": "MIT",
            "text": "This research introduces a new method called RC-PPO that directly solves the minimum-cost reach-avoid problem, unlike previous methods that rely on surrogate objectives. It achieves this by converting the problem into a reachability problem on an augmented system.",
            "paper-title": "Solving Minimum-Cost Reach Avoid using Reinforcement Learning",
            "image-path": "flux_paper_image/2410.22600_1730402515.png"
        },

        {
            "startTime": "27:28",
            "arxivId": "2410.22987",
            "arxivLink": "https://arxiv.org/abs/2410.22987",
            "title": "Traffic Jam? No Problem! Cars Chat to Solve Merging Mayhem",
            "institute": "Jiangnan University, Tsinghua University, Brunel University London...",
            "text": "This paper proposes a novel framework for distributed computing and control of connected and automated vehicles (CAVs) in ramp merging scenarios. Unlike existing methods, this approach leverages V2X communication to distribute computational tasks among CAVs, enabling parallel solving and reducing reliance on a central controller.",
            "paper-title": "V2X-Assisted Distributed Computing and Control Framework for Connected and Automated Vehicles under Ramp Merging Scenario",
            "image-path": "flux_paper_image/2410.22987_1730404360.png"
        },

        {
            "startTime": "28:02",
            "arxivId": "2410.22480",
            "arxivLink": "https://arxiv.org/abs/2410.22480",
            "title": "LLMs: Stop Wasting Compute, Get Smart With Mixed Allocations!",
            "institute": "CMU",
            "text": "This research proposes a novel algorithm, OSCA, that optimizes the allocation of compute resources across different sampling configurations during LLM inference. Unlike previous work that focuses on finding a single optimal configuration, OSCA leverages a mixed allocation strategy, distributing compute across multiple configurations to maximize accuracy.",
            "paper-title": "Scaling LLM Inference with Optimized Sample Compute Allocation",
            "image-path": "flux_paper_image/2410.22480_1730402666.png"
        },

        {
            "startTime": "28:27",
            "arxivId": "2410.23129",
            "arxivLink": "https://arxiv.org/abs/2410.23129",
            "title": "Fine-Grained Labels: The Secret Sauce for Super-Smart AI?",
            "institute": "Purdue University, Nvidia, Google",
            "text": "This paper introduces a new data model called \"hierarchical multi-view\" to explain why pretraining with fine-grained labels improves generalization in deep neural networks. This model differs from previous work by explicitly considering the hierarchical structure of labels and their correspondence to input features.",
            "paper-title": "Why Fine-grained Labels in Pretraining Benefit Generalization?",
            "image-path": "flux_paper_image/2410.23129_1730404587.png"
        },

        {
            "startTime": "28:50",
            "arxivId": "2410.22944",
            "arxivLink": "https://arxiv.org/abs/2410.22944",
            "title": "LLMs: Focus On This, Not That! Steering AI with Feature Filters",
            "institute": "University of Oxford",
            "text": "This research introduces Focus Instruction Tuning (FIT), a method that trains LLMs to adjust their responses based on user-specified features. Unlike traditional instruction tuning, FIT allows users to dynamically steer model behavior by indicating which features should be considered or ignored when performing a task.",
            "paper-title": "Focus On This, Not That! Steering LLMs With Adaptive Feature Specification",
            "image-path": "flux_paper_image/2410.22944_1730404965.png"
        },

        {
            "startTime": "29:14",
            "arxivId": "2410.22367",
            "arxivLink": "https://arxiv.org/abs/2410.22367",
            "title": "Drug Discovery Gets a Multi-Modal Makeover: MAMMAL to the Rescue!",
            "institute": "IBM",
            "text": "This research introduces MAMMAL, a multi-aligned foundation model that integrates multiple data domains to support a wide range of drug discovery tasks. Unlike previous models, MAMMAL is trained on a massive dataset of 2 billion samples across diverse modalities, including proteins, small molecules, and genes.",
            "paper-title": "MAMMAL -- Molecular Aligned Multi-Modal Architecture and Language",
            "image-path": "flux_paper_image/2410.22367_1730403055.png"
        },

        {
            "startTime": "29:32",
            "arxivId": "2410.23130",
            "arxivLink": "https://arxiv.org/abs/2410.23130",
            "title": "Cardiac Segmentation Gets a Metadata Makeover: A Multi-Task Approach to Heart Imaging",
            "institute": "Queen Mary University of London, University College London",
            "text": "This research proposes a novel compositional segmentation approach for cardiac images that simultaneously localizes the heart and segments its internal structures. It also introduces a Cross-Modal Feature Integration (CMFI) module to incorporate metadata associated with each image, such as acquisition parameters, patient conditions, and demographics, into the segmentation process. This distinguishes it from previous work that primarily relied on image data alone.",
            "paper-title": "Compositional Segmentation of Cardiac Images Leveraging Metadata",
            "image-path": "flux_paper_image/2410.23130_1730405006.png"
        },

        {
            "startTime": "29:54",
            "arxivId": "2410.22454",
            "arxivLink": "https://arxiv.org/abs/2410.22454",
            "title": "Brain Age: It's Not Just About Wrinkles, It's About the Wires!",
            "institute": "University of Pennsylvania, University of Pittsburgh, University of California San Diego...",
            "text": "This research focuses on using diffusion MRI (dMRI) to estimate brain age, but with a twist. Instead of relying on the usual macrostructural information, they minimize it by using non-rigid registration, allowing them to isolate the microstructural information. This approach aims to create a more sensitive biomarker for neurodegenerative diseases.",
            "paper-title": "Brain age identification from diffusion MRI synergistically predicts neurodegenerative disease",
            "image-path": "flux_paper_image/2410.22454_1730403879.png"
        },

        {
            "startTime": "30:16",
            "arxivId": "2410.23169",
            "arxivLink": "https://arxiv.org/abs/2410.23169",
            "title": "Deep Learning's Hidden Bias: Why Simple Structures Stick Around",
            "institute": "University of Oxford",
            "text": "This research extends previous work on deep neural collapse (DNC) by analyzing the impact of low-rank bias in a deep unconstrained feature model (DUFM) with cross-entropy loss. Unlike previous studies that focused on mean squared error (MSE) loss, this paper explores the effects of low-rank bias on the entire loss surface, not just on DNC solutions.",
            "paper-title": "The Persistence of Neural Collapse Despite Low-Rank Bias: An Analytic Perspective Through Unconstrained Features",
            "image-path": "flux_paper_image/2410.23169_1730404283.png"
        },

        {
            "startTime": "30:42",
            "arxivId": "2410.22699",
            "arxivLink": "https://arxiv.org/abs/2410.22699",
            "title": "Privacy-Preserving Sampling: A Minimax-Optimal Solution for Your Data!",
            "institute": "Korea Advanced Institute of Science and Technology, McMaster University",
            "text": "This research defines the optimal privacy-utility trade-off for private sampling under local differential privacy (LDP) in a minimax sense, using f-divergence as the utility measure. It differs from previous work by characterizing the exact trade-off without relying on an arbitrarily chosen reference distribution.",
            "paper-title": "Exactly Minimax-Optimal Locally Differentially Private Sampling",
            "image-path": "flux_paper_image/2410.22699_1730404929.png"
        },

        {
            "startTime": "31:07",
            "arxivId": "2410.23208",
            "arxivLink": "https://arxiv.org/abs/2410.23208",
            "title": "Kinetix: Training a General Agent to Play Physics-Based Games!",
            "institute": "University of Oxford",
            "text": "This research introduces Kinetix, a framework for training general RL agents on a vast, open-ended space of 2D physics-based environments. Unlike previous work that focuses on specific tasks, Kinetix allows for the generation of a diverse range of tasks, including robotic locomotion, grasping, and classic RL environments.",
            "paper-title": "Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks",
            "image-path": "flux_paper_image/2410.23208_1730403501.png"
        },

        {
            "startTime": "31:24",
            "arxivId": "2410.23280",
            "arxivLink": "https://arxiv.org/abs/2410.23280",
            "title": "Generating Images That Actually \"Get\" the Relationship",
            "institute": "Peking University, UC Merced, National University of Singapore...",
            "text": "This research focuses on generating images that not only include specific objects but also accurately depict the relationships between them, a challenge that previous methods often overlooked.",
            "paper-title": "RelationBooth: Towards Relation-Aware Customized Object Generation",
            "image-path": "flux_paper_image/2410.23280_1730402407.png"
        },

        {
            "startTime": "31:50",
            "arxivId": "2410.23087",
            "arxivLink": "https://arxiv.org/abs/2410.23087",
            "title": "Density Estimation: A Trade-Off Between Samples and Time",
            "institute": "MIT, Columbia University, University of Wisconsin-Madison",
            "text": "This paper presents a lower bound for the density estimation problem, showing that algorithms using sublinear samples must have a query time close to linear in the number of distributions. This is a novel statistical-computational trade-off, demonstrating that any data structure must use close to a linear number of samples or take close to linear query time.",
            "paper-title": "Statistical-Computational Trade-offs for Density Estimation",
            "image-path": "flux_paper_image/2410.23087_1730402395.png"
        },

        {
            "startTime": "32:16",
            "arxivId": "2410.22749",
            "arxivLink": "https://arxiv.org/abs/2410.22749",
            "title": "Can Simple Learners Conquer Complex Classifications?",
            "institute": "University of Southern California, Aarhus University, Yale University",
            "text": "This research explores the effectiveness of simple aggregations of proper learners in multiclass classification, a task that has traditionally been more challenging than binary classification. Unlike previous work that focused on specific algorithms, this paper investigates the generalizability of these approaches and provides both upper and lower bounds on their performance.",
            "paper-title": "Understanding Aggregations of Proper Learners in Multiclass Classification",
            "image-path": "flux_paper_image/2410.22749_1730403983.png"
        },

        {
            "startTime": "32:38",
            "arxivId": "2410.22368",
            "arxivLink": "https://arxiv.org/abs/2410.22368",
            "title": "LLM IQ Test: A One-Number Score for Your AI's Smarts",
            "institute": "Google Research, UC Berkeley, KAIST...",
            "text": "This research proposes a new method to aggregate performance across various LLM benchmarks, creating a single \"Goodness\" score and a \"Performance\" score, unlike previous Elo-based systems.",
            "paper-title": "Project MPG: towards a generalized performance benchmark for LLM capabilities",
            "image-path": "flux_paper_image/2410.22368_1730403223.png"
        },

        {
            "startTime": "32:59",
            "arxivId": "2410.23105",
            "arxivLink": "https://arxiv.org/abs/2410.23105",
            "title": "Fire Patterns: From Fuzzy to Fancy with AI!",
            "institute": "CMU",
            "text": "This research introduces a framework for quantitative fire pattern classification using aspect ratios and spatial relationships, moving beyond subjective visual assessments.",
            "paper-title": "Automated Image-Based Identification and Consistent Classification of Fire Patterns with Quantitative Shape Analysis and Spatial Location Identification",
            "image-path": "flux_paper_image/2410.23105_1730404694.png"
        },

        {
            "startTime": "33:23",
            "arxivId": "2410.22707",
            "arxivLink": "https://arxiv.org/abs/2410.22707",
            "title": "Robots Learn to See Like Humans: Language Makes State Recognition a Breeze!",
            "institute": "University of Tokyo",
            "text": "This research proposes a novel approach to robotic state recognition that leverages pre-trained vision-language models (VLMs) and black-box optimization. Unlike previous methods that rely on manual annotations, training neural networks, or specialized sensors, this method utilizes language prompts to recognize states, simplifying the process and enabling recognition of complex states.",
            "paper-title": "Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization",
            "image-path": "flux_paper_image/2410.22707_1730404895.png"
        },

        {
            "startTime": "33:42",
            "arxivId": "2410.22422",
            "arxivLink": "https://arxiv.org/abs/2410.22422",
            "title": "Say Goodbye to Holes: New Gradient Distance Function Makes 3D Surfaces Smooth and Easy to Learn",
            "institute": "EPFL",
            "text": "This research introduces a new representation for 3D surfaces called Gradient Distance Functions (GDFs). Unlike traditional Unsigned Distance Functions (UDFs), GDFs are differentiable at the surface, making them easier to learn for deep networks. This addresses the issue of holes and non-smooth surfaces often encountered with UDFs.",
            "paper-title": "Gradient Distance Function",
            "image-path": "flux_paper_image/2410.22422_1730402324.png"
        },

        {
            "startTime": "34:03",
            "arxivId": "2410.22626",
            "arxivLink": "https://arxiv.org/abs/2410.22626",
            "title": "Scene Understanding: It's Not Just What You See, It's How It's Arranged!",
            "institute": "Carnegie Mellon University, Honda Research Institute",
            "text": "This research proposes a novel approach to scene understanding by combining scene graphs and knowledge graphs. Unlike previous methods that rely solely on image features or symbolic reasoning, this approach leverages both spatial information and domain knowledge to infer compound concepts.",
            "paper-title": "Symbolic Graph Inference for Compound Scene Understanding",
            "image-path": "flux_paper_image/2410.22626_1730403360.png"
        },

        {
            "startTime": "34:22",
            "arxivId": "2410.22812",
            "arxivLink": "https://arxiv.org/abs/2410.22812",
            "title": "Model Collapse: Augment Your Way Out of a Data Disaster!",
            "institute": "Stanford University",
            "text": "This research provides a universal theoretical framework for understanding the effects of iterative model training with synthetic data. It goes beyond previous work by demonstrating that the \"augment\" workflow, where real data is continuously used alongside synthetic data, consistently avoids model collapse across a wide range of statistical models.",
            "paper-title": "Universality of the $\\pi^2/6$ Pathway in Avoiding Model Collapse",
            "image-path": "flux_paper_image/2410.22812_1730402954.png"
        },

        {
            "startTime": "34:43",
            "arxivId": "2410.22489",
            "arxivLink": "https://arxiv.org/abs/2410.22489",
            "title": "Point Clouds Need a Chat: Multimodal 3D Segmentation Gets a Language Boost",
            "institute": "University of Copenhagen, ETH Zurich, Nankai University...",
            "text": "This research introduces a novel approach to few-shot 3D point cloud segmentation by incorporating textual labels and simulated 2D image features. Unlike previous methods that solely rely on point cloud data, this work leverages multimodal information to improve generalization to unseen categories.",
            "paper-title": "Multimodality Helps Few-Shot 3D Point Cloud Semantic Segmentation",
            "image-path": "flux_paper_image/2410.22489_1730404901.png"
        },

        {
            "startTime": "35:14",
            "arxivId": "2410.23039",
            "arxivLink": "https://arxiv.org/abs/2410.23039",
            "title": "Grasping the Future: AI Learns to See Beyond the Surface for Dexterous Grasping",
            "institute": "Peking University, Stanford University",
            "text": "This research introduces the \"neural attention field,\" a new approach to representing semantic features in 3D scenes. Unlike previous methods that rely on individual point features, this method models the relevance between points, allowing for a more nuanced understanding of hand-object interactions.",
            "paper-title": "Neural Attention Field: Emerging Point Relevance in 3D Scenes for One-Shot Dexterous Grasping",
            "image-path": "flux_paper_image/2410.23039_1730402660.png"
        },

        {
            "startTime": "35:36",
            "arxivId": "2410.23242",
            "arxivLink": "https://arxiv.org/abs/2410.23242",
            "title": "LLMs: Can They Pass a Virtual Puppy Test?",
            "institute": "University of Cambridge",
            "text": "This research evaluates the physical common-sense reasoning of LLMs by placing them in a 3D virtual environment, rather than relying on static benchmarks.",
            "paper-title": "A little less conversation, a little more action, please: Investigating the physical common-sense of LLMs in a 3D embodied environment",
            "image-path": "flux_paper_image/2410.23242_1730403156.png"
        },

        {
            "startTime": "35:54",
            "arxivId": "2410.23155",
            "arxivLink": "https://arxiv.org/abs/2410.23155",
            "title": "Causal Discovery Gets a Speed Boost: QWO Makes It Faster Than Ever!",
            "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
            "text": "This paper introduces QW-Orthogonality (QWO), a new method for computing the causal graph G\u03c0 in Linear Gaussian Acyclic Models (LiGAMs). QWO significantly improves the computational efficiency of existing methods by reducing the time complexity from O(n^5) to O(n^3) for initial computation and from O(n^4d) to O(n^2d) for updates, where n is the number of variables and d is the length of the updated block of the permutation.",
            "paper-title": "QWO: Speeding Up Permutation-Based Causal Discovery in LiGAMs",
            "image-path": "flux_paper_image/2410.23155_1730403334.png"
        },

        {
            "startTime": "36:14",
            "arxivId": "2410.22341",
            "arxivLink": "https://arxiv.org/abs/2410.22341",
            "title": "Bird Brains, Robot Swarms, and the Overton Window: A New Energy for Consensus Dynamics",
            "institute": "Princeton University",
            "text": "This paper introduces new bounds on the s-energy, a tool used to analyze the convergence rates of time-varying averaging systems. The new bounds highlight the dependency of the s-energy on the connectivity of the underlying networks, which helps explain the exponential gap in convergence rates between stationary and time-varying consensus systems.",
            "paper-title": "The $s$-Energy and Its Applications",
            "image-path": "flux_paper_image/2410.22341_1730404033.png"
        },

        {
            "startTime": "36:34",
            "arxivId": "2410.23072",
            "arxivLink": "https://arxiv.org/abs/2410.23072",
            "title": "CNNs Need a Decoder Ring: New Method Makes Deep Learning More Transparent",
            "institute": "\u00c9cole Normale Sup\u00e9rieure, French Institute for Research in Computer Science and Automation",
            "text": "This research introduces a new method called Tucker Saliency Maps (TSM) for explaining CNN decisions. Unlike previous methods that rely on ground truth labels, TSM uses Tucker tensor decomposition to analyze feature maps, providing a label-independent approach.",
            "paper-title": "CNN Explainability with Multivector Tucker Saliency Maps for Self-Supervised Models",
            "image-path": "flux_paper_image/2410.23072_1730404646.png"
        },

        {
            "startTime": "37:10",
            "arxivId": "2410.22870",
            "arxivLink": "https://arxiv.org/abs/2410.22870",
            "title": "Quantum Annealing: A Faster Way to Simulate Particle Showers?",
            "institute": "TRIUMF, Perimeter Institute for Theoretical Physics, University of British Columbia...",
            "text": "This research proposes a conditioned quantum-assisted deep generative model for simulating particle-calorimeter interactions. The model integrates a conditioned variational autoencoder (VAE) with a conditioned Restricted Boltzmann Machine (RBM) in the latent space, enabling the use of qubits and couplers on D-Wave's quantum annealer for sampling. The paper introduces a novel method for conditioning the quantum-assisted RBM using flux biases and proposes a novel adaptive mapping to estimate the effective inverse temperature in quantum annealers.",
            "paper-title": "Conditioned quantum-assisted deep generative surrogate for particle-calorimeter interactions",
            "image-path": "flux_paper_image/2410.22870_1730404626.png"
        },

        {
            "startTime": "37:34",
            "arxivId": "2410.23152",
            "arxivLink": "https://arxiv.org/abs/2410.23152",
            "title": "Quantum States: Neural Networks Get a Correlation Checkup!",
            "institute": "University of Illinois Urbana-Champaign, National Taiwan University, California Institute of Technology...",
            "text": "This research explores the role of conditional correlations in the measurement distribution of quantum states, which are crucial for understanding the efficiency of neural network representations of these states. This approach differs from previous work that focused on entanglement entropy or other properties.",
            "paper-title": "When can classical neural networks represent quantum states?",
            "image-path": "flux_paper_image/2410.23152_1730403390.png"
        },

        {
            "startTime": "38:03",
            "arxivId": "2410.22554",
            "arxivLink": "https://arxiv.org/abs/2410.22554",
            "title": "Weed-Whackin' Robots: AI Helps Farmers Target Ryegrass with Precision",
            "institute": "Microsoft, Interlake High School",
            "text": "This research explores the use of both drone and satellite imagery for weed detection and control, focusing on the development of a novel weed segmentation model that can accurately identify ryegrass in winter wheat fields. The study distinguishes itself by comparing the effectiveness of different model architectures and loss functions for drone-based weed detection, ultimately achieving a high level of accuracy while minimizing overspray.",
            "paper-title": "Remote Sensing for Weed Detection and Control",
            "image-path": "flux_paper_image/2410.22554_1730403589.png"
        },

        {
            "startTime": "38:24",
            "arxivId": "2410.23118",
            "arxivLink": "https://arxiv.org/abs/2410.23118",
            "title": "Tricking Language Models: A Tiny Adversarial Training Set Makes a Big Difference",
            "institute": "The University of Texas at Austin",
            "text": "This research focuses on improving the performance of language models on adversarial test sets, which are specifically designed to expose model weaknesses. Unlike previous work that focused on paraphrasing or concatenating inputs, this study manually creates adversarial examples by modifying existing sentences in a way that keeps the label constant but makes the task more challenging for the model.",
            "paper-title": "Teaching a Language Model to Distinguish Between Similar Details using a Small Adversarial Training Set",
            "image-path": "flux_paper_image/2410.23118_1730404039.png"
        },

        {
            "startTime": "38:47",
            "arxivId": "2410.23238",
            "arxivLink": "https://arxiv.org/abs/2410.23238",
            "title": "Earthquake Source Inversions: When Gaussian Noise Just Doesn't Cut It!",
            "institute": "University College London, University of Geneva, Royal Holloway University of London",
            "text": "This research introduces a novel framework for full-waveform seismic source inversion using simulation-based inference (SBI). Unlike traditional probabilistic approaches that rely on simplifying assumptions about data errors, SBI uses machine learning to build an empirical probabilistic model of the data errors.",
            "paper-title": "Full-waveform earthquake source inversion using simulation-based inference",
            "image-path": "flux_paper_image/2410.23238_1730404087.png"
        },

        {
            "startTime": "39:16",
            "arxivId": "2410.22906",
            "arxivLink": "https://arxiv.org/abs/2410.22906",
            "title": "From Baby Babble to Big Words: Training Language Models on Phonemes",
            "institute": "University of Cambridge, University of G\u00f6ttingen",
            "text": "This research explores the impact of training language models on continuous streams of phonemes, rather than the standard orthographic text. It systematically compares three key transformations: character tokenization, word boundary removal, and phonemic transcription, evaluating their effects on various benchmarks.",
            "paper-title": "From Babble to Words: Pre-Training Language Models on Continuous Streams of Phonemes",
            "image-path": "flux_paper_image/2410.22906_1730402748.png"
        }
    ],
    "stats": {
        "num_pick": 96,
        "num_total": 337,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202410311329_audio.mp3"
}

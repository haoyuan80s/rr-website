
daily_data = {
    "date": "2024-10-28",
    "tweets": [
        
        {
            "startTime": "01:15",
            "arxivId": "2410.19324",
            "arxivLink": "https://arxiv.org/abs/2410.19324",
            "title": "Pixel-Perfect Images: Simple Diffusion Makes Latent Models Sweat!",
            "institute": "Google",
            "text": "This paper challenges the notion that latent diffusion models are superior to pixel-space models for high-resolution image generation. It presents a simpler recipe for scaling end-to-end pixel-space diffusion models to high resolutions, achieving competitive results with latent approaches.",
            "paper-title": "Simpler Diffusion (SiD2): 1.5 FID on ImageNet512 with pixel-space diffusion",
            "image-path": "flux_paper_image/2410.19324_1730142577.png"
        },

        {
            "startTime": "01:36",
            "arxivId": "2410.19313",
            "arxivLink": "https://arxiv.org/abs/2410.19313",
            "title": "FP8 Training: Optimizing Memory, Not Just Speed!",
            "institute": "University of California Berkeley, NVIDIA, MIT...",
            "text": "This paper introduces COAT, a novel FP8 training framework that goes beyond just speeding up matrix multiplications. It also compresses optimizer states and activations into FP8, significantly reducing memory footprint. Unlike previous work, COAT tackles the memory consumption of activations and second-order momentum, which are often left in higher precision.",
            "paper-title": "COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training",
            "image-path": "flux_paper_image/2410.19313_1730142662.png"
        },

        {
            "startTime": "01:56",
            "arxivId": "2410.19092",
            "arxivLink": "https://arxiv.org/abs/2410.19092",
            "title": "Deep Learning's Overfitting: Not So Bad After All!",
            "institute": "Technion, The University of Chicago, Weizmann Institute of Science...",
            "text": "This research explores the overfitting behavior of deep neural networks with binary weights, focusing on both minimal and random interpolating networks. Unlike previous work, it analyzes the overfitting behavior in deep networks without requiring very high or very low input dimensions.",
            "paper-title": "Provable Tempered Overfitting of Minimal Nets and Typical Nets",
            "image-path": "flux_paper_image/2410.19092_1730141767.png"
        },

        {
            "startTime": "02:20",
            "arxivId": "2410.19055",
            "arxivLink": "https://arxiv.org/abs/2410.19055",
            "title": "Neural Networks: Stop Losing Your Cool, Use Newton Losses!",
            "institute": "Stanford University, University of T\u00fcbingen",
            "text": "This research introduces Newton Losses, a method that improves the performance of hard-to-optimize loss functions by incorporating second-order information. Unlike previous work that applies second-order optimization to the entire neural network, Newton Losses focuses on the loss function itself, making it computationally efficient.",
            "paper-title": "Newton Losses: Using Curvature Information for Learning with Differentiable Algorithms",
            "image-path": "flux_paper_image/2410.19055_1730141984.png"
        },

        {
            "startTime": "02:38",
            "arxivId": "2410.19406",
            "arxivLink": "https://arxiv.org/abs/2410.19406",
            "title": "AI's Got a New Watchdog: Auditing Language Models for Behavioral Shifts",
            "institute": "University College London",
            "text": "This research introduces a new method for continuously monitoring language models for behavioral changes, using a customizable tolerance parameter to detect even subtle shifts. Unlike previous work, this approach focuses on detecting changes in the distribution of behaviors rather than just comparing mean values.",
            "paper-title": "An Auditing Test To Detect Behavioral Shift in Language Models",
            "image-path": "flux_paper_image/2410.19406_1730141667.png"
        },

        {
            "startTime": "02:58",
            "arxivId": "2410.19314",
            "arxivLink": "https://arxiv.org/abs/2410.19314",
            "title": "AI Assistants: Are They Gender Biased? A New Study Says Yes!",
            "institute": "Technical University of Munich, Helmholtz Munich, MCML...",
            "text": "This research focuses on evaluating and mitigating gender bias in vision-language assistants (VLAs), a relatively new area of study compared to the extensive research on bias in LLMs. The paper goes beyond simply identifying bias and explores various debiasing techniques, comparing their effectiveness in reducing bias while maintaining performance on downstream tasks.",
            "paper-title": "Revealing and Reducing Gender Biases in Vision and Language Assistants (VLAs)",
            "image-path": "flux_paper_image/2410.19314_1730142514.png"
        },

        {
            "startTime": "03:28",
            "arxivId": "2410.19644",
            "arxivLink": "https://arxiv.org/abs/2410.19644",
            "title": "Newton's Got Momentum: A Second-Order Method That Loves Small Batches!",
            "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
            "text": "This paper introduces a new version of momentum for stochastic second-order optimization methods, specifically the Cubic Newton method. Unlike previous work, this method can converge to a second-order stationary point for non-convex functions even when using only a single data sample per iteration.",
            "paper-title": "Improving Stochastic Cubic Newton with Momentum",
            "image-path": "flux_paper_image/2410.19644_1730141865.png"
        },

        {
            "startTime": "03:53",
            "arxivId": "2410.19247",
            "arxivLink": "https://arxiv.org/abs/2410.19247",
            "title": "Robots Learn to Hang Clothes Like a Pro: New AI Can Handle Deformable Objects!",
            "institute": "CMU",
            "text": "This research extends the concept of \"relative placement\" to deformable objects, using a dense diffusion model to predict how each point on a deformable object should move to achieve a desired configuration. This is different from previous work that focused on rigid objects and their transformations.",
            "paper-title": "Non-rigid Relative Placement through 3D Dense Diffusion",
            "image-path": "flux_paper_image/2410.19247_1730141830.png"
        },

        {
            "startTime": "04:20",
            "arxivId": "2410.19453",
            "arxivLink": "https://arxiv.org/abs/2410.19453",
            "title": "LLMs: From English-Centric to Multilingual Masters with a Shift-Based Trick!",
            "institute": "Tsinghua University",
            "text": "This research proposes a novel Shift-based Contrastive framework (ShifCon) to enhance the performance of non-dominant languages in LLMs. Unlike previous work that focuses on aligning representations across languages, ShifCon specifically targets the internal forward process of the model, shifting representations of non-dominant languages into the dominant language subspace to access richer information.",
            "paper-title": "ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework",
            "image-path": "flux_paper_image/2410.19453_1730141650.png"
        },

        {
            "startTime": "04:43",
            "arxivId": "2410.19115",
            "arxivLink": "https://arxiv.org/abs/2410.19115",
            "title": "MoGe: Unlocking 3D Geometry from a Single Image, No Scale Needed!",
            "institute": "Microsoft",
            "text": "This research introduces a new method for monocular geometry estimation that uses affine-invariant point maps, which are agnostic to global scale and shift. This differs from previous methods that rely on scale-invariant point maps, which can be affected by focal-distance ambiguity.",
            "paper-title": "MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision",
            "image-path": "flux_paper_image/2410.19115_1730142199.png"
        },

        {
            "startTime": "05:07",
            "arxivId": "2410.19378",
            "arxivLink": "https://arxiv.org/abs/2410.19378",
            "title": "Missing Data? No Problem! New AI Model Synthesizes Images From Incomplete Sets",
            "institute": "Harvard Medical School, Brigham and Women's Hospital, Massachusetts Institute of Technology",
            "text": "This research proposes a novel approach called MMHVAE, a hierarchical multimodal variational auto-encoder, that can synthesize missing images from observed images in different modalities. Unlike previous methods that require complete data for training, MMHVAE can handle incomplete datasets, making it more practical for real-world applications.",
            "paper-title": "Unified Cross-Modal Image Synthesis with Hierarchical Mixture of Product-of-Experts",
            "image-path": "flux_paper_image/2410.19378_1730142590.png"
        },

        {
            "startTime": "05:39",
            "arxivId": "2410.19702",
            "arxivLink": "https://arxiv.org/abs/2410.19702",
            "title": "Long Videos? No Problem! MLLMs Get Grounded for Better Understanding",
            "institute": "Nanjing University, Shanghai AI Laboratory, SIAT Chinese Academy of Sciences...",
            "text": "This research proposes TimeSuite, a collection of techniques to improve the performance of Multimodal Large Language Models (MLLMs) on long videos. Unlike previous work that focused on architecture design, TimeSuite introduces a new instruction tuning task called Temporal Grounded Caption, which explicitly incorporates grounding supervision into the traditional question-answering format. This helps the MLLM learn to correctly attend to relevant visual segments when generating answers, reducing the risk of hallucinations.",
            "paper-title": "TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning",
            "image-path": "flux_paper_image/2410.19702_1730142569.png"
        },

        {
            "startTime": "06:06",
            "arxivId": "2410.19198",
            "arxivLink": "https://arxiv.org/abs/2410.19198",
            "title": "AI's New Palette: Mixing Human Values Without Compromise",
            "institute": "University of Minnesota, IBM",
            "text": "This research introduces a novel approach called Multi-Human-Value Alignment Palette (MAP) that allows for the simultaneous alignment of multiple human values in generative AI systems. Unlike previous methods that rely on linear combinations of reward functions, MAP uses a structured approach with user-defined constraints to achieve a more precise and reliable alignment.",
            "paper-title": "MAP: Multi-Human-Value Alignment Palette",
            "image-path": "flux_paper_image/2410.19198_1730142672.png"
        },

        {
            "startTime": "06:36",
            "arxivId": "2410.19323",
            "arxivLink": "https://arxiv.org/abs/2410.19323",
            "title": "Earthquake Location Gets a Neural Network Makeover!",
            "institute": "Stanford University",
            "text": "This research introduces a Graph Neural Network (GNN) approach to earthquake double-difference relocation, called GraphDD. Unlike traditional methods that relocate events individually, GraphDD minimizes the double-difference residuals over an entire catalog simultaneously.",
            "paper-title": "Double Difference Earthquake Location with Graph Neural Networks",
            "image-path": "flux_paper_image/2410.19323_1730141811.png"
        },

        {
            "startTime": "06:57",
            "arxivId": "2410.19419",
            "arxivLink": "https://arxiv.org/abs/2410.19419",
            "title": "KAHANI: Telling Stories That Don't Just Talk About India, They Show It!",
            "institute": "Microsoft",
            "text": "This research focuses on developing a visual storytelling pipeline called KAHANI that generates culturally grounded visual stories for non-Western cultures. Unlike previous work that often reinforces cultural biases and stereotypes, KAHANI leverages Chain of Thought (CoT) and T2I prompting techniques to capture cultural context from user prompts and generate vivid descriptions of characters and scene compositions.",
            "paper-title": "KAHANI: Culturally-Nuanced Visual Storytelling Pipeline for Non-Western Cultures",
            "image-path": "flux_paper_image/2410.19419_1730142074.png"
        },

        {
            "startTime": "07:26",
            "arxivId": "2410.19697",
            "arxivLink": "https://arxiv.org/abs/2410.19697",
            "title": "Robots with Common Sense: Navigating to Objects Like a Human!",
            "institute": "ETH Zurich, Google",
            "text": "This research introduces a novel approach to object goal navigation by incorporating common sense reasoning from a large language model (LLM) into the planning process. This differs from previous work that primarily relied on semantic mapping and exploration algorithms.",
            "paper-title": "IPPON: Common Sense Guided Informative Path Planning for Object Goal Navigation",
            "image-path": "flux_paper_image/2410.19697_1730142858.png"
        },

        {
            "startTime": "07:43",
            "arxivId": "2410.19288",
            "arxivLink": "https://arxiv.org/abs/2410.19288",
            "title": "Super-Resolution MRSI: Diffusion Models Get a Speed Boost!",
            "institute": "Yale University, Xi\u2019an Jiaotong University, Medical University of Vienna",
            "text": "This research introduces a Flow-based Truncated Denoising Diffusion Model (FTDDM) for super-resolution Magnetic Resonance Spectroscopic Imaging (MRSI). Unlike previous diffusion models, FTDDM shortens the diffusion process by truncating the diffusion chain and estimating the truncated steps using a normalizing flow-based network.",
            "paper-title": "A Flow-based Truncated Denoising Diffusion Model for super-resolution Magnetic Resonance Spectroscopic Imaging",
            "image-path": "flux_paper_image/2410.19288_1730142818.png"
        },

        {
            "startTime": "08:05",
            "arxivId": "2410.19730",
            "arxivLink": "https://arxiv.org/abs/2410.19730",
            "title": "LLMs Can't Count? Tokenization is the Real Villain!",
            "institute": "University of Alberta, University of British Columbia, Yale University",
            "text": "This research focuses on the impact of tokenization on the counting abilities of large language models (LLMs), specifically highlighting how byte-pair encoding (BPE) can hinder their performance. Unlike previous studies that focused on the limitations of Transformer architectures, this paper investigates the role of tokenization in bridging the gap between theoretical and practical counting abilities.",
            "paper-title": "Counting Ability of Large Language Models and Impact of Tokenization",
            "image-path": "flux_paper_image/2410.19730_1730142396.png"
        },

        {
            "startTime": "08:30",
            "arxivId": "2410.19179",
            "arxivLink": "https://arxiv.org/abs/2410.19179",
            "title": "Predicting Power Grid Meltdowns: A Causal Approach to Cascading Failures",
            "institute": "Rensselaer Polytechnic Institute, IBM",
            "text": "This research uses causal inference to model cascading failures in power transmission networks, going beyond traditional topology-based approaches and scenario-based simulations. It learns cause-effect relationships among transmission lines, enabling more accurate predictions even in previously unseen scenarios.",
            "paper-title": "Cascading Failure Prediction via Causal Inference",
            "image-path": "flux_paper_image/2410.19179_1730142365.png"
        },

        {
            "startTime": "08:58",
            "arxivId": "2410.19274",
            "arxivLink": "https://arxiv.org/abs/2410.19274",
            "title": "LLMs on Smartphones? No Problem! Ripple Makes It Happen!",
            "institute": "Tsinghua University",
            "text": "This research proposes Ripple, a novel approach that optimizes neuron placement in flash memory to accelerate LLM inference on smartphones. Unlike previous works that focus on computation efficiency or memory management, Ripple directly addresses the I/O bottleneck by maximizing bandwidth utilization.",
            "paper-title": "Ripple: Accelerating LLM Inference on Smartphones with Correlation-Aware Neuron Management",
            "image-path": "flux_paper_image/2410.19274_1730142002.png"
        },

        {
            "startTime": "09:18",
            "arxivId": "2410.19135",
            "arxivLink": "https://arxiv.org/abs/2410.19135",
            "title": "YAML Ain't Just for Data: A New Language for Prompt Programming",
            "institute": "IBM Research, UC Davis",
            "text": "This paper introduces the Prompt Declaration Language (PDL), a declarative data-oriented language for prompt programming. Unlike other prompting frameworks that are embedded in imperative languages, PDL is based on YAML, a data serialization format that is both human-readable and provides structure.",
            "paper-title": "PDL: A Declarative Prompt Programming Language",
            "image-path": "flux_paper_image/2410.19135_1730142583.png"
        },

        {
            "startTime": "09:36",
            "arxivId": "2410.19733",
            "arxivLink": "https://arxiv.org/abs/2410.19733",
            "title": "AI Chatbots: Your New Brain Training Buddies?",
            "institute": "Microsoft, Shanghai Jiao Tong University",
            "text": "This research proposes a framework called ReMe, which uses AI chatbots to personalize cognitive training, particularly for episodic memory. Unlike previous work, ReMe leverages life logs to create tailored training tasks, making the experience more engaging and relevant for users.",
            "paper-title": "The Potential and Value of AI Chatbot in Personalized Cognitive Training",
            "image-path": "flux_paper_image/2410.19733_1730142789.png"
        },

        {
            "startTime": "09:56",
            "arxivId": "2410.19034",
            "arxivLink": "https://arxiv.org/abs/2410.19034",
            "title": "MoE Models: Memory Masters or Reasoning Misfits?",
            "institute": "Harvard University",
            "text": "This research investigates the performance trade-offs between Mixture-of-Experts (MoE) and standard dense transformers, focusing on the impact of scaling the number of experts on reasoning and memorization tasks. The study goes beyond previous work by providing theoretical analysis and empirical validation on both synthetic and real-world datasets.",
            "paper-title": "Mixture of Parrots: Experts improve memorization more than reasoning",
            "image-path": "flux_paper_image/2410.19034_1730142280.png"
        },

        {
            "startTime": "10:16",
            "arxivId": "2410.19728",
            "arxivLink": "https://arxiv.org/abs/2410.19728",
            "title": "Calabi-Yau Metrics: Machine Learning Makes String Theory Less Stringy!",
            "institute": "University of New Hampshire, University of Lisbon, University of Cambridge...",
            "text": "This research introduces a new Python library called \"cymyc\" that uses machine learning to approximate tensor fields on Calabi-Yau manifolds. This approach differs from previous methods that relied on algebraic ansatzes or numerical solutions of partial differential equations.",
            "paper-title": "cymyc -- Calabi-Yau Metrics, Yukawas, and Curvature",
            "image-path": "flux_paper_image/2410.19728_1730142596.png"
        },

        {
            "startTime": "10:40",
            "arxivId": "2410.19665",
            "arxivLink": "https://arxiv.org/abs/2410.19665",
            "title": "Metaverse Driving: Trading Models for a Smoother Ride!",
            "institute": "Education University of Hong Kong, Singapore University of Technology and Design, Guangdong University of Technology...",
            "text": "This research proposes a novel immersion-aware model trading framework for vehicular metaverse services, integrating federated learning (FL) to incentivize users to contribute learning models trained on their local data. This approach differs from previous work by focusing on the specific needs of immersive AR services in the vehicular metaverse, considering the freshness and accuracy of models, and addressing the challenges of privacy and resource constraints.",
            "paper-title": "MetaTrading: An Immersion-Aware Model Trading Framework for Vehicular Metaverse Services",
            "image-path": "flux_paper_image/2410.19665_1730142954.png"
        },

        {
            "startTime": "11:04",
            "arxivId": "2410.19704",
            "arxivLink": "https://arxiv.org/abs/2410.19704",
            "title": "Molecules on Multi-View: A Foundation Model for Drug Discovery",
            "institute": "IBM",
            "text": "This research introduces a multi-view foundation model, MMELON, that integrates molecular representations from graph, image, and text modalities. Unlike previous work that focused on single representations, MMELON combines these views to create a more comprehensive understanding of molecules.",
            "paper-title": "Multi-view biomedical foundation models for molecule-target and property prediction",
            "image-path": "flux_paper_image/2410.19704_1730142347.png"
        },

        {
            "startTime": "11:26",
            "arxivId": "2410.19482",
            "arxivLink": "https://arxiv.org/abs/2410.19482",
            "title": "LLMs: Memorizing More Than We Thought? Probabilistic Extraction Reveals the Truth!",
            "institute": "Google",
            "text": "This research introduces a probabilistic approach to measuring memorization in LLMs, going beyond the traditional single-sequence greedy sampling method. This new approach considers various sampling schemes and multiple attempts, providing a more comprehensive and realistic assessment of memorization rates.",
            "paper-title": "Measuring memorization through probabilistic discoverable extraction",
            "image-path": "flux_paper_image/2410.19482_1730142634.png"
        },

        {
            "startTime": "11:44",
            "arxivId": "2410.19258",
            "arxivLink": "https://arxiv.org/abs/2410.19258",
            "title": "Not All Heads Are Created Equal: A Head-Level KV Cache Compression Method for LLMs",
            "institute": "UC Riverside, Microsoft",
            "text": "This research proposes a head-level KV cache compression method that allocates cache budgets based on the importance of individual attention heads, rather than relying on layer-level allocation strategies.",
            "paper-title": "Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning",
            "image-path": "flux_paper_image/2410.19258_1730142290.png"
        },

        {
            "startTime": "12:09",
            "arxivId": "2410.19434",
            "arxivLink": "https://arxiv.org/abs/2410.19434",
            "title": "Reinforcement Learning: When Optimism Wins the Race!",
            "institute": "\u00c9cole Normale Sup\u00e9rieure, Universit\u00e9 de Recherche Paris Science et Lettres, Institut National de la Sant\u00e9 et de la Recherche M\u00e9dicale",
            "text": "This study compares two computational processes, positivity bias and gradual perseveration, to understand their adaptive value in reinforcement learning. Unlike previous work, it uses an evolutionary algorithm to simulate agents in various bandit tasks, exploring a wider range of task contingencies and feedback regimes.",
            "paper-title": "Evolving choice hysteresis in reinforcement learning: comparing the adaptive value of positivity bias and gradual perseveration",
            "image-path": "flux_paper_image/2410.19434_1730141939.png"
        },

        {
            "startTime": "12:32",
            "arxivId": "2410.19657",
            "arxivLink": "https://arxiv.org/abs/2410.19657",
            "title": "DiffGS: Splatting 3D Shapes with a Diffusion Model's Magic Touch",
            "institute": "Tsinghua University",
            "text": "This paper proposes DiffGS, a generative model for 3D Gaussian Splatting, which uses a latent diffusion model to generate Gaussian primitives at arbitrary numbers. Unlike previous methods that rely on voxelization, DiffGS directly represents 3DGS with continuous functions, avoiding information loss and enabling more flexible generation.",
            "paper-title": "DiffGS: Functional Gaussian Splatting Diffusion",
            "image-path": "flux_paper_image/2410.19657_1730141871.png"
        },

        {
            "startTime": "12:48",
            "arxivId": "2410.19315",
            "arxivLink": "https://arxiv.org/abs/2410.19315",
            "title": "Spiking Neurons, Bayesian Brains: A New Recipe for AI",
            "institute": "UC Berkeley",
            "text": "This research introduces a new type of neural network called the iterative Poisson VAE (iP-VAE) that uses Poisson distributions instead of Gaussian distributions to model neuron activity. This approach leads to a model that more closely resembles biological neurons and avoids some of the limitations of previous predictive coding models.",
            "paper-title": "A prescriptive theory for brain-like inference",
            "image-path": "flux_paper_image/2410.19315_1730141823.png"
        },

        {
            "startTime": "13:15",
            "arxivId": "2410.19222",
            "arxivLink": "https://arxiv.org/abs/2410.19222",
            "title": "Protein Language Models: GPT-3's Cousin Designs Peptides with a Purpose!",
            "institute": "CMU",
            "text": "This research introduces PeptideGPT, a protein language model fine-tuned to generate protein sequences with specific properties like hemolytic activity, solubility, and non-fouling characteristics. Unlike previous work, PeptideGPT incorporates a bioinformatic supervision pipeline to ensure the generated sequences are valid proteins with ordered structures.",
            "paper-title": "Peptide-GPT: Generative Design of Peptides using Generative Pre-trained Transformers and Bio-informatic Supervision",
            "image-path": "flux_paper_image/2410.19222_1730142204.png"
        },

        {
            "startTime": "13:37",
            "arxivId": "2410.19400",
            "arxivLink": "https://arxiv.org/abs/2410.19400",
            "title": "Offline RL's New Trick: Fixing States, Not Just Actions!",
            "institute": "Tsinghua University",
            "text": "This paper tackles a previously overlooked issue in offline reinforcement learning: the \"out-of-distribution\" state problem. Unlike prior work that focused solely on OOD actions, this research proposes a method called SCAS that simultaneously corrects OOD states and suppresses OOD actions.",
            "paper-title": "Offline Reinforcement Learning with OOD State Correction and OOD Action Suppression",
            "image-path": "flux_paper_image/2410.19400_1730142780.png"
        },

        {
            "startTime": "14:00",
            "arxivId": "2410.19290",
            "arxivLink": "https://arxiv.org/abs/2410.19290",
            "title": "Fake News, Real Knowledge: How Synthetic Data Can Make LLMs More Factual",
            "institute": "UC Santa Barbara, MIT, IBM",
            "text": "This research proposes a new fine-tuning strategy called PREREQ-TUNE that disentangles the learning of skills and knowledge in LLMs. Unlike previous work, PREREQ-TUNE introduces a prerequisite learning stage to equip the LLM with the necessary knowledge before fine-tuning for a specific task. This approach aims to reduce hallucinations by ensuring the model grounds its outputs to its internal knowledge.",
            "paper-title": "Fictitious Synthetic Data Can Improve LLM Factuality via Prerequisite Learning",
            "image-path": "flux_paper_image/2410.19290_1730142407.png"
        },

        {
            "startTime": "14:28",
            "arxivId": "2410.19446",
            "arxivLink": "https://arxiv.org/abs/2410.19446",
            "title": "Fusion-Then-Distillation: A Love Story Between 2D and 3D Semantic Segmentation",
            "institute": "Xiamen University, Tsinghua University, East China Normal University",
            "text": "This research proposes a novel \"fusion-then-distillation\" (FtD++) method for 3D semantic segmentation. Unlike previous methods that focus on mimicking cross-modal outputs, FtD++ leverages the complementary advantages of fusing 2D images and 3D point clouds to improve domain adaptation.",
            "paper-title": "Fusion-then-Distillation: Toward Cross-modal Positive Distillation for Domain Adaptive 3D Semantic Segmentation",
            "image-path": "flux_paper_image/2410.19446_1730142934.png"
        },

        {
            "startTime": "14:58",
            "arxivId": "2410.19100",
            "arxivLink": "https://arxiv.org/abs/2410.19100",
            "title": "Video-Savvy AI: Can They Learn From YouTube Tutorials?",
            "institute": "Carnegie Mellon University, Massachusetts Institute of Technology, New York University...",
            "text": "This research introduces VideoWebArena, a benchmark specifically designed to evaluate the ability of long-context multimodal agents to understand and utilize video information for completing tasks. Unlike previous benchmarks, VideoWebArena focuses on tasks that require agents to retain information from videos over extended periods, making it more relevant to real-world applications.",
            "paper-title": "VideoWebArena: Evaluating Long Context Multimodal Agents with Video Understanding Web Tasks",
            "image-path": "flux_paper_image/2410.19100_1730142519.png"
        },

        {
            "startTime": "15:26",
            "arxivId": "2410.19705",
            "arxivLink": "https://arxiv.org/abs/2410.19705",
            "title": "Thompson Sampling: Now with Added Robustness Against Poisoning Attacks!",
            "institute": "University of Illinois, Tsinghua University",
            "text": "This research introduces robust Thompson sampling algorithms for both stochastic and contextual linear bandit settings, addressing the vulnerability of traditional Thompson sampling to adversarial reward poisoning attacks. The key innovation lies in the use of optimistic posteriors and weighted estimators to mitigate the impact of corrupted rewards.",
            "paper-title": "Robust Thompson Sampling Algorithms Against Reward Poisoning Attacks",
            "image-path": "flux_paper_image/2410.19705_1730142747.png"
        },

        {
            "startTime": "15:49",
            "arxivId": "2410.19680",
            "arxivLink": "https://arxiv.org/abs/2410.19680",
            "title": "Neural Networks Learn to See Through Noise: A New Way to Reconstruct 3D Shapes from Noisy Point Clouds",
            "institute": "Tsinghua University, Wayne State University",
            "text": "This research proposes a method to infer a neural signed distance function (SDF) from a single noisy point cloud by finetuning a data-driven based prior. The key innovation lies in a novel statistical reasoning algorithm that operates on local regions of the point cloud, enabling the method to recover more accurate and sharper surface details from noisy data. This approach differs from previous methods that either rely on large-scale training datasets or struggle with slow convergence when dealing with noisy point clouds.",
            "paper-title": "Inferring Neural Signed Distance Functions by Overfitting on Single Noisy Point Clouds through Finetuning Data-Driven based Priors",
            "image-path": "flux_paper_image/2410.19680_1730142838.png"
        },

        {
            "startTime": "16:08",
            "arxivId": "2410.19283",
            "arxivLink": "https://arxiv.org/abs/2410.19283",
            "title": "\"AI Learns to See the Future: Predicting Patient Changes with a Neural Time Machine\"",
            "institute": "Stanford University, University of Michigan",
            "text": "This research proposes a novel approach called ST-NeRP, which utilizes Implicit Neural Representation (INR) to learn a spatial-temporal deformation function for patient-specific imaging studies. Unlike previous methods that focus on aligning images at two distinct time points, ST-NeRP can predict unseen images at any target time point within a sequence.",
            "paper-title": "ST-NeRP: Spatial-Temporal Neural Representation Learning with Prior Embedding for Patient-specific Imaging Study",
            "image-path": "flux_paper_image/2410.19283_1730142232.png"
        },

        {
            "startTime": "16:35",
            "arxivId": "2410.19590",
            "arxivLink": "https://arxiv.org/abs/2410.19590",
            "title": "Depth Perception: A New Trick for Monocular 3D Object Detection",
            "institute": "Tsinghua University",
            "text": "This paper introduces a new approach to monocular 3D object detection called MonoDGP. Instead of directly predicting depth, it focuses on predicting the \"depth error\" - the difference between the actual depth and the depth calculated using geometric priors. This approach simplifies the learning process and improves accuracy.",
            "paper-title": "MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors",
            "image-path": "flux_paper_image/2410.19590_1730142863.png"
        },

        {
            "startTime": "17:05",
            "arxivId": "2410.19008",
            "arxivLink": "https://arxiv.org/abs/2410.19008",
            "title": "ECG Images: AI Learns to Read the Rhythm of Your Heart!",
            "institute": "The Ohio State University, Carnegie Mellon University",
            "text": "This research introduces ECGInstruct, a large-scale instruction tuning dataset for ECG image interpretation, which is different from previous work that primarily focused on raw ECG signals.",
            "paper-title": "Teach Multimodal LLMs to Comprehend Electrocardiographic Images",
            "image-path": "flux_paper_image/2410.19008_1730142923.png"
        },

        {
            "startTime": "17:28",
            "arxivId": "2410.19103",
            "arxivLink": "https://arxiv.org/abs/2410.19103",
            "title": "LLMs on a Diet: Tiny Weights, Big Performance!",
            "institute": "Yale University",
            "text": "This research introduces TesseraQ, a new post-training quantization (PTQ) technique that optimizes weight rounding parameters using block reconstruction. Unlike previous methods that focus on optimizing distribution transformation or weight clipping ranges, TesseraQ directly adjusts the entire weight tensor, enabling ultra-low-bit quantization with minimal performance loss.",
            "paper-title": "TesseraQ: Ultra Low-Bit LLM Post-Training Quantization with Block Reconstruction",
            "image-path": "flux_paper_image/2410.19103_1730141907.png"
        },

        {
            "startTime": "17:57",
            "arxivId": "2410.19150",
            "arxivLink": "https://arxiv.org/abs/2410.19150",
            "title": "Wikipedia's Got Talent: Predicting Which Articles Will Stay on Top",
            "institute": "University of Michigan",
            "text": "This research introduces a novel metric called \"Sustainable Success\" to assess the long-term quality of online collaborations. Unlike previous work that focuses on success at a single point in time, this study examines the factors that contribute to the sustained success of collaborative efforts over time.",
            "paper-title": "A Test of Time: Predicting the Sustainable Success of Online Collaboration in Wikipedia",
            "image-path": "flux_paper_image/2410.19150_1730141912.png"
        },

        {
            "startTime": "18:28",
            "arxivId": "2410.19560",
            "arxivLink": "https://arxiv.org/abs/2410.19560",
            "title": "JEPA Gets a Boost: VICReg to the Rescue!",
            "institute": "CMU, NYU",
            "text": "This research introduces C-JEPA, a new framework that combines the Joint-Embedding Predictive Architecture (JEPA) with Variance-Invariance-Covariance Regularization (VICReg). This integration aims to address limitations in the original I-JEPA model, particularly its tendency to collapse and its inability to accurately learn the mean of patch representations.",
            "paper-title": "Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning",
            "image-path": "flux_paper_image/2410.19560_1730142907.png"
        },

        {
            "startTime": "18:55",
            "arxivId": "2410.18987",
            "arxivLink": "https://arxiv.org/abs/2410.18987",
            "title": "Shape Shifting: A New Way to Generate 3D Objects Using Topology",
            "institute": "Helmholtz Munich, Technical University of Munich, University of Fribourg",
            "text": "This paper introduces a novel framework for shape generation tasks on point clouds by inverting the Euler Characteristic Transform (ECT), a powerful invariant for assessing geometric and topological characteristics of shapes. Unlike previous work that only focused on special cases, this research develops a deep-learning model that can learn the inversion of the ECT for general datasets.",
            "paper-title": "Generative Topology for Shape Synthesis",
            "image-path": "flux_paper_image/2410.18987_1730142164.png"
        },

        {
            "startTime": "19:17",
            "arxivId": "2410.19149",
            "arxivLink": "https://arxiv.org/abs/2410.19149",
            "title": "Diffusion Models Get a Makeover: Mixing It Up for Faster Training!",
            "institute": "UC Berkeley",
            "text": "This research proposes a new type of diffusion model that uses a mixture of Gaussian distributions as its prior, instead of a single Gaussian. This allows the model to incorporate structured information about the data, potentially leading to faster training and improved performance.",
            "paper-title": "Structured Diffusion Models with Mixture of Gaussians as Prior Distribution",
            "image-path": "flux_paper_image/2410.19149_1730141644.png"
        },

        {
            "startTime": "19:44",
            "arxivId": "2410.19235",
            "arxivLink": "https://arxiv.org/abs/2410.19235",
            "title": "Robots Learn to Grind Coffee (and More) with Diffusion Policies!",
            "institute": "OMRON SINIC X Corporation, Osaka University",
            "text": "This research introduces a new framework called DIPCOM, which uses diffusion models to learn compliant control policies for robots. Unlike previous methods that rely on variational autoencoders, DIPCOM leverages the ability of diffusion models to capture multi-modal action distributions, leading to more diverse and adaptable robot behaviors.",
            "paper-title": "Learning Diffusion Policies from Demonstrations For Compliant Contact-rich Manipulation",
            "image-path": "flux_paper_image/2410.19235_1730142463.png"
        },

        {
            "startTime": "20:16",
            "arxivId": "2410.19450",
            "arxivLink": "https://arxiv.org/abs/2410.19450",
            "title": "Offline RL for Multi-Agent Teams: Remembering the Past, Exploring the Future",
            "institute": "Tsinghua University",
            "text": "This research focuses on Offline-to-Online Multi-Agent Reinforcement Learning (O2OMARL), a setting where agents learn from past data and then fine-tune their strategies in real-time. The paper proposes a novel framework called Offline Value Function Memory with Sequential Exploration (OVMSE) to address the challenges of unlearning pre-trained knowledge and inefficient exploration in multi-agent systems.",
            "paper-title": "Offline-to-Online Multi-Agent Reinforcement Learning with Offline Value Function Memory and Sequential Exploration",
            "image-path": "flux_paper_image/2410.19450_1730141960.png"
        },

        {
            "startTime": "20:46",
            "arxivId": "2410.19493",
            "arxivLink": "https://arxiv.org/abs/2410.19493",
            "title": "Image Compression Gets a Mind of Its Own: New Model Knows When to Hallucinate!",
            "institute": "ETH Zurich",
            "text": "This research introduces a novel image compression method that dynamically adjusts the level of detail hallucination based on image content. Unlike previous methods that optimize for a fixed level of hallucination, this approach uses a classifier to predict user preferences for detail hallucination and adjusts the compression process accordingly.",
            "paper-title": "Conditional Hallucinations for Image Compression",
            "image-path": "flux_paper_image/2410.19493_1730142169.png"
        },

        {
            "startTime": "21:12",
            "arxivId": "2410.19486",
            "arxivLink": "https://arxiv.org/abs/2410.19486",
            "title": "Event Cameras Get a Grip on XR Gestures: X-RAGE Dataset Unleashes a New Era of Interaction!",
            "institute": "Meta, Indian Institute of Technology Delhi",
            "text": "This research introduces the first event-camera-based egocentric gesture dataset, X-RAGE, specifically designed for extended reality (XR) applications. Unlike previous datasets that rely on traditional frame-based cameras, X-RAGE leverages the unique capabilities of event cameras to capture high-speed motions and handle dynamic lighting conditions.",
            "paper-title": "x-RAGE: eXtended Reality -- Action&Gesture Events Dataset",
            "image-path": "flux_paper_image/2410.19486_1730142964.png"
        },

        {
            "startTime": "21:34",
            "arxivId": "2410.19238",
            "arxivLink": "https://arxiv.org/abs/2410.19238",
            "title": "AI Gets a Personality Makeover: Big Five Traits for Language Models",
            "institute": "University of Chicago",
            "text": "This research introduces a novel method for assigning quantifiable, controllable, and psychometrically validated personalities to Large Language Model-Based Agents (Agents) using the Big Five personality framework. Unlike previous approaches that relied on simple adjectives, demographic descriptions, or fine-tuning, this method leverages established psychometric tests to create Agents with more realistic and nuanced personalities.",
            "paper-title": "Designing LLM-Agents with Personalities: A Psychometric Approach",
            "image-path": "flux_paper_image/2410.19238_1730141578.png"
        },

        {
            "startTime": "21:56",
            "arxivId": "2410.19241",
            "arxivLink": "https://arxiv.org/abs/2410.19241",
            "title": "Deep Learning Predicts Exchange Rates: RMB/USD Gets a Tech Makeover",
            "institute": "Central University of Finance and Economics, New York University, Harvard University...",
            "text": "This research explores the use of advanced deep learning models, including transformer-based architectures, to predict the RMB/USD exchange rate. It differs from previous work by incorporating a comprehensive set of features and employing advanced feature selection techniques to enhance predictive accuracy and model interpretability.",
            "paper-title": "Enhancing Exchange Rate Forecasting with Explainable Deep Learning Models",
            "image-path": "flux_paper_image/2410.19241_1730142759.png"
        },

        {
            "startTime": "22:27",
            "arxivId": "2410.19631",
            "arxivLink": "https://arxiv.org/abs/2410.19631",
            "title": "Active Learning: Smartly Picking Data to Save You Time and Money!",
            "institute": "University of Toronto",
            "text": "This research introduces a new active learning strategy called \"inference set design\" that focuses on optimizing performance on a specific target set of samples, rather than just improving generalization on a held-out test set.",
            "paper-title": "Efficient Biological Data Acquisition through Inference Set Design",
            "image-path": "flux_paper_image/2410.19631_1730142833.png"
        },

        {
            "startTime": "23:02",
            "arxivId": "2410.19343",
            "arxivLink": "https://arxiv.org/abs/2410.19343",
            "title": "Seismic Waveforms: AI Makes Them Shake Like Real Earthquakes!",
            "institute": "ETH Zurich, Politecnico di Milano",
            "text": "This research uses a denoising diffusion model to generate realistic seismic waveforms, unlike previous methods that rely on empirical models or physics-based simulations.",
            "paper-title": "High Resolution Seismic Waveform Generation using Denoising Diffusion",
            "image-path": "flux_paper_image/2410.19343_1730142550.png"
        },

        {
            "startTime": "23:25",
            "arxivId": "2410.19471",
            "arxivLink": "https://arxiv.org/abs/2410.19471",
            "title": "Folding Peptides: A New Recipe for Diversity!",
            "institute": "Stanford University, NVIDIA, Technion - Israel Institute of Technology...",
            "text": "This research introduces a new method for fine-tuning inverse folding models, specifically for peptide design. It uses Direct Preference Optimization (DPO) with two key enhancements: online diversity regularization and domain-specific priors. This approach aims to improve the diversity of generated peptide sequences while maintaining their structural consistency.",
            "paper-title": "Improving Inverse Folding for Peptide Design with Diversity-regularized Direct Preference Optimization",
            "image-path": "flux_paper_image/2410.19471_1730141742.png"
        },

        {
            "startTime": "23:56",
            "arxivId": "2410.19200",
            "arxivLink": "https://arxiv.org/abs/2410.19200",
            "title": "Random Forests Get a Boost: New Weights Make Trees Smarter!",
            "institute": "MIT",
            "text": "This research introduces Enhanced Random Forests, which differ from traditional Random Forests by assigning weights to both individual samples and the trees themselves. This allows for more accurate predictions and even helps to recover some of the interpretability that is often lost in ensemble methods.",
            "paper-title": "Binary Classification: Is Boosting stronger than Bagging?",
            "image-path": "flux_paper_image/2410.19200_1730142446.png"
        },

        {
            "startTime": "24:19",
            "arxivId": "2410.19009",
            "arxivLink": "https://arxiv.org/abs/2410.19009",
            "title": "GANs Go on a Diet: Training in Dual Space for Faster, Smarter Models",
            "institute": "CMU",
            "text": "This research proposes training GANs on encoded representations of data in a \"dual space\" using invertible mappings, like autoencoders. This approach aims to reduce training complexity and resource requirements compared to traditional methods that directly learn from data distributions.",
            "paper-title": "Dual Space Training for GANs: A Pathway to Efficient and Creative Generative Models",
            "image-path": "flux_paper_image/2410.19009_1730141817.png"
        },

        {
            "startTime": "24:37",
            "arxivId": "2410.19353",
            "arxivLink": "https://arxiv.org/abs/2410.19353",
            "title": "Numbers Talking: New AI Learns to Speak Math!",
            "institute": "IBM",
            "text": "This research introduces a novel approach to embedding numbers within a transformer architecture, allowing for more expressive numerical representations and a routing layer that differentiates between text and number tokens. This differs from previous work that relied on discrete tokenization of numbers, which often led to prediction artefacts.",
            "paper-title": "Interleaving Text and Number Embeddings to Solve Mathemathics Problems",
            "image-path": "flux_paper_image/2410.19353_1730141514.png"
        },

        {
            "startTime": "25:04",
            "arxivId": "2410.19514",
            "arxivLink": "https://arxiv.org/abs/2410.19514",
            "title": "Volterra Series Get a Machine Learning Makeover: Aerodynamics Gets a Speed Boost!",
            "institute": "University of Southampton, Zurich University of Applied Sciences ZHAW, Federal Institute of Technology Zurich ETHZ",
            "text": "This research uses machine learning to interpolate Volterra kernels within a parametric space, enabling efficient modeling of unsteady transonic aerodynamics. This approach differs from previous work by leveraging machine learning for kernel reconstruction, rather than relying solely on traditional interpolation techniques.",
            "paper-title": "Parametric Nonlinear Volterra Series via Machine Learning: Transonic Aerodynamics",
            "image-path": "flux_paper_image/2410.19514_1730142246.png"
        },

        {
            "startTime": "25:35",
            "arxivId": "2410.19310",
            "arxivLink": "https://arxiv.org/abs/2410.19310",
            "title": "Flow-Matching Models Get a Speed Boost: One-Step Generation is Here!",
            "institute": "Zhejiang University, CMU, Peking University",
            "text": "This research introduces Flow Generator Matching (FGM), a method for distilling flow-matching models into one-step generators. Unlike previous work that focused on straightening trajectories, FGM directly matches the vector fields of the student and teacher models.",
            "paper-title": "Flow Generator Matching",
            "image-path": "flux_paper_image/2410.19310_1730142061.png"
        },

        {
            "startTime": "26:00",
            "arxivId": "2410.19604",
            "arxivLink": "https://arxiv.org/abs/2410.19604",
            "title": "Microplastics: AI's New Weapon Against Tiny Pollution",
            "institute": "UC Riverside, Stanford University",
            "text": "This research uses a Generative Adversarial Network (GAN) to create synthetic images of microplastics in diverse ecological contexts, supplementing real-world data for training a deep learning segmentation model. This approach addresses the lack of diverse training data for microplastic detection models.",
            "paper-title": "Microplastic Identification Using AI-Driven Image Segmentation and GAN-Generated Ecological Context",
            "image-path": "flux_paper_image/2410.19604_1730142890.png"
        }
    ],
    "stats": {
        "num_pick": 61,
        "num_total": 274,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202410281346_audio.mp3"
}


daily_data = {
    "date": "2024-08-07",
    "tweets": [
            {
                "startTime": "00:54",
                "arxivId": "2408.02948",
                "arxivLink": "https://arxiv.org/abs/2408.02948",
                "title": "Are Female Carpenters Like Blue Bananas? A Surprising Look at Gender in Language",
                "institute": "Meta",
                "text": "This research investigates the relationship between gender mentioning and occupation gender typicality, using information theoretic techniques to analyze large text corpora. Unlike previous work that focused on the \"blue banana\" hypothesis (where surprising features are more likely to be mentioned), this study finds that gender mentioning is more correlated with the salience of gender in woman-dominated occupations.",
                "paper-title": "Are Female Carpenters like Blue Bananas? A Corpus Investigation of Occupation Gender Typicality",
                "image-path": ""
            },

            {
                "startTime": "01:17",
                "arxivId": "2408.02919",
                "arxivLink": "https://arxiv.org/abs/2408.02919",
                "title": "Data Checklists: Unit-Testing Datasets for a More Robust AI",
                "institute": "Stanford University, Georgetown University",
                "text": "This research proposes a new approach to evaluating datasets by introducing a taxonomy of unit tests based on the concept of usable information. This differs from previous work that primarily focused on evaluating models themselves.",
                "paper-title": "Data Checklist: On Unit-Testing Datasets with Usable Information",
                "image-path": ""
            },

            {
                "startTime": "01:52",
                "arxivId": "2408.03314",
                "arxivLink": "https://arxiv.org/abs/2408.03314",
                "title": "LLMs: Think Harder, Not Bigger!",
                "institute": "UC Berkeley",
                "text": "This research explores the scaling of inference-time computation in LLMs, focusing on how much performance can be improved with a fixed amount of compute at inference time. Unlike previous work that primarily focused on best-of-N sampling, this study investigates the effectiveness of scaling test-time compute through two mechanisms: refining the proposal distribution and optimizing verifiers.",
                "paper-title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters",
                "image-path": ""
            },

            {
                "startTime": "02:17",
                "arxivId": "2408.03284",
                "arxivLink": "https://arxiv.org/abs/2408.03284",
                "title": "ReSyncer: Lip-Syncing with a 3D Twist!",
                "institute": "Tsinghua University, Baidu",
                "text": "This paper introduces ReSyncer, a framework that uses 3D facial meshes as intermediate representations to improve lip-syncing quality. Unlike previous methods that rely on audio features alone, ReSyncer leverages the spatial information provided by the meshes to guide the generation process.",
                "paper-title": "ReSyncer: Rewiring Style-based Generator for Unified Audio-Visually Synced Facial Performer",
                "image-path": ""
            },

            {
                "startTime": "02:37",
                "arxivId": "2408.02899",
                "arxivLink": "https://arxiv.org/abs/2408.02899",
                "title": "Stock Embeddings: Text and Network Data, a Match Made in Finance Heaven!",
                "institute": "The University of Tokyo",
                "text": "This research proposes a novel stock embedding method called SETN, which jointly trains a transformer-based model for textual information and a graph neural network model for network information. This approach differs from previous work that typically focuses on either textual or network data alone.",
                "paper-title": "SETN: Stock Embedding Enhanced with Textual and Network Information",
                "image-path": ""
            },

            {
                "startTime": "03:03",
                "arxivId": "2408.02752",
                "arxivLink": "https://arxiv.org/abs/2408.02752",
                "title": "AI's New Party Trick: Mining Visual Data with Diffusion Models",
                "institute": "LIGM, \u00c9cole des Ponts ParisTech, CNRS...",
                "text": "This research proposes using generative diffusion models, typically used for image synthesis, as tools for visual data mining. Unlike traditional methods that rely on pairwise comparisons, this approach leverages the model's learned representation of the training data to identify typical visual elements.",
                "paper-title": "Diffusion Models as Data Mining Tools",
                "image-path": ""
            },

            {
                "startTime": "03:34",
                "arxivId": "2408.02983",
                "arxivLink": "https://arxiv.org/abs/2408.02983",
                "title": "Forgetful AI? Not anymore! Diffusion Models Save the Day for Class-Incremental Learning.",
                "institute": "Tsinghua University",
                "text": "This paper proposes a novel approach called Diffusion-based Feature Replay (DiffFR) for non-exemplar class-incremental learning (NECIL). Unlike previous methods that rely on simple rules to generate features for replay, DiffFR utilizes diffusion models to generate class-representative features that are highly similar to real features.",
                "paper-title": "Diffusion Model Meets Non-Exemplar Class-Incremental Learning and Beyond",
                "image-path": ""
            },

            {
                "startTime": "04:01",
                "arxivId": "2408.02687",
                "arxivLink": "https://arxiv.org/abs/2408.02687",
                "title": "AI Learns Physics by Watching YouTube: New Dataset and Model Unravel Hidden Properties",
                "institute": "Harvard University, University of Illinois, UC Berkeley...",
                "text": "This research introduces a new dataset, ComPhy, that focuses on inferring hidden physical properties like mass and charge from object interactions in videos. Unlike previous benchmarks, ComPhy requires models to learn these properties from a limited number of video examples and then use this knowledge to predict future dynamics.",
                "paper-title": "Compositional Physical Reasoning of Objects and Events from Videos",
                "image-path": ""
            },

            {
                "startTime": "04:27",
                "arxivId": "2408.02930",
                "arxivLink": "https://arxiv.org/abs/2408.02930",
                "title": "Big World, Small Agent: A New Simulator for Continual Learning",
                "institute": "Stanford University, University of Alberta",
                "text": "This paper proposes a new type of simulator for continual learning, focusing on the \"small agent, big world\" framework. Unlike existing benchmarks, it emphasizes the need for environments where increasing an agent's capacity consistently leads to significant performance improvements, and where an optimal agent never stops learning.",
                "paper-title": "The Need for a Big World Simulator: A Scientific Challenge for Continual Learning",
                "image-path": ""
            },

            {
                "startTime": "04:44",
                "arxivId": "2408.02900",
                "arxivLink": "https://arxiv.org/abs/2408.02900",
                "title": "MedTrinity-25M: A Medical Dataset So Big, It's Got a Multimodal Personality!",
                "institute": "Huazhong University of Science and Technology, UC Santa Cruz, Harvard University...",
                "text": "This research introduces MedTrinity-25M, a dataset that differs from previous work by generating multigranular annotations for unpaired medical images. Unlike existing methods that rely on image-text pairs, this approach leverages expert grounding models, retrieval-augmented generation techniques, and advanced multi-modal large language models (MLLMs) to create a comprehensive dataset.",
                "paper-title": "MedTrinity-25M: A Large-scale Multimodal Dataset with Multigranular Annotations for Medicine",
                "image-path": ""
            },

            {
                "startTime": "05:16",
                "arxivId": "2408.02932",
                "arxivLink": "https://arxiv.org/abs/2408.02932",
                "title": "Clustering with a Doubly Stochastic Twist: Marcus Mapping Makes it Happen!",
                "institute": "Northwestern Polytechnical University, Tsinghua University",
                "text": "This research extends the Marcus theorem by proposing the Marcus mapping, which allows for the transformation of certain sparse matrices into doubly stochastic matrices. This is different from previous work that focused on transforming positive matrices.",
                "paper-title": "Doubly Stochastic Adaptive Neighbors Clustering via the Marcus Mapping",
                "image-path": ""
            },

            {
                "startTime": "05:39",
                "arxivId": "2408.02936",
                "arxivLink": "https://arxiv.org/abs/2408.02936",
                "title": "Ensemble Learning Gets a Confidence Boost: Tensor Optimization for Smarter Decisions",
                "institute": "Northwestern Polytechnical University, Tsinghua University",
                "text": "This research introduces a learnable confidence tensor to enhance ensemble learning. Unlike previous methods that rely on equal weighting or fixed confidence values, this approach dynamically adjusts the confidence of each base learner based on its performance across different classes.",
                "paper-title": "Achieving More with Less: A Tensor-Optimization-Powered Ensemble Method",
                "image-path": ""
            },

            {
                "startTime": "06:05",
                "arxivId": "2408.03274",
                "arxivLink": "https://arxiv.org/abs/2408.03274",
                "title": "Model Compression: A Visual Guide to Untangling the Mess",
                "institute": "MIT, CMU, Apple Inc.",
                "text": "This research introduces COMPRESS AND COMPARE, an interactive visualization system that helps ML practitioners analyze and compare the performance and behavior of compressed models. Unlike previous work that focuses on specific compression techniques or profiling efficiency metrics, COMPRESS AND COMPARE supports more general, iterative compression workflows that may involve dozens of models with different sets of techniques applied.",
                "paper-title": "Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments",
                "image-path": ""
            },

            {
                "startTime": "06:32",
                "arxivId": "2408.03094",
                "arxivLink": "https://arxiv.org/abs/2408.03094",
                "title": "500xCompressor: Squishing Prompts Without Losing Your Mind!",
                "institute": "University of Cambridge",
                "text": "This research proposes 500xCompressor, a method that compresses natural language prompts into a single special token, achieving compression ratios up to 480x. Unlike previous methods, 500xCompressor utilizes the K V values of the compressed tokens instead of their embeddings, leading to better information preservation and performance.",
                "paper-title": "500xCompressor: Generalized Prompt Compression for Large Language Models",
                "image-path": ""
            },

            {
                "startTime": "06:54",
                "arxivId": "2408.02859",
                "arxivLink": "https://arxiv.org/abs/2408.02859",
                "title": "Slideshow of Stains: New AI Learns from Multiple Colors to See Pathology Better",
                "institute": "Harvard University",
                "text": "This research introduces a new approach to slide representation learning in computational pathology by leveraging multiple stains, such as immunohistochemistry, as different \"views\" of the same tissue. This differs from previous methods that primarily rely on single-stain images or limited augmentations.",
                "paper-title": "Multistain Pretraining for Slide Representation Learning in Pathology",
                "image-path": ""
            },

            {
                "startTime": "07:23",
                "arxivId": "2408.03325",
                "arxivLink": "https://arxiv.org/abs/2408.03325",
                "title": "CoverBench: Testing AI's Reasoning Skills with a Truth-or-Dare Challenge!",
                "institute": "Google",
                "text": "This research introduces CoverBench, a new benchmark specifically designed to evaluate the ability of language models to verify complex claims. Unlike previous benchmarks that focus on specific tasks like question answering, CoverBench aims to assess general reasoning abilities across diverse domains and sources of complexity.",
                "paper-title": "CoverBench: A Challenging Benchmark for Complex Claim Verification",
                "image-path": ""
            },

            {
                "startTime": "07:47",
                "arxivId": "2408.02862",
                "arxivLink": "https://arxiv.org/abs/2408.02862",
                "title": "Moral Compass Wobbles: AI Ethics Needs a Stability Check",
                "institute": "Activision, Duke University, Carnegie Mellon University...",
                "text": "This research investigates the stability of moral preferences in the context of AI ethics, specifically focusing on kidney allocation scenarios. Unlike previous studies that primarily examined action-vs-inaction choices, this paper explores action-vs-action scenarios, which are more common in AI-related preference elicitation frameworks.",
                "paper-title": "On The Stability of Moral Preferences: A Problem with Computational Elicitation Methods",
                "image-path": ""
            },

            {
                "startTime": "08:27",
                "arxivId": "2408.03297",
                "arxivLink": "https://arxiv.org/abs/2408.03297",
                "title": "LLMs Gone Wild: How to Tame Knowledge-Hungry Language Models",
                "institute": "Peking University, Ministry of Education, NanhuLaboratory",
                "text": "This research proposes a novel Knowledge-aware Preference Optimization (KaPO) method to address knowledge conflicts in Retrieval-Augmented Language Models (RAG). Unlike previous approaches that rely on instruction tuning, KaPO introduces negative signals and optimizes knowledge selection through preference learning, simulating real-world RAG scenarios and addressing preference imbalances.",
                "paper-title": "KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models",
                "image-path": ""
            },

            {
                "startTime": "08:47",
                "arxivId": "2408.02679",
                "arxivLink": "https://arxiv.org/abs/2408.02679",
                "title": "Visualizing the Web of Causes: A New Tool for Multi-Disease Analysis",
                "institute": "Peking University, University of Stuttgart",
                "text": "This research introduces a visual analysis method for comparing causal graphs of multiple outcomes, a feature not found in previous work. It uses a combination of state-of-the-art causal discovery algorithms and a novel graph layout technique to facilitate comparisons.",
                "paper-title": "Visual Analysis of Multi-outcome Causal Graphs",
                "image-path": ""
            },

            {
                "startTime": "09:23",
                "arxivId": "2408.02879",
                "arxivLink": "https://arxiv.org/abs/2408.02879",
                "title": "Humanoid Agent Learns to Talk, Move, and Even Manipulate Objects!",
                "institute": "Peking University",
                "text": "This research proposes a unified end-to-end framework for creating interactive virtual humanoid agents, unlike previous systems that typically only consider a subset of elements.",
                "paper-title": "Body of Her: A Preliminary Study on End-to-End Humanoid Agent",
                "image-path": ""
            },

            {
                "startTime": "09:46",
                "arxivId": "2408.03208",
                "arxivLink": "https://arxiv.org/abs/2408.03208",
                "title": "Surgical Robots Get a Personal Touch: AI Learns to Segment Instruments Like a Pro!",
                "institute": "University College London, Xiamen University, University of Hong Kong...",
                "text": "This research introduces a personalized federated learning (PFL) method for surgical instrument segmentation (SIS) that leverages visual trait priors, specifically instrument shape similarity and surgical appearance discrepancy. Unlike previous PFL methods, this approach personalizes multi-headed self-attention and incorporates hypernetworks for site-specific parameter updates.",
                "paper-title": "Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery",
                "image-path": ""
            },

            {
                "startTime": "10:17",
                "arxivId": "2408.02797",
                "arxivLink": "https://arxiv.org/abs/2408.02797",
                "title": "Water Leaks? Let's Get Algorithmic!",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research proposes an algorithm-informed graph neural network (AIGNN) for leakage detection and localization in water distribution networks. Unlike previous data-driven methods that often learn shortcuts and struggle with generalization, AIGNN incorporates the knowledge of the Ford-Fulkerson algorithm for solving max-flow problems, enhancing its ability to generalize to out-of-distribution data.",
                "paper-title": "Algorithm-Informed Graph Neural Networks for Leakage Detection and Localization in Water Distribution Networks",
                "image-path": ""
            },

            {
                "startTime": "10:45",
                "arxivId": "2408.03322",
                "arxivLink": "https://arxiv.org/abs/2408.03322",
                "title": "SAM2: Segmenting Medical Images and Videos, One Prompt at a Time!",
                "institute": "University Health Network, Vector Institute for Artificial Intelligence, University of Toronto",
                "text": "This research extends the Segment Anything Model (SAM) to medical images and videos, including 3D data. It benchmarks SAM2 across 11 medical image modalities and compares its performance to previous models like SAM1 and MedSAM. The paper also develops a transfer learning pipeline to adapt SAM2 to the medical domain and implements it as a 3DSlicer plugin and Gradio API for user-friendly deployment.",
                "paper-title": "Segment Anything in Medical Images and Videos: Benchmark and Deployment",
                "image-path": ""
            },

            {
                "startTime": "11:13",
                "arxivId": "2408.02897",
                "arxivLink": "https://arxiv.org/abs/2408.02897",
                "title": "Training Transformers with 8-Bit Math: A Metric-Driven Approach to Mixed Precision",
                "institute": "Google",
                "text": "This research introduces a metric-driven methodology for choosing the optimal low-precision numeric formats during the training of transformer models. Unlike previous work that focused on inference, this paper explores the use of 8-bit formats for training, specifically focusing on the impact of different quantization techniques on model quality.",
                "paper-title": "A Metric Driven Approach to Mixed Precision Training",
                "image-path": ""
            },

            {
                "startTime": "11:32",
                "arxivId": "2408.02882",
                "arxivLink": "https://arxiv.org/abs/2408.02882",
                "title": "LLMs: The New Backdoor for Robots?",
                "institute": "Beihang University, National University of Singapore, Zhongguancun Laboratory...",
                "text": "This research introduces a novel attack method called Contextual Backdoor Attack, which targets the contextual environment of LLMs used to generate code for embodied agents. Unlike previous backdoor attacks that focus on poisoning training data, this attack injects malicious code through a few poisoned demonstrations, making it more stealthy and efficient.",
                "paper-title": "Compromising Embodied Agents with Contextual Backdoor Attacks",
                "image-path": ""
            },

            {
                "startTime": "12:08",
                "arxivId": "2408.02796",
                "arxivLink": "https://arxiv.org/abs/2408.02796",
                "title": "Stereo Vision Gets a Dose of Uncertainty: Gaussian Mixture Models to the Rescue!",
                "institute": "A*STAR, Harvard University",
                "text": "This research introduces a novel approach to stereo matching by employing a Gaussian mixture model for evidential learning. Unlike previous methods that rely on a single Gaussian distribution, this framework assumes that individual image data adheres to a mixture of Gaussian distributions, leading to more precise pixel-level predictions and a more accurate representation of real-world image distributions.",
                "paper-title": "Gaussian Mixture based Evidential Learning for Stereo Matching",
                "image-path": ""
            },

            {
                "startTime": "12:39",
                "arxivId": "2408.02950",
                "arxivLink": "https://arxiv.org/abs/2408.02950",
                "title": "Fluid Flow on Weird Shapes: Deep Learning Gets a New Trick",
                "institute": "Stanford University",
                "text": "This research introduces a new deep learning framework called Kolmogorov-Arnold PointNet (KA-PointNet) that uses shared Kolmogorov-Arnold Networks (KANs) to predict fluid flow fields in irregular domains. This approach differs from previous work by replacing traditional Multilayer Perceptrons (MLPs) with KANs within the PointNet architecture.",
                "paper-title": "Kolmogorov-Arnold PointNet: Deep learning for prediction of fluid fields on irregular geometries",
                "image-path": ""
            },

            {
                "startTime": "13:11",
                "arxivId": "2408.03160",
                "arxivLink": "https://arxiv.org/abs/2408.03160",
                "title": "AI Cooking Assistants: Can They Handle a Real Kitchen?",
                "institute": "CMU, Columbia University, Meta",
                "text": "This research evaluates multimodal LLMs for activity assistance in a real-world setting, unlike previous work that focused solely on offline benchmarks. The study compares two approaches, Socratic Models and Vision-Conditioned Language Models (VCLMs), in an online user-in-the-loop evaluation.",
                "paper-title": "User-in-the-loop Evaluation of Multimodal LLMs for Activity Assistance",
                "image-path": ""
            },

            {
                "startTime": "13:38",
                "arxivId": "2408.02865",
                "arxivLink": "https://arxiv.org/abs/2408.02865",
                "title": "Ophthalmologist in a Box: AI Diagnoses Eye Diseases Like a Pro!",
                "institute": "Shanghai Artificial Intelligence Laboratory, University of Washington, Zhongshan Ophthalmic Center...",
                "text": "This research introduces VisionUnite, a vision-language foundation model specifically designed for ophthalmology. Unlike previous models, VisionUnite incorporates clinical knowledge and can predict multiple diseases simultaneously, engage in multi-round dialogues with users, and provide interpretable diagnostic results.",
                "paper-title": "VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge",
                "image-path": ""
            },

            {
                "startTime": "14:06",
                "arxivId": "2408.02922",
                "arxivLink": "https://arxiv.org/abs/2408.02922",
                "title": "Pose Magic: 3D Human Pose Estimation Gets a Speed Boost!",
                "institute": "Tsinghua University",
                "text": "This research proposes a new architecture called \"Pose Magic\" for 3D human pose estimation. Unlike previous Transformer-based methods, Pose Magic combines Mamba, a state space model, with Graph Convolutional Networks (GCNs) to achieve both high accuracy and computational efficiency.",
                "paper-title": "Pose Magic: Efficient and Temporally Consistent Human Pose Estimation with a Hybrid Mamba-GCN Network",
                "image-path": ""
            },

            {
                "startTime": "14:32",
                "arxivId": "2408.03093",
                "arxivLink": "https://arxiv.org/abs/2408.03093",
                "title": "Learning Policies That Can Handle Uncertainty: A New Approach to Robust AI",
                "institute": "University of Oxford",
                "text": "This research focuses on learning policies for Markov Decision Processes (MDPs) where the transition probabilities are defined by parameters with an unknown distribution. It differs from previous work by providing a probably approximately correct (PAC) guarantee for the performance of learned policies in unseen environments.",
                "paper-title": "Learning Provably Robust Policies in Uncertain Parametric Environments",
                "image-path": ""
            },

            {
                "startTime": "14:59",
                "arxivId": "2408.03292",
                "arxivLink": "https://arxiv.org/abs/2408.03292",
                "title": "AI Predicts Chip Hotspots, Then Explains Why They're Hot!",
                "institute": "University of Wisconsin-Madison",
                "text": "This research introduces a new neural network model called AttUNet, which uses attention gates to focus on relevant parts of the input data for more accurate static IR drop prediction. Unlike previous work, AttUNet also includes a method for generating saliency maps, which explain the contribution of each input pixel to the predicted IR drop.",
                "paper-title": "Static IR Drop Prediction with Attention U-Net and Saliency-Based Explainability",
                "image-path": ""
            },

            {
                "startTime": "15:29",
                "arxivId": "2408.02949",
                "arxivLink": "https://arxiv.org/abs/2408.02949",
                "title": "Robot Learns to Scoop on Alien Worlds in a Few Tries!",
                "institute": "Yale University",
                "text": "This research introduces a new meta-training method called Deep Kernel Calibration with Maximal Deployment Gaps (kCMD) that explicitly trains deep kernel models to adapt to large domain shifts. This method differs from previous work by creating simulated maximal deployment gaps during training, forcing the model to learn to overcome these gaps.",
                "paper-title": "Few-shot Scooping Under Domain Shift via Simulated Maximal Deployment Gaps",
                "image-path": ""
            },

            {
                "startTime": "15:58",
                "arxivId": "2408.02971",
                "arxivLink": "https://arxiv.org/abs/2408.02971",
                "title": "Wave Interpolation Neural Operator: Predicting Light's Dance Across Untrained Wavelengths",
                "institute": "Hanyang University, Yale University",
                "text": "This research introduces a new neural operator called Wave Interpolation Neural Operator (WINO) that can predict electric fields across a continuous spectrum of wavelengths, even for wavelengths it wasn't trained on. This is different from previous models that were limited to fixed simulation conditions and required retraining for different wavelengths.",
                "paper-title": "Wave Interpolation Neural Operator: Interpolated Prediction of Electric Fields Across Untrained Wavelengths",
                "image-path": ""
            },

            {
                "startTime": "16:26",
                "arxivId": "2408.02861",
                "arxivLink": "https://arxiv.org/abs/2408.02861",
                "title": "LLMs Get a Multi-Dataset Makeover: Fine-Tuning with Heterogeneous Feedback!",
                "institute": "Carnegie Mellon University, Adobe Research",
                "text": "This research proposes a framework for fine-tuning LLMs using datasets with different types of feedback, unlike previous methods that rely on a single type of supervision.",
                "paper-title": "A Framework for Fine-Tuning LLMs using Heterogeneous Feedback",
                "image-path": ""
            },

            {
                "startTime": "16:51",
                "arxivId": "2408.02849",
                "arxivLink": "https://arxiv.org/abs/2408.02849",
                "title": "Active Learning for WBANs: Predicting Your Health, One Step at a Time!",
                "institute": "IBM, Chungnam National University, Pennsylvania State University",
                "text": "This research proposes a novel active learning method for health monitoring in wireless body area networks (WBANs) that addresses the challenges of limited resources at body sensors and the need for human intervention in labeling data. Unlike previous work, this method leverages noisy predictions of unlabeled samples to select a subset of data for labeling, reducing the overall data collection and labeling cost.",
                "paper-title": "Active Learning for WBAN-based Health Monitoring",
                "image-path": ""
            },

            {
                "startTime": "17:18",
                "arxivId": "2408.03070",
                "arxivLink": "https://arxiv.org/abs/2408.03070",
                "title": "Can AI Really Understand \"Not\"? A Deep Dive into Negation in Language Models",
                "institute": "University of Paris, \u00c9cole Normale Sup\u00e9rieure",
                "text": "This research focuses on how language models encode the structural impact of negation, specifically the \"negation scope\" and its influence on the licensing of negative polarity items (NPIs). Unlike previous work that focused on truth value or the presence of negation, this study investigates the model's ability to capture the syntactic constraints imposed by negation.",
                "paper-title": "Probing structural constraints of negation in Pretrained Language Models",
                "image-path": ""
            },

            {
                "startTime": "17:44",
                "arxivId": "2408.02830",
                "arxivLink": "https://arxiv.org/abs/2408.02830",
                "title": "A/B Testing: How Long is Too Long? (And How to Tell!)",
                "institute": "Google",
                "text": "This paper introduces a new formula to calculate the confidence interval (CI) width for A/B tests, taking into account the duration of the experiment and the persistence of users over time. This is different from previous work that focused primarily on sample size.",
                "paper-title": "Setting the duration of online A/B experiments",
                "image-path": ""
            },

            {
                "startTime": "18:19",
                "arxivId": "2408.02946",
                "arxivLink": "https://arxiv.org/abs/2408.02946",
                "title": "Big Brains, Big Problems: How LLMs Get Poisoned by Scale",
                "institute": "FAR AI, University of California Berkeley, University of Cambridge...",
                "text": "This research investigates the relationship between the size of large language models (LLMs) and their susceptibility to data poisoning. Unlike previous work that focused on specific types of data poisoning or limited model sizes, this study examines three distinct threat models across 23 LLMs ranging from 1.5 to 72 billion parameters.",
                "paper-title": "Scaling Laws for Data Poisoning in LLMs",
                "image-path": ""
            },

            {
                "startTime": "18:45",
                "arxivId": "2408.02676",
                "arxivLink": "https://arxiv.org/abs/2408.02676",
                "title": "Retinal Images: A UK Biobank Study Reveals Bias in AI's Eye",
                "institute": "University of Oxford",
                "text": "This study investigates bias in a retinal image classification model trained on the UK Biobank dataset, focusing on disparities across various population groups, including assessment centers, age, and sex. It goes beyond simply identifying bias and explores the effectiveness of various mitigation methods, finding that they are largely ineffective in improving fairness.",
                "paper-title": "On Biases in a UK Biobank-based Retinal Image Classification Model",
                "image-path": ""
            },

            {
                "startTime": "19:10",
                "arxivId": "2408.03223",
                "arxivLink": "https://arxiv.org/abs/2408.03223",
                "title": "CNNs on a Diet: Streamlining Deep Learning for Real-Time Data",
                "institute": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
                "text": "This research proposes a new method called StreamiNNC to optimize the inference of convolutional neural networks (CNNs) for real-time data processing. Unlike previous work that focuses on reducing computations within a single window, StreamiNNC leverages the shift-invariance property of convolutions to skip redundant calculations between overlapping windows.",
                "paper-title": "Don't Think It Twice: Exploit Shift Invariance for Efficient Online Streaming Inference of CNNs",
                "image-path": ""
            },

            {
                "startTime": "19:35",
                "arxivId": "2408.02683",
                "arxivLink": "https://arxiv.org/abs/2408.02683",
                "title": "Heart Rate Variability: The Secret Weapon Against Sepsis?",
                "institute": "Stanford University, UC Berkeley",
                "text": "This research focuses solely on heart rate variability (HRV) features to predict sepsis, unlike previous studies that used a wider range of data.",
                "paper-title": "Improving Machine Learning Based Sepsis Diagnosis Using Heart Rate Variability",
                "image-path": ""
            },

            {
                "startTime": "19:57",
                "arxivId": "2408.02871",
                "arxivLink": "https://arxiv.org/abs/2408.02871",
                "title": "LLMs Play Hide and Seek: Fingerprinting Language Models with Evolutionary Learning",
                "institute": "University of Texas at Austin",
                "text": "This research introduces a novel black-box approach for fingerprinting LLMs using an evolutionary strategy. It leverages the capabilities of one LLM to discover the most salient features for identifying other LLMs, unlike previous methods that rely on token counting or contextual cues.",
                "paper-title": "Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning",
                "image-path": ""
            },

            {
                "startTime": "20:22",
                "arxivId": "2408.02784",
                "arxivLink": "https://arxiv.org/abs/2408.02784",
                "title": "LLMs: More Human Than Economicus?",
                "institute": "MIT",
                "text": "This research uses utility theory to quantify and compare the economic biases of LLMs, a novel approach that allows for a more systematic and rigorous evaluation of their decision-making.",
                "paper-title": "LLM economicus? Mapping the Behavioral Biases of LLMs via Utility Theory",
                "image-path": ""
            }
    ],
    "stats": {
        "num_pick": 44,
        "num_total": 211,
    },
    "audio": "https://d2irtorupa9e8g.cloudfront.net/daily_podcast/202408070752_audio.mp3"
}